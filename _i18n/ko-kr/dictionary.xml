<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">업계 동향, 혁신, 실제 영향에 대한 내용을 다루는 AI/ML 블로그를 읽어보세요. 또한 개발자 리소스, 커뮤니티 통찰력, NetApp AI 솔루션을 사용하는 데 필요한 실용적인 도구도 제공합니다.</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">NetApp 전문가의 AI 솔루션 블로그를 읽어보세요</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">업계 동향, 혁신, 실제 영향에 대한 내용을 다루는 AI/ML 블로그를 읽어보세요. 또한 개발자 리소스, 커뮤니티 통찰력, NetApp AI 솔루션을 사용하는 데 필요한 실용적인 도구도 제공합니다.</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">AI 동향 및 산업 통찰력</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">영어</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">다양한 분야에서 산업 동향, 혁신, 그리고 AI가 실제로 미치는 영향을 살펴보세요. <block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[AI, 분석, 인공지능]++[ NetApp 에서 AI 블로그 읽기^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">개발자 리소스 및 커뮤니티</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">Pub에서 AI 블로그를 읽어보세요</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">AI/ML 실무자를 위한 기술적 통찰력, 실용적인 도구 및 커뮤니티 중심 콘텐츠를 제공합니다.<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">이 문서에서는 AWS 서비스를 사용하여 MLOps 파이프라인을 구축하는 방법에 대한 가이드를 제공하며, 자동화된 모델 재교육, 배포 및 비용 최적화에 중점을 둡니다.</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">3부 - 단순화된 MLOps 파이프라인(CI/CT/CD) 구축</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">이 문서에서는 AWS 서비스를 사용하여 MLOps 파이프라인을 구축하는 방법에 대한 가이드를 제공하며, 자동화된 모델 재교육, 배포 및 비용 최적화에 중점을 둡니다.</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">소개</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">이 튜토리얼에서는 다양한 AWS 서비스를 활용하여 CI(지속적 통합), CT(지속적 학습), CD(지속적 배포)를 포함하는 간단한 MLOps 파이프라인을 구성하는 방법을 알아봅니다.  기존 DevOps 파이프라인과 달리 MLOps는 운영 주기를 완료하기 위해 추가적인 고려 사항이 필요합니다.  이 튜토리얼을 따라하면 CT를 MLOps 루프에 통합하여 모델의 지속적인 학습과 추론을 위한 원활한 배포에 대한 통찰력을 얻을 수 있습니다.  이 튜토리얼에서는 AWS 서비스를 활용하여 엔드투엔드 MLOps 파이프라인을 구축하는 과정을 안내합니다.</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">명백한</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">기능성</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">이름</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">논평</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">데이터 저장</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">1부 - Amazon FSx for NetApp ONTAP (FSx ONTAP)을 AWS SageMaker에 개인 S3 버킷으로 통합</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">데이터 과학 IDE</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS 세이지메이커</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">2부 - SageMaker에서 모델 학습을 위한 데이터 소스로 Amazon FSx for NetApp ONTAP (FSx ONTAP) 활용</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">이 튜토리얼은 Jupyter notebook을 기반으로 합니다.<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">MLOps 파이프라인을 트리거하는 기능</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">AWS 람다 함수</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Cron 작업 트리거</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS 이벤트브리지</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">딥러닝 프레임워크</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">파이토치</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">AWS 파이썬 SDK</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">boto3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">프로그래밍 언어</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">파이썬</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">v3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">필수 조건</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">사전 구성된 FSx ONTAP 파일 시스템.  이 튜토리얼에서는 FSx ONTAP 에 저장된 데이터를 활용하여 학습 과정을 진행합니다.</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">위에 언급된 FSx ONTAP 파일 시스템과 동일한 VPC를 공유하도록 구성된 *SageMaker Notebook 인스턴스*.</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">*AWS Lambda 함수*를 트리거하기 전에 *SageMaker Notebook 인스턴스*가 *중지* 상태인지 확인하세요.</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">*ml.g4dn.xlarge* 인스턴스 유형은 딥 신경망의 계산에 필요한 GPU 가속을 활용하는 데 필요합니다.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">아키텍처</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">이 MLOps 파이프라인은 Cron 작업을 활용하여 서버리스 함수를 트리거하고, 이를 통해 라이프사이클 콜백 함수에 등록된 AWS 서비스를 실행하는 실용적인 구현입니다.  *AWS EventBridge*는 cron 작업 역할을 합니다.  주기적으로 모델을 재교육하고 재배포하는 AWS Lambda 함수를 호출합니다.  이 프로세스에는 필요한 작업을 수행하기 위해 *AWS SageMaker Notebook* 인스턴스를 시작하는 작업이 포함됩니다.</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">단계별 구성</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">수명 주기 구성</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">AWS SageMaker Notebook 인스턴스에 대한 수명 주기 콜백 함수를 구성하려면 *수명 주기 구성*을 활용합니다.  이 서비스를 사용하면 노트북 인스턴스를 시작할 때 수행해야 하는 필요한 작업을 정의할 수 있습니다.  구체적으로, 훈련 및 배포 프로세스가 완료되면 노트북 인스턴스를 자동으로 종료하기 위해 *라이프사이클 구성* 내에 셸 스크립트를 구현할 수 있습니다.  MLOps에서 비용은 주요 고려 사항 중 하나이므로 이는 필수 구성입니다.</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">*라이프사이클 구성*에 대한 구성은 미리 설정해야 한다는 점에 유의하세요.  따라서 다른 MLOps 파이프라인 설정을 진행하기 전에 이 측면의 구성을 우선시하는 것이 좋습니다.</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">라이프사이클 구성을 설정하려면 *Sagemaker* 패널을 열고 *관리자 구성* 섹션 아래의 *라이프사이클 구성*으로 이동합니다.</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">SageMaker 패널</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">*노트북 인스턴스* 탭을 선택하고 *구성 생성* 버튼을 클릭합니다.</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">라이프사이클 구성 시작 페이지</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">아래 코드를 입력란에 붙여넣으세요.</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">이 스크립트는 추론을 위해 모델을 재교육하고 재배포하는 Jupyter Notebook을 실행합니다.  실행이 완료되면 5분 이내에 노트북이 자동으로 종료됩니다.  문제 설명과 코드 구현에 대해 자세히 알아보려면 다음을 참조하세요.<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> .</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">라이프사이클 구성 생성</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">생성 후 Notebook 인스턴스로 이동하여 대상 인스턴스를 선택하고 작업 드롭다운에서 *설정 업데이트*를 클릭합니다.</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">업데이트 설정 드롭다운</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">생성된 *라이프사이클 구성*을 선택하고 *노트북 인스턴스 업데이트*를 클릭합니다.</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">노트북의 수명 주기 구성 업데이트</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">AWS Lambda 서버리스 함수</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">앞서 언급했듯이 *AWS Lambda 함수*는 *AWS SageMaker Notebook 인스턴스*를 시작하는 역할을 합니다.</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">*AWS Lambda 함수*를 만들려면 해당 패널로 이동하여 *함수* 탭으로 전환하고 *함수 만들기*를 클릭합니다.</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">AWS 람다 함수 시작 페이지</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">모든 필수 항목을 페이지에 입력하시고 런타임을 *Python 3.10*으로 전환하는 것을 잊지 마세요.</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">AWS 람다 함수 생성</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">지정된 역할에 필요한 권한인 *AmazonSageMakerFullAccess*가 있는지 확인하고 *함수 생성* 버튼을 클릭하세요.</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">실행 역할 선택</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">생성된 Lambda 함수를 선택합니다.  코드 탭에서 다음 코드를 복사하여 텍스트 영역에 붙여넣습니다.  이 코드는 *fsxn-ontap*이라는 노트북 인스턴스를 시작합니다.</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">이 코드 변경 사항을 적용하려면 *배포* 버튼을 클릭하세요.</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">전개</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">이 AWS Lambda 함수를 트리거하는 방법을 지정하려면 트리거 추가 버튼을 클릭합니다.</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">AWS 함수 트리거 추가</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">드롭다운 메뉴에서 EventBridge를 선택한 다음, 새 규칙 만들기라는 라벨이 있는 라디오 버튼을 클릭합니다.  일정 표현 필드에 다음을 입력하세요.<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block> , 추가 버튼을 클릭하여 이 새로운 Cron 작업 규칙을 생성하고 AWS Lambda 함수에 적용합니다.</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">트리거 마무리</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">2단계 구성을 완료한 후에는 매일 *AWS Lambda 함수*가 *SageMaker Notebook*을 시작하고, *FSx ONTAP* 저장소의 데이터를 사용하여 모델 재교육을 수행하고, 업데이트된 모델을 프로덕션 환경으로 다시 배포하고, 비용을 최적화하기 위해 *SageMaker Notebook 인스턴스*를 자동으로 종료합니다.  이렇게 하면 모델이 최신 상태로 유지됩니다.</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">이것으로 MLOps 파이프라인을 개발하기 위한 튜토리얼이 끝났습니다.</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">이는 FSx ONTAP MLOps 섹션의 소개 페이지입니다.</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">MLOps용 Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">이 섹션에서는 AI 인프라 개발의 실제 적용을 깊이 있게 살펴보고 FSx ONTAP 사용하여 MLOps 파이프라인을 구성하는 방법에 대한 종단 간 연습을 제공합니다.  세 가지 포괄적인 예로 구성된 이 문서는 강력한 데이터 관리 플랫폼을 통해 MLOps 요구 사항을 충족하는 방법을 안내합니다.</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">이 기사에서는 다음 주제에 대해 다룹니다.</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">이 섹션을 마치면 FSx ONTAP 사용하여 MLOps 프로세스를 간소화하는 방법을 확실히 이해하게 될 것입니다.</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">이 게시물에서는 AWS SageMaker를 사용하여 FSx ONTAP 프라이빗 S3 버킷으로 구성하는 방법에 대한 가이드를 제공합니다.</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">이 섹션에서는 AWS SageMaker를 사용하여 FSx ONTAP 프라이빗 S3 버킷으로 구성하는 방법에 대한 가이드를 제공합니다.</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">이 페이지에서는 SageMaker를 예로 들어 FSx ONTAP 개인 S3 버킷으로 구성하는 방법에 대한 지침을 제공합니다.</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">비디오 링크</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">FSx ONTAP 에 대한 자세한 내용은 이 프레젠테이션을 참조하세요.<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> )</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">사용자 가이드</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">서버 생성</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">SageMaker Notebook 인스턴스 생성</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">AWS 콘솔을 엽니다.  검색 패널에서 SageMaker를 검색하고 *Amazon SageMaker* 서비스를 클릭합니다.</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">AWS 콘솔 열기</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">노트북 탭에서 *노트북 인스턴스*를 열고 주황색 버튼인 *노트북 인스턴스 만들기*를 클릭합니다.</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">AWS SageMaker Notebook 인스턴스 콘솔</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">생성 페이지에서 *노트북 인스턴스 이름*을 입력합니다. *네트워크* 패널을 확장합니다. 다른 항목은 기본값으로 두고 *VPC*, *서브넷*, *보안 그룹*을 선택합니다.  (이 *VPC*와 *서브넷*은 나중에 FSx ONTAP 파일 시스템을 만드는 데 사용됩니다.) 오른쪽 하단에 있는 주황색 버튼 *노트북 인스턴스 만들기*를 클릭합니다.</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">노트북 인스턴스 생성</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">FSx ONTAP 파일 시스템 생성</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">AWS 콘솔을 엽니다.  검색 패널에서 Fsx를 검색하고 서비스 *FSx*를 클릭합니다.</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">FSx 패널</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">*파일 시스템 만들기*를 클릭합니다.</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">파일 시스템 생성</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">첫 번째 카드인 *FSx ONTAP*을 선택하고 *다음*을 클릭합니다.</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">파일 시스템 유형을 선택하세요</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">세부 정보 구성 페이지에서.</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">*표준 생성* 옵션을 선택하세요.</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">파일 시스템 패널 생성</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">*파일 시스템 이름*과 *SSD 저장 용량*을 입력하세요.</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">파일 시스템 세부 정보 지정</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">*SageMaker Notebook* 인스턴스에 *VPC*와 *서브넷*을 동일하게 사용해야 합니다.</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">네트워크 및 보안 구성</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">SVM(스토리지 가상 머신)에 대한 *스토리지 가상 머신* 이름을 입력하고 *암호를 지정*합니다.</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">기본 스토리지 가상 머신 구성</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">다른 항목은 기본값으로 두고 오른쪽 하단에 있는 주황색 버튼 *다음*을 클릭하세요.</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">구성 확인</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">검토 페이지 오른쪽 하단에 있는 주황색 버튼 *파일 시스템 만들기*를 클릭하세요.</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">구성을 검토하고 생성을 확인하세요</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">FSx 파일 시스템을 시작하는 데 약 *20~40분*이 걸릴 수 있습니다.</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">FSx 콘솔을 검사하세요</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">서버 구성</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">ONTAP 구성</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">생성된 FSx 파일 시스템을 엽니다.  상태가 *사용 가능*인지 확인하세요.</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">백엔드 생성을 기다리세요</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">*관리* 탭을 선택하고 *관리 엔드포인트 - IP 주소*와 * ONTAP 관리자 사용자 이름*을 그대로 둡니다.</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">파일 시스템 세부 정보 콘솔</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">생성된 *SageMaker Notebook 인스턴스*를 열고 *JupyterLab 열기*를 클릭합니다.</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">AWS SageMaker Notebook 인스턴스 콘솔</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">Jupyter Lab 페이지에서 새 *터미널*을 엽니다.</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Jupyter Lab 환영 페이지</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">FSx ONTAP 파일 시스템에 로그인하려면 ssh 명령어 ssh &lt;관리자 사용자 이름&gt;@&lt; ONTAP 서버 IP&gt;를 입력하세요.  (사용자 이름과 IP 주소는 2단계에서 검색됩니다.) *스토리지 가상 머신*을 생성할 때 사용한 비밀번호를 사용하세요.</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Jupyter Lab 터미널</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">다음 순서대로 명령을 실행하세요.  우리는 *FSx ONTAP 개인 S3 버킷 이름*의 이름으로 *fsxn-ontap*을 사용합니다.  -vserver 인수에는 *스토리지 가상 머신 이름*을 사용하세요.</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Jupyter Lab 터미널 출력</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">아래 명령을 실행하여 FSx ONTAP private S3의 엔드포인트 IP와 자격 증명을 검색합니다.</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">나중에 사용할 수 있도록 엔드포인트 IP와 자격 증명을 보관하세요.</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">클라이언트 구성</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">SageMaker Notebook 인스턴스에서 새로운 Jupyter notebook을 만듭니다.</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">새로운 Jupyter 노트북을 엽니다</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">아래 코드를 해결 방법으로 사용하여 FSx ONTAP 개인 S3 버킷에 파일을 업로드하세요.  포괄적인 코드 예제는 이 노트북을 참조하세요.<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">이것으로 FSx ONTAP 과 SageMaker 인스턴스 간의 통합이 완료되었습니다.</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">유용한 디버깅 체크리스트</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">SageMaker Notebook 인스턴스와 FSx ONTAP 파일 시스템이 동일한 VPC에 있는지 확인하세요.</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">ONTAP 에서 *set dev* 명령을 실행하여 권한 수준을 *dev*로 설정하는 것을 잊지 마세요.</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">FAQ (2023년 9월 27일 기준)</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">질문: FSx ONTAP 에 파일을 업로드할 때 "*CreateMultipartUpload 작업을 호출하는 동안 오류가 발생했습니다(NotImplemented). 요청한 s3 명령이 구현되지 않았습니다*"라는 오류가 발생하는 이유는 무엇입니까?</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">답변: FSx ONTAP 개인 S3 버킷으로서 최대 100MB의 파일 업로드를 지원합니다.  S3 프로토콜을 사용할 경우, 100MB가 넘는 파일은 100MB 단위로 나누고, 'CreateMultipartUpload' 함수를 호출합니다.  하지만 현재 FSx ONTAP private S3 구현에서는 이 기능을 지원하지 않습니다.</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">질문: FSx ONTAP 에 파일을 업로드할 때 "*PutObject 작업을 호출하는 동안 오류가 발생했습니다(AccessDenied): 액세스가 거부되었습니다*"라는 오류가 발생하는 이유는 무엇입니까?</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">답변: SageMaker Notebook 인스턴스에서 FSx ONTAP 개인 S3 버킷에 액세스하려면 AWS 자격 증명을 FSx ONTAP 자격 증명으로 전환하세요.  그러나 인스턴스에 쓰기 권한을 부여하려면 버킷을 마운트하고 'chmod' 셸 명령을 실행하여 권한을 변경하는 임시 해결책이 필요합니다.</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">질문: FSx ONTAP 개인 S3 버킷을 다른 SageMaker ML 서비스와 통합하려면 어떻게 해야 하나요?</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">A: 안타깝게도 SageMaker 서비스 SDK는 개인 S3 버킷의 엔드포인트를 지정하는 방법을 제공하지 않습니다.  결과적으로 FSx ONTAP S3는 Sagemaker Data Wrangler, Sagemaker Clarify, Sagemaker Glue, Sagemaker Athena, Sagemaker AutoML 등의 SageMaker 서비스와 호환되지 않습니다.</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">이 문서는 SageMaker에서 PyTorch 모델을 학습하기 위해 Amazon FSx for NetApp ONTAP (FSx ONTAP)을 사용하는 방법에 대한 튜토리얼로, 특히 타이어 품질 분류 프로젝트에 관한 것입니다.</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">2부 - SageMaker에서 모델 학습을 위한 데이터 소스로 AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) 활용</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">이 문서는 SageMaker에서 PyTorch 모델을 학습하기 위해 Amazon FSx for NetApp ONTAP (FSx ONTAP)을 사용하는 방법에 대한 튜토리얼로, 특히 타이어 품질 분류 프로젝트에 대한 내용입니다.</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">이 튜토리얼에서는 컴퓨터 비전 분류 프로젝트의 실제 사례를 제시하고, SageMaker 환경 내에서 FSx ONTAP 데이터 소스로 활용하는 ML 모델을 구축하는 실무 경험을 제공합니다.  이 프로젝트는 딥러닝 프레임워크인 PyTorch를 사용하여 타이어 이미지를 기반으로 타이어 품질을 분류하는 데 중점을 두고 있습니다.  Amazon SageMaker에서 FSx ONTAP 데이터 소스로 사용하여 머신 러닝 모델을 개발하는 데 중점을 둡니다.</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">FSx ONTAP 무엇입니까?</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP AWS가 제공하는 완전 관리형 스토리지 솔루션입니다.  NetApp의 ONTAP 파일 시스템을 활용하여 안정적이고 고성능의 스토리지를 제공합니다.  NFS, SMB, iSCSI와 같은 프로토콜을 지원하므로 다양한 컴퓨팅 인스턴스와 컨테이너에서 원활하게 액세스할 수 있습니다.  이 서비스는 뛰어난 성능을 제공하고 빠르고 효율적인 데이터 작업을 보장하도록 설계되었습니다.  또한 높은 가용성과 내구성을 제공하여 데이터에 항상 접근하고 보호할 수 있습니다.  또한 Amazon FSx ONTAP 의 저장 용량은 확장 가능하므로 필요에 따라 쉽게 조정할 수 있습니다.</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">네트워크 환경</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">네트워크 환경</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP (Amazon FSx ONTAP)은 AWS 스토리지 서비스입니다.  여기에는 NetApp ONTAP 시스템에서 실행되는 파일 시스템과 이에 연결되는 AWS 관리 시스템 가상 머신(SVM)이 포함됩니다.  제공된 다이어그램에서 AWS가 관리하는 NetApp ONTAP 서버는 VPC 외부에 있습니다.  SVM은 SageMaker와 NetApp ONTAP 시스템 사이의 중개자 역할을 하며, SageMaker로부터 작업 요청을 수신하여 기본 스토리지로 전달합니다.  FSx ONTAP 에 액세스하려면 SageMaker가 FSx ONTAP 배포와 동일한 VPC 내에 있어야 합니다.  이 구성은 SageMaker와 FSx ONTAP 간의 통신과 데이터 액세스를 보장합니다.</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">데이터 액세스</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">실제 상황에서 데이터 과학자는 일반적으로 FSx ONTAP 에 저장된 기존 데이터를 활용하여 머신 러닝 모델을 구축합니다.  그러나 데모 목적으로, FSx ONTAP 파일 시스템은 생성된 후 처음에는 비어 있으므로 수동으로 교육 데이터를 업로드해야 합니다.  이는 FSx ONTAP SageMaker에 볼륨으로 마운트하여 달성할 수 있습니다.  파일 시스템이 성공적으로 마운트되면 마운트된 위치에 데이터 세트를 업로드하여 SageMaker 환경 내에서 모델을 학습할 수 있습니다.  이 접근 방식을 사용하면 SageMaker를 사용하여 모델을 개발하고 학습하는 동안 FSx ONTAP 의 저장 용량과 기능을 활용할 수 있습니다.</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">1부 - Amazon FSx for NetApp ONTAP (FSx ONTAP)을 AWS SageMaker에 개인 S3 버킷으로 통합</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">데이터 읽기 프로세스에는 FSx ONTAP 개인 S3 버킷으로 구성하는 작업이 포함됩니다.  자세한 구성 지침을 알아보려면 다음을 참조하세요.<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">통합 개요</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">교육 워크플로</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">FSx ONTAP 의 학습 데이터를 사용하여 SageMaker에서 딥러닝 모델을 구축하는 워크플로는 데이터 로더 정의, 모델 학습, 배포의 세 가지 주요 단계로 요약할 수 있습니다.  높은 수준에서 이러한 단계는 MLOps 파이프라인의 기반을 형성합니다.  그러나 각 단계에는 포괄적인 구현을 위한 여러 가지 세부적인 하위 단계가 포함됩니다.  이러한 하위 단계에는 데이터 전처리, 데이터 세트 분할, 모델 구성, 하이퍼파라미터 튜닝, 모델 평가, 모델 배포와 같은 다양한 작업이 포함됩니다.  이러한 단계를 거치면 SageMaker 환경 내에서 FSx ONTAP 의 학습 데이터를 사용하여 딥 러닝 모델을 구축하고 배포하는 철저하고 효과적인 프로세스가 보장됩니다.</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">단계별 통합</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">데이터 Loader</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">PyTorch 딥러닝 네트워크를 데이터로 학습시키기 위해, 데이터 공급을 용이하게 하는 데이터 로더가 만들어졌습니다.  데이터 로더는 배치 크기를 정의할 뿐만 아니라 배치 내의 각 레코드를 읽고 사전 처리하는 절차도 결정합니다.  데이터 로더를 구성하면 일괄적으로 데이터를 처리하여 딥 러닝 네트워크를 학습시킬 수 있습니다.</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">데이터 로더는 3개 부분으로 구성됩니다.</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">전처리 기능</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">위의 코드 조각은 *torchvision.transforms* 모듈을 사용하여 이미지 전처리 변환의 정의를 보여줍니다.  이 튜토리얼에서는 일련의 변환을 적용하기 위해 전처리 객체를 생성합니다.  첫째, *ToTensor()* 변환은 이미지를 텐서 표현으로 변환합니다.  이후, *Resize((224,224))* 변환은 이미지 크기를 224x224픽셀의 고정 크기로 조정합니다.  마지막으로, *Normalize()* 변환은 각 채널의 평균을 빼고 표준 편차로 나누어 텐서 값을 정규화합니다.  정규화에 사용되는 평균 및 표준 편차 값은 일반적으로 사전 학습된 신경망 모델에 사용됩니다.  전반적으로 이 코드는 이미지 데이터를 텐서로 변환하고, 크기를 조정하고, 픽셀 값을 정규화하여 추가 처리나 사전 학습된 모델에 입력할 수 있도록 이미지 데이터를 준비합니다.</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">PyTorch 데이터셋 클래스</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">이 클래스는 데이터 세트의 총 레코드 수를 얻는 기능을 제공하고 각 레코드에 대한 데이터를 읽는 방법을 정의합니다.  *__getitem__* 함수 내에서 코드는 boto3 S3 버킷 객체를 활용하여 FSx ONTAP 에서 바이너리 데이터를 검색합니다.  FSx ONTAP 에서 데이터에 액세스하는 코드 스타일은 Amazon S3에서 데이터를 읽는 것과 비슷합니다.  이후 설명에서는 개인 S3 객체 *버킷*의 생성 과정에 대해 자세히 설명합니다.</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">FSx ONTAP 개인 S3 저장소로 사용</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">SageMaker에서 FSx ONTAP 에서 데이터를 읽으려면 S3 프로토콜을 사용하여 FSx ONTAP 저장소를 가리키는 핸들러가 생성됩니다.  이를 통해 FSx ONTAP 개인 S3 버킷으로 처리할 수 있습니다.  핸들러 구성에는 FSx ONTAP SVM의 IP 주소, 버킷 이름 및 필요한 자격 증명을 지정하는 것이 포함됩니다.  이러한 구성 항목을 얻는 것에 대한 포괄적인 설명은 다음 문서를 참조하십시오.<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> .</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">위에서 언급한 예에서 버킷 객체는 PyTorch 데이터세트 객체를 인스턴스화하는 데 사용됩니다.  데이터 세트 객체에 대해서는 다음 섹션에서 자세히 설명하겠습니다.</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">PyTorch 데이터 Loader</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">제공된 예에서는 배치 크기가 64로 지정되어 각 배치에 64개의 레코드가 포함된다는 것을 나타냅니다.  PyTorch *Dataset* 클래스, 전처리 함수, 학습 배치 크기를 결합하여 학습을 위한 데이터 로더를 얻습니다.  이 데이터 로더는 학습 단계 동안 데이터 세트를 일괄적으로 반복하는 과정을 용이하게 합니다.</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">모델 학습</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">이 코드는 표준 PyTorch 학습 과정을 구현합니다.  이는 합성곱 계층과 선형 계층을 사용하여 타이어 품질을 분류하는 *TyreQualityClassifier*라는 신경망 모델을 정의합니다.  학습 루프는 데이터 배치를 반복하고, 손실을 계산하고, 역전파와 최적화를 사용하여 모델의 매개변수를 업데이트합니다.  또한 모니터링 목적으로 현재 시간, 에포크, 배치 및 손실을 인쇄합니다.</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">모델 배포</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">SageMaker는 배포를 위해 모델을 S3에 저장해야 하므로 이 코드는 PyTorch 모델을 *Amazon S3*에 저장합니다.  모델을 *Amazon S3*에 업로드하면 SageMaker에서 접근할 수 있게 되어 배포된 모델에 대한 배포와 추론이 가능해집니다.</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">이 코드는 SageMaker에서 PyTorch 모델을 배포하는 것을 용이하게 합니다.  PyTorch 텐서로 입력 데이터를 전처리하고 직렬화하는 사용자 정의 직렬화기인 *TyreQualitySerializer*를 정의합니다.  *TyreQualityPredictor* 클래스는 정의된 직렬화기와 *JSONDeserializer*를 활용하는 사용자 정의 예측기입니다.  또한 이 코드는 모델의 S3 위치, IAM 역할, 프레임워크 버전, 추론 진입점을 지정하기 위해 *PyTorchModel* 객체를 생성합니다.  이 코드는 타임스탬프를 생성하고 모델과 타임스탬프를 기반으로 엔드포인트 이름을 구성합니다.  마지막으로, 인스턴스 수, 인스턴스 유형, 생성된 엔드포인트 이름을 지정하여 배포 메서드를 사용하여 모델을 배포합니다.  이를 통해 PyTorch 모델을 배포하고 SageMaker에서 추론에 액세스할 수 있습니다.</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">추론</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">이는 배포된 엔드포인트를 사용하여 추론을 수행하는 예입니다.</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">이 섹션에서는 Apache Spark용 NetApp 스토리지 솔루션과 관련된 문서를 요약합니다.</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">결론</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">이 문서에서는 Apache Spark 아키텍처, 고객 사용 사례, 그리고 빅데이터, 최신 분석, AI, ML, DL과 관련된 NetApp 스토리지 포트폴리오에 대해 설명합니다.  업계 표준 벤치마킹 도구와 고객 수요에 따른 성능 검증 테스트에서 NetApp Spark 솔루션은 기본 Hadoop 시스템에 비해 뛰어난 성능을 보였습니다.  이 보고서에 제시된 고객 사용 사례와 성능 결과를 조합하면 배포에 적합한 Spark 솔루션을 선택하는 데 도움이 될 수 있습니다.</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">이 문서는 Apache Spark 아키텍처, 고객 사용 사례, 빅데이터 분석 및 인공 지능과 관련된 NetApp 스토리지 포트폴리오에 중점을 둡니다.  또한 일반적인 Hadoop 시스템에 대해 업계 표준 AI, 머신 러닝, 딥 러닝 도구를 사용하여 다양한 테스트 결과를 제시하여 적절한 Spark 솔루션을 선택할 수 있도록 도와줍니다.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Apache Spark용 NetApp 스토리지 솔루션: 아키텍처, 사용 사례 및 성능 결과</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">이 문서는 Apache Spark 아키텍처, 고객 사용 사례, 빅데이터 분석 및 인공 지능(AI)과 관련된 NetApp 스토리지 포트폴리오에 중점을 둡니다.  또한 일반적인 Hadoop 시스템에 대해 업계 표준 AI, 머신 러닝(ML), 딥 러닝(DL) 도구를 사용하여 다양한 테스트 결과를 제시하여 적절한 Spark 솔루션을 선택할 수 있도록 도와줍니다.  시작하려면 Spark 아키텍처, 적절한 구성 요소, 두 가지 배포 모드(클러스터 및 클라이언트)가 필요합니다.</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">이 문서에서는 구성 문제를 해결하기 위한 고객 사용 사례를 제공하고 Spark를 활용한 빅데이터 분석 및 AI, ML, DL과 관련된 NetApp 스토리지 포트폴리오에 대한 개요를 설명합니다.  그런 다음 Spark 관련 사용 사례와 NetApp Spark 솔루션 포트폴리오에서 파생된 테스트 결과로 마무리합니다.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">고객의 과제</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">이 섹션에서는 소매, 디지털 마케팅, 뱅킹, 개별 제조, 공정 제조, 정부 및 전문 서비스와 같은 데이터 증가 산업에서 빅데이터 분석 및 AI/ML/DL과 관련된 고객 과제에 중점을 둡니다.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">예측할 수 없는 성능</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">기존 Hadoop 배포에서는 일반적으로 상용 하드웨어를 사용합니다.  성능을 향상시키려면 네트워크, 운영 체제, Hadoop 클러스터, Spark와 같은 생태계 구성 요소, 하드웨어를 조정해야 합니다.  각 계층을 조정하더라도 Hadoop은 사용자 환경에서 고성능을 위해 설계되지 않은 상용 하드웨어에서 실행되기 때문에 원하는 성능 수준을 달성하는 것이 어려울 수 있습니다.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">미디어 및 노드 오류</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">일반적인 조건에서도 상용 하드웨어는 고장이 나기 쉽습니다.  데이터 노드의 디스크 하나에 장애가 발생하면 Hadoop 마스터는 기본적으로 해당 노드가 비정상적이라고 간주합니다.  그런 다음 네트워크를 통해 해당 노드의 특정 데이터를 복제본에서 정상 노드로 복사합니다.  이 프로세스는 Hadoop 작업에 대한 네트워크 패킷 속도를 늦춥니다.  그런 다음 클러스터는 데이터를 다시 복사하고, 건강에 해로운 노드가 건강한 상태로 돌아오면 과도하게 복제된 데이터를 제거해야 합니다.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoop 공급업체 종속</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop 배포업체는 자체 버전을 갖춘 자체 Hadoop 배포판을 보유하고 있어 고객이 해당 배포판에 종속됩니다.  그러나 많은 고객은 특정 Hadoop 배포판에 구애받지 않는 메모리 내 분석에 대한 지원을 요구합니다.  그들은 배포 방식을 변경하면서도 분석 결과를 그대로 적용할 수 있는 자유가 필요합니다.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">두 개 이상의 언어에 대한 지원 부족</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">고객은 종종 작업을 실행하기 위해 MapReduce Java 프로그램 외에도 여러 언어에 대한 지원을 요구합니다.  SQL 및 스크립트와 같은 옵션은 답변을 얻는 데 더 많은 유연성을 제공하고, 데이터를 구성하고 검색하는 데 더 많은 옵션을 제공하며, 분석 프레임워크로 데이터를 이동하는 더 빠른 방법을 제공합니다.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">사용의 어려움</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">얼마 전부터 사람들은 Hadoop을 사용하기 어렵다고 불평해 왔습니다.  Hadoop은 새로운 버전이 나올 때마다 더 간단해지고 강력해졌지만, 이러한 비판은 여전히 존재합니다.  Hadoop을 사용하려면 Java와 MapReduce 프로그래밍 패턴을 이해해야 하는데, 이는 데이터베이스 관리자와 기존 스크립팅 기술을 보유한 사람들에게는 어려운 일입니다.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">복잡한 프레임워크와 도구</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">기업의 AI 팀은 여러 가지 과제에 직면합니다.  전문적인 데이터 과학 지식이 있더라도, 다양한 배포 생태계와 애플리케이션에 맞는 도구와 프레임워크를 하나에서 다른 하나로 간단히 변환할 수는 없습니다.  데이터 과학 플랫폼은 Spark 기반으로 구축된 해당 빅데이터 플랫폼과 원활하게 통합되어야 하며, 데이터 이동이 쉽고, 재사용 가능한 모델, 즉시 사용 가능한 코드, 프로토타입 제작, 검증, 버전 관리, 공유, 재사용 및 모델의 신속한 프로덕션 배포를 위한 모범 사례를 지원하는 도구가 있어야 합니다.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">왜 NetApp 선택해야 하나요?</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp 다음과 같은 방법으로 Spark 경험을 개선할 수 있습니다.</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">NetApp NFS 직접 액세스(아래 그림 참조)를 통해 고객은 데이터를 이동하거나 복사하지 않고도 기존 또는 새로운 NFSv3 또는 NFSv4 데이터에 대한 빅데이터 분석 작업을 실행할 수 있습니다.  이를 통해 여러 개의 데이터 사본이 생성되는 것을 방지하고 소스와 데이터를 동기화할 필요성이 없어집니다.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">더 효율적인 저장과 더 적은 서버 복제.  예를 들어, NetApp E-Series Hadoop 솔루션은 3개가 아닌 2개의 데이터 복제본이 필요하고, FAS Hadoop 솔루션은 데이터 소스는 필요하지만 데이터 복제나 사본은 필요하지 않습니다.  NetApp 스토리지 솔루션은 서버 간 트래픽도 줄어듭니다.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">드라이브 및 노드 장애 발생 시 Hadoop 작업 및 클러스터 동작이 개선되었습니다.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">더 나은 데이터 수집 성능.</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">대체 Apache Spark 구성.</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">예를 들어, 금융 및 의료 분야에서는 데이터를 한 장소에서 다른 장소로 이동하려면 법적 의무를 충족해야 하는데, 이는 쉬운 일이 아닙니다.  이 시나리오에서 NetApp NFS 직접 액세스는 원래 위치에서 재무 및 의료 데이터를 분석합니다.  또 다른 주요 이점은 NetApp NFS 직접 액세스를 사용하면 기본 Hadoop 명령을 사용하고 NetApp 의 풍부한 데이터 관리 포트폴리오를 통해 데이터 보호 워크플로를 활성화하여 Hadoop 데이터를 보호하는 것이 간소화된다는 것입니다.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS 직접 액세스는 Hadoop/Spark 클러스터에 대해 두 가지 종류의 배포 옵션을 제공합니다.</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">기본적으로 Hadoop 또는 Spark 클러스터는 데이터 저장을 위해 Hadoop 분산 파일 시스템(HDFS)과 기본 파일 시스템을 사용합니다.  NetApp NFS 직접 액세스를 통해 기본 HDFS를 NFS 스토리지로 대체하여 기본 파일 시스템으로 사용할 수 있으므로 NFS 데이터에 대한 직접 분석이 가능합니다.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">또 다른 배포 옵션으로, NetApp NFS 직접 액세스는 단일 Hadoop 또는 Spark 클러스터에서 HDFS와 함께 추가 스토리지로 NFS를 구성하는 것을 지원합니다.  이 경우, 고객은 NFS 내보내기를 통해 데이터를 공유하고 HDFS 데이터와 함께 동일한 클러스터에서 해당 데이터에 액세스할 수 있습니다.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">NetApp NFS 직접 액세스를 사용하면 다음과 같은 주요 이점이 있습니다.</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">현재 위치에서 데이터를 분석하면 HDFS와 같은 Hadoop 인프라로 분석 데이터를 이동하는 데 드는 시간과 성능이 많이 소요되는 작업을 방지할 수 있습니다.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">복제본 수를 3개에서 1개로 줄입니다.</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">사용자가 컴퓨팅과 스토리지를 분리하여 독립적으로 확장할 수 있도록 지원합니다.</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">ONTAP 의 풍부한 데이터 관리 기능을 활용하여 기업 데이터 보호를 제공합니다.</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Hortonworks 데이터 플랫폼 인증.</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">하이브리드 데이터 분석 배포를 활성화합니다.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">동적 멀티스레드 기능을 활용하여 백업 시간을 줄입니다.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657: NetApp 하이브리드 클라우드 데이터 솔루션 - 고객 사용 사례 기반 Spark 및 Hadoop</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">보다<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block> Hadoop 데이터 백업, 클라우드에서 온프레미스로의 백업 및 재해 복구, 기존 Hadoop 데이터에 대한 DevTest 지원, 데이터 보호 및 멀티클라우드 연결, 분석 워크로드 가속화를 지원합니다.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">다음 섹션에서는 Spark 고객에게 중요한 저장 기능에 대해 설명합니다.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">스토리지 계층화</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Hadoop 스토리지 계층화를 사용하면 스토리지 정책에 따라 다양한 스토리지 유형에 파일을 저장할 수 있습니다.  저장 유형에는 다음이 포함됩니다.<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block> ,<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> ,<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> ,<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> ,<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> , 그리고<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block> .</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">우리는 SSD와 SAS 드라이브가 서로 다른 스토리지 정책을 사용하는 NetApp AFF 스토리지 컨트롤러와 E-Series 스토리지 컨트롤러에서 Hadoop 스토리지 계층화의 검증을 수행했습니다.  AFF-A800이 있는 Spark 클러스터에는 4개의 컴퓨팅 워커 노드가 있는 반면, E-Series가 있는 클러스터에는 8개가 있습니다.  이는 주로 솔리드 스테이트 드라이브(SSD)와 하드 드라이브 디스크(HDD)의 성능을 비교하기 위한 것입니다.</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">다음 그림은 Hadoop SSD에 대한 NetApp 솔루션의 성능을 보여줍니다.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">1TB의 데이터를 정리할 시간입니다.</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">Hadoop을 위한 TR-3969 NetApp E-Series 솔루션</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">기본 NL-SAS 구성에서는 8개의 컴퓨팅 노드와 96개의 NL-SAS 드라이브를 사용했습니다.  이 구성에서는 4분 38초 만에 1TB의 데이터가 생성되었습니다.  보다<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block> 클러스터 및 스토리지 구성에 대한 자세한 내용은 다음을 참조하세요.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">TeraGen을 사용하면 SSD 구성이 NL-SAS 구성보다 15.66배 빠르게 1TB의 데이터를 생성할 수 있습니다.  게다가 SSD 구성은 컴퓨팅 노드 수와 디스크 드라이브 수를 절반으로 줄였습니다(총 24개의 SSD 드라이브).  작업 완료 시간을 기준으로 볼 때 NL-SAS 구성보다 거의 두 배나 빨랐습니다.</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">TeraSort를 사용하면 SSD 구성이 NL-SAS 구성보다 1TB의 데이터를 1138.36배 더 빠르게 정렬할 수 있습니다.  게다가 SSD 구성은 컴퓨팅 노드 수와 디스크 드라이브 수를 절반으로 줄였습니다(총 24개의 SSD 드라이브).  따라서 드라이브당으로 따지면 NL-SAS 구성보다 약 3배 더 빠릅니다.</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">결론은 회전 디스크에서 올플래시로 전환하면 성능이 향상된다는 것입니다.  병목 현상은 컴퓨팅 노드의 수가 아니었습니다.  NetApp의 올플래시 스토리지를 사용하면 런타임 성능이 원활하게 확장됩니다.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">NFS를 사용하면 데이터가 모두 풀링된 것과 기능적으로 동일하므로 작업 부하에 따라 컴퓨팅 노드 수를 줄일 수 있습니다.  Apache Spark 클러스터 사용자는 컴퓨팅 노드 수를 변경할 때 수동으로 데이터를 재조정할 필요가 없습니다.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">성능 확장 - 확장</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">AFF 솔루션에서 Hadoop 클러스터로부터 더 많은 컴퓨팅 성능이 필요한 경우 적절한 수의 스토리지 컨트롤러가 있는 데이터 노드를 추가할 수 있습니다.  NetApp 워크로드 특성에 따라 스토리지 컨트롤러 어레이당 4개의 데이터 노드로 시작하여 스토리지 컨트롤러당 8개의 데이터 노드로 늘릴 것을 권장합니다.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF 와 FAS 현장 분석에 적합합니다.  컴퓨팅 요구 사항에 따라 노드 관리자를 추가할 수 있으며, 중단 없는 운영을 통해 가동 중지 없이 필요에 따라 스토리지 컨트롤러를 추가할 수 있습니다.  AFF 및 FAS 에는 NVME 미디어 지원, 효율성 보장, 데이터 감소, QoS, 예측 분석, 클라우드 계층화, 복제, 클라우드 배포 및 보안과 같은 풍부한 기능이 제공됩니다.  고객의 요구 사항을 충족할 수 있도록 NetApp 추가 라이선스 비용 없이 파일 시스템 분석, 할당량, 온박스 로드 밸런싱과 같은 기능을 제공합니다.  NetApp 경쟁사보다 동시 작업 수, 대기 시간, 작업이 더 간단하고 초당 기가바이트 처리량이 더 높은 성능을 제공합니다.  또한 NetApp Cloud Volumes ONTAP 3대 주요 클라우드 공급업체 모두에서 실행됩니다.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">성능 확장 - 확장</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">확장 기능을 사용하면 추가 저장 용량이 필요할 때 AFF, FAS 및 E-시리즈 시스템에 디스크 드라이브를 추가할 수 있습니다.  Cloud Volumes ONTAP 사용하면 스토리지를 PB 수준으로 확장하는 데 두 가지 요소가 결합됩니다. 블록 스토리지에서 개체 스토리지로 자주 사용되지 않는 데이터를 계층화하고 추가 컴퓨팅 없이 Cloud Volumes ONTAP 라이선스를 스태킹합니다.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">다중 프로토콜</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetApp 시스템은 SAS, iSCSI, FCP, InfiniBand, NFS를 포함하여 Hadoop 배포를 위한 대부분의 프로토콜을 지원합니다.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">운영 및 지원 솔루션</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">호튼웍스</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">인증</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">파트너</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">이 문서에 설명된 Hadoop 솔루션은 NetApp 에서 지원됩니다.  이러한 솔루션은 주요 Hadoop 유통업체로부터도 인증을 받았습니다.  자세한 내용은 다음을 참조하세요.<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> 사이트 및 Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> 그리고<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> 사이트.</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">이 섹션에서는 Apache Spark의 특성과 구성 요소를 설명하고 이들이 이 솔루션에 어떻게 기여하는지 설명합니다.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">솔루션 기술</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark는 Hadoop 분산 파일 시스템(HDFS)과 직접 작동하는 Hadoop 애플리케이션을 작성하기 위한 인기 있는 프로그래밍 프레임워크입니다.  Spark는 프로덕션에 바로 사용할 수 있으며, 스트리밍 데이터 처리를 지원하며 MapReduce보다 빠릅니다.  Spark는 효율적인 반복을 위해 구성 가능한 메모리 내 데이터 캐싱 기능을 갖추고 있으며, Spark 셸은 데이터를 학습하고 탐색하기 위해 대화형으로 작동합니다.  Spark를 사용하면 Python, Scala 또는 Java로 애플리케이션을 만들 수 있습니다.  Spark 애플리케이션은 하나 이상의 작업을 포함하는 하나 이상의 작업으로 구성됩니다.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">모든 Spark 애플리케이션에는 Spark 드라이버가 있습니다.  YARN-Client 모드에서는 드라이버가 클라이언트에서 로컬로 실행됩니다.  YARN-클러스터 모드에서 드라이버는 애플리케이션 마스터의 클러스터에서 실행됩니다.  클러스터 모드에서는 클라이언트가 연결을 끊더라도 애플리케이션은 계속 실행됩니다.</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">입력/출력 대화 상자 또는 서면 내용을 나타내는 그림</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">클러스터 관리자는 세 가지가 있습니다.</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*독립형.*  이 관리자는 Spark의 일부로, 클러스터를 쉽게 설정할 수 있도록 해줍니다.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*아파치 메소스.*  이는 MapReduce 및 기타 애플리케이션을 실행하는 일반 클러스터 관리자입니다.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*하둡 YARN.*  이는 Hadoop 3의 리소스 관리자입니다.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">탄력적 분산 데이터 세트(RDD)는 Spark의 주요 구성 요소입니다.  RDD는 클러스터의 메모리에 저장된 데이터에서 손실되거나 누락된 데이터를 다시 생성하고 파일에서 나오거나 프로그래밍 방식으로 생성된 초기 데이터를 저장합니다.  RDD는 파일, 메모리의 데이터 또는 다른 RDD로부터 생성됩니다.  Spark 프로그래밍은 변환과 동작이라는 두 가지 작업을 수행합니다.  변형은 기존 RDD를 기반으로 새로운 RDD를 생성합니다.  액션은 RDD에서 값을 반환합니다.</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">변환과 작업은 Spark Datasets와 DataFrames에도 적용됩니다.  데이터 세트는 RDD(강력한 타이핑, 람다 함수 사용)의 이점과 Spark SQL의 최적화된 실행 엔진의 이점을 모두 제공하는 분산된 데이터 컬렉션입니다.  데이터 세트는 JVM 객체로부터 구성된 다음 함수 변환(map, flatMap, filter 등)을 사용하여 조작될 수 있습니다.  DataFrame은 이름이 지정된 열로 구성된 데이터 집합입니다.  개념적으로는 관계형 데이터베이스의 테이블이나 R/Python의 데이터 프레임과 동일합니다.  DataFrames는 구조화된 데이터 파일, Hive/HBase의 테이블, 온프레미스 또는 클라우드의 외부 데이터베이스, 기존 RDD 등 다양한 소스에서 구성할 수 있습니다.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Spark 애플리케이션에는 하나 이상의 Spark 작업이 포함됩니다.  작업은 실행자에서 작업을 실행하고 실행자는 YARN 컨테이너에서 실행됩니다.  각 실행자는 단일 컨테이너에서 실행되며 실행자는 애플리케이션의 수명 동안 존재합니다.  실행자는 애플리케이션이 시작된 후에 고정되고, YARN은 이미 할당된 컨테이너의 크기를 조정하지 않습니다.  실행자는 메모리 내 데이터에서 동시에 작업을 실행할 수 있습니다.</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">이 섹션에서는 이 솔루션의 내용에 관심이 있을 수 있는 사람을 설명합니다.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">타겟 고객층</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">분석 및 데이터 과학의 세계는 IT와 비즈니스의 여러 분야에 영향을 미칩니다.</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">데이터 과학자는 자신이 선택한 도구와 라이브러리를 사용할 수 있는 유연성이 필요합니다.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">데이터 엔지니어는 데이터가 어떻게 흐르는지, 어디에 있는지 알아야 합니다.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOps 엔지니어에게는 새로운 AI 및 ML 애플리케이션을 CI 및 CD 파이프라인에 통합할 수 있는 도구가 필요합니다.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">클라우드 관리자와 설계자는 하이브리드 클라우드 리소스를 설정하고 관리할 수 있어야 합니다.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">비즈니스 사용자는 분석, AI, ML, DL 애플리케이션에 액세스할 수 있기를 원합니다.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">이 기술 보고서에서는 NetApp AFF, E-Series, StorageGRID, NFS 직접 액세스, Apache Spark, Horovod 및 Keras가 이러한 각 역할이 비즈니스에 가치를 제공하는 데 어떻게 도움이 되는지 설명합니다.</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">TeraGen 벤치마킹 도구의 TeraSort 및 TeraValidate 스크립트를 사용하여 E5760, E5724 및 AFF-A800 구성으로 Spark 성능 검증을 측정했습니다.  또한, Spark NLP 파이프라인과 TensorFlow 분산 학습, Horovod 분산 학습, DeepFM을 사용한 CTR 예측을 위한 Keras를 사용한 다중 워커 딥 러닝이라는 세 가지 주요 사용 사례가 테스트되었습니다.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">테스트 결과</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">TeraGen 벤치마킹 도구의 TeraSort 및 TeraValidate 스크립트를 사용하여 E5760, E5724 및 AFF-A800 구성으로 Spark 성능 검증을 측정했습니다.  또한, Spark NLP 파이프라인과 TensorFlow 분산 학습, Horovod 분산 학습, DeepFM을 사용한 CTR 예측을 위한 Keras를 사용한 다중 워커 딥 러닝의 세 가지 주요 사용 사례가 테스트되었습니다.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">E-Series와 StorageGRID 검증에는 Hadoop 복제 계수 2를 사용했습니다.  AFF 검증을 위해 우리는 단 하나의 데이터 소스만 사용했습니다.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">다음 표는 Spark 성능 검증을 위한 하드웨어 구성을 나열한 것입니다.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">유형</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoop 워커 노드</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">구동 유형</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">노드당 드라이브</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">스토리지 컨트롤러</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">단일 고가용성(HA) 쌍</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">단일 HA 쌍</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">다음 표에는 소프트웨어 요구 사항이 나열되어 있습니다.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">소프트웨어</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">버전</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK 런타임 환경</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64비트 서버 VM</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">깃</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">불꽃</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">파이스파크</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">스파크NLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">텐서플로우</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">케라스</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">호로보드</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">금융 심리 분석</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910: NetApp AI를 활용한 고객 커뮤니케이션의 감정 분석</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">NetApp DataOps 툴킷</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA 리바 SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">타오 프레임워크</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">우리는 출판했다<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block> , 종단 간 대화형 AI 파이프라인이 다음을 사용하여 구축되었습니다.<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block> , AFF 스토리지 및 NVIDIA DGX 시스템.  파이프라인은 DataOps Toolkit을 활용하여 일괄 오디오 신호 처리, 자동 음성 인식(ASR), 전이 학습 및 감정 분석을 수행합니다.<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> , 그리고<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block> .  감정 분석 사용 사례를 금융 서비스 산업으로 확장하여 SparkNLP 워크플로를 구축하고, 명명된 엔터티 인식과 같은 다양한 NLP 작업을 위해 세 개의 BERT 모델을 로드하고, NASDAQ 상위 10대 기업의 분기별 실적 전화 회의에 대한 문장 수준의 감정을 얻었습니다.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">다음 스크립트<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block> 다음 표에 표시된 것처럼 FinBERT 모델을 사용하여 HDFS에서 전사본을 처리하고 긍정적, 중립적, 부정적 감정 수를 생성합니다.</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">다음 표는 2016년부터 2020년까지 NASDAQ 상위 10개 기업의 수익 발표 및 문장 단위 감정 분석을 나열한 것입니다.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">감정 수와 백분율</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">10개 회사 모두</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">아에이피엘</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">아마존</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">구글</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">인티씨</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">엔비디아</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">양성 카운트</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">중립 카운트</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">음수 카운트</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">분류되지 않은 카운트</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(총 개수)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">백분율로 보면, CEO와 CFO가 말한 대부분의 문장은 사실에 기반을 두고 있어 중립적인 감정을 담고 있습니다.  수익 전화 회의에서 분석가들은 긍정적이거나 부정적인 감정을 전달할 수 있는 질문을 합니다.  부정적 또는 긍정적 감정이 거래 당일이나 다음 날의 주가에 어떤 영향을 미치는지 정량적으로 추가 조사해 볼 가치가 있습니다.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">다음 표는 NASDAQ 상위 10개 기업의 문장 수준 감정 분석을 백분율로 나타낸 것입니다.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">감정 비율</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">긍정적인</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">중립적</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">부정적인</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">분류되지 않음</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">워크플로 런타임 측면에서 우리는 4.78배의 상당한 개선을 보았습니다.<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> HDFS의 분산 환경으로 모드를 전환하고 NFS를 활용하여 0.14% 더 개선되었습니다.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">다음 그림에서 볼 수 있듯이, 데이터 및 모델 병렬 처리로 데이터 처리와 분산 TensorFlow 모델 추론 속도가 향상되었습니다.  NFS에서 데이터를 배치하면 워크플로 병목 현상이 사전 학습된 모델을 다운로드하는 데서 발생하기 때문에 런타임이 약간 더 향상됩니다.  전사본 데이터 세트의 크기를 늘리면 NFS의 장점이 더욱 분명해집니다.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Spark NLP 감정 분석 종단간 워크플로 런타임.</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Horovod 성능을 활용한 분산 학습</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">각 주요 사용 사례에 대한 Python 스크립트</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">다음 명령은 단일 명령을 사용하여 Spark 클러스터에서 런타임 정보와 로그 파일을 생성했습니다.<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block> 각각 1개의 코어를 갖춘 160개의 실행자가 있는 노드입니다.  메모리 부족 오류를 방지하기 위해 실행자 메모리는 5GB로 제한되었습니다.  섹션을 참조하세요<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block> 데이터 처리, 모델 학습 및 모델 정확도 계산에 대한 자세한 내용은<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">10개의 학습 에포크를 적용한 결과 런타임은 다음과 같습니다.</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">입력 데이터를 처리하고, DNN 모델을 훈련하고, 정확도를 계산하고, TensorFlow 체크포인트와 예측 결과를 위한 CSV 파일을 생성하는 데 43분 이상 걸렸습니다.  우리는 훈련 에포크의 수를 10으로 제한했는데, 실제로는 만족스러운 모델 정확도를 보장하기 위해 종종 100으로 설정합니다.  일반적으로 학습 시간은 에포크 수에 따라 선형적으로 증가합니다.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">다음으로 클러스터에서 사용 가능한 4개의 작업자 노드를 사용하여 동일한 스크립트를 실행했습니다.<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> HDFS에 데이터가 있는 모드:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">그 결과 런타임은 다음과 같이 개선되었습니다.</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">Spark에서 Horovod의 모델과 데이터 병렬 처리를 통해 런타임 속도가 5.29배 향상되었습니다.<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> ~ 대<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block> 10개의 훈련 에포크를 가진 모드.  이는 다음 그림에서 범례와 함께 표시됩니다.<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block> 그리고<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block> .  사용 가능한 경우 GPU를 사용하여 기본 TensorFlow DNN 모델 학습을 더욱 가속화할 수 있습니다.  우리는 이 테스트를 수행하고 그 결과를 향후 기술 보고서에 발표할 계획입니다.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">다음 테스트에서는 NFS와 HDFS에 있는 입력 데이터를 사용하여 런타임을 비교했습니다.  AFF A800 의 NFS 볼륨은 다음에 마운트되었습니다.<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> Spark 클러스터의 5개 노드(마스터 1개, 워커 4개)에 걸쳐 있습니다.  우리는 이전 테스트와 유사한 명령을 실행했습니다.<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block> 이제 NFS 마운트를 가리키는 매개변수:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">NFS를 사용한 결과 런타임은 다음과 같습니다.</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">다음 그림에서 볼 수 있듯이, 1.43배 더 속도가 향상되었습니다.  따라서 클러스터에 연결된 NetApp 올플래시 스토리지를 통해 고객은 Horovod Spark 워크플로우에서 빠른 데이터 전송 및 배포의 이점을 누릴 수 있으며, 단일 노드에서 실행하는 것보다 7.55배 빠른 속도를 달성할 수 있습니다.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark 워크플로 런타임.</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">CTR 예측 성능을 위한 딥러닝 모델</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">CTR을 극대화하도록 설계된 추천 시스템의 경우, 낮은 순위에서 높은 순위까지 수학적으로 계산할 수 있는 사용자 행동의 이면에 있는 정교한 기능 상호작용을 학습해야 합니다.  좋은 딥 러닝 모델에서는 낮은 순서와 높은 순서의 특징 상호작용이 둘 다 똑같이 중요해야 하며, 어느 한쪽에 치우치지 않아야 합니다.  인수분해 머신 기반 신경망인 DeepFM(Deep Factorization Machine)은 추천을 위한 인수분해 머신과 기능 학습을 위한 딥러닝을 새로운 신경망 아키텍처로 결합합니다.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">와이드 &amp; 딥 모델</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">기존의 인수분해 머신은 쌍별 특징 상호작용을 특징 간의 잠재 벡터의 내적으로 모델링하고 이론적으로는 고차 정보를 포착할 수 있지만, 실제로 머신 러닝 실무자는 높은 계산 및 저장 복잡성으로 인해 2차 특징 상호작용만 사용합니다.  Google과 같은 딥 신경망 변형<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> 반면에 선형 광역 모델과 심층 모델을 결합하여 하이브리드 네트워크 구조에서 정교한 기능 상호 작용을 학습합니다.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">이 Wide &amp; Deep 모델에는 두 가지 입력이 있습니다. 하나는 기본 Wide 모델을 위한 것이고 다른 하나는 Deep 모델을 위한 것입니다. Deep 모델의 후자에는 여전히 전문적인 기능 엔지니어링이 필요하므로 이 기술을 다른 도메인으로 일반화하기는 어렵습니다.  Wide &amp; Deep 모델과 달리 DeepFM은 와이드 부분과 딥 부분이 동일한 입력과 임베딩 벡터를 공유하기 때문에 기능 엔지니어링 없이 원시 기능으로 효율적으로 학습할 수 있습니다.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">주요 사용 사례별로 Python 스크립트가 제공됩니다.</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">우리는 먼저 Criteo를 처리했습니다.<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> (11GB) 파일을 CSV 파일로 변환<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> NFS 마운트에 저장됨<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block> 사용 중<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> 섹션에서<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> 이 스크립트 내에서 함수<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block> 탭을 제거하고 삽입하기 위해 여러 문자열 메서드를 수행합니다.<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block> 구분 기호로<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block> 줄바꿈으로.  원본만 처리하면 된다는 점에 유의하세요.<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> 한 번, 코드 블록이 주석으로 표시됩니다.</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">다양한 DL 모델에 대한 다음 테스트를 위해 다음을 사용했습니다.<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> 입력 파일로.  이후 테스트 실행에서 입력 CSV 파일은 스키마가 포함된 Spark DataFrame으로 읽혀졌습니다.<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block> , 정수 밀집 기능<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block> , 그리고 희소한 특징<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block> .  다음<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block> 명령은 입력 CSV를 받고, 교차 검증을 위해 20% 분할로 DeepFM 모델을 학습하고, 10번의 학습 에포크 후에 가장 좋은 모델을 선택하여 테스트 세트에서 예측 정확도를 계산합니다.</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">데이터 파일 이후에는<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block> 11GB가 넘으면 충분한 용량을 설정해야 합니다.<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block> 오류를 피하기 위해 데이터 세트 크기보다 크게 설정합니다.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">아파치 애로우</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">위의<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block> 구성도 활성화했습니다<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block> Spark DataFrame을 Pandas DataFrame으로 변환하는<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block> 방법.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">무작위 분할 후, 훈련 데이터 세트에는 3,600만 개가 넘는 행이 있고 테스트 세트에는 900만 개의 샘플이 있습니다.</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">이 기술 보고서는 GPU를 사용하지 않고 CPU 테스트에 초점을 맞추고 있으므로 적절한 컴파일러 플래그로 TensorFlow를 빌드하는 것이 중요합니다.  이 단계에서는 GPU 가속 라이브러리를 호출하지 않고 TensorFlow의 AVX(Advanced Vector Extensions) 및 AVX2 명령어를 최대한 활용합니다.  이러한 기능은 벡터화된 덧셈, 피드포워드 내부의 행렬 곱셈 또는 역전파 DNN 훈련과 같은 선형 대수 계산을 위해 설계되었습니다.  AVX2에서 제공하는 256비트 부동 소수점(FP) 레지스터를 사용하는 융합 곱셈 및 덧셈(FMA) 명령어는 정수 코드와 데이터 유형에 이상적이며 최대 2배의 속도 향상을 가져옵니다.  FP 코드와 데이터 유형의 경우 AVX2는 AVX보다 8% 더 빠른 속도를 달성합니다.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">바젤</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">소스에서 TensorFlow를 빌드하려면 NetApp 다음을 사용하는 것이 좋습니다.<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block> .  우리 환경에서는 셸 프롬프트에서 다음 명령을 실행하여 설치했습니다.<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block> ,<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> , 그리고 바젤.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">RHEL에서 SCL(소프트웨어 컬렉션 라이브러리)을 통해 제공하는 C++17 기능을 빌드 프로세스 중에 사용하려면 GCC 5 이상 버전을 활성화해야 합니다.  다음 명령어를 설치합니다.<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block> 그리고 RHEL 7.9 클러스터에 GCC 11.2.1이 있습니다.</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">기사</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">마지막 두 명령은 다음을 활성화합니다.<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block> , 사용하는<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block> (GCC 11.2.1).  또한 다음을 확인하세요.<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> 버전이 1.8.3보다 높습니다(RHEL 7.9에 포함됨).  이것을 참조하세요<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> 업데이트용<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block> 2.24.1로.</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">각 주요 사용 사례에 대한 Python 스크립트</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">쿠다</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">귀하가 이미 최신 TensorFlow 마스터 저장소를 복제했다고 가정합니다.  그런 다음 생성하세요<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block> 디렉토리<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block> AVX, AVX2, FMA를 사용하여 소스에서 TensorFlow를 빌드하는 파일입니다.  실행하다<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block> 파일을 만들고 올바른 Python 바이너리 위치를 지정합니다.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> 우리는 GPU를 사용하지 않았기 때문에 테스트를 위해 비활성화되었습니다.  에이<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> 파일은 귀하의 설정에 따라 생성됩니다.  또한, 우리는 파일을 편집하고 설정했습니다.<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block> HDFS 지원을 활성화합니다.  참조하다<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block> 섹션에서<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block> 설정 및 플래그의 전체 목록을 확인하세요.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">올바른 플래그로 TensorFlow를 빌드한 후 다음 스크립트를 실행하여 Criteo Display Ads 데이터 세트를 처리하고 DeepFM 모델을 학습시키고 예측 점수에서 수신자 조작 특성 곡선 아래의 면적(ROC AUC)을 계산합니다.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">10번의 훈련 에포크 후에 우리는 테스트 데이터 세트에 대한 AUC 점수를 얻었습니다.</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">이전 사용 사례와 유사한 방식으로 Spark 워크플로 런타임을 다양한 위치에 있는 데이터와 비교했습니다.  다음 그림은 Spark 워크플로 런타임에 대한 딥 러닝 CTR 예측을 비교한 것입니다.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Spark 워크플로 런타임에 대한 딥러닝 CTR 예측 비교.</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">이 페이지에서는 이 솔루션을 사용할 수 있는 다양한 영역을 설명합니다.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">사용 사례 요약</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">스트리밍 데이터</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark는 스트리밍 데이터를 처리할 수 있으며, 이 데이터는 스트리밍 추출, 변환 및 로드(ETL) 프로세스, 데이터 강화, 이벤트 감지 트리거, 복잡한 세션 분석에 사용됩니다.</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*스트리밍 ETL.*  데이터는 데이터 저장소에 푸시되기 전에 지속적으로 정리되고 집계됩니다.  Netflix는 Kafka와 Spark 스트리밍을 사용하여 다양한 데이터 소스에서 하루에 수십억 개의 이벤트를 처리할 수 있는 실시간 온라인 영화 추천 및 데이터 모니터링 솔루션을 구축합니다.  하지만 일괄 처리를 위한 기존 ETL은 다르게 처리됩니다.  이 데이터는 먼저 읽혀지고, 그런 다음 데이터베이스에 기록되기 전에 데이터베이스 형식으로 변환됩니다.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*데이터 강화.*  Spark 스트리밍은 실시간 데이터에 정적 데이터를 추가하여 보다 실시간적인 데이터 분석을 가능하게 합니다.  예를 들어, 온라인 광고주는 고객 행동에 대한 정보를 바탕으로 개인화되고 타겟이 지정된 광고를 게재할 수 있습니다.</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*트리거 이벤트 감지.*  Spark 스트리밍을 사용하면 잠재적으로 심각한 문제를 나타낼 수 있는 비정상적인 동작을 감지하고 신속하게 대응할 수 있습니다.  예를 들어, 금융 기관은 트리거를 사용하여 사기 거래를 감지하고 중단하고, 병원에서는 트리거를 사용하여 환자의 생체 신호에서 발견된 위험한 건강 변화를 감지합니다.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*복잡한 세션 분석.*  Spark 스트리밍은 웹사이트나 애플리케이션에 로그인한 후의 사용자 활동과 같은 이벤트를 수집한 다음 이를 그룹화하여 분석합니다.  예를 들어, Netflix는 이 기능을 사용하여 실시간으로 영화를 추천해 줍니다.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912: NetApp 사용한 Confluent Kafka 계층형 스토리지에 대한 모범 사례 가이드라인</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">스트리밍 데이터 구성, Confluent Kafka 검증 및 성능 테스트에 대한 자세한 내용은 다음을 참조하세요.<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block> .</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">머신러닝</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Spark 통합 프레임워크는 머신 러닝 라이브러리(MLlib)를 사용하여 데이터 세트에 대한 반복 쿼리를 실행하는 데 도움이 됩니다.  MLlib은 예측 인텔리전스, 마케팅 목적을 위한 고객 세분화, 감정 분석 등 일반적인 빅데이터 기능에 대한 클러스터링, 분류, 차원 축소와 같은 분야에서 사용됩니다.  MLlib은 네트워크 보안에서 악의적인 활동을 나타내는 데이터 패킷의 실시간 검사를 수행하는 데 사용됩니다.  보안 서비스 제공업체가 새로운 위협에 대해 알아내고 해커보다 앞서 나가는 동시에 실시간으로 고객을 보호하는 데 도움이 됩니다.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">딥러닝</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow는 업계 전반에서 사용되는 인기 있는 딥 러닝 프레임워크입니다.  TensorFlow는 CPU 또는 GPU 클러스터에서의 분산 학습을 지원합니다.  이 분산형 학습을 통해 사용자는 많은 심층 레이어가 있는 대량의 데이터에서 학습을 실행할 수 있습니다.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">얼마 전까지만 해도 Apache Spark에서 TensorFlow를 사용하려면 PySpark에서 TensorFlow에 대한 모든 필수 ETL을 수행한 다음 중간 저장소에 데이터를 써야 했습니다.  그런 다음 해당 데이터는 실제 학습 과정을 위해 TensorFlow 클러스터에 로드됩니다.  이 워크플로를 사용하려면 사용자가 두 개의 서로 다른 클러스터를 유지해야 합니다. 하나는 ETL용이고 다른 하나는 TensorFlow의 분산 학습용입니다.  여러 개의 클러스터를 실행하고 유지 관리하는 일은 일반적으로 지루하고 시간이 많이 걸렸습니다.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">이전 Spark 버전의 DataFrames와 RDD는 무작위 접근이 제한되어 있어 딥러닝에 적합하지 않았습니다.  Spark 3.0과 Project Hydrogen에서는 딥러닝 프레임워크에 대한 기본 지원이 추가되었습니다.  이 접근 방식을 사용하면 Spark 클러스터에서 MapReduce 기반이 아닌 스케줄링이 가능합니다.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">대화형 분석</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark는 SQL, R, Python 등 Spark 이외의 개발 언어로 샘플링하지 않고도 탐색적 쿼리를 수행할 만큼 빠릅니다.  Spark는 시각화 도구를 사용하여 복잡한 데이터를 처리하고 대화형으로 시각화합니다.  구조화된 스트리밍을 탑재한 Spark는 웹 분석에서 라이브 데이터에 대한 대화형 쿼리를 수행하여 웹 방문자의 현재 세션에 대한 대화형 쿼리를 실행할 수 있습니다.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">추천 시스템</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">수년에 걸쳐 추천 시스템은 우리 삶에 엄청난 변화를 가져왔습니다. 기업과 소비자는 온라인 쇼핑, 온라인 엔터테인먼트 등 여러 산업의 극적인 변화에 대응해 왔습니다.  실제로 이러한 시스템은 생산 현장에서 AI를 활용한 가장 확실한 성공 사례 중 하나입니다.  많은 실제 사용 사례에서 추천 시스템은 NLP 백엔드와 인터페이스된 대화형 AI 또는 챗봇과 결합되어 관련 정보를 얻고 유용한 추론을 생성합니다.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">오늘날 많은 소매업체가 온라인에서 구매하고 매장에서 픽업하는 방식, 연석 픽업, 셀프 체크아웃, 스캔 앤 고 등 새로운 비즈니스 모델을 도입하고 있습니다.  이러한 모델은 소비자의 쇼핑을 더 안전하고 편리하게 만들어줌으로써 COVID-19 팬데믹 기간 동안 두각을 나타냈습니다.  소비자 행동에 영향을 받는 이러한 성장하는 디지털 트렌드에 AI는 매우 중요합니다.  소비자의 증가하는 요구를 충족하고, 고객 경험을 강화하고, 운영 효율성을 개선하고, 수익을 늘리기 위해 NetApp 기업 고객과 사업체가 머신 러닝과 딥 러닝 알고리즘을 사용하여 더 빠르고 정확한 추천 시스템을 설계할 수 있도록 지원합니다.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">추천을 제공하는 데 사용되는 여러 가지 인기 있는 기술이 있는데, 여기에는 협업 필터링, 콘텐츠 기반 시스템, 딥러닝 추천 모델(DLRM), 하이브리드 기술이 포함됩니다.  이전에 고객들은 PySpark를 활용해 추천 시스템을 만드는 협업 필터링을 구현했습니다.  Spark MLlib은 DLRM이 등장하기 전에 기업에서 매우 인기 있는 알고리즘인 협업 필터링을 위한 교대 최소 제곱법(ALS)을 구현합니다.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">자연어 처리</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">가트너</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">자연어 처리(NLP)를 통해 가능해진 대화형 AI는 컴퓨터가 인간과 소통하는 데 도움이 되는 AI의 한 분야입니다.  NLP는 모든 산업 분야에서 널리 사용되고 있으며, 스마트 어시스턴트와 챗봇부터 Google 검색과 예측 텍스트에 이르기까지 다양한 사용 사례가 있습니다.  에 따르면<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> 예측에 따르면 2022년까지 70%의 사람들이 매일 대화형 AI 플랫폼과 상호작용하게 될 것입니다.  인간과 기계가 고품질 대화를 하려면 응답이 빠르고, 지능적이며, 자연스럽게 들려야 합니다.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">고객은 NLP 및 자동 음성 인식(ASR) 모델을 처리하고 훈련하기 위해 대량의 데이터가 필요합니다.  또한 엣지, 코어, 클라우드 전반에서 데이터를 이동해야 하며, 인간과 자연스러운 소통을 구축하기 위해 밀리초 단위로 추론을 수행할 수 있는 능력이 필요합니다.  NetApp AI와 Apache Spark는 컴퓨팅, 스토리지, 데이터 처리, 모델 학습, 미세 조정 및 배포에 이상적인 조합입니다.</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">감정 분석은 NLP 내의 연구 분야로, 텍스트에서 긍정적, 부정적 또는 중립적 감정을 추출합니다.  감정 분석은 통화자와의 대화에서 지원 센터 직원의 성과를 파악하는 것부터 적절한 자동화된 챗봇 응답을 제공하는 것까지 다양한 사용 사례에 적용됩니다.  또한 분기별 실적 발표에서 회사 대표와 청중 간의 상호 작용을 기반으로 회사 주가를 예측하는 데 사용되었습니다.  더욱이, 감정 분석은 브랜드가 제공하는 제품, 서비스 또는 지원에 대한 고객의 견해를 파악하는 데 사용될 수 있습니다.</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">스파크 NLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">존 스노우 랩스</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">금융 뉴스 감정</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">핀버트</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">우리는 사용했다<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> 도서관에서<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> BERT(Transformers) 모델을 포함하여 사전 학습된 파이프라인 및 양방향 인코더 표현을 로드하려면<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block> 그리고<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block> 대규모로 토큰화, 명명된 엔터티 인식, 모델 학습, 피팅 및 감정 분석을 수행합니다.  Spark NLP는 BERT, ALBERT, ELECTRA, XLNet, DistilBERT, RoBERTa, DeBERTa, XLM- RoBERTa, Longformer, ELMO, Universal Sentence Encoder, Google T5, MarianMT, GPT2와 같은 최첨단 변환기를 제공하는 유일한 오픈 소스 NLP 라이브러리입니다.  이 라이브러리는 Python과 R에서 작동할 뿐만 아니라 Apache Spark를 기본적으로 확장하여 JVM 생태계(Java, Scala, Kotlin)에서도 대규모로 작동합니다.</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">개요</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">이 문서에서는 빅데이터 분석 및 고성능 컴퓨팅(HPC) 시스템에서 데이터를 이동하여 인공 지능(AI) 워크플로에 사용할 수 있는 방법을 설명합니다.  AI는 일반적으로 NFS 내보내기를 통해 NFS 데이터를 처리합니다.  하지만 AI 데이터는 빅데이터 분석 및 고성능 컴퓨팅(HPC) 플랫폼에 있을 수도 있습니다.  이는 Hadoop 분산 파일 시스템(HDFS), 바이너리 대형 객체(Blob), S3 스토리지 또는 IBM의 일반 병렬 파일 시스템(GPFS)일 수 있습니다.  이 문서에서는 Hadoop 기반 명령, NetApp In-Place Analytics Module(NIPAM), NetApp XCP를 사용하여 빅데이터 분석 플랫폼과 GPFS에서 NFS로 데이터를 이동하는 방법을 설명합니다.  이 문서에서는 빅데이터와 HPC에서 AI로 데이터를 옮기는 비즈니스 이점에 대해서도 설명합니다.</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">추가 정보를 찾을 수 있는 곳</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹사이트를 검토하세요.</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroup 볼륨 모범 사례 및 구현 가이드</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp 제품 문서</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">이 섹션에서는 이 솔루션의 비즈니스 이점에 대해 설명합니다.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">사업상의 이점</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">빅데이터 분석에서 AI로 데이터를 이동하면 다음과 같은 이점이 있습니다.</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">다양한 Hadoop 파일 시스템과 GPFS에서 데이터를 추출하여 통합된 NFS 스토리지 시스템으로 구축하는 기능</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Hadoop에 통합되고 자동화된 데이터 전송 방식</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Hadoop 파일 시스템에서 데이터를 이동하기 위한 라이브러리 개발 비용 절감</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">NIPAM을 사용하여 단일 데이터 소스에서 여러 네트워크 인터페이스의 처리량을 집계하여 최대 성능을 구현합니다.</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">데이터를 전송하기 위한 예약 및 주문형 방법</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">ONTAP 데이터 관리 소프트웨어를 사용하여 통합 NFS 데이터에 대한 스토리지 효율성 및 엔터프라이즈 관리 기능 제공</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">Hadoop 방식을 이용한 데이터 전송으로 데이터 이동 비용 없음</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">이 페이지에서는 AI 운영을 위해 빅데이터 분석 데이터에 액세스하려고 할 때 고객이 직면할 수 있는 과제에 대해 설명합니다.</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">고객은 AI 운영을 위해 빅데이터 분석 데이터에 액세스하려고 할 때 다음과 같은 문제에 직면할 수 있습니다.</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">고객 데이터는 데이터 레이크 저장소에 저장됩니다.  데이터 레이크에는 구조화된 데이터, 구조화되지 않은 데이터, 반구조화된 데이터, 로그, 머신 간 데이터 등 다양한 유형의 데이터가 포함될 수 있습니다.  이러한 모든 데이터 유형은 AI 시스템에서 처리되어야 합니다.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI는 Hadoop 파일 시스템과 호환되지 않습니다.  일반적인 AI 아키텍처는 HDFS 및 HCFS 데이터에 직접 액세스할 수 없으므로, 해당 데이터는 AI가 이해할 수 있는 파일 시스템(NFS)으로 옮겨야 합니다.</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">데이터 레이크 데이터를 AI로 옮기려면 일반적으로 전문적인 프로세스가 필요합니다.  데이터 레이크에 저장되는 데이터의 양은 매우 클 수 있습니다.  고객은 데이터를 AI 시스템으로 옮기는 데 효율적이고 처리량이 높으며 비용 효율적인 방법이 필요합니다.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">데이터 동기화.  고객이 빅데이터 플랫폼과 AI 간에 데이터를 동기화하고 싶어하는 경우, AI를 통해 처리된 데이터를 빅데이터와 함께 사용하여 분석 처리할 수도 있습니다.</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">빅데이터 클러스터에서는 데이터가 MapR-FS, Windows Azure Storage Blob, S3, Google 파일 시스템 등의 HDFS나 HCFS에 저장됩니다.  HDFS, MapR-FS, S3를 소스로 사용하여 NIPAM의 도움으로 NetApp ONTAP NFS 내보내기로 데이터를 복사하고 소스에서 hadoop distcp 명령을 사용하여 테스트를 수행했습니다.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">데이터 무버 솔루션</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">빅데이터 클러스터에서는 데이터가 MapR-FS, Windows Azure Storage Blob, S3, Google 파일 시스템 등의 HDFS나 HCFS에 저장됩니다.  우리는 NIPAM의 도움으로 NetApp ONTAP NFS 내보내기에 데이터를 복사하기 위해 HDFS, MapR-FS 및 S3를 소스로 사용하여 테스트를 수행했습니다.<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> 소스로부터의 명령.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">다음 다이어그램은 NVIDIA AI 작업을 처리할 수 있도록 HDFS 스토리지를 사용하는 Spark 클러스터에서 NetApp ONTAP NFS 볼륨으로 일반적인 데이터 이동을 보여줍니다.</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">그만큼<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> 명령은 MapReduce 프로그램을 사용하여 데이터를 복사합니다.  NIPAM은 Hadoop 클러스터의 드라이버 역할을 하기 위해 MapReduce와 함께 작동하여 데이터를 복사합니다.  NIPAM은 단일 내보내기에 대해 여러 네트워크 인터페이스에 부하를 분산할 수 있습니다.  이 프로세스는 HDFS 또는 HCFS에서 NFS로 데이터를 복사할 때 여러 네트워크 인터페이스에 데이터를 분산시켜 네트워크 처리량을 극대화합니다.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM은 MapR에서 지원 또는 인증을 받지 않았습니다.</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">AI를 위한 데이터 무버 솔루션은 AI 작업에서 Hadoop 데이터를 처리하려는 고객의 요구 사항을 기반으로 합니다.  NetApp NIPAM을 사용하여 HDFS에서 NFS로 데이터를 이동합니다.  한 가지 사용 사례에서 고객은 사내 NFS로 데이터를 옮겨야 했고, 다른 고객은 클라우드의 GPU 클라우드 인스턴스에서 데이터를 처리하기 위해 Windows Azure Storage Blob에서 Google Cloud NetApp Volumes 로 데이터를 옮겨야 했습니다.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">AI를 위한 데이터 무버 솔루션</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">다음 다이어그램은 데이터 이동 솔루션의 세부 정보를 보여줍니다.</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">데이터 무버 솔루션을 구축하려면 다음 단계가 필요합니다.</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN은 HDFS를 제공하고 NAS는 NIPAM을 통해 프로덕션 데이터 레이크 클러스터에 NFS 볼륨을 제공합니다.</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">고객 데이터는 HDFS와 NFS에 있습니다.  NFS 데이터는 빅데이터 분석 및 AI 운영에 사용되는 다른 애플리케이션의 프로덕션 데이터일 수 있습니다.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone 기술은 프로덕션 NFS 볼륨의 복제본을 생성하여 온프레미스 AI 클러스터에 프로비저닝합니다.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">HDFS SAN LUN의 데이터는 NIPAM을 사용하여 NFS 볼륨으로 복사됩니다.<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> 명령.  NIPAM은 여러 네트워크 인터페이스의 대역폭을 사용하여 데이터를 전송합니다.  이 프로세스를 통해 데이터 복사 시간이 줄어들어 더 많은 데이터를 전송할 수 있습니다.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">두 NFS 볼륨 모두 AI 작업을 위해 AI 클러스터에 프로비저닝됩니다.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">클라우드에서 GPU를 사용하여 온프레미스 NFS 데이터를 처리하려면 NFS 볼륨을 NetApp SnapMirror 기술을 사용하여 NetApp Private Storage(NPS)로 미러링하고 GPU용 클라우드 서비스 제공업체에 마운트해야 합니다.</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">고객은 클라우드 서비스 제공업체의 GPU를 사용하여 EC2/EMR, HDInsight 또는 DataProc 서비스의 데이터를 처리하려고 합니다.  Hadoop 데이터 이동기는 Hadoop 서비스에서 NIPAM을 사용하여 Google Cloud NetApp Volumes 로 데이터를 이동합니다.<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Google Cloud NetApp Volumes 데이터는 NFS 프로토콜을 통해 AI에 프로비저닝됩니다. AI를 통해 처리된 데이터는 NIPAM, SnapMirror 및 NPS를 통해 NVIDIA 클러스터 외에도 빅데이터 분석을 위해 온프레미스 위치로 전송될 수 있습니다.</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">이 시나리오에서 고객은 사내 NetApp 스토리지 컨트롤러에서 AI를 처리하는 데 필요한 대용량 파일 수의 데이터를 원격 위치의 NAS 시스템에 보관합니다.  이 시나리오에서는 XCP 마이그레이션 도구를 사용하여 더 빠른 속도로 데이터를 마이그레이션하는 것이 더 좋습니다.</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">하이브리드 사용 사례 고객은 BlueXP Copy and Sync를 사용하여 온프레미스 데이터를 NFS, CIFS 및 S3 데이터에서 클라우드로 마이그레이션하고, 그 반대로 NVIDIA 클러스터에 있는 GPU와 같은 GPU를 사용하여 AI 처리를 수행할 수 있습니다.  BlueXP Copy and Sync와 XCP Migration Tool은 모두 NFS 데이터를 NetApp ONTAP NFS로 마이그레이션하는 데 사용됩니다.</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">이 검증에서는 GPFS에 대한 물리적 디스크를 제공하기 위해 4개의 서버를 네트워크 공유 디스크(NSD) 서버로 사용했습니다.  아래 그림과 같이 GPFS는 NSD 디스크 위에 생성되어 NFS 내보내기 형식으로 내보내어 NFS 클라이언트가 액세스할 수 있도록 합니다.  XCP를 사용하여 GPFS에서 내보낸 NFS의 데이터를 NetApp NFS 볼륨으로 복사했습니다.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS에서 NetApp ONTAP NFS로</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPFS 필수 사항</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS에서는 다음과 같은 노드 유형이 사용됩니다.</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*관리자 노드.*  관리 명령에서 노드 간 통신에 사용되는 노드 이름을 포함하는 선택적 필드를 지정합니다.  예를 들어, 관리 노드<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block> 클러스터의 다른 모든 노드에 네트워크 검사를 전달할 수 있습니다.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*쿼럼 노드.*  쿼럼이 파생된 노드 풀에 노드가 포함되는지 여부를 결정합니다.  최소한 하나의 노드가 쿼럼 노드로 필요합니다.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*관리자 노드.*  노드가 파일 시스템 관리자와 토큰 관리자를 선택할 수 있는 노드 풀에 속하는지 여부를 나타냅니다.  두 개 이상의 노드를 관리자 노드로 정의하는 것이 좋습니다.  관리자로 지정하는 노드 수는 작업 부하와 보유한 GPFS 서버 라이선스 수에 따라 달라집니다.  대규모 병렬 작업을 실행하는 경우 웹 애플리케이션을 지원하는 4노드 클러스터보다 더 많은 관리자 노드가 필요할 수 있습니다.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD 서버.*  GPFS와 함께 사용할 각 물리적 디스크를 준비하는 서버입니다.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*프로토콜 노드.*  NFS와 Secure Shell(SSH) 프로토콜을 통해 GPFS 데이터를 직접 공유하는 노드입니다.  이 노드에는 GPFS 서버 라이센스가 필요합니다.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS, NFS 및 XCP에 대한 작업 목록</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">이 섹션에서는 GPFS를 생성하고, GPFS를 NFS 내보내기로 내보내고, XCP를 사용하여 데이터를 전송하는 작업 목록을 제공합니다.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFS 생성</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">GPFS를 생성하려면 다음 단계를 완료하세요.</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">Linux 버전용 Spectrum-Scale Data Access를 서버 중 하나에 다운로드하여 설치합니다.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">모든 노드에 필수 패키지(예: chef)를 설치하고 모든 노드에서 SELinux(Security-Enhanced Linux)를 비활성화합니다.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">설치 노드를 설정하고 관리 노드와 GPFS 노드를 클러스터 정의 파일에 추가합니다.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">관리자 노드, 쿼럼 노드, NSD 서버, GPFS 노드를 추가합니다.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">GUI, 관리자, GPFS 노드를 추가하고, 필요한 경우 추가 GUI 서버를 추가합니다.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">다른 GPFS 노드를 추가하고 모든 노드 목록을 확인합니다.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">클러스터 정의 파일에서 모든 GPFS 노드에 설정할 클러스터 이름, 프로필, 원격 셸 바이너리, 원격 파일 복사 바이너리 및 포트 범위를 지정합니다.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">GPFS 구성 설정을 보고 추가 관리 노드를 추가합니다.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">데이터 수집을 비활성화하고 데이터 패키지를 IBM 지원 센터에 업로드합니다.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">설치 전에 NTP를 활성화하고 구성을 미리 확인하세요.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">NSD 디스크를 구성, 생성 및 확인합니다.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">GPFS을 생성합니다.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">GPFS를 마운트합니다.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">GPFS에 필요한 권한을 확인하고 제공합니다.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">다음을 실행하여 GPFS 읽기 및 쓰기를 확인하세요.<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFS를 NFS로 내보내기</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">GPFS를 NFS로 내보내려면 다음 단계를 완료하세요.</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">GPFS를 NFS로 내보내기<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> 파일.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">필요한 NFS 서버 패키지를 설치합니다.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">NFS 서비스를 시작합니다.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">NFS 클라이언트를 검증하기 위해 GPFS에 있는 파일을 나열합니다.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">NFS 클라이언트 구성</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">NFS 클라이언트를 구성하려면 다음 단계를 완료하세요.</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">GPFS를 NFS로 내보내기<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block> 파일.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">NFS 클라이언트 서비스를 시작합니다.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">NFS 클라이언트에서 NFS 프로토콜을 통해 GPFS를 마운트합니다.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">NFS로 마운트된 폴더의 GPFS 파일 목록을 검증합니다.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">XCP를 사용하여 GPFS에서 내보낸 NFS의 데이터를 NetApp NFS로 이동합니다.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">NFS 클라이언트에서 GPFS 파일을 검증합니다.</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">이 섹션에서는 NetApp XCP를 사용하여 GPFS를 구성하고 데이터를 NFS로 이동하는 데 필요한 자세한 단계를 제공합니다.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS에서 NFS로의 자세한 단계</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">GPFS 구성</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">Linux용 Spectrum Scale Data Access를 서버 중 하나에 다운로드하여 설치합니다.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">모든 노드에 필수 패키지(chef 및 커널 헤더 포함)를 설치합니다.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">모든 노드에서 SELinux를 비활성화합니다.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">설치 노드를 설정합니다.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">클러스터 정의 파일에 관리 노드와 GPFS 노드를 추가합니다.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">관리자 노드와 GPFS 노드를 추가합니다.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">쿼럼 노드와 GPFS 노드를 추가합니다.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">NSD 서버와 GPFS 노드를 추가합니다.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">GUI, 관리자, GPFS 노드를 추가합니다.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">GUI 서버를 하나 더 추가합니다.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">다른 GPFS 노드를 추가합니다.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">모든 노드를 확인하고 나열합니다.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">클러스터 정의 파일에 클러스터 이름을 지정합니다.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">프로필을 지정하세요.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">GPFS에서 사용할 원격 셸 바이너리를 지정합니다.<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block> .</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">GPFS에서 사용할 원격 파일 복사 바이너리를 지정합니다.<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block> .</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">모든 GPFS 노드에 설정할 포트 범위를 지정합니다.<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block> .</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">GPFS 구성 설정을 확인합니다.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">관리 노드를 추가합니다.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">NTP를 활성화합니다.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">설치하기 전에 구성을 미리 확인하세요.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">NSD 디스크를 구성합니다.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">NSD 디스크를 만듭니다.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">NSD 디스크 상태를 확인하세요.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">GPFS에 필요한 권한을 확인하고 제공하세요.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">다음을 실행하여 GPFS 읽기 및 쓰기를 확인하세요.<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">GPFS를 NFS로 내보내려면 다음 단계를 완료하세요.</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">NFS 클라이언트를 검증하기 위해 GPFS에 있는 파일을 나열합니다.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">NFS 클라이언트 구성</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">NFS 클라이언트에 패키지를 설치합니다.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">NFS로 마운트된 폴더의 GPFS 파일 목록을 검증합니다.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">XCP를 사용하여 GPFS에서 내보낸 NFS에서 NetApp NFS로 데이터를 이동합니다.</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">이 솔루션의 경우 NetApp 데이터 레이크(HDFS) 및 MapR 클러스터 데이터에서 ONTAP NFS로의 데이터 마이그레이션을 검증했습니다.  데이터는 MapR-FS와 HDFS에 저장되었습니다.  NetApp XCP는 HDFS 및 MapR-FS와 같은 분산 파일 시스템에서 ONTAP NFS로 데이터를 직접 마이그레이션하는 새로운 기능을 도입했습니다.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS 및 MapR-FS에서 ONTAP NFS로</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">이 솔루션의 경우 NetApp 데이터 레이크(HDFS) 및 MapR 클러스터 데이터에서 ONTAP NFS로의 데이터 마이그레이션을 검증했습니다.  데이터는 MapR-FS와 HDFS에 저장되었습니다.  NetApp XCP는 HDFS 및 MapR-FS와 같은 분산 파일 시스템에서 ONTAP NFS로 데이터를 직접 마이그레이션하는 새로운 기능을 도입했습니다.  XCP는 비동기 스레드와 HDFS C API 호출을 사용하여 MapR-FS와 HDFS 간에 데이터를 통신하고 전송합니다.</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">아래 그림은 데이터 레이크(HDFS)와 MapR-FS에서 ONTAP NFS로의 데이터 마이그레이션을 보여줍니다.  이 새로운 기능을 사용하면 소스를 NFS 공유로 내보낼 필요가 없습니다.</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">고객이 HDFS와 MapR-FS에서 NFS로 이동하는 이유는 무엇입니까?</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">Cloudera, Hortonworks 등 대부분의 Hadoop 배포판은 HDFS를 사용하고 MapR 배포판은 Mapr-FS라는 자체 파일 시스템을 사용하여 데이터를 저장합니다.  HDFS와 MapR-FS 데이터는 머신 러닝(ML)과 딥 러닝(DL)에 활용할 수 있는 귀중한 통찰력을 데이터 과학자에게 제공합니다.  HDFS와 MapR-FS의 데이터는 공유되지 않으므로 다른 애플리케이션에서 사용할 수 없습니다.  고객은 공유 데이터를 찾고 있으며, 특히 고객의 민감한 데이터가 여러 애플리케이션에서 사용되는 은행 부문에서 그렇습니다.  Hadoop의 최신 버전(3.x 이상)은 추가적인 타사 소프트웨어 없이 액세스할 수 있는 NFS 데이터 소스를 지원합니다.  새로운 NetApp XCP 기능을 사용하면 HDFS 및 MapR-FS에서 NetApp NFS로 직접 데이터를 이동하여 여러 애플리케이션에 액세스할 수 있습니다.</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">초기 성능 테스트를 위해 12개의 MAPR 노드와 4개의 NFS 서버를 사용하여 MapR-FS에서 NFS로 데이터를 전송하는 테스트는 Amazon Web Services(AWS)에서 수행되었습니다.</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">수량</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">크기</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">메모리</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">스토리지</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">회로망</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS 서버</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x 7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR 노드</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x 7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">초기 테스트 결과, 20GBps 처리량을 얻었고 하루에 2PB의 데이터를 전송할 수 있었습니다.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863: NetApp XCP - 데이터 무버, 파일 마이그레이션 및 분석을 위한 모범 사례 지침</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">HDFS를 NFS로 내보내지 않고 HDFS 데이터 마이그레이션에 대한 자세한 내용은 "배포 단계 - NAS" 섹션을 참조하세요.<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block> .</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">이 논문에서는 NetApp XCP와 NIPAM을 사용하여 빅데이터 분석 데이터와 HPC 데이터를 AI로 옮기는 방법에 대한 지침을 제공합니다.  또한 빅데이터와 HPC에서 AI로 데이터를 옮기는 비즈니스 이점에 대해서도 논의합니다.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: 빅데이터 분석 데이터를 인공지능으로</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">Karthikeyan Nagalingam, NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">이 문서에서는 빅데이터 분석 데이터와 HPC 데이터를 AI로 옮기는 방법을 설명합니다.  AI는 NFS 내보내기를 통해 NFS 데이터를 처리하는 반면, 고객은 종종 HDFS, Blob, S3 스토리지와 같은 빅데이터 분석 플랫폼이나 GPFS와 같은 HPC 플랫폼에 AI 데이터를 보관합니다.  이 논문에서는 NetApp XCP와 NIPAM을 사용하여 빅데이터 분석 데이터와 HPC 데이터를 AI로 옮기는 방법에 대한 지침을 제공합니다.  또한 빅데이터와 HPC에서 AI로 데이터를 옮기는 비즈니스 이점에 대해서도 논의합니다.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">개념 및 구성 요소</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">빅데이터 분석 저장</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">빅데이터 분석은 HDFS의 주요 저장 제공자입니다.  고객은 종종 Windows Azure Blob Storage, MapR File System(MapR-FS), S3 개체 스토리지와 같은 Hadoop 호환 파일 시스템(HCFS)을 사용합니다.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">일반 병렬 파일 시스템</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">IBM의 GPFS는 HDFS에 대한 대안을 제공하는 엔터프라이즈 파일 시스템입니다.  GPFS는 애플리케이션이 블록 크기와 복제 레이아웃을 결정할 수 있는 유연성을 제공하여 뛰어난 성능과 효율성을 제공합니다.</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">NetApp In-Place 분석 모듈</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">NetApp In-Place Analytics Module(NIPAM)은 Hadoop 클러스터가 NFS 데이터에 액세스하기 위한 드라이버 역할을 합니다.  여기에는 연결 풀, NFS 입력 스트림, 파일 핸들 캐시, NFS 출력 스트림의 4가지 구성 요소가 있습니다. 자세한 내용은 다음을 참조하세요. <block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> .</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop 분산 복사</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy(DistCp)는 대규모 클러스터 간 및 클러스터 내 대처 작업에 사용되는 분산 복사 도구입니다.  이 도구는 데이터 배포, 오류 처리, 보고를 위해 MapReduce를 사용합니다.  파일과 디렉토리 목록을 확장하고 이를 맵 작업에 입력하여 소스 목록에서 데이터를 복사합니다.  아래 이미지는 HDFS와 nonHDFS에서의 DistCp 작업을 보여줍니다.</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp는 추가 드라이버를 사용하지 않고 두 HDFS 시스템 간에 데이터를 이동합니다.  NetApp HDFS가 아닌 시스템에 대한 드라이버를 제공합니다.  NFS 대상의 경우, NIPAM은 Hadoop DistCp가 데이터를 복사할 때 NFS 대상과 통신하는 데 사용하는 데이터를 복사하기 위한 드라이버를 제공합니다.</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Google Cloud NetApp Volumes 뛰어난 성능을 갖춘 클라우드 기반 파일 서비스입니다.  이 서비스는 고객이 리소스를 빠르게 확장 및 축소하고 NetApp 기능을 사용하여 생산성을 향상시키고 직원의 가동 중지 시간을 줄임으로써 시장 출시 시간을 단축하는 데 도움이 됩니다.  Google Cloud NetApp Volumes 재해 복구와 클라우드 백업을 위한 올바른 대안으로, 전체 데이터 센터 공간을 줄이고 기본 퍼블릭 클라우드 스토리지 사용량을 줄입니다.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP는 빠르고 안정적인 any-to- NetApp 및 NetApp-to- NetApp 데이터 마이그레이션을 가능하게 하는 클라이언트 소프트웨어입니다.  이 도구는 대량의 비정형 NAS 데이터를 모든 NAS 시스템에서 NetApp 스토리지 컨트롤러로 복사하도록 설계되었습니다.  XCP 마이그레이션 도구는 데이터 마이그레이션, 파일 또는 디렉토리 목록, 공간 보고 등 많은 요청을 병렬로 처리할 수 있는 멀티코어, 멀티채널 I/O 스트리밍 엔진을 사용합니다.  이는 기본 NetApp 데이터 마이그레이션 도구입니다.  XCP를 사용하면 Hadoop 클러스터와 HPC에서 NetApp NFS 스토리지로 데이터를 복사할 수 있습니다.  아래 다이어그램은 XCP를 사용하여 Hadoop 및 HPC 클러스터에서 NetApp NFS 볼륨으로 데이터를 전송하는 과정을 보여줍니다.</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">NetApp BlueXP 복사 및 동기화</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync는 온프레미스 스토리지와 클라우드 스토리지 간에 NFS, S3, CIFS 데이터를 원활하고 안전하게 전송하고 동기화하는 하이브리드 데이터 복제 소프트웨어입니다.  이 소프트웨어는 데이터 마이그레이션, 보관, 협업, 분석 등에 사용됩니다.  데이터가 전송된 후, BlueXP Copy and Sync는 소스와 대상 간의 데이터를 지속적으로 동기화합니다.  앞으로는 델타를 전송합니다.  또한 자체 네트워크, 클라우드 또는 사내 데이터의 보안도 강화됩니다.  이 소프트웨어는 사용량에 따라 비용을 지불하는 모델을 기반으로 하며, 비용 효율적인 솔루션을 제공하고 데이터 전송에 대한 모니터링 및 보고 기능을 제공합니다.</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">이 섹션에서는 NetApp XCP를 사용하여 MapR-FS 데이터를 ONTAP NFS로 이동하는 데 필요한 자세한 단계를 제공합니다.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS에서 ONTAP NFS로</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">각 MapR 노드에 대해 3개의 LUN을 제공하고 LUN에 모든 MapR 노드의 소유권을 부여합니다.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">설치 중에 MapR-FS에 사용되는 MapR 클러스터 디스크에 새로 추가된 LUN을 선택합니다.</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">MapR 6.1 문서에 따라 MapR 클러스터를 설치합니다.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">MapReduce 명령을 사용하여 기본 Hadoop 작업을 확인합니다.<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block> .</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">고객 데이터를 MapR-FS에 보관합니다.  예를 들어, 우리는 Teragen을 사용하여 MapR-FS에서 약 1테라바이트의 샘플 데이터를 생성했습니다.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">MapR-FS를 NFS 내보내기로 구성합니다.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">모든 MapR 노드에서 nlockmgr 서비스를 비활성화합니다.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">MapR 노드의 모든 MapR-FS에서 특정 폴더를 내보냅니다.<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block> 파일.  하위 폴더를 내보낼 때 다른 권한이 있는 부모 폴더를 내보내지 마세요.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">MapR-FS NFS 서비스를 새로 고칩니다.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">MapR 클러스터의 특정 서버나 서버 세트에 가상 IP 범위를 할당합니다.  그런 다음 MapR 클러스터는 NFS 데이터 액세스를 위해 특정 서버에 IP를 할당합니다.  IP는 고가용성을 가능하게 합니다. 즉, 특정 IP를 사용하는 서버나 네트워크에 장애가 발생하면 해당 IP 범위의 다음 IP를 NFS 액세스에 사용할 수 있습니다.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">모든 MapR 노드에서 NFS 액세스를 제공하려면 각 서버에 가상 IP 세트를 할당하고 각 MapR 노드의 리소스를 NFS 데이터 액세스에 사용할 수 있습니다.</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">각 MapR 노드에 할당된 가상 IP를 확인하고 이를 NFS 데이터 액세스에 사용합니다.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">NFS 작업을 확인하기 위해 할당된 가상 IP를 사용하여 NFS로 내보낸 MapR-FS를 마운트합니다.  하지만 NetApp XCP를 사용하여 데이터를 전송하는 경우에는 이 단계가 필요하지 않습니다.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">MapR-FS NFS 게이트웨이에서 ONTAP NFS로 데이터를 전송하도록 NetApp XCP를 구성합니다.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">XCP에 대한 카탈로그 위치를 구성합니다.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">라이센스 파일을 복사하세요<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block> .</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">XCP를 사용하여 활성화하세요<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">NFS 내보내기의 소스를 확인하세요.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">여러 소스 IP와 여러 대상 IP(ONTAP LIF)에서 여러 MapR 노드의 XCP를 사용하여 데이터를 전송합니다.</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">저장 컨트롤러의 부하 분산을 확인하세요.</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">이러한 검증을 기반으로 데이터 과학자와 엔지니어는 NetApp Cloud Volumes ONTAP 의 S3 버킷을 통해 AWS SageMaker Jupyter Notebooks에서 NFS 데이터에 액세스할 수 있습니다.  이 접근 방식을 사용하면 추가 소프트웨어가 필요 없이 NFS와 S3 모두에서 동일한 데이터에 쉽게 액세스하고 공유할 수 있습니다.</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">SageMaker BlazingText를 사용한 텍스트 분류</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">S3 객체 스토리지에 대한 ONTAP 버전 지원</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">데이터는 NFS에서 사용할 수 있으며 AWS SageMaker의 S3에서 액세스할 수 있습니다.</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">데이터 과학자 및 기타 애플리케이션을 위한 데이터 이중성</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">기술 요구 사항</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">데이터 이중성 사용 사례에는 NetApp BlueXP, NetApp Cloud Volumes ONTAP 및 AWS SageMaker Notebooks가 필요합니다.</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">소프트웨어 요구 사항</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">다음 표는 사용 사례를 구현하는 데 필요한 소프트웨어 구성 요소를 나열합니다.</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetApp Cloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">AWS SageMaker 노트북</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">배포 절차</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">데이터 이중성 솔루션을 배포하려면 다음 작업이 필요합니다.</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">BlueXP 커넥터</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">머신러닝을 위한 데이터</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Jupyter Notebooks에서 검증된 머신 러닝</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">BlueXP 커넥터</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">이 검증에서는 AWS를 사용했습니다.  Azure와 Google Cloud에도 적용할 수 있습니다.  AWS에서 BlueXP 커넥터를 생성하려면 다음 단계를 완료하세요.</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">우리는 BlueXP 의 mcarl-marketplace-subscription에 기반한 자격 증명을 사용했습니다.</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">사용자 환경에 적합한 지역(예: us-east-1[N. Virginia])을 선택하고 인증 방법(예: 역할 가정 또는 AWS 키)을 선택합니다.  이 검증에서는 AWS 키를 사용합니다.</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">커넥터의 이름을 제공하고 역할을 만듭니다.</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">공용 IP가 필요한지 여부에 따라 VPC, 서브넷 또는 키 쌍과 같은 네트워크 세부 정보를 제공합니다.</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">소스 유형에서 HTTP, HTTPS 또는 SSH 액세스와 같은 보안 그룹에 대한 세부 정보(어디서나 가능, IP 범위 정보 등)를 제공합니다.</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">BlueXP 커넥터를 검토하고 생성합니다.</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">AWS 콘솔에서 BlueXP EC2 인스턴스 상태가 실행 중인지 확인하고, *네트워킹* 탭에서 IP 주소를 확인하세요.</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">BlueXP 포털에서 커넥터 사용자 인터페이스에 로그인하거나 브라우저에서 IP 주소를 사용하여 액세스할 수 있습니다.</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">BlueXP 에서 Cloud Volumes ONTAP 인스턴스를 생성하려면 다음 단계를 완료하세요.</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">새로운 작업 환경을 만들고, 클라우드 공급자를 선택하고, Cloud Volumes ONTAP 인스턴스 유형(단일 CVO, HA 또는 ONTAP 용 Amazon FSx ONTAP 등)을 선택합니다.</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Cloud Volumes ONTAP 클러스터 이름 및 자격 증명과 같은 세부 정보를 제공합니다.  이 검증에서 우리는 Cloud Volumes ONTAP 인스턴스를 생성했습니다.<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> .</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Cloud Volumes ONTAP 에 필요한 서비스를 선택하세요.  이 검증에서는 모니터링만 하기로 했기 때문에 *데이터 감지 및 규정 준수*와 *클라우드 서비스에 대한 백업*을 비활성화했습니다.</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">*위치 및 연결* 섹션에서 AWS 지역, VPC, 서브넷, 보안 그룹, SSH 인증 방법, 비밀번호 또는 키 쌍을 선택합니다.</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">충전 방법을 선택하세요.  이 검증에는 *전문가* 모드를 사용했습니다.</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">*POC 및 소규모 워크로드*, *데이터베이스 및 애플리케이션 데이터 프로덕션 워크로드*, *비용 효율적인 DR* 또는 *최고 성능 프로덕션 워크로드*와 같은 미리 구성된 패키지를 선택할 수 있습니다.  이 검증에서는 *Poc 및 소규모 워크로드*를 선택합니다.</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">특정 크기, 허용되는 프로토콜, 내보내기 옵션으로 볼륨을 생성합니다.  이 검증에서 우리는 볼륨이라는 것을 생성했습니다.<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">프로필 디스크 유형과 계층화 정책을 선택하세요.  이 검증 과정에서는 *저장소 효율성*과 *범용 SSD - 동적 성능*을 비활성화했습니다.</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">마지막으로 Cloud Volumes ONTAP 인스턴스를 검토하고 생성합니다.  그런 다음 BlueXP 가 Cloud Volumes ONTAP 작업 환경을 생성하는 동안 15~20분 정도 기다립니다.</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Duality 프로토콜을 활성화하려면 다음 매개변수를 구성하세요.  Duality 프로토콜(NFS/S3)은 ONTAP 9부터 지원됩니다.  12.1 이상.</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">이 검증에서 우리는 SVM을 생성했습니다.<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> 그리고 볼륨<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> .</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">SVM이 NFS 및 S3에 대한 프로토콜을 지원하는지 확인하세요.  그렇지 않은 경우 이를 지원하도록 SVM을 수정하세요.</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">필요한 경우 CA 인증서를 만들고 설치합니다.</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">서비스 데이터 정책을 만듭니다.</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">집계 세부 정보를 확인하세요.</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">사용자와 그룹을 만듭니다.</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">NFS 볼륨에 버킷을 생성합니다.</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">AWS SageMaker에서 AWS Notebook을 만들려면 다음 단계를 완료하세요.</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">Notebook 인스턴스를 생성하는 사용자에게 AmazonSageMakerFullAccess IAM 정책이 있는지 또는 AmazonSageMakerFullAccess 권한이 있는 기존 그룹에 속해 있는지 확인하세요.  이 검증에서 사용자는 기존 그룹의 일부입니다.</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">다음 정보를 제공하세요.</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">노트북 인스턴스 이름.</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">인스턴스 유형.</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">플랫폼 식별자.</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">AmazonSageMakerFullAccess 권한이 있는 IAM 역할을 선택합니다.</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">루트 접근 - 활성화.</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">암호화 키 - 사용자 정의 암호화를 선택하지 않습니다.</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">나머지 기본 옵션은 그대로 둡니다.</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">이 검증에서 SageMaker 인스턴스 세부 정보는 다음과 같습니다.</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">해당 단계를 묘사한 스크린샷.</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">AWS Notebook을 시작합니다.</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Jupyter 랩을 엽니다.</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">터미널에 로그인하여 Cloud Volumes ONTAP 볼륨을 마운트합니다.</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">AWS CLI 명령을 사용하여 Cloud Volumes ONTAP 볼륨에 생성된 버킷을 확인합니다.</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">이 검증 과정에서 우리는 크라우드 소싱 커뮤니티 활동인 DBpedia의 데이터 세트를 사용하여 다양한 위키미디어 프로젝트에서 생성된 정보로부터 구조화된 콘텐츠를 추출했습니다.</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">DBpedia GitHub 위치에서 데이터를 다운로드하고 추출합니다.  이전 섹션에서 사용한 것과 동일한 터미널을 사용하세요.</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">데이터를 Cloud Volumes ONTAP 위치로 복사한 다음 AWS CLI를 사용하여 S3 버킷에서 확인합니다.</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">기본 검증을 수행하여 S3 버킷에서 읽기/쓰기 기능이 작동하는지 확인합니다.</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Jupyter Notebooks에서 머신 러닝 검증</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">다음 검증은 아래의 SageMaker BlazingText 예제를 사용하여 텍스트 분류를 통해 머신 러닝 모델을 빌드, 학습 및 배포하는 방법을 제공합니다.</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">boto3 및 SageMaker 패키지를 설치합니다.</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">산출:</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">다음 단계에서는 데이터<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block> )은 s3 버킷에서 다운로드됩니다.<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> 머신 러닝에 사용되는 Jupyter Notebook 인스턴스로.</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">다음 코드는 추론 중에 실제 클래스 이름을 검색하는 데 사용되는 정수 인덱스에서 클래스 레이블로의 매핑을 생성합니다.</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">출력에는 파일과 폴더가 나열됩니다.<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> AWS SageMaker 머신 러닝 검증을 위한 데이터로 사용되는 버킷입니다.</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">데이터 전처리 단계를 시작하여 훈련 데이터를 공백으로 구분된 토큰화된 텍스트 형식으로 전처리합니다. 이 텍스트는 BlazingText 알고리즘과 nltk 라이브러리에서 사용되어 DBPedia 데이터 세트의 입력 문장을 토큰화합니다.  nltk 토크나이저와 기타 라이브러리를 다운로드하세요.  그만큼<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block> 각 데이터 인스턴스에 병렬로 적용하려면 Python multiprocessing 모듈을 사용합니다.</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">포맷된 학습 데이터 세트를 S3에 업로드하여 SageMaker에서 학습 작업을 실행할 수 있도록 합니다.  그런 다음 Python SDK를 사용하여 두 개의 파일을 버킷과 접두사 위치에 업로드합니다.</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">모델 아티팩트가 로드되는 S3에 출력 위치를 설정하여 아티팩트가 알고리즘의 학습 작업의 출력이 될 수 있도록 합니다.  생성하다<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block> 훈련 작업을 시작하기 위한 객체입니다.</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">SageMaker 정의<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block> DBPedia 데이터세트에서 c4.4xlarge 인스턴스의 감독 모드를 사용하여 텍스트 분류를 훈련하기 위한 리소스 구성과 하이퍼파라미터를 사용합니다.</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">데이터 채널과 알고리즘 간의 핸드셰이크를 준비합니다.  이를 위해 다음을 생성합니다.<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block> 데이터 채널의 객체를 알고리즘이 사용할 수 있도록 사전에 보관합니다.</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">작업이 완료되면 작업 완료 메시지가 나타납니다.  훈련된 모델은 설정된 S3 버킷에서 찾을 수 있습니다.<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block> 추정자에서.</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">학습이 완료되면 학습된 모델을 Amazon SageMaker 실시간 호스팅 엔드포인트로 배포하여 예측을 수행합니다.</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">기본적으로 모델은 확률이 가장 높은 예측 하나를 반환합니다.  상단을 검색하려면<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> 예측, 설정<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block> 구성 파일에서.</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">노트북을 닫기 전에 엔드포인트를 삭제하세요.</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">데이터 과학자와 엔지니어는 종종 NFS 형식으로 저장된 데이터에 액세스해야 하지만, AWS SageMaker의 S3 프로토콜에서 직접 이 데이터에 액세스하는 것은 어려울 수 있습니다. AWS는 S3 버킷 액세스만 지원하기 때문입니다.  하지만 NetApp ONTAP NFS와 S3에 대한 이중 프로토콜 액세스를 활성화하여 솔루션을 제공합니다.  이 솔루션을 사용하면 데이터 과학자와 엔지니어가 NetApp Cloud Volumes ONTAP 의 S3 버킷을 통해 AWS SageMaker 노트북에서 NFS 데이터에 액세스할 수 있습니다.  이 접근 방식을 사용하면 추가 소프트웨어가 필요 없이 NFS와 S3 모두에서 동일한 데이터에 쉽게 액세스하고 공유할 수 있습니다.</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967: NetApp 파일-객체 이중성 및 AWS SageMaker를 활용한 클라우드 데이터 관리</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">NFS와 S3의 이중 프로토콜 액세스에 대한 잠재적 사용 사례로는 머신 러닝과 데이터 과학 분야가 있습니다.  예를 들어, 데이터 과학자 팀이 AWS SageMaker를 사용하여 머신 러닝 프로젝트를 진행하는 경우, NFS 형식으로 저장된 데이터에 액세스해야 합니다.  하지만 다른 팀원과 협업하거나 S3를 사용하는 다른 애플리케이션과 통합하기 위해 S3 버킷을 통해 데이터에 액세스하고 공유해야 할 수도 있습니다.</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">이 솔루션은 다음 기술을 활용합니다.</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*AWS SageMaker 노트북.*  개발자와 데이터 과학자에게 머신 러닝 기능을 제공하여 고품질 ML 모델을 효율적으로 만들고, 학습시키고, 배포할 수 있도록 지원합니다.</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP.*  온프레미스뿐 아니라 AWS, Azure, Google Cloud에서도 스토리지를 검색, 배포, 운영할 수 있습니다.  데이터 손실, 사이버 위협, 계획되지 않은 중단으로부터 데이터를 보호하고 데이터 저장소와 인프라를 최적화합니다.</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP.*  AWS, Azure, Google Cloud에서 NFS, SMB/CIFS, iSCSI, S3 프로토콜을 갖춘 엔터프라이즈급 스토리지 볼륨을 제공하여 사용자가 클라우드에서 데이터에 액세스하고 관리할 수 있는 유연성을 높여줍니다.</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">BlueXP 에서 생성된 NetApp Cloud Volumes ONTAP ML 데이터를 저장합니다.</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">다음 그림은 솔루션의 기술적 구성 요소를 보여줍니다.</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">이 그림은 솔루션의 기술적 구성 요소를 보여줍니다.</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">NetApp Cloud Volumes ONTAP 활용함으로써 팀은 데이터를 단일 위치에 저장하고 NFS와 S3 프로토콜을 모두 사용하여 액세스할 수 있습니다.  데이터 과학자는 AWS SageMaker에서 직접 NFS 형식의 데이터에 액세스할 수 있으며, 다른 팀원이나 애플리케이션은 S3 버킷을 통해 동일한 데이터에 액세스할 수 있습니다.</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">이러한 접근 방식을 사용하면 추가 소프트웨어나 서로 다른 저장 솔루션 간의 데이터 마이그레이션이 필요 없이 쉽고 효율적으로 데이터에 액세스하고 공유할 수 있습니다.  또한 팀원 간의 워크플로와 협업이 간소화되어 머신 러닝 모델을 더 빠르고 효과적으로 개발할 수 있습니다.</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">이 문서에서는 Confluent Kafka 인증 테스트, 성능 결과, 튜닝, Kafka 커넥터 및 자체 리밸런싱 기능을 포함하여 NetApp 스토리지와 함께 Kafka를 사용하기 위한 모범 사례 가이드라인을 제공합니다.</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">이 문서에서는 검증 테스트, 계층형 스토리지 성능 결과, 튜닝, Confluent S3 커넥터, 셀프 밸런싱 기능을 포함하여 NetApp 스토리지와 함께 Confluent Tiered Storage를 사용하기 위한 모범 사례 가이드라인을 제공합니다.  ILM 정책, 검증을 위한 여러 성능 테스트를 통한 Confluent 성능, 업계 표준 S3 API를 고려할 때 NetApp StorageGRID 개체 스토리지는 Confluent 계층형 스토리지에 최적의 선택입니다.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Apache Kafka란 무엇입니까?</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3-싱크 매개변수 세부 정보</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">아파치 카프카</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Confluent 플랫폼의 무한 스토리지</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent Tiered Storage - 모범 사례 및 크기 조정</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Confluent Platform용 Amazon S3 싱크 커넥터</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">카프카 크기 조정</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID 크기 조정</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">카프카 사용 사례</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Confluent 플랫폼 6.0에서 Kafka 클러스터의 자체 균형 조정</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">이 문서에서는 NetApp 스토리지 컨트롤러에서 Kafka를 사용하기 위한 모범 사례 가이드라인을 설명합니다.</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam, Joseph Kandatilparambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka는 하루에 수조 개의 이벤트를 처리할 수 있는 커뮤니티 분산형 이벤트 스트리밍 플랫폼입니다.  처음에는 메시징 큐로 구상되었지만, 카프카는 분산 커밋 로그의 추상화를 기반으로 합니다.  카프카는 2011년 LinkedIn에서 개발되어 오픈 소스로 공개된 이후 메시지 큐에서 본격적인 이벤트 스트리밍 플랫폼으로 발전했습니다.  Confluent는 Confluent Platform을 통해 Apache Kafka를 배포합니다.  Confluent 플랫폼은 Kafka에 커뮤니티 및 상용 기능을 추가하여 대규모 프로덕션 환경에서 운영자와 개발자 모두의 스트리밍 경험을 향상시키도록 설계되었습니다.</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">이 문서에서는 NetApp의 개체 스토리지 제품에서 Confluent Tiered Storage를 사용하기 위한 모범 사례 가이드라인을 설명하며, 다음과 같은 내용을 제공합니다.</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">NetApp Object Storage를 통한 Confluent 검증 – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">계층형 스토리지 성능 테스트</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">NetApp 스토리지 시스템에서 Confluent를 위한 모범 사례 가이드라인</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Confluent Tiered Storage를 선택해야 하는 이유는 무엇인가요?</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">Confluent의 이 기사</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent는 특히 빅데이터, 분석 및 스트리밍 워크로드를 위한 다양한 애플리케이션의 기본 실시간 스트리밍 플랫폼이 되었습니다.  계층형 스토리지를 사용하면 사용자가 Confluent 플랫폼에서 컴퓨팅과 스토리지를 분리할 수 있습니다.  이를 통해 데이터 저장의 비용 효율성이 높아지고, 사실상 무한한 양의 데이터를 저장하고 필요에 따라 작업 부하를 확장(또는 축소)할 수 있으며, 데이터 및 테넌트 재조정과 같은 관리 작업이 더 쉬워집니다.  S3 호환 스토리지 시스템은 이러한 모든 기능을 활용하여 모든 이벤트를 한곳에서 관리함으로써 데이터를 민주화하고 복잡한 데이터 엔지니어링의 필요성을 없앨 수 있습니다.  Kafka에 계층형 스토리지를 사용해야 하는 이유에 대한 자세한 내용은 다음을 확인하세요.<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block> .</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">계층형 스토리지에 NetApp StorageGRID 사용해야 하는 이유는 무엇인가요?</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID 는 NetApp 이 제공하는 업계 최고의 객체 스토리지 플랫폼입니다.  StorageGRID Amazon Simple Storage Service(S3) API를 비롯한 업계 표준 객체 API를 지원하는 소프트웨어 정의 객체 기반 스토리지 솔루션입니다.  StorageGRID 대규모로 비정형 데이터를 저장하고 관리하여 안전하고 내구성 있는 객체 스토리지를 제공합니다.  콘텐츠는 적절한 위치, 적절한 시간, 적절한 저장 계층에 배치되어 워크플로를 최적화하고 전 세계적으로 분산된 리치 미디어의 비용을 절감합니다.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID 의 가장 큰 차별화 요소는 정책 기반의 데이터 수명 주기 관리를 지원하는 정보 수명 주기 관리(ILM) 정책 엔진입니다.  정책 엔진은 메타데이터를 사용하여 데이터가 수명 동안 저장되는 방식을 관리하여 초기에는 성능을 최적화하고, 데이터가 오래됨에 따라 비용과 내구성을 자동으로 최적화할 수 있습니다.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Confluent 계층형 스토리지 활성화</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">계층형 스토리지의 기본 아이디어는 데이터 저장 작업과 데이터 처리를 분리하는 것입니다.  이러한 분리를 통해 데이터 저장 계층과 데이터 처리 계층이 독립적으로 확장하기가 훨씬 쉬워집니다.</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Confluent의 계층형 스토리지 솔루션은 두 가지 요소를 고려해야 합니다.  첫째, LIST 작업의 불일치나 가끔씩 발생하는 객체 사용 불가 등 공통적인 객체 저장소의 일관성 및 가용성 속성을 해결하거나 방지해야 합니다.  둘째, 계층형 스토리지와 카프카의 복제 및 장애 허용 모델 간의 상호 작용을 올바르게 처리해야 하며, 여기에는 좀비 리더가 계속해서 계층 오프셋 범위를 유지할 가능성이 포함됩니다.  NetApp 개체 스토리지는 일관된 개체 가용성과 HA 모델을 모두 제공하여 피곤한 스토리지를 계층 오프셋 범위에 사용할 수 있도록 합니다.  NetApp 개체 스토리지는 일관된 개체 가용성과 HA 모델을 제공하여 소모된 스토리지를 계층 오프셋 범위에 사용할 수 있도록 합니다.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">계층형 스토리지를 사용하면 스트리밍 데이터의 끝부분에 가까운 저지연 읽기 및 쓰기에 고성능 플랫폼을 사용할 수 있으며, 높은 처리량의 과거 읽기에 NetApp StorageGRID 와 같은 저렴하고 확장 가능한 개체 저장소를 사용할 수도 있습니다.  또한 NetApp 스토리지 컨트롤러를 갖춘 Spark에 대한 기술 솔루션도 있으며 자세한 내용은 여기에서 확인하세요.  다음 그림은 Kafka가 실시간 분석 파이프라인에 어떻게 적용되는지 보여줍니다.</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">다음 그림은 NetApp StorageGRID Confluent Kafka의 객체 스토리지 계층으로 어떻게 적용되는지 보여줍니다.</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">이 섹션에서는 Confluent 인증에 사용되는 하드웨어와 소프트웨어에 대해 설명합니다.  이 정보는 NetApp 스토리지를 사용한 Kafka 배포에 적용할 수 있습니다.</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">사이징</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">카프카 크기 조정은 간단, 세분화, 역방향, 파티션의 4가지 구성 모드로 수행할 수 있습니다.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">단순한</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">간단 모드는 Apache Kafka를 처음 사용하는 사용자나 초기 상태 사용 사례에 적합합니다.  이 모드에서는 처리량(MBps), 읽기 팬아웃, 보존 및 리소스 활용률(기본값은 60%)과 같은 요구 사항을 제공합니다.  또한 온프레미스(베어메탈, VMware, Kubernetes 또는 OpenStack)나 클라우드와 같은 환경으로 들어갑니다.  이 정보를 기반으로 Kafka 클러스터의 크기를 조정하면 브로커, Zookeeper, Apache Kafka Connect Worker, 스키마 레지스트리, REST 프록시, ksqlDB 및 Confluent 제어 센터에 필요한 서버 수가 제공됩니다.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">계층형 스토리지의 경우 Kafka 클러스터 크기를 조정하기 위한 세분화된 구성 모드를 고려하세요.  세분화 모드는 숙련된 Apache Kafka 사용자나 명확하게 정의된 사용 사례에 적합합니다.  이 섹션에서는 생산자, 스트림 프로세서, 소비자의 크기 조정에 대해 설명합니다.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">프로듀서</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Apache Kafka의 제작자(예: 네이티브 클라이언트, REST 프록시 또는 Kafka 커넥터)를 설명하려면 다음 정보를 제공하세요.</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*이름.*  불꽃.</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*생산자 유형.*  애플리케이션 또는 서비스, 프록시(REST, MQTT, 기타), 기존 데이터베이스(RDBMS, NOSQL, 기타).  "모르겠습니다"를 선택할 수도 있습니다.</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*평균 처리량.*  초당 이벤트 수(예: 1,000,000개).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*최대 처리량.*  초당 이벤트 수(예: 4,000,000개).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*평균 메시지 크기.*  압축되지 않은 바이트 단위(최대 1MB, 예: 1000).</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*메시지 형식.*  옵션으로는 Avro, JSON, 프로토콜 버퍼, 바이너리, 텍스트, "모르겠습니다" 및 기타가 있습니다.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*복제 인자.*  옵션은 1, 2, 3(Confluent 추천), 4, 5, 6입니다.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*보존 시간.*  어느 날(예를 들어).  Apache Kafka에 데이터를 얼마 동안 저장하고 싶으신가요?  무한한 시간을 원하면 -1을 아무 단위나 입력하세요.  계산기는 무한 보존을 위해 보존 기간이 10년이라고 가정합니다.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">"계층형 스토리지를 사용하여 브로커 수를 줄이고 무한한 스토리지를 허용하시겠습니까?" 확인란을 선택하세요.</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">계층형 스토리지가 활성화되면 보존 필드는 브로커에 로컬로 저장된 핫 데이터 세트를 제어합니다.  보관 보존 필드는 데이터가 보관 개체 저장소에 저장되는 기간을 제어합니다.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*보관 보관*  (예를 들어) 1년.  귀하의 데이터를 보관 저장소에 얼마 동안 보관하고 싶으신가요?  무한한 시간을 원하면 -1을 아무 단위나 입력하세요.  계산기는 무한 보존을 위해 10년간 보존한다고 가정합니다.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*성장 배수.*  1 (예를 들어).  이 매개변수의 값이 현재 처리량을 기반으로 하는 경우 1로 설정합니다.  추가적인 성장에 따라 크기를 조정하려면 이 매개변수를 성장 배수로 설정하세요.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*생산자 인스턴스 수.*  10 (예를 들어).  몇 개의 프로듀서 인스턴스가 실행될 예정인가요?  이 입력은 CPU 부하를 크기 계산에 통합하는 데 필요합니다.  빈 값은 CPU 부하가 계산에 포함되지 않음을 나타냅니다.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">이 예시 입력을 기준으로 하면 크기 조정은 생산자에게 다음과 같은 영향을 미칩니다.</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">압축되지 않은 바이트의 평균 처리량: 1GBps.  압축되지 않은 바이트의 최대 처리량: 4GBps.  압축된 바이트의 평균 처리량: 400MBps.  압축 바이트의 최대 처리량: 1.6GBps.  이는 기본 60% 압축률을 기준으로 합니다(이 값은 변경할 수 있습니다).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">브로커 내 핫셋 스토리지에 필요한 총 용량: 복제를 포함하여 압축된 용량으로 31,104TB입니다.  필요한 총 오프브로커 보관 저장 용량: 압축 시 378,432TB.  사용<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> StorageGRID 크기 조정을 위해.</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">스트림 프로세서는 Apache Kafka에서 데이터를 소비하고 Apache Kafka로 다시 생성하는 애플리케이션이나 서비스를 설명해야 합니다.  대부분의 경우 이러한 기능은 ksqlDB 또는 Kafka Streams에 내장되어 있습니다.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*이름.*  스파크 스트리머.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*처리 시간.*  이 프로세서가 단일 메시지를 처리하는 데 얼마나 걸리나요?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1ms(단순, 상태 비저장 변환) [예], 10ms(상태 저장 메모리 내 작업).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100ms(상태 저장 네트워크 또는 디스크 작업), 1000ms(제3자 REST 호출).</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">저는 이 매개변수를 벤치마킹했고, 얼마나 걸리는지 정확히 알고 있습니다.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*산출물 보존.*  1일(예시).  스트림 프로세서는 Apache Kafka로 출력을 생성합니다.  이 출력 데이터를 Apache Kafka에 얼마 동안 저장하고 싶으신가요?  무한한 시간을 원하면 -1을 아무 단위나 입력하세요.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">"계층형 스토리지를 사용하여 브로커 수를 줄이고 무한한 스토리지를 허용하시겠습니까?" 확인란을 선택하세요.</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*보관 보관*  1년(예를 들어).  귀하의 데이터를 보관 저장소에 얼마 동안 보관하고 싶으신가요?  무한한 시간을 원하면 -1을 아무 단위나 입력하세요.  계산기는 무한 보존을 위해 10년간 보존한다고 가정합니다.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*출력 패스스루 백분율.*  100(예를 들어).  스트림 프로세서는 Apache Kafka로 출력을 생성합니다.  인바운드 처리량 중 Apache Kafka로 다시 출력되는 비율은 얼마입니까?  예를 들어, 인바운드 처리량이 20MBps이고 이 값이 10이면 출력 처리량은 2MBps가 됩니다.</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">이것은 어떤 응용프로그램에서 읽어오는 것인가요?  생산자 유형 기반 크기 조정에 사용되는 이름인 "Spark"를 선택합니다.  위의 입력을 기반으로 스트림 프로세서 인스턴스와 토픽 파티션 추정에 대한 크기 조정의 다음과 같은 효과를 기대할 수 있습니다.</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">이 스트림 프로세서 애플리케이션에는 다음과 같은 개수의 인스턴스가 필요합니다.  들어오는 주제에도 이 정도의 파티션이 필요할 가능성이 있습니다.  이 매개변수를 확인하려면 Confluent에 문의하세요.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">성장 배수 없이 평균 처리량의 경우 1,000</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">성장 배수 없이 최대 처리량의 경우 4,000</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">성장 배수를 적용한 평균 처리량의 경우 1,000</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">성장 배수를 적용한 최대 처리량의 경우 4,000</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">소비자들</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Apache Kafka에서 데이터를 사용하지만 Apache Kafka로 다시 데이터를 생성하지 않는 애플리케이션이나 서비스를 설명해 주세요. 예를 들어, 네이티브 클라이언트나 Kafka 커넥터가 있습니다.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*이름.*  소비자를 자극합니다.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*처리 시간.*  이 소비자가 단일 메시지를 처리하는 데 얼마나 걸리나요?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1ms(예: 로깅과 같은 간단하고 상태 없는 작업)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10ms(데이터 저장소에 대한 빠른 쓰기)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100ms(데이터 저장소에 대한 느린 쓰기)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000ms(제3자 REST 호출)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">기간이 알려진 다른 벤치마크 프로세스.</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*소비자 유형.*  기존 데이터 저장소(RDBMS, NoSQL, 기타)에 대한 애플리케이션, 프록시 또는 싱크입니다.</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">이것은 어떤 응용프로그램에서 읽어오는 것인가요?  이 매개변수를 이전에 결정된 프로듀서 및 스트림 크기에 연결합니다.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">위의 입력 내용을 기반으로 소비자 인스턴스 크기와 주제 파티션 추정치를 결정해야 합니다.  소비자 애플리케이션에는 다음과 같은 수의 인스턴스가 필요합니다.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">평균 처리량의 경우 2,000, 성장 배수 없음</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">최대 처리량의 경우 8,000, 성장 배수 없음</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">성장 배수를 포함한 평균 처리량의 경우 2,000</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">최대 처리량의 경우 8,000(성장 배수 포함)</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">들어오는 주제에도 이 개수의 파티션이 필요할 가능성이 높습니다.  확인하려면 Confluent에 문의하세요.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">생산자, 스트림 프로세서, 소비자에 대한 요구 사항 외에 다음과 같은 추가 요구 사항을 제공해야 합니다.</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*재건 시간입니다.*  예를 들어, 4시간.  Apache Kafka 브로커 호스트에 장애가 발생하여 데이터가 손실되고, 장애가 발생한 호스트를 대체하기 위해 새로운 호스트가 프로비저닝되는 경우, 이 새로운 호스트는 얼마나 빨리 자체적으로 재구축해야 합니까?  값을 알 수 없는 경우 이 매개변수를 비워 두세요.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*자원 활용 목표(백분율).*  예를 들어, 60.  평균 처리량 동안 호스트를 얼마나 활용하고 싶으신가요?  Confluent는 Confluent 자체 균형 클러스터를 사용하지 않는 한 60%의 사용률을 권장하지만, Confluent 자체 균형 클러스터를 사용하는 경우 사용률이 더 높아질 수 있습니다.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">주변 환경을 설명하세요</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*클러스터는 어떤 환경에서 실행되나요?*  Amazon Web Services, Microsoft Azure, Google Cloud Platform, 온프레미스 베어메탈, 온프레미스 VMware, 온프레미스 OpenStack, 온프레미스 Kubernates 중 어떤 것을 선택하시겠습니까?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*호스트 정보.*  코어 수: 48개(예시), 네트워크 카드 유형(10GbE, 40GbE, 16GbE, 1GbE 또는 다른 유형).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*저장 용량.*  호스트: 12(예시)  호스트당 몇 개의 하드 드라이브 또는 SSD가 지원됩니까?  Confluent는 호스트당 12개의 하드 드라이브를 권장합니다.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*저장 용량/볼륨(GB)*  1000(예를 들어).  단일 볼륨은 기가바이트 단위로 얼마나 많은 저장 공간을 저장할 수 있나요?  Confluent에서는 1TB 디스크를 권장합니다.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*저장 구성.*  저장 볼륨은 어떻게 구성되나요?  Confluent에서는 모든 Confluent 기능을 활용하기 위해 RAID10을 권장합니다.  JBOD, SAN, RAID 1, RAID 0, RAID 5 및 기타 유형도 지원됩니다.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*단일 볼륨 처리량(MBps).*  125 (예를 들어).  단일 저장 볼륨은 초당 메가바이트 단위로 얼마나 빨리 읽거나 쓸 수 있습니까?  Confluent는 일반적으로 처리량이 125MBps인 표준 하드 드라이브를 권장합니다.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*메모리 용량(GB).*  64(예를 들어).</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">환경 변수를 결정한 후 클러스터 크기를 선택합니다.  위에 표시된 예시 매개변수를 기반으로 Confluent Kafka에 대한 다음 크기를 결정했습니다.</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*아파치 카프카.*  브로커 수: 22개.  귀하의 클러스터는 저장소에 제한되어 있습니다.  호스트 수를 줄이고 무한한 저장 공간을 확보하려면 계층형 저장소를 활성화하는 것을 고려하세요.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*아파치 동물원 관리자.*  개수: 5; Apache Kafka Connect Workers: 개수: 2; 스키마 레지스트리: 개수: 2; REST 프록시: 개수: 2; ksqlDB: 개수: 2; Confluent Control Center: 개수: 1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">사용 사례가 고려되지 않은 플랫폼 팀의 경우 역방향 모드를 사용합니다.  파티션 모드를 사용하면 단일 주제에 필요한 파티션 수를 계산할 수 있습니다.  보다<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> 역방향 및 파티션 모드에 따른 크기 조정을 위해.</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">솔루션 아키텍처 세부 정보</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">이 섹션에서는 Confluent 검증에 사용되는 하드웨어와 소프트웨어에 대해 설명합니다.  이 정보는 NetApp 스토리지를 사용한 Confluent Platform 배포에 적용됩니다.  다음 표는 테스트된 솔루션 아키텍처와 기본 구성 요소를 보여줍니다.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">솔루션 구성 요소</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">세부</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka 버전 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">세 명의 동물원 관리인</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">5개의 브로커 서버</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">5개의 도구 서버</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">원 그라파나</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">하나의 제어 센터</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">리눅스(우분투 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">모든 서버</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">계층형 스토리지를 위한 NetApp StorageGRID</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID 소프트웨어</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000(로드 밸런서)</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 프로토콜</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100GbE(브로커와 StorageGRID 인스턴스 간 네트워크 연결)</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15개의 Fujitsu PRIMERGY RX2540 서버</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">각각 다음이 장착되어 있습니다: * 2개의 CPU, 총 16개의 물리적 코어 * Intel Xeon * 256GB 물리적 메모리 * 100GbE 듀얼 포트</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">이 문서에서는 TPCDS 인증 테스트, 튜닝 및 고객 사용 사례 세부 정보를 포함하여 NetApp 스토리지와 함께 Dremio를 사용하기 위한 모범 사례 가이드라인을 제공합니다.</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">결론적으로 이 기술 보고서는 ONTAP S3, NAS, StorageGRID 포함한 NetApp 스토리지 컨트롤러의 다양한 데이터 소스와 함께 Dremio를 사용한 q Hybrid Iceberg Lakehouse의 포괄적인 배포 세부 정보를 제공했습니다.  배포 프로세스가 성공적으로 실행되었으며, TPC-DS 벤치마킹 도구를 활용하여 다양한 데이터 소스에서 99개의 SQL 쿼리를 수행했습니다.  이 보고서에서는 NetApp 의 고객 사용 사례도 살펴보았고, 이를 통해 다양한 비즈니스 요구 사항을 충족하는 데 있어 Dremio의 다재다능함과 효과성을 입증했습니다.  또한 자동차 부품 판매 고객을 포함한 특정 사용 사례를 조사하여 데이터 분석 및 통찰력을 위해 Dremio를 활용하는 실제적 적용과 이점을 강조했습니다.</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">전반적으로 이 문서는 NetApp 스토리지 컨트롤러와 함께 Dremio를 배포하고 사용하는 방법을 이해하는 데 귀중한 자료가 되며, 다양한 산업에서 데이터 중심 의사 결정과 최적화를 추진하는 기능과 잠재력을 보여줍니다.</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Zookeeper 설치</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">드레미오</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">storageGRID를 사용하여 Dremio 구성</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">NetApp 사용 사례</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">우리는 NetApp Object Storage에서 레이크하우스 검증을 통해 Dremio 플랫폼에 대한 인증을 수행했습니다.</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">배포 절차</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">NetApp 스토리지 컨트롤러를 사용한 Dremio 아키텍처를 보여주는 그림</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">이 참조 아키텍처 검증에서 우리는 하나의 코디네이터와 네 개의 실행자로 구성된 Dremio 구성을 사용했습니다.<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">NetApp 설정</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">스토리지 시스템 초기화</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">스토리지 가상 머신(SVM) 생성</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">논리적 네트워크 인터페이스 할당</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">NFS, S3 구성 및 라이센싱</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">NFS(네트워크 파일 시스템)의 경우 아래 단계를 따르세요. 1.  NFSv4 또는 NFSv3에 대한 Flex Group 볼륨을 만듭니다.  이 검증을 위한 설정에서 우리는 48개의 SSD를 사용했는데, 그 중 1개는 컨트롤러의 루트 볼륨에 전용으로 사용되었고, 47개는 NFSv4에 분산되어 있었습니다.  Flex Group 볼륨에 대한 NFS 내보내기 정책에 Dremio 서버 네트워크에 대한 읽기/쓰기 권한이 있는지 확인합니다.</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">모든 Dremio 서버에서 폴더를 만들고 각 Dremio 서버의 논리 인터페이스(LIF)를 통해 Flex Group 볼륨을 이 폴더에 마운트합니다.</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">S3(Simple Storage Service)의 경우 아래 단계를 따르세요.</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">"vserver object-store-server create" 명령을 사용하여 HTTP를 활성화하고 관리 상태를 'up'으로 설정한 객체 저장소 서버를 설정합니다.  HTTPS를 활성화하고 사용자 정의 리스너 포트를 설정할 수 있습니다.</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">"vserver object-store-server user create -user &lt;username&gt;" 명령을 사용하여 object-store-server 사용자를 생성합니다.</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">액세스 키와 비밀 키를 얻으려면 다음 명령을 실행하세요: "set diag; vserver object-store-server user show -user &lt;username&gt;".  하지만 앞으로는 이러한 키가 사용자 생성 프로세스 중에 제공되거나 REST API 호출을 사용하여 검색할 수 있습니다.</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">2단계에서 생성한 사용자를 사용하여 객체-저장소-서버 그룹을 설정하고 액세스 권한을 부여합니다.  이 예에서는 "FullAccess"를 제공했습니다.</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">유형을 "S3"로 설정하여 두 개의 S3 버킷을 만듭니다.  하나는 Dremio 구성용이고 다른 하나는 고객 데이터용입니다.</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">Zookeeper 설정</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">Dremio가 제공하는 Zookeeper 구성을 사용할 수 있습니다.  이 검증에서 우리는 별도의 Zookeeper를 사용했습니다. 우리는 이 웹 링크에 언급된 단계를 따랐습니다.<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Dremio 설정</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">우리는 이 웹링크를 따라 타르볼을 통해 Dremio를 설치했습니다.</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">Dremio 그룹을 만드세요.</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">dremio 사용자를 생성합니다.</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">Dremio 디렉토리를 만듭니다.</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">tar 파일을 다운로드하세요<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">Dremio를 /opt/dremio 디렉터리에 압축을 풉니다.</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">구성 폴더에 대한 심볼릭 링크를 만듭니다.</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">서비스 구성(SystemD 설정)을 설정합니다.</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">dremio 데몬의 단위 파일을 /opt/dremio/share/dremio.service에서 /etc/systemd/system/dremio.service로 복사합니다.</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">시스템 재시작</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">부팅 시 dremio를 시작하도록 설정합니다.</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">코디네이터에서 Dremio를 구성합니다.  자세한 내용은 Dremio 구성을 참조하세요.</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">드레미오.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">코어-사이트.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">Dremio 구성은 NetApp 개체 스토리지에 저장됩니다.  검증 결과, "dremioconf" 버킷은 ontap S3 버킷에 있습니다.  아래 그림은 "dremioconf" S3 버킷의 "scratch" 및 "uploads" 폴더의 일부 세부 정보를 보여줍니다.</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">NetApp 개체 스토리지를 사용한 Dremio를 보여주는 그림</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">실행자에서 Dremio를 구성합니다.  우리의 설정에는 3명의 실행자가 있습니다.</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml – 코디네이터 구성과 동일합니다.</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp Datalake 및 Lakehouse 환경을 위한 기본 개체 스토리지 솔루션으로 StorageGRID 권장합니다.  또한 NetApp ONTAP 파일/객체 이중성을 위해 사용됩니다.  이 문서의 맥락에서 우리는 고객 요청에 따라 ONTAP S3에 대한 테스트를 수행했으며, 이는 데이터 소스로서 성공적으로 기능했습니다.</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">다중 소스 설정</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">Dremio에서 ONTAP S3 및 storageGRID를 S3 소스로 구성합니다.</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Dremio 대시보드 -&gt; 데이터 세트 -&gt; 소스 -&gt; 소스 추가.</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">일반 섹션에서 AWS 액세스 및 비밀 키를 업데이트하세요.</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">고급 옵션에서 호환 모드를 활성화하고 아래 세부 정보로 연결 속성을 업데이트합니다.  NetApp 스토리지 컨트롤러의 엔드포인트 IP/이름은 ontap S3 또는 storageGRID에서 가져옵니다.</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">가능하면 로컬 캐싱을 활성화하고, 가능한 경우 사용할 수 있는 총 캐시의 최대 백분율은 100입니다.</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">NetApp 개체 스토리지의 파일 목록을 보여주는 그림</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">그런 다음 NetApp 개체 스토리지의 버킷 목록을 봅니다.<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">storageGRID 버킷 세부 정보의 샘플 보기<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">Dremio에서 NAS(특히 NFS)를 소스로 구성합니다.</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">일반 섹션에 이름과 NFS 마운트 경로를 입력합니다.  Dremio 클러스터의 모든 노드에서 NFS 마운트 경로가 동일한 폴더에 마운트되었는지 확인하세요.</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">이 문서에서는 NetApp 스토리지 컨트롤러에서 Dremio를 사용하기 위한 모범 사례 가이드라인을 설명합니다.</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">NetApp 과 Dremio의 차세대 하이브리드 Iceberg Lakehouse 솔루션</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">이 문서에서는 ONTAP S3, NAS, StorageGRID 포함한 NetApp 스토리지 컨트롤러의 다양한 데이터 소스를 활용한 Dremio의 배포 세부 정보에 대해 설명합니다.  배포하는 동안 TPC-DS 벤치마킹 도구를 사용하여 다양한 소스에서 99개의 SQL 쿼리를 실행했습니다.  이 문서에서는 NetApp 의 고객 사용 사례와 자동차 부품 판매 고객과 관련된 사용 사례도 살펴봅니다.</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">이 섹션에서는 Dremio 인증에 사용되는 하드웨어와 소프트웨어에 대해 설명합니다.  이 정보는 NetApp 스토리지를 사용한 Dremio 배포에 적용할 수 있습니다.</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">솔루션 개요</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">하이브리드 아이스버그 레이크하우스 솔루션은 데이터 레이크 고객이 직면한 과제를 해결하는 데 고유한 이점을 제공합니다.  Dremio Unified Lakehouse 플랫폼과 NetApp ONTAP, StorageGRID, NetApp Cloud 솔루션을 활용하면 회사는 비즈니스 운영에 상당한 가치를 더할 수 있습니다.  이 솔루션은 NetApp 소스를 포함한 여러 데이터 소스에 대한 액세스를 제공할 뿐만 아니라 전반적인 분석 성능을 향상시키고 회사가 비즈니스 성장으로 이어지는 비즈니스 통찰력을 얻는 데 도움을 줍니다.</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetApp 개요</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">ONTAP 및 StorageGRID 와 같은 NetApp의 제품은 스토리지와 컴퓨팅을 분리하여 특정 요구 사항에 따라 최적의 리소스 활용을 가능하게 합니다.  이러한 유연성 덕분에 고객은 NetApp 스토리지 솔루션을 사용하여 스토리지를 독립적으로 확장할 수 있습니다.</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">NetApp의 스토리지 컨트롤러를 활용하면 고객은 NFS 및 S3 프로토콜을 사용하여 벡터 데이터베이스에 효율적으로 데이터를 제공할 수 있습니다.  이러한 프로토콜은 고객 데이터 저장을 용이하게 하고 벡터 데이터베이스 인덱스를 관리하며, 파일 및 객체 메서드를 통해 액세스하는 여러 데이터 사본의 필요성을 제거합니다.</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP AWS, Azure, Google Cloud 등 주요 클라우드 서비스 공급업체에서 NAS 및 개체 스토리지에 대한 기본 지원을 제공합니다.  이러한 광범위한 호환성은 원활한 통합을 보장하여 고객 데이터 이동성, 글로벌 접근성, 재해 복구, 동적 확장성 및 고성능을 구현합니다.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">업계를 선도하는 당사 객체 스토리지 storageGRID는 자동화된 데이터 배치를 위한 강력한 정책 엔진, 유연한 배포 옵션, 계층적 삭제 코딩을 통한 탁월한 내구성을 제공합니다.  단일 네임스페이스에서 수십억 개의 객체와 페타바이트 규모의 데이터를 지원하는 확장 가능한 아키텍처를 갖추고 있습니다.  이 솔루션은 하이브리드 클라우드 통합을 지원하여 주요 클라우드 플랫폼으로 데이터를 계층화할 수 있습니다.  2019 IDC Marketscape Worldwide Object-Based Vendor Assessment에서 리더로 인정받았습니다.</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">또한, storageGRID는 소프트웨어 정의 객체 스토리지, 지리적 중복성, 다중 사이트 기능을 통해 대규모 비정형 데이터를 관리하는 데 탁월합니다.  정책 기반 정보 수명 주기 관리를 통합하고 미러링 및 검색과 같은 클라우드 통합 기능을 제공합니다.  Common Criteria, NF203 디지털 금고 부품, ISO/IEC 25051, KPMG, Cohasset 규정 준수 평가를 포함한 다양한 인증을 받았습니다.</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">요약하자면, NetApp storageGRID는 대규모 비정형 데이터를 효율적으로 관리하는 데 필요한 강력한 기능, 확장성, 하이브리드 클라우드 통합 및 규정 준수 인증을 제공합니다.</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAP 은 광범위한 엔터프라이즈 기능을 제공하는 강력한 스토리지 솔루션입니다.  여기에는 애플리케이션 일관적이고 변조 방지된 즉각 백업을 제공하는 스냅샷이 포함되어 있습니다.  SnapRestore 필요에 따라 백업을 거의 즉시 복원할 수 있게 해주는 반면, SnapMirror 통합된 원격 백업 및 재해 복구 기능을 제공합니다.  이 솔루션은 다중 관리자 검증, FIPS 인증을 통한 저장 데이터 암호화, 전송 중 데이터 암호화, 다중 요소 인증(MFA), 역할 기반 액세스 제어(RBAC)와 같은 기능으로 데이터 보안을 보장하는 자율형 랜섬웨어 보호(ARP) 기능도 통합합니다.  포괄적인 로깅, 감사, 온보딩 및 외부 키 관리, 안전한 정리, 여러 테넌트의 안전한 관리를 통해 데이터 보안과 규정 준수가 더욱 강화됩니다.</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP 또한 낮은 총소유비용으로 높은 수준의 무결성, 성능 및 보존을 제공하는 규정을 준수하는 데이터 보존 기능을 제공하는 SnapLock 기능을 갖추고 있습니다.  NetApp ONTAP 9와 완벽하게 통합되어 악의적인 행위, 사기성 관리자 및 랜섬웨어로부터 보호 기능을 제공합니다.</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">이 솔루션은 전송 중 및 저장 데이터 암호화를 위한 NSE/NVE 암호화, 다중 관리자 액세스, 다중 관리자 검증을 포함합니다.  Active IQ AI 기반 예측 분석과 시정 조치를 제공하고, QoS는 서비스 품질 워크로드 제어를 보장합니다.  관리 및 자동화 통합은 SysMgr/GUI/CLI/API를 통해 직관적으로 이루어집니다.  FabricPool 자동 데이터 계층화를 지원하고, 해당 솔루션은 인라인 데이터 압축, 중복 제거 및 압축을 통해 효율성을 제공합니다.  NetApp 고객에게 추가 비용 없이 워크로드 효율성 목표 달성을 보장합니다.</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP NVMe/FC, FC, NVMe/TCP, iSCSI, NFS, SMB, S3 등 다양한 프로토콜을 지원하여 통합 스토리지 솔루션을 제공합니다.  전반적으로 NetApp ONTAP 다양한 스토리지 요구 사항을 충족하는 광범위한 엔터프라이즈 기능, 강력한 보안, 규정 준수, 효율성 및 다용성을 제공합니다.</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">드레미오 개요</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio는 셀프서비스 분석 및 AI를 위한 통합 레이크하우스 플랫폼입니다.  Dremio 통합 분석 플랫폼은 기존 데이터웨어하우스 솔루션 비용의 일부만으로 레이크하우스의 유연성, 확장성 및 성능을 제공하여 사용자가 데이터에 더욱 가까이 접근할 수 있도록 합니다.  Dremio는 복잡하고 비용이 많이 드는 데이터 통합 및 ETL을 없애는 "시프트-레프트" 분석을 지원하여 데이터 이동 없이 원활한 엔터프라이즈 규모 분석을 제공합니다.  Dremio의 또 다른 특징은 다음과 같습니다.</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">범용 의미 계층과 긴밀하게 통합된 고성능 SQL 쿼리 엔진을 통해 사용하기 쉬운 셀프 서비스 분석이 가능하므로 클라우드와 온프레미스 모두에서 모든 데이터를 보다 쉽게 연결, 관리 및 분석할 수 있습니다.</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Dremio의 Apache Iceberg 기반 레이크하우스 관리 기능은 데이터 검색을 간소화하고, 데이터 최적화를 자동화하며, Git에서 영감을 받은 데이터 버전 관리를 통해 고성능 분석을 제공합니다.</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">오픈 소스와 개방형 표준을 기반으로 구축된 Dremio는 기업이 특정 분야에 얽매이지 않고 혁신을 위한 입지를 유지할 수 있도록 지원합니다.  대기업들은 Dremio를 모든 워크로드에 걸쳐 가장 가격 대비 성능이 뛰어나고 사용하기 가장 쉬운 레이크하우스 플랫폼으로 신뢰합니다.</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Dremio와 NetApp Hybrid Iceberg Lakehouse 솔루션은 고객에게 어떤 가치를 제공합니까?</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*향상된 데이터 관리 및 접근성*: Dremio는 조직이 데이터 레이크에서 고속으로 직접 데이터를 쿼리할 수 있도록 하는 데이터 레이크하우스 플랫폼으로 잘 알려져 있습니다.  반면, NetApp 클라우드 데이터 서비스와 데이터 저장 솔루션 분야의 선두주자입니다.  이 공동 제안은 고객에게 기업의 데이터를 효율적이고 효과적으로 저장, 관리, 액세스 및 분석할 수 있는 포괄적인 솔루션을 제공합니다.</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*성능 최적화*: NetApp의 데이터 스토리지 전문성과 Dremio의 데이터 처리 및 데이터 최적화 역량을 바탕으로, 이 파트너십은 데이터 운영의 성능을 개선하고, 대기 시간을 줄이고, 비즈니스 통찰력을 얻는 속도를 높여주는 솔루션을 제공합니다.  Dremio는 NetApp의 내부 IT 분석 인프라에도 성능상의 이점을 제공했습니다.</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*확장성*: Dremio와 NetApp 모두 확장 가능하도록 설계된 솔루션을 제공합니다.  이 공동 솔루션은 고객에게 확장성이 뛰어난 데이터 저장, 데이터 관리 및 분석 환경을 제공합니다.  하이브리드 Iceberg Lakehouse 환경에서 Dremio SQL 쿼리 엔진은 NetApp StorageGRID 와 결합되어 모든 비즈니스의 분석 요구 사항을 처리할 수 있는 탁월한 확장성, 동시성 및 쿼리 성능을 제공합니다.</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*데이터 보안 및 거버넌스*: 두 회사 모두 데이터 보안과 거버넌스에 중점을 두고 있습니다.  이 두 가지 솔루션을 함께 사용하면 강력한 보안 및 데이터 거버넌스 기능을 제공하여 데이터가 보호되고 데이터 거버넌스 요구 사항이 충족되도록 할 수 있습니다.  역할 기반 및 세분화된 액세스 제어, 포괄적인 감사, 종단 간 데이터 계보, 통합 ID 관리, 광범위한 규정 준수 및 보안 프레임워크를 갖춘 SSO와 같은 기능을 통해 회사의 분석 데이터 환경이 안전하고 관리되도록 보장합니다.</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*비용 효율성*: Dremio의 데이터 레이크 엔진을 NetApp의 스토리지 솔루션과 통합함으로써 고객은 데이터 관리 및 데이터 이동과 관련된 비용을 줄일 수 있습니다.  조직은 기존 데이터 레이크 환경에서 NetApp 과 Dremio로 구성된 보다 현대적인 레이크하우스 솔루션으로 전환할 수도 있습니다.  이 하이브리드 Iceberg Lakehouse 솔루션은 고속 쿼리 성능과 시장 선도적인 쿼리 동시성을 제공하여 TCO를 낮추고 비즈니스 통찰력을 얻는 시간을 단축합니다.</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">이 섹션에서는 이 솔루션에 사용된 기술에 대해 설명합니다.</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">기술 요구 사항</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">아래에 설명된 하드웨어 및 소프트웨어 구성은 이 문서에서 수행된 검증에 활용되었습니다.  이러한 구성은 환경을 설정하는 데 도움이 되는 지침으로 사용되지만, 특정 구성 요소는 개별 고객 요구 사항에 따라 달라질 수 있습니다.</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">하드웨어 요구 사항</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">하드웨어</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">NetApp AFF 스토리지 어레이 HA 쌍</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48 x 3.49TB SSD-NVM</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">두 개의 S3 버킷: Dremio 메타데이터와 고객 데이터.</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">후지쯔 프라이머지 RX2540 M4 4개</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">64개의 CPU</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">인텔 제온 골드 6142 CPU @ 2.60GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM 물리적 메모리</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 x 100GbE 네트워크 포트</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">네트워킹</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100GbE</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7.68TB * 2개의 S3 버킷: Dremio 메타데이터 및 고객 데이터.</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">버전 - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">엔터프라이즈 에디션</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">온프레미스</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">5개 노드 Dremio 클러스터</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">1명의 마스터 코디네이터와 4명의 실행자</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">이 섹션에서는 NetApp 개체 스토리지와 함께 Dremio를 사용하는 고객 사용 사례 세부 정보를 다룹니다.</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">고객 사용 사례</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">NetApp ActiveIQ 사용 사례</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">ActiveIQ 이전 아키텍처</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*과제*: NetApp의 자체 Active IQ 솔루션은 원래 다양한 사용 사례를 지원하도록 설계되었지만, 이제는 내부 사용자와 고객 모두를 위한 포괄적인 솔루션으로 발전했습니다.  그러나 데이터의 급속한 성장과 효율적인 데이터 액세스의 필요성으로 인해 Hadoop/MapR 기반 백엔드 인프라는 비용과 성능 측면에서 과제를 안고 있었습니다.  저장소를 확장하면 불필요한 컴퓨팅 리소스가 추가되어 비용이 증가하게 됩니다.</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">게다가 Hadoop 클러스터를 관리하는 일은 시간이 많이 걸리고 전문적인 지식이 필요했습니다.  데이터 성능 및 관리 문제로 인해 상황이 더욱 복잡해졌으며, 쿼리를 실행하는 데 평균 45분이 걸리고 구성 오류로 인해 리소스가 부족해졌습니다.  이러한 과제를 해결하기 위해 NetApp 기존의 레거시 Hadoop 환경에 대한 대안을 모색했고 Dremio를 기반으로 하는 새로운 현대적 솔루션이 비용을 절감하고, 스토리지와 컴퓨팅을 분리하고, 성능을 개선하고, 데이터 관리를 간소화하고, 세분화된 제어 기능을 제공하고, 재해 복구 기능을 제공할 것이라고 판단했습니다.</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">dremio를 탑재한 ActiveIQ의 새로운 아키텍처</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*해결책*:<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio는 NetApp 단계적 접근 방식으로 Hadoop 기반 데이터 인프라를 현대화할 수 있도록 지원하여 통합 분석을 위한 로드맵을 제공했습니다.  데이터 처리를 크게 변경해야 했던 다른 공급업체와 달리 Dremio는 기존 파이프라인과 완벽하게 통합되어 마이그레이션하는 동안 시간과 비용을 절감했습니다.  NetApp 완전히 컨테이너화된 환경으로 전환함으로써 관리 오버헤드를 줄이고, 보안을 강화하고, 복원력을 향상시켰습니다.  Dremio는 Apache Iceberg와 Arrow와 같은 개방형 생태계를 도입하여 미래 지향적인 운영, 투명성, 확장성을 확보했습니다.</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">Dremio는 Hadoop/Hive 인프라를 대체하여 의미 계층을 통해 2차 사용 사례에 대한 기능을 제공했습니다.  기존의 Spark 기반 ETL 및 데이터 수집 메커니즘은 그대로 유지하면서 Dremio는 중복 없이 데이터를 보다 쉽게 검색하고 탐색할 수 있는 통합 액세스 계층을 제공했습니다.  이러한 접근 방식은 데이터 복제 요소를 크게 줄이고 스토리지와 컴퓨팅을 분리했습니다.</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*이점*: NetApp Dremio를 통해 데이터 환경에서 컴퓨팅 소비와 디스크 공간 요구 사항을 최소화하여 상당한 비용 절감을 달성했습니다.  새로운 Active IQ Data Lake는 7페타바이트가 넘는 기존 인프라에 비해 3페타바이트의 데이터를 보유한 8,900개의 테이블로 구성됩니다.  Dremio로의 마이그레이션에는 Kubernetes 클러스터에서 33개의 미니 클러스터와 4,000개의 코어를 16개의 실행자 노드로 전환하는 작업도 포함되었습니다.  컴퓨팅 리소스가 크게 감소했음에도 불구하고 NetApp 놀라운 성능 향상을 경험했습니다.  Dremio를 통해 데이터에 직접 액세스함으로써 쿼리 런타임이 45분에서 2분으로 단축되었고, 그 결과 예측 유지 관리 및 최적화를 위한 통찰력을 얻는 시간이 95% 빨라졌습니다.  마이그레이션을 통해 컴퓨팅 비용이 60% 이상 절감되고, 쿼리 속도가 20배 이상 빨라졌으며, 총 소유 비용(TCO)도 30% 이상 절감되었습니다.</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">자동차 부품 판매 고객 활용 사례.</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*과제*: 이 글로벌 자동차 부품 판매 회사 내에서 임원 및 기업 재무 계획 및 분석 그룹은 판매 보고서에 대한 통합된 보기를 얻지 못하고 각 사업부 판매 지표 보고서를 읽고 이를 통합하려고 시도해야 했습니다.  이로 인해 고객은 적어도 하루 이상 지난 데이터를 바탕으로 결정을 내리는 경우가 많아졌습니다.  새로운 분석 통찰력을 얻는 데 걸리는 리드타임은 일반적으로 4주 이상 걸립니다.  데이터 파이프라인의 문제를 해결하려면 더 많은 시간이 필요하며, 이미 긴 일정에 3일 이상이 추가될 것입니다.  보고서 개발 프로세스가 느리고 보고서 성능도 좋지 않아 분석가 커뮤니티는 데이터가 처리되거나 로드될 때까지 계속 기다려야 했고, 그 결과 새로운 비즈니스 통찰력을 찾고 새로운 비즈니스 행동을 촉진하는 데 어려움을 겪었습니다.  이러한 문제가 있는 환경은 다양한 사업 부문을 위한 수많은 데이터베이스로 구성되어 있었고, 이로 인해 수많은 데이터 사일로가 생겨났습니다.  느리고 단편화된 환경은 분석가가 단일 진실 소스에 의존하는 대신, 각자의 진실 버전을 도출해낼 방법이 너무 많았기 때문에 데이터 거버넌스를 복잡하게 만들었습니다.  이 접근 방식에는 데이터 플랫폼 비용과 인건비로 190만 달러가 넘게 들었습니다.  기존 플랫폼을 유지 관리하고 데이터 요청을 충족하려면 연간 7명의 현장 기술 엔지니어(FTE)가 필요했습니다.  데이터 요청이 증가함에 따라 데이터 인텔리전스 팀은 향후 요구 사항을 충족하기 위해 레거시 환경을 확장할 수 없었습니다.</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*해결책*: NetApp Object Store에서 대규모 Iceberg 테이블을 비용 효율적으로 저장하고 관리합니다.  Dremio의 의미 계층을 사용하여 데이터 도메인을 구축하면 비즈니스 사용자가 쉽게 데이터 제품을 만들고, 검색하고, 공유할 수 있습니다.</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*고객 혜택*: • 기존 데이터 아키텍처 개선 및 최적화, 통찰력 확보 시간 4주에서 단 몇 시간으로 단축 • 문제 해결 시간 3일에서 단 몇 시간으로 단축 • 데이터 플랫폼 및 관리 비용 38만 달러 이상 절감 • 연간 데이터 인텔리전스 작업 FTE 2명 절감</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">우리는 ONTAP 및 storagegrid와 같은 NetApp 개체 스토리지를 사용하여 SQL 워크로드에 대해 5개 노드로 tpc-ds 테스트를 수행했습니다.</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">솔루션 검증 개요</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">이 섹션에서는 여러 소스에서 SQL 테스트 쿼리를 실행하여 기능을 검증하고 NetApp 스토리지로의 스필오버를 테스트하고 확인했습니다.</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">객체 스토리지에 대한 SQL 쿼리</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">dremio.env에서 서버당 메모리를 250GB로 설정합니다.</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">dremio.conf 파일에서 스필오버 위치(${DREMIO_HOME}"/dremiocache)와 저장소 세부 정보를 확인하세요.</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">Dremio 스필오버 위치를 NetApp NFS 스토리지로 지정합니다.</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">맥락을 선택하세요.  우리 테스트에서는 ONTAP S3에 있는 TPCDS에서 생성된 Parquet 파일을 대상으로 테스트를 실행했습니다.  Dremio 대시보드 -&gt; SQL 러너 -&gt; 컨텍스트 -&gt; NetAppONTAPS3-&gt;Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">컨텍스트를 ontaps3 parquet 폴더로 설정하세요</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">Dremio 대시보드에서 TPC-DS 쿼리67을 실행합니다.</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">TPC-DS의 99개 쿼리 중 하나인 쿼리 67을 실행합니다.</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">모든 실행자에서 작업이 실행 중인지 확인하세요.  Dremio 대시보드 -&gt; 작업 -&gt; &lt;작업 ID&gt; -&gt; 원시 프로필 -&gt; EXTERNAL_SORT 선택 -&gt; 호스트 이름</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">Q67 쿼리의 노드 목록</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">SQL 쿼리가 실행 중일 때 NetApp 스토리지 컨트롤러에서 데이터 캐싱을 위한 분할 폴더를 확인할 수 있습니다.</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">쿼리 67이 완료되면 세부 정보가 넘칩니다.</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">스필오버로 완료된 SQL 쿼리<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">완료된 쿼리 67의 작업 요약</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">작업 완료 요약.<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">쿼리 결과의 splleddata 세부 정보</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">유출된 데이터 크기를 확인하세요<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">NAS 및 StorageGRID Object Storage에도 동일한 절차가 적용됩니다.</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">이 섹션에서는 NetApp 다양한 Hadoop 데이터 보호 요구 사항을 충족하기 위해 제공하는 사용 사례와 솔루션을 요약하여 제공합니다.</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">이 섹션에서는 NetApp 다양한 Hadoop 데이터 보호 요구 사항을 충족하기 위해 제공하는 사용 사례와 솔루션을 요약하여 제공합니다.  NetApp 이 제공하는 데이터 패브릭을 사용하면 고객은 다음을 수행할 수 있습니다.</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">NetApp의 풍부한 데이터 관리 기능과 Hadoop 기본 워크플로우와의 통합을 활용하여 올바른 데이터 보호 솔루션을 선택할 수 있는 유연성을 확보하세요.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Hadoop 클러스터 백업 윈도우 시간을 약 70% 단축했습니다.</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Hadoop 클러스터 백업으로 인해 발생하는 성능 영향을 제거합니다.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">다양한 클라우드 공급업체에서 동시에 단일 분석 데이터 소스로 멀티클라우드 데이터 보호 및 데이터 액세스를 제공합니다.</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">FlexClone 기술을 사용하여 빠르고 공간 효율적인 Hadoop 클러스터 복사본을 만듭니다.</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹사이트를 참조하세요.</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp 빅데이터 분석 솔루션</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">NetApp 스토리지를 사용한 Apache Spark 워크로드</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Apache Spark를 위한 NetApp 스토리지 솔루션</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">NetApp 이 지원하는 데이터 패브릭 기반 Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">감사의 말</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">폴 버랜드, ANZ 빅토리아 지구 영업 담당자, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, NetApp 사업 개발 관리자</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, NetApp MPSG 이사</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, 시스템 엔지니어, ANZ Victoria District SE, NetApp</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">버전 기록</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">날짜</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">문서 버전 기록</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">버전 1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018년 1월</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">최초 출시</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">버전 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021년 10월</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">사용 사례 #5로 업데이트됨: 분석 작업 가속화</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">버전 3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">2023년 11월</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">NIPAM 세부 정보 제거됨</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">NetApp 이 지원하는 데이터 패브릭은 클라우드와 온프레미스 환경 전반의 데이터 관리를 간소화하고 통합하여 디지털 혁신을 가속화합니다.  NetApp 이 지원하는 데이터 패브릭은 데이터 가시성 및 통찰력, 데이터 액세스 및 제어, 데이터 보호 및 보안을 위한 일관되고 통합된 데이터 관리 서비스와 애플리케이션(빌딩 블록)을 제공합니다.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">빅데이터 아키텍처를 위한 NetApp 기반 데이터 패브릭</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">NetApp 이 지원하는 데이터 패브릭은 클라우드와 온프레미스 환경 전반의 데이터 관리를 간소화하고 통합하여 디지털 혁신을 가속화합니다.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">NetApp 이 지원하는 데이터 패브릭은 아래 그림에서 볼 수 있듯이 데이터 가시성 및 통찰력, 데이터 액세스 및 제어, 데이터 보호 및 보안을 위한 일관되고 통합된 데이터 관리 서비스와 애플리케이션(빌딩 블록)을 제공합니다.</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">검증된 데이터 패브릭 고객 사용 사례</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">NetApp 이 제공하는 데이터 패브릭은 고객에게 다음과 같은 9가지 검증된 사용 사례를 제공합니다.</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">분석 워크로드 가속화</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">DevOps 혁신 가속화</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">클라우드 호스팅 인프라 구축</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">클라우드 데이터 서비스 통합</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">데이터 보호 및 보안</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">비정형 데이터 최적화</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">데이터 센터 효율성 확보</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">데이터 통찰력과 제어 제공</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">단순화하고 자동화하세요</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">이 문서에서는 9가지 사용 사례 중 2가지와 해당 솔루션을 다룹니다.</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS 직접 액세스</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">NetApp NFS를 사용하면 고객은 데이터를 이동하거나 복사하지 않고도 기존 또는 새로운 NFSv3 또는 NFSv4 데이터에 대한 빅데이터 분석 작업을 실행할 수 있습니다.  이를 통해 여러 개의 데이터 사본이 생성되는 것을 방지하고 소스와 데이터를 동기화할 필요성이 없어집니다.  예를 들어, 금융 부문에서 데이터를 한 장소에서 다른 장소로 이동하려면 법적 의무를 충족해야 하는데, 이는 쉬운 일이 아닙니다.  이 시나리오에서 NetApp NFS 직접 액세스는 원래 위치에서 재무 데이터를 분석합니다.  또 다른 주요 이점은 NetApp NFS 직접 액세스를 사용하면 기본 Hadoop 명령을 사용하여 Hadoop 데이터를 보호하는 작업이 간소화되고 NetApp의 풍부한 데이터 관리 포트폴리오를 활용한 데이터 보호 워크플로가 가능해진다는 것입니다.</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 직접 액세스는 Hadoop/Spark 클러스터에 대해 두 가지 종류의 배포 옵션을 제공합니다.</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">기본적으로 Hadoop/Spark 클러스터는 데이터 저장을 위해 Hadoop 분산 파일 시스템(HDFS)과 기본 파일 시스템을 사용합니다.  NetApp NFS 직접 액세스를 통해 기본 HDFS를 NFS 스토리지로 대체하여 기본 파일 시스템으로 사용할 수 있으며, 이를 통해 NFS 데이터에 대한 직접 분석 작업이 가능합니다.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">또 다른 배포 옵션에서 NetApp NFS 직접 액세스는 단일 Hadoop/Spark 클러스터에서 HDFS와 함께 추가 스토리지로 NFS를 구성하는 것을 지원합니다.  이 경우, 고객은 NFS 내보내기를 통해 데이터를 공유하고 HDFS 데이터와 함께 동일한 클러스터에서 해당 데이터에 액세스할 수 있습니다.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">NetApp NFS 직접 액세스를 사용하면 다음과 같은 주요 이점이 있습니다.</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">현재 위치에서 데이터를 분석하므로 HDFS와 같은 Hadoop 인프라로 분석 데이터를 이동하는 데 드는 시간과 성능이 많이 소요되는 작업을 방지할 수 있습니다.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">복제본의 개수를 3개에서 1개로 줄입니다.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">사용자가 컴퓨팅과 스토리지를 분리하여 독립적으로 확장할 수 있습니다.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">ONTAP 의 풍부한 데이터 관리 기능을 활용하여 엔터프라이즈 데이터 보호를 제공합니다.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Hortonworks 데이터 플랫폼에 대한 인증을 받았습니다.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">하이브리드 데이터 분석 배포를 지원합니다.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">동적 멀티스레드 기능을 활용하여 백업 시간을 줄입니다.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">빅데이터를 위한 빌딩 블록</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">NetApp 이 제공하는 데이터 패브릭은 아래 그림에서 볼 수 있듯이 데이터 액세스, 제어, 보호 및 보안을 위한 데이터 관리 서비스와 애플리케이션(빌딩 블록)을 통합합니다.</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">위 그림의 구성 요소는 다음과 같습니다.</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 직접 액세스.*  추가 소프트웨어나 드라이버가 필요하지 않고 최신 Hadoop 및 Spark 클러스터에서 NetApp NFS 볼륨에 직접 액세스할 수 있습니다.</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAP 및 Google Cloud NetApp Volumes.*  Amazon Web Services(AWS)에서 실행되는 ONTAP 또는 Microsoft Azure 클라우드 서비스의 Azure NetApp Files (ANF) 기반의 소프트웨어 정의 연결 스토리지입니다.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirror 기술*.  온프레미스와 ONTAP Cloud 또는 NPS 인스턴스 간의 데이터 보호 기능을 제공합니다.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*클라우드 서비스 제공자.*  이러한 공급업체로는 AWS, Microsoft Azure, Google Cloud, IBM Cloud가 있습니다.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS.*  AWS의 Amazon Elastic MapReduce(EMR) 및 Databricks, Microsoft Azure HDInsight 및 Azure Databricks와 같은 클라우드 기반 분석 서비스입니다.</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp는 대규모 클러스터 간 및 클러스터 내 복사에 사용되는 기본 도구입니다.  Hadoop DistCp 기본 프로세스는 MapReduce와 같은 Hadoop 기본 도구를 사용하여 HDFS 소스에서 해당 대상으로 Hadoop 데이터를 복사하는 일반적인 백업 워크플로입니다.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop 데이터 보호 및 NetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp는 대규모 클러스터 간 및 클러스터 내 복사에 사용되는 기본 도구입니다.  아래 그림에 표시된 Hadoop DistCp 기본 프로세스는 MapReduce와 같은 Hadoop 기본 도구를 사용하여 HDFS 소스에서 해당 대상으로 Hadoop 데이터를 복사하는 일반적인 백업 워크플로입니다.</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">NetApp NFS 직접 액세스를 통해 고객은 Hadoop DistCp 도구의 대상 위치를 NFS로 설정하여 MapReduce를 통해 HDFS 소스의 데이터를 NFS 공유로 복사할 수 있습니다.  NetApp NFS 직접 액세스는 DistCp 도구에 대한 NFS 드라이버 역할을 합니다.</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">이 문서에서는 NetApp AFF 및 FAS 스토리지 시스템, NetApp Cloud Volumes ONTAP, NetApp 연결 스토리지, Spark 및 Hadoop용 NetApp FlexClone 기술을 사용하는 하이브리드 클라우드 데이터 솔루션을 설명합니다.  이러한 솔루션 아키텍처를 통해 고객은 자사 환경에 적합한 데이터 보호 솔루션을 선택할 수 있습니다.  NetApp 고객과의 상호 작용과 비즈니스 사용 사례를 기반으로 이러한 솔루션을 설계했습니다.</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">Karthikeyan Nagalingam 및 Sathish Thyagarajan, NetApp</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">이 문서에서는 NetApp AFF 및 FAS 스토리지 시스템, NetApp Cloud Volumes ONTAP, NetApp 연결 스토리지, Spark 및 Hadoop용 NetApp FlexClone 기술을 사용하는 하이브리드 클라우드 데이터 솔루션을 설명합니다.  이러한 솔루션 아키텍처를 통해 고객은 자사 환경에 적합한 데이터 보호 솔루션을 선택할 수 있습니다.  NetApp 고객과의 상호 작용과 비즈니스 사용 사례를 기반으로 이러한 솔루션을 설계했습니다.  이 문서에서는 다음과 같은 자세한 정보를 제공합니다.</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Spark 및 Hadoop 환경에서 데이터 보호가 필요한 이유와 고객 과제</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">NetApp 비전과 구성 요소 및 서비스를 기반으로 하는 데이터 패브릭입니다.</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">이러한 구성 요소를 사용하여 유연한 데이터 보호 워크플로를 구축하는 방법</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">실제 고객 사용 사례를 기반으로 한 여러 아키텍처의 장단점.  각 사용 사례는 다음 구성 요소를 제공합니다.</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">고객 시나리오</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">요구 사항 및 과제</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">솔루션</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">해결책 요약</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Hadoop 데이터 보호가 필요한 이유는?</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Hadoop 및 Spark 환경에서는 다음과 같은 문제를 해결해야 합니다.</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*소프트웨어 또는 사람의 실패.*  Hadoop 데이터 작업을 수행하는 동안 소프트웨어 업데이트에서 인적 오류가 발생하면 작업에서 예상치 못한 결과가 발생할 수 있는 잘못된 동작이 발생할 수 있습니다.  이런 경우에는 실패나 부당한 결과를 방지하기 위해 데이터를 보호해야 합니다.  예를 들어, 교통 신호 분석 애플리케이션에 대한 소프트웨어 업데이트가 제대로 실행되지 않아 일반 텍스트 형태의 교통 신호 데이터를 제대로 분석하지 못하는 새로운 기능이 생겼습니다.  해당 소프트웨어는 여전히 JSON 및 기타 텍스트가 아닌 파일 형식을 분석하여 실시간 교통 제어 분석 시스템에서 데이터 포인트가 누락된 예측 결과를 생성합니다.  이런 상황은 신호등에서 사고로 이어질 수 있는 잘못된 출력을 유발할 수 있습니다.  데이터 보호는 이전에 작동하던 애플리케이션 버전으로 빠르게 롤백하는 기능을 제공함으로써 이 문제를 해결할 수 있습니다.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*크기와 규모.*  데이터 소스와 볼륨이 끊임없이 증가함에 따라 분석 데이터의 크기도 날이 갈수록 커지고 있습니다.  소셜 미디어, 모바일 앱, 데이터 분석, 클라우드 컴퓨팅 플랫폼은 현재 빅데이터 시장의 주요 데이터 소스이며, 매우 빠르게 증가하고 있습니다. 따라서 정확한 데이터 작업을 보장하기 위해 데이터를 보호하는 것이 중요합니다.</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Hadoop의 기본 데이터 보호.*  Hadoop에는 데이터를 보호하는 기본 명령이 있지만, 이 명령은 백업하는 동안 데이터의 일관성을 제공하지 않습니다.  디렉토리 수준의 백업만 지원합니다.  Hadoop에서 생성된 스냅샷은 읽기 전용이므로 백업 데이터를 직접 재사용하는 데 사용할 수 없습니다.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop 및 Spark 고객을 위한 데이터 보호 과제</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop 및 Spark 고객이 겪는 일반적인 과제는 데이터 보호 중에 프로덕션 클러스터의 성능에 부정적인 영향을 미치지 않으면서 백업 시간을 줄이고 백업 안정성을 높이는 것입니다.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">또한 고객은 최적의 비즈니스 연속성을 위해 복구 지점 목표(RPO)와 복구 시간 목표(RTO) 가동 중지 시간을 최소화하고 온프레미스 및 클라우드 기반 재해 복구 사이트를 제어해야 합니다.  이러한 통제는 일반적으로 기업 수준의 관리 도구를 갖는 데서 비롯됩니다.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Hadoop과 Spark 환경은 데이터 볼륨이 엄청나고 계속 증가하고 있을 뿐만 아니라, 데이터가 도착하는 속도도 빨라지고 있기 때문에 복잡합니다.  이러한 시나리오에서는 소스 데이터로부터 효율적이고 최신 DevTest 및 QA 환경을 신속하게 만드는 것이 어렵습니다.  NetApp 이러한 과제를 인식하고 이 논문에서 제시하는 솔루션을 제공합니다.</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">이 시나리오에서는 대형 금융 서비스 및 투자 은행의 분석 플랫폼이 NetApp NFS 스토리지 솔루션을 사용하여 현대화되어 자산 관리 및 양적 사업 부문의 투자 위험 및 파생 상품 분석이 크게 개선되었습니다.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">사용 사례 5: 분석 워크로드 가속화</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">대본</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">고객의 기존 환경에서 분석 플랫폼에 사용된 Hadoop 인프라는 Hadoop 서버의 내부 스토리지를 활용했습니다.  JBOD 환경의 독점적 특성으로 인해 조직 내의 많은 내부 고객은 실시간 데이터의 반복적인 샘플에 의존하는 시뮬레이션인 몬테카를로 정량적 모델을 활용하지 못했습니다.  시장 움직임의 불확실성이 미치는 영향을 이해하는 능력이 부족하여 양적 자산 관리 사업부에 불리하게 작용했습니다.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">은행의 양적 사업부에서는 정확하고 시기적절한 예측을 달성하기 위해 효율적인 예측 방법을 원했습니다.  이를 위해 팀은 인프라를 현대화하고, 기존 I/O 대기 시간을 줄이고, Hadoop 및 Spark와 같은 분석 애플리케이션의 성능을 개선하여 투자 모델을 효율적으로 시뮬레이션하고, 잠재적 이익을 측정하고, 위험을 분석할 필요성을 인식했습니다.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">해결책</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">해당 고객은 기존 Spark 솔루션에 JBOD를 사용하고 있었습니다.  NetApp ONTAP, NetApp StorageGRID 및 MinIO Gateway to NFS를 활용하여 투자 모델에 대한 시뮬레이션과 분석을 실행하고 잠재적 이익과 위험을 평가하는 은행의 양적 금융 그룹의 I/O 대기 시간을 줄였습니다.  이 이미지는 NetApp 스토리지를 갖춘 Spark 솔루션을 보여줍니다.</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">위 그림에서 볼 수 있듯이, AFF A800, A700 시스템 및 StorageGRID Spark, YARN 및 Hive 메타데이터 서비스를 갖춘 6노드 Hadoop 클러스터에서 NFS 및 S3 프로토콜을 통해 Parquet 파일에 액세스하여 데이터 분석 작업을 수행하도록 배포되었습니다.</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">고객의 기존 환경에서는 DAS(Direct Attached Storage) 솔루션이 컴퓨팅과 스토리지를 독립적으로 확장할 수 없다는 단점이 있었습니다.  Spark용 NetApp ONTAP 솔루션을 통해 은행의 재무 분석 사업부는 스토리지와 컴퓨팅을 분리하고 필요에 따라 인프라 리소스를 보다 효과적으로 원활하게 활용할 수 있었습니다.</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">NFS와 함께 ONTAP 사용함으로써, 컴퓨팅 서버 CPU가 Spark SQL 작업에 거의 완전히 활용되었고 I/O 대기 시간이 약 70% 단축되었습니다. 그 결과, Spark 워크로드에 더 나은 컴퓨팅 성능과 향상이 제공되었습니다.  이후 CPU 활용도가 높아짐에 따라 고객은 GPUDirect와 같은 GPU를 활용하여 플랫폼을 더욱 현대화할 수 있게 되었습니다.  또한, StorageGRID Spark 워크로드를 위한 저렴한 스토리지 옵션을 제공하고 MinIO Gateway는 S3 프로토콜을 통해 NFS 데이터에 대한 안전한 액세스를 제공합니다.  클라우드에 있는 데이터의 경우 NetApp Cloud Volumes ONTAP, Azure NetApp Files, Google Cloud NetApp Volumes 권장합니다.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">이 사용 사례는 클라우드 기반 분석 데이터를 온프레미스 데이터 센터에 백업해야 하는 방송 고객을 기반으로 합니다.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">사용 사례 2: 클라우드에서 온프레미스로의 백업 및 재해 복구</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">이 사용 사례는 아래 그림에서 볼 수 있듯이 클라우드 기반 분석 데이터를 온프레미스 데이터 센터에 백업해야 하는 방송 고객을 기반으로 합니다.</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">이 시나리오에서는 IoT 센서 데이터가 클라우드로 수집되어 AWS 내의 오픈 소스 Apache Spark 클러스터를 사용하여 분석됩니다.  필요한 것은 클라우드에서 처리된 데이터를 온프레미스로 백업하는 것입니다.</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">이 사용 사례에 대한 주요 요구 사항과 과제는 다음과 같습니다.</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">데이터 보호를 활성화해도 클라우드의 프로덕션 Spark/Hadoop 클러스터의 성능에 영향이 없어야 합니다.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">클라우드 센서 데이터는 효율적이고 안전한 방식으로 온프레미스로 이동되고 보호되어야 합니다.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">온디맨드, 즉각적, 클러스터 부하가 적은 시간 등 다양한 조건에 따라 클라우드에서 온프레미스로 데이터를 전송할 수 있는 유연성이 있습니다.</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">고객은 Spark 클러스터 HDFS 스토리지로 AWS Elastic Block Store(EBS)를 사용하여 Kafka를 통해 원격 센서로부터 데이터를 수신하고 수집합니다.  따라서 HDFS 저장소는 백업 데이터의 소스 역할을 합니다.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">이러한 요구 사항을 충족하기 위해 NetApp ONTAP Cloud를 AWS에 배포하고 Spark/Hadoop 클러스터의 백업 대상으로 사용할 NFS 공유를 생성합니다.</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">NFS 공유가 생성된 후 HDFS EBS 스토리지에서 ONTAP NFS 공유로 데이터를 복사합니다.  데이터가 ONTAP 클라우드의 NFS에 저장된 후, SnapMirror 기술을 사용하여 필요에 따라 안전하고 효율적인 방식으로 클라우드의 데이터를 온프레미스 스토리지로 미러링할 수 있습니다.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">이 이미지는 클라우드에서 온프레미스 솔루션으로의 백업 및 재해 복구를 보여줍니다.</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">이 시나리오에서 고객은 대규모 온프레미스 Hadoop 저장소를 보유하고 있으며 재해 복구 목적으로 이를 백업하려고 합니다.  그러나 고객의 현재 백업 솔루션은 비용이 많이 들고 백업 시간이 24시간 이상 걸리는 문제점이 있습니다.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">사용 사례 1: Hadoop 데이터 백업</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">소프트웨어 이전 버전과의 호환성:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">제안된 대체 백업 솔루션은 프로덕션 Hadoop 클러스터에서 사용되는 현재 실행 중인 소프트웨어 버전과 호환되어야 합니다.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">약속된 SLA를 충족하기 위해 제안된 대안 솔루션은 매우 낮은 RPO와 RTO를 달성해야 합니다.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">NetApp 백업 솔루션으로 생성된 백업은 데이터 센터에 로컬로 구축된 Hadoop 클러스터뿐만 아니라 원격 사이트의 재해 복구 위치에서 실행되는 Hadoop 클러스터에서도 사용할 수 있습니다.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">제안된 솔루션은 비용 효율적이어야 합니다.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">제안된 솔루션은 백업 시간 동안 현재 실행 중인 프로덕션 분석 작업에 미치는 성능 영향을 줄여야 합니다.</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">고객의 기존 백업 솔루션x</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">아래 그림은 원래 Hadoop 기본 백업 솔루션을 보여줍니다.</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">생산 데이터는 중간 백업 클러스터를 통해 테이프로 보호됩니다.</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">HDFS1 데이터는 다음을 실행하여 HDFS2로 복사됩니다.<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">백업 클러스터는 NFS 게이트웨이 역할을 하며 데이터는 Linux를 통해 수동으로 테이프에 복사됩니다.<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block> 테이프 라이브러리를 통한 명령.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">원래 Hadoop 네이티브 백업 솔루션의 이점은 다음과 같습니다.</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">이 솔루션은 Hadoop 기본 명령을 기반으로 하므로 사용자는 새로운 절차를 배울 필요가 없습니다.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">이 솔루션은 업계 표준 아키텍처와 하드웨어를 활용합니다.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">원래 Hadoop 네이티브 백업 솔루션의 단점은 다음과 같습니다.</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">백업 윈도우 시간이 24시간을 초과하면 운영 데이터가 취약해집니다.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">백업하는 동안 클러스터 성능이 크게 저하됩니다.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">테이프에 복사하는 작업은 수동 작업입니다.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">백업 솔루션은 필요한 하드웨어와 수동 프로세스에 필요한 인력 시간 측면에서 비용이 많이 듭니다.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">백업 솔루션</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">이러한 과제와 요구 사항을 바탕으로 기존 백업 시스템을 고려하여 세 가지 가능한 백업 솔루션이 제안되었습니다.  다음 하위 섹션에서는 솔루션 A부터 솔루션 C까지 라벨이 붙은 세 가지 백업 솔루션 각각에 대해 설명합니다.</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">솔루션 A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">솔루션 A에서는 백업 Hadoop 클러스터가 보조 백업을 NetApp NFS 스토리지 시스템으로 보내서 아래 그림과 같이 테이프가 필요하지 않습니다.</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">솔루션 A에 대한 세부 작업은 다음과 같습니다.</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">프로덕션 Hadoop 클러스터에는 보호가 필요한 HDFS에 고객의 분석 데이터가 있습니다.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">HDFS가 있는 백업 Hadoop 클러스터는 데이터의 중간 위치 역할을 합니다.  JBOD(Just a Bunch Of Disks)는 프로덕션 및 백업 Hadoop 클러스터 모두에서 HDFS에 대한 스토리지를 제공합니다.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Hadoop 프로덕션 데이터는 프로덕션 클러스터 HDFS에서 백업 클러스터 HDFS로 보호됩니다.<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop 스냅샷은 프로덕션 데이터를 백업 Hadoop 클러스터로 보호하는 데 사용됩니다.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP 스토리지 컨트롤러는 백업 Hadoop 클러스터에 프로비저닝되는 NFS 내보낸 볼륨을 제공합니다.</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">실행하여<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block> MapReduce와 여러 매퍼를 활용하는 명령을 사용하면 분석 데이터가 백업 Hadoop 클러스터에서 NFS로 보호됩니다.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">데이터가 NetApp 스토리지 시스템의 NFS에 저장된 후, NetApp Snapshot, SnapRestore 및 FlexClone 기술을 사용하여 필요에 따라 Hadoop 데이터를 백업, 복원 및 복제합니다.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">SnapMirror 기술을 사용하면 Hadoop 데이터를 클라우드뿐만 아니라 재해 복구 위치에도 보호할 수 있습니다.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">솔루션 A의 이점은 다음과 같습니다.</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop 프로덕션 데이터는 백업 클러스터에서 보호됩니다.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS 데이터는 클라우드 및 재해 복구 위치로의 보호를 지원하는 NFS를 통해 보호됩니다.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">백업 작업을 백업 클러스터로 오프로드하여 성능을 향상시킵니다.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">수동 테이프 작업을 제거합니다.</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">NetApp 도구를 통해 엔터프라이즈 관리 기능을 제공합니다.</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">기존 환경을 최소한으로 변경해야 합니다.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">비용 효율적인 솔루션입니다.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">이 솔루션의 단점은 성능을 개선하려면 백업 클러스터와 추가 매퍼가 필요하다는 것입니다.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">해당 고객은 최근 단순성, 비용, 전반적인 성능 때문에 솔루션 A를 구축했습니다.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">이 솔루션에서는 JBOD 대신 ONTAP 의 SAN 디스크를 사용할 수 있습니다.  이 옵션을 선택하면 백업 클러스터 스토리지 부하가 ONTAP 으로 분산됩니다. 하지만 단점은 SAN 패브릭 스위치가 필요하다는 것입니다.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">솔루션 B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">솔루션 B는 프로덕션 Hadoop 클러스터에 NFS 볼륨을 추가하여 아래 그림과 같이 백업 Hadoop 클러스터가 필요 없게 합니다.</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">솔루션 B에 대한 세부 작업은 다음과 같습니다.</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP 스토리지 컨트롤러는 프로덕션 Hadoop 클러스터에 NFS 내보내기 기능을 제공합니다.</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Hadoop 네이티브<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block> 명령은 프로덕션 클러스터 HDFS의 Hadoop 데이터를 NFS로 보호합니다.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">데이터가 NetApp 스토리지 시스템의 NFS에 저장된 후 Snapshot, SnapRestore 및 FlexClone 기술을 사용하여 필요에 따라 Hadoop 데이터를 백업, 복원 및 복제합니다.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">솔루션 B의 이점은 다음과 같습니다.</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">백업 솔루션을 위해 프로덕션 클러스터를 약간 수정하여 구현을 간소화하고 추가 인프라 비용을 절감했습니다.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">백업 작업을 위한 백업 클러스터가 필요하지 않습니다.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS 프로덕션 데이터는 NFS 데이터로 변환될 때 보호됩니다.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">이 솔루션은 NetApp 도구를 통해 엔터프라이즈 관리 기능을 제공합니다.</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">이 솔루션의 단점은 프로덕션 클러스터에서 구현되기 때문에 프로덕션 클러스터에서 추가적인 관리자 작업이 필요할 수 있다는 점입니다.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">솔루션 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">솔루션 C에서는 NetApp SAN 볼륨이 아래 그림과 같이 HDFS 스토리지를 위한 Hadoop 프로덕션 클러스터에 직접 프로비저닝됩니다.</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">솔루션 C에 대한 자세한 단계는 다음과 같습니다.</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN 스토리지는 HDFS 데이터 스토리지를 위해 프로덕션 Hadoop 클러스터에 프로비저닝됩니다.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot 및 SnapMirror 기술은 프로덕션 Hadoop 클러스터의 HDFS 데이터를 백업하는 데 사용됩니다.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">백업이 스토리지 계층에서 수행되므로 스냅샷 복사 백업 프로세스 동안 Hadoop/Spark 클러스터의 프로덕션 성능에 영향이 없습니다.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">스냅샷 기술은 데이터 크기에 관계없이 몇 초 안에 완료되는 백업을 제공합니다.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">솔루션 C의 이점은 다음과 같습니다.</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">스냅샷 기술을 사용하면 공간 효율적인 백업을 만들 수 있습니다.</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">이 사용 사례에서 고객 요구 사항은 DevTest 및 보고 목적으로 동일한 데이터 센터와 원격 위치에서 대량의 분석 데이터가 포함된 기존 Hadoop 클러스터를 기반으로 새로운 Hadoop/Spark 클러스터를 빠르고 효율적으로 구축하는 것입니다.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">사용 사례 3: 기존 Hadoop 데이터에 DevTest 활성화</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">이 시나리오에서는 대규모 Hadoop 데이터 레이크 구현을 기반으로 온프레미스와 재해 복구 위치에서 여러 개의 Spark/Hadoop 클러스터가 구축됩니다.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">DevTest, QA 또는 동일한 프로덕션 데이터에 액세스해야 하는 다른 목적을 위해 여러 개의 Hadoop 클러스터를 만듭니다.  여기서의 과제는 매우 큰 Hadoop 클러스터를 매우 공간 효율적인 방식으로 즉시 여러 번 복제하는 것입니다.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">운영 효율성을 위해 Hadoop 데이터를 DevTest 및 보고 팀과 동기화합니다.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">동일한 자격 증명을 사용하여 Hadoop 데이터를 프로덕션 클러스터와 새 클러스터에 분산합니다.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">예약된 정책을 사용하면 프로덕션 클러스터에 영향을 주지 않고 효율적으로 QA 클러스터를 만들 수 있습니다.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone 기술은 위에서 설명한 요구 사항에 답하는 데 사용됩니다.  FlexClone 기술은 스냅샷 복사본의 읽기/쓰기 복사본입니다.  부모 스냅샷 복사본 데이터에서 데이터를 읽고 새 블록/수정된 블록에 대해서만 추가 공간을 사용합니다.  빠르고 공간 효율적입니다.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">먼저, NetApp 일관성 그룹을 사용하여 기존 클러스터의 스냅샷 복사본을 만들었습니다.</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">NetApp System Manager 또는 스토리지 관리자 프롬프트에서 스냅샷 복사본을 생성합니다.  일관성 그룹 스냅샷 복사본은 애플리케이션 일관성 그룹 스냅샷 복사본이며, FlexClone 볼륨은 일관성 그룹 스냅샷 복사본을 기반으로 생성됩니다.  FlexClone 볼륨은 부모 볼륨의 NFS 내보내기 정책을 상속한다는 점을 언급하는 것이 좋습니다.  스냅샷 복사본이 생성된 후에는 아래 그림과 같이 DevTest 및 보고 목적으로 새로운 Hadoop 클러스터를 설치해야 합니다.  새로운 Hadoop 클러스터에서 복제된 NFS 볼륨은 NFS 데이터에 액세스합니다.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">이 이미지는 DevTest를 위한 Hadoop 클러스터를 보여줍니다.</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">이 사용 사례는 고객의 빅데이터 분석 데이터에 대한 멀티클라우드 연결을 제공하는 업무를 맡은 클라우드 서비스 파트너에게 적합합니다.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">사용 사례 4: 데이터 보호 및 멀티클라우드 연결</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">이 시나리오에서는 다양한 소스에서 AWS로 수신된 IoT 데이터가 NPS의 중앙 위치에 저장됩니다.  NPS 스토리지는 AWS와 Azure에 있는 Spark/Hadoop 클러스터에 연결되어 여러 클라우드에서 실행되는 빅데이터 분석 애플리케이션이 동일한 데이터에 액세스할 수 있도록 합니다.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">고객은 여러 클라우드를 사용하여 동일한 데이터에 대한 분석 작업을 실행하려고 합니다.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">데이터는 다양한 센서와 허브를 통해 온프레미스, 클라우드 등 다양한 소스에서 수신되어야 합니다.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">해결책은 효율적이고 비용 효과적이어야 합니다.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">가장 큰 과제는 온프레미스와 다양한 클라우드 간에 하이브리드 분석 서비스를 제공하는 비용 효율적이고 효과적인 솔루션을 구축하는 것입니다.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">이 이미지는 데이터 보호 및 멀티클라우드 연결 솔루션을 보여줍니다.</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">위 그림에서 볼 수 있듯이, 센서의 데이터는 Kafka를 통해 AWS Spark 클러스터로 스트리밍되고 수집됩니다.  데이터는 클라우드 제공자 외부의 Equinix 데이터 센터 내에 있는 NPS에 있는 NFS 공유에 저장됩니다.  NetApp NPS는 Direct Connect와 Express Route 연결을 통해 Amazon AWS와 Microsoft Azure에 연결되어 있으므로 고객은 Amazon과 AWS 분석 클러스터 모두에서 NFS 데이터에 액세스할 수 있습니다.  이 접근 방식은 여러 하이퍼스케일러에서 클라우드 분석을 수행하는 문제를 해결합니다.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">따라서 온프레미스와 NPS 스토리지 모두 ONTAP 소프트웨어를 실행하므로 SnapMirror NPS 데이터를 온프레미스 클러스터로 미러링하여 온프레미스와 여러 클라우드에서 하이브리드 클라우드 분석을 제공할 수 있습니다.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">최상의 성능을 위해 NetApp 일반적으로 여러 네트워크 인터페이스와 직접 연결/고속 경로를 사용하여 클라우드 인스턴스의 데이터에 액세스할 것을 권장합니다.</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">이 섹션에서는 본 논문의 초점인 데이터 보호 사용 사례에 대한 간략한 설명을 제공합니다.  나머지 섹션에서는 고객 문제(시나리오), 요구 사항 및 과제, 솔루션 등 각 사용 사례에 대한 자세한 내용을 제공합니다.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop 데이터 보호 사용 사례 개요</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">이 사용 사례에서 NetApp NFS 볼륨은 대형 금융 기관이 백업 시간을 24시간 이상에서 몇 시간 이내로 줄이는 데 도움이 되었습니다.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">NetApp 이 제공하는 데이터 패브릭을 빌딩 블록으로 사용하여 대형 방송 회사는 주문형, 즉시 또는 Hadoop/Spark 클러스터 부하 기반 등 다양한 데이터 전송 모드에 따라 클라우드 데이터를 온프레미스 데이터 센터에 백업해야 하는 요구 사항을 충족할 수 있었습니다.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetApp 솔루션은 온라인 음악 유통사가 여러 지점에 공간 효율적인 Hadoop 클러스터를 빠르게 구축하여 예약된 정책을 사용하여 보고서를 작성하고 일일 DevTest 작업을 실행하는 데 도움이 되었습니다.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">대규모 서비스 제공업체는 NetApp 이 제공하는 데이터 패브릭을 사용하여 다양한 클라우드 인스턴스의 고객에게 멀티클라우드 분석을 제공했습니다.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">최대 규모의 금융 서비스 및 투자 은행 중 하나가 NetApp 네트워크 연결 스토리지 솔루션을 사용하여 I/O 대기 시간을 줄이고 정량적 금융 분석 플랫폼을 가속화했습니다.</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">이 섹션에서는 이 인증으로부터 얻은 교훈을 소개합니다.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">모범 사례 지침</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">검증 결과, Confluent가 데이터를 보관하는 데는 S3 개체 스토리지가 가장 적합합니다.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Confluent 계층형 스토리지 구성에서 브로커 데이터 디렉토리에 보관되는 데이터 크기는 세그먼트 크기와 데이터가 개체 스토리지로 이동될 때의 보존 시간에 따라 결정되므로, 고처리량 SAN(특히 FC)을 사용하여 브로커의 핫 데이터나 로컬 디스크를 유지할 수 있습니다.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">segment.bytes가 높을수록 개체 저장소의 성능이 더 좋습니다. 테스트에서는 512MB를 사용했습니다.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Kafka에서는 주제에 생성된 각 레코드의 키 또는 값의 길이(바이트)가 다음에 의해 제어됩니다.<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> 매개변수.  StorageGRID 의 경우 S3 객체 수집 및 검색 성능이 더 높은 값으로 향상되었습니다.  예를 들어, 512바이트는 5.8GBps 검색 속도를 제공하고, 1024바이트는 7.5GBps s3 검색 속도를 제공하며, 2048바이트는 거의 10GBps 검색 속도를 제공합니다.</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">다음 그림은 S3 객체 수집 및 검색을 기반으로 보여줍니다.<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> .</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*카프카 튜닝.*  계층형 저장소의 성능을 개선하려면 TierFetcherNumThreads와 TierArchiverNumThreads를 늘릴 수 있습니다.  일반적인 지침으로, TierFetcherNumThreads를 실제 CPU 코어 수와 일치하도록 늘리고 TierArchiverNumThreads를 CPU 코어 수의 절반으로 늘리는 것이 좋습니다.  예를 들어, 서버 속성에서 물리적 코어가 8개인 머신이 있는 경우 confluent.tier.fetcher.num.threads = 8, confluent.tier.archiver.num.threads = 4로 설정합니다.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*주제 삭제 시간 간격.*  주제가 삭제되면 개체 스토리지에 있는 로그 세그먼트 파일의 삭제가 즉시 시작되지 않습니다.  대신, 해당 파일이 삭제되기 전에 기본값인 3시간의 시간 간격이 있습니다.  confluent.tier.topic.delete.check.interval.ms 구성을 수정하여 이 간격의 값을 변경할 수 있습니다.  주제나 클러스터를 삭제하는 경우 해당 버킷에 있는 객체를 수동으로 삭제할 수도 있습니다.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*계층화된 스토리지 내부 주제에 대한 ACL.*  온프레미스 배포에 권장되는 모범 사례는 계층형 저장소에 사용되는 내부 항목에 ACL 권한 부여자를 활성화하는 것입니다.  ACL 규칙을 설정하여 이 데이터에 대한 액세스를 브로커 사용자로만 제한합니다.  이를 통해 내부 주제가 보호되고 계층형 스토리지 데이터와 메타데이터에 대한 무단 액세스가 방지됩니다.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">사용자를 교체하세요<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block> 배포 시 실제 브로커 주체와 함께.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">예를 들어, 명령<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block> 계층형 저장소에 대한 내부 주제에 ACL을 설정합니다.  현재 계층형 스토리지와 관련된 내부 주제는 단 하나뿐입니다.  이 예제에서는 내부 주제에 대한 모든 작업에 대한 주요 Kafka 권한을 제공하는 ACL을 만듭니다.</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">NetApp StorageGRID 의 계층형 스토리지를 위해 Kafka를 사용하여 Confluent Platform에 대한 인증을 수행했습니다.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Confluent 검증</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">NetApp StorageGRID 의 Confluent Platform 6.2 Tiered Storage를 사용하여 검증을 수행했습니다.  NetApp 과 Confluent 팀은 이 검증 작업을 함께 수행했으며 검증에 필요한 테스트 사례를 실행했습니다.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Confluent 플랫폼 설정</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">우리는 검증을 위해 다음과 같은 설정을 사용했습니다.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">검증을 위해 3개의 동물원 관리자, 5개의 브로커, 5개의 테스트 스크립트 실행 서버, 256GB RAM과 16개의 CPU가 장착된 명명된 도구 서버를 사용했습니다.  NetApp 스토리지의 경우, 4개의 SGF6024를 탑재한 SG1000 로드 밸런서와 함께 StorageGRID 사용했습니다.  저장소와 브로커는 100GbE 연결을 통해 연결되었습니다.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">다음 그림은 Confluent 검증에 사용된 구성의 네트워크 토폴로지를 보여줍니다.</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">도구 서버는 Confluent 노드에 요청을 보내는 애플리케이션 클라이언트 역할을 합니다.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Confluent 계층형 스토리지 구성</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">Kafka에서 계층형 스토리지 구성에는 다음 매개변수가 필요합니다.</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">검증을 위해 HTTP 프로토콜을 사용하는 StorageGRID 사용했지만 HTTPS도 가능합니다.  액세스 키와 비밀 키는 제공된 파일 이름에 저장됩니다.<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> 매개변수.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp 객체 스토리지 - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">검증을 위해 StorageGRID 에서 단일 사이트 구성을 구성했습니다.</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">검증 테스트</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">우리는 검증을 위해 다음의 5가지 테스트 사례를 완료했습니다.  이러한 테스트는 Trogdor 프레임워크에서 실행됩니다.  처음 두 가지는 기능 테스트였고 나머지 세 가지는 성능 테스트였습니다.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">객체 저장소 정확성 테스트</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">이 테스트는 계층형 스토리지의 요구 사항에 따라 객체 저장소 API의 모든 기본 작업(예: 가져오기/넣기/삭제)이 제대로 작동하는지 여부를 판별합니다.  이는 모든 객체 저장 서비스가 다음 테스트에 앞서 통과해야 하는 기본 테스트입니다.  합격 아니면 불합격이 결정되는 단정적 시험입니다.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">계층화 기능 정확성 테스트</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">이 테스트는 엔드투엔드 계층형 스토리지 기능이 통과하거나 실패하는 단정적 테스트를 통해 잘 작동하는지 확인합니다.  이 테스트는 기본적으로 계층화가 활성화되고 핫셋 크기가 크게 줄어든 테스트 주제를 생성합니다.  새로 생성된 테스트 주제에 대한 이벤트 스트림을 생성하고, 브로커가 세그먼트를 객체 저장소에 보관할 때까지 기다린 다음, 이벤트 스트림을 사용하여 사용된 스트림이 생성된 스트림과 일치하는지 확인합니다.  이벤트 스트림에 생성되는 메시지의 수는 구성 가능하므로 사용자는 테스트 요구 사항에 따라 충분히 큰 작업 부하를 생성할 수 있습니다.  핫셋 크기를 줄이면 활성 세그먼트 외부의 소비자 페치가 객체 저장소에서만 제공되도록 보장됩니다. 이는 읽기에 대한 객체 저장소의 정확성을 테스트하는 데 도움이 됩니다.  우리는 객체 저장소 오류 주입을 적용한 경우와 적용하지 않은 경우로 이 테스트를 수행했습니다.  StorageGRID 의 노드 중 하나에서 서비스 관리자 서비스를 중지하고 엔드투엔드 기능이 개체 스토리지에서 작동하는지 검증하여 노드 장애를 시뮬레이션했습니다.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">티어 페치 벤치마크</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">이 테스트는 계층형 개체 스토리지의 읽기 성능을 검증하고 벤치마크에서 생성된 세그먼트에서 높은 부하가 걸리는 범위 페치 읽기 요청을 확인했습니다.  이 벤치마크에서 Confluent는 계층별 페치 요청을 처리하기 위해 사용자 정의 클라이언트를 개발했습니다.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">생산-소비 워크로드 벤치마크</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">이 테스트는 세그먼트 보관을 통해 개체 저장소에 대한 쓰기 작업 부하를 간접적으로 생성했습니다.  소비자 그룹이 세그먼트를 가져올 때 개체 스토리지에서 읽기 작업 부하(세그먼트 읽기)가 생성되었습니다.  이 작업 부하는 테스트 스크립트에 의해 생성되었습니다.  이 테스트는 병렬 스레드에서 개체 스토리지의 읽기 및 쓰기 성능을 확인했습니다.  우리는 계층화 기능 정확성 테스트에서 했던 것처럼 객체 저장소 오류 주입을 적용한 경우와 적용하지 않은 경우를 테스트했습니다.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">유지 관리 작업 벤치마크</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">이 테스트는 주제 보존 작업 부하가 큰 상황에서 객체 저장소의 삭제 성능을 확인했습니다.  보존 작업 부하는 테스트 주제와 병렬로 많은 메시지를 생성하는 테스트 스크립트를 사용하여 생성되었습니다.  테스트 주제는 이벤트 스트림이 개체 저장소에서 지속적으로 제거되도록 하는 공격적인 크기 기반 및 시간 기반 보존 설정으로 구성되었습니다.  그런 다음 세그먼트는 보관되었습니다.  이로 인해 브로커에 의한 개체 저장소의 대량 삭제가 발생하고 개체 저장소 삭제 작업의 성능이 저하되었습니다.</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">아파치 카프카란 무엇인가요?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">어리석은 이름 바꾸기란 무엇입니까?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP는 스트리밍 애플리케이션에 사용됩니다.</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp 제품 설명서</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">NFS란 무엇인가요?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">카프카 파티션 재할당이란 무엇인가요?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">OpenMessaging 벤치마크란 무엇인가요?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">카프카 브로커를 어떻게 마이그레이션하나요?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">Prometheus를 사용하여 Kafka 브로커를 어떻게 모니터링합니까?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Apache Kafka를 위한 관리형 플랫폼</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Apache Kafka 지원</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Apache Kafka 컨설팅 서비스</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">어리석은 이름 변경 문제에 대한 NetApp 솔루션은 이전에는 NFS와 호환되지 않았던 워크로드에 대해 간단하고 저렴하며 중앙에서 관리되는 형태의 스토리지를 제공합니다.</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">이 새로운 패러다임을 통해 고객은 재해 복구 및 데이터 보호 목적으로 마이그레이션 및 미러링하기 쉬운 Kafka 클러스터를 보다 쉽게 만들 수 있습니다.  또한 NFS는 CPU 사용률 감소, 복구 시간 단축, 스토리지 효율성의 획기적 개선, NetApp ONTAP 통한 성능 향상 등의 추가 이점을 제공한다는 것을 확인했습니다.</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">이 문서에서는 어리석은 이름 바꾸기 문제와 솔루션 검증, I/O 대기 시간을 줄이기 위한 CPU 사용률 감소, 더 빠른 Kafka 브로커 복구 시간, 클라우드 및 온프레미스에서의 성능 등에 대해 설명합니다.</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: NetApp NFS 스토리지를 사용한 Apache Kafka 워크로드 - 기능 검증 및 성능</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole, Karthikeyan Nagalingam 및 Joe Scott, NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">카프카는 대량의 메시지 데이터를 수용할 수 있는 강력한 큐를 갖춘 분산형 게시-구독 메시징 시스템입니다.  Kafka를 사용하면 애플리케이션이 매우 빠르게 주제에 데이터를 쓰고 읽을 수 있습니다.  Kafka는 내결함성과 확장성이 뛰어나서 빅데이터 분야에서 많은 데이터 스트림을 매우 빠르게 수집하고 이동하는 안정적인 방법으로 자주 사용됩니다.  사용 사례로는 스트림 처리, 웹사이트 활동 추적, 메트릭 수집 및 모니터링, 로그 집계, 실시간 분석 등이 있습니다.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">여기</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">NFS에서 일반적인 Kafka 작업은 잘 작동하지만, NFS에서 실행되는 Kafka 클러스터의 크기를 조정하거나 다시 분할하는 동안 어리석은 이름 바꾸기 문제로 인해 애플리케이션이 충돌합니다.  이는 부하 분산이나 유지 관리를 위해 카프카 클러스터의 크기를 조정하거나 다시 분할해야 하기 때문에 중요한 문제입니다.  추가 세부 정보를 찾을 수 있습니다<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block> .</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">이 문서에서는 다음 주제에 대해 설명합니다.</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">어리석은 이름 바꾸기 문제와 솔루션 검증</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">I/O 대기 시간을 줄이기 위해 CPU 사용률을 줄이세요</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">더 빠른 Kafka 브로커 복구 시간</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">클라우드 및 온프레미스에서의 성능</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">Kafka 워크로드에 NFS 스토리지를 사용하는 이유는 무엇입니까?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">프로덕션 애플리케이션의 Kafka 워크로드는 애플리케이션 간에 엄청난 양의 데이터를 스트리밍할 수 있습니다.  이 데이터는 Kafka 클러스터의 Kafka 브로커 노드에 보관되고 저장됩니다.  카프카는 가용성과 병렬 처리로도 유명한데, 이는 주제를 파티션으로 나누고 해당 파티션을 클러스터 전체에 복제함으로써 달성됩니다.  결국 이는 카프카 클러스터를 통과하는 엄청난 양의 데이터 크기가 일반적으로 몇 배로 증가한다는 것을 의미합니다.  NFS를 사용하면 브로커 수가 변경되어도 데이터를 매우 빠르고 쉽게 재조정할 수 있습니다.  대규모 환경에서 브로커 수가 변경될 때 DAS 전체에서 데이터를 재조정하는 작업은 매우 많은 시간이 소요되며, 대부분의 Kafka 환경에서는 브로커 수가 자주 변경됩니다.</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">기타 혜택은 다음과 같습니다.</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*성숙함.*  NFS는 성숙한 프로토콜이므로 구현, 보안 및 사용의 대부분 측면이 잘 이해되어 있습니다.</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*열려 있는.*  NFS는 개방형 프로토콜이며, 무료 개방형 네트워크 프로토콜로서 지속적인 개발이 인터넷 사양에 문서화되어 있습니다.</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*비용 효율적입니다.*  NFS는 기존 네트워크 인프라를 활용하기 때문에 설정이 쉬운 저비용 네트워크 파일 공유 솔루션입니다.</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*중앙에서 관리됨.*  NFS를 중앙에서 관리하면 개별 사용자 시스템에서 추가 소프트웨어와 디스크 공간에 대한 필요성이 줄어듭니다.</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*분배됨.*  NFS는 분산 파일 시스템으로 사용할 수 있으므로 이동식 미디어 저장 장치의 필요성이 줄어듭니다.</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">Kafka 워크로드에 NetApp 하는 이유는 무엇입니까?</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">NetApp NFS 구현은 프로토콜에 대한 황금 표준으로 간주되며 수많은 기업 NAS 환경에서 사용됩니다. NetApp 의 신뢰성 외에도 다음과 같은 이점이 있습니다.</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">신뢰성과 효율성</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">확장성 및 성능</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">고가용성( NetApp ONTAP 클러스터의 HA 파트너)</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">데이터 보호</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*재해 복구(NetApp SnapMirror).*  사이트가 다운되거나 다른 사이트에서 바로 시작해서 중단했던 부분부터 계속하고 싶은 경우.</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">스토리지 시스템의 관리 용이성( NetApp OnCommand 사용한 관리 및 운영).</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*부하 분산.*  클러스터를 사용하면 다양한 노드에 호스팅된 데이터 LIF에서 다양한 볼륨에 액세스할 수 있습니다.</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*중단 없는 운영.*  LIF 또는 볼륨 이동은 NFS 클라이언트에 투명하게 처리됩니다.</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">온프레미스에서는 ONTAP 9.12.1RC1과 NetApp AFF A900 스토리지 컨트롤러를 사용하여 Kafka 클러스터의 성능과 확장성을 검증했습니다.  우리는 ONTAP 과 AFF 활용한 이전 계층형 스토리지 모범 사례와 동일한 테스트베드를 사용했습니다.</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">온프레미스 AFF A900 통한 성능 개요 및 검증</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">온프레미스에서는 ONTAP 9.12.1RC1과 NetApp AFF A900 스토리지 컨트롤러를 사용하여 Kafka 클러스터의 성능과 확장성을 검증했습니다.  우리는 ONTAP 과 AFF 활용한 이전 계층형 스토리지 모범 사례와 동일한 테스트베드를 사용했습니다.</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">우리는 Confluent Kafka 6.2.0을 사용하여 AFF A900 평가했습니다.  클러스터는 8개의 브로커 노드와 3개의 주키퍼 노드로 구성됩니다.  성능 테스트를 위해 OMB 작업자 노드 5개를 사용했습니다.</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">스토리지 구성</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">NetApp FlexGroups 인스턴스를 사용하여 로그 디렉토리에 대한 단일 네임스페이스를 제공하고, 이를 통해 복구 및 구성을 간소화했습니다.  로그 세그먼트 데이터에 대한 직접 경로 액세스를 제공하기 위해 NFSv4.1과 pNFS를 사용했습니다.</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">클라이언트 튜닝</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">각 클라이언트는 다음 명령을 사용하여 FlexGroup 인스턴스를 마운트했습니다.</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">또한, 우리는 증가했습니다<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block> 기본값에서<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block> 에게<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block> .  이는 ONTAP 의 기본 세션 슬롯 제한과 일치합니다.</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">카프카 브로커 튜닝</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">테스트 중인 시스템의 처리량을 극대화하기 위해 특정 주요 스레드 풀에 대한 기본 매개변수를 크게 늘렸습니다.  대부분의 구성에 대해 Confluent Kafka 모범 사례를 따르는 것이 좋습니다.  이 튜닝은 스토리지에 대한 뛰어난 I/O의 동시성을 극대화하는 데 사용되었습니다.  이러한 매개변수는 브로커의 컴퓨팅 리소스와 스토리지 속성에 맞게 조정할 수 있습니다.</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">워크로드 생성기 테스트 방법론</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">처리량 드라이버와 주제 구성을 위해 클라우드 테스트와 동일한 OMB 구성을 사용했습니다.</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">FlexGroup 인스턴스는 AFF 클러스터에서 Ansible을 사용하여 프로비저닝되었습니다.</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">ONTAP SVM에서 pNFS가 활성화되었습니다.</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">작업 부하는 Cloud Volumes ONTAP 과 동일한 작업 부하 구성을 사용하여 처리량 드라이버로 트리거되었습니다.  "섹션을 참조하세요.<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> " 아래에.  작업 부하에는 3의 복제 요소가 사용되었는데, 이는 로그 세그먼트의 3개 사본이 NFS에 유지된다는 것을 의미합니다.</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">마지막으로, 우리는 소비자들이 최신 메시지를 따라잡을 수 있는 능력을 측정하기 위해 백로그를 활용한 측정을 완료했습니다.  OMB는 측정 시작 시 소비자의 활동을 일시 정지시켜 백로그를 구성합니다.  이는 세 가지 뚜렷한 단계를 생성합니다. 백로그 생성(생산자 전용 트래픽), 백로그 드레이닝(소비자가 토픽에서 놓친 이벤트를 따라잡는 소비자 중심 단계), 정상 상태입니다. "섹션을 참조하세요.<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block> " 자세한 내용은.</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">정상 상태 성능</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">AWS의 Cloud Volumes ONTAP 과 AWS의 DAS에 대한 비교와 유사한 비교를 제공하기 위해 OpenMessaging 벤치마크를 사용하여 AFF A900 평가했습니다.  모든 성능 값은 프로듀서 및 소비자 수준에서의 카프카 클러스터 처리량을 나타냅니다.</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Confluent Kafka와 AFF A900 사용한 정상 상태 성능은 제작자와 소비자 모두에서 평균 3.4GBps 이상의 처리량을 달성했습니다.  이는 Kafka 클러스터 전체에 340만 개가 넘는 메시지입니다.  BrokerTopicMetrics의 초당 바이트 단위의 지속적인 처리량을 시각화하면 AFF A900 이 지원하는 뛰어난 정상 상태 성능과 트래픽을 확인할 수 있습니다.</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">이 그래프는 브로커 네트워크 처리량을 보여줍니다.</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">이는 주제별로 전달된 메시지의 관점과 잘 일치합니다.  다음 그래프는 주제별 분석을 제공합니다.  테스트한 구성에서는 4개 주제에 걸쳐 주제당 약 90만 개의 메시지를 확인했습니다.</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">극한의 성능과 저장 한계 탐색</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">AFF 의 경우, 백로그 기능을 사용하여 OMB에서도 테스트했습니다.  백로그 기능은 Kafka 클러스터에 이벤트 백로그가 축적되는 동안 소비자 구독을 일시 중지합니다.  이 단계에서는 프로듀서 트래픽만 발생하며, 이를 통해 로그에 커밋되는 이벤트가 생성됩니다.  이는 일괄 처리나 오프라인 분석 워크플로를 가장 밀접하게 에뮬레이션합니다. 이러한 워크플로에서 소비자 구독이 시작되고 브로커 캐시에서 이미 제거된 과거 데이터를 읽어야 합니다.</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">이 구성에서 소비자 처리량에 대한 저장 제한을 파악하기 위해 생산자 전용 단계를 측정하여 A900이 얼마나 많은 쓰기 트래픽을 흡수할 수 있는지 파악했습니다.  다음 섹션을 참조하세요.<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block> "이 데이터를 활용하는 방법을 이해합니다.</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">이 측정의 생산자 전용 부분에서 우리는 A900 성능의 한계를 뛰어넘는 높은 피크 처리량을 확인했습니다(생산자 및 소비자 트래픽을 제공하는 다른 브로커 리소스가 포화 상태가 아니었을 때).</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">이 측정에서는 메시지 당 오버헤드를 제한하고 NFS 마운트 지점에 대한 저장 처리량을 극대화하기 위해 메시지 크기를 16k로 늘렸습니다.</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Confluent Kafka 클러스터는 최대 프로듀서 처리량 4.03GBps를 달성했습니다.</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">OMB가 이벤트 백로그 채우기를 완료한 후 소비자 트래픽이 다시 시작되었습니다.  백로그 드레이닝을 통한 측정 동안 모든 주제에서 최대 소비자 처리량이 20GBps가 넘는 것을 관찰했습니다.  OMB 로그 데이터를 저장하는 NFS 볼륨에 대한 결합 처리량은 ~30GBps에 달했습니다.</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">사이즈 가이드</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">사이즈 가이드</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Services는 다음을 제공합니다.<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block> 카프카 클러스터 크기 조정 및 확장을 위한 것입니다.</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">이 크기 조정은 Kafka 클러스터의 스토리지 처리량 요구 사항을 결정하는 데 유용한 공식을 제공합니다.</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">r의 복제 인자를 사용하여 tcluster의 클러스터에 생성된 집계된 처리량의 경우, 브로커 저장소에서 수신한 처리량은 다음과 같습니다.</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">이것은 더욱 단순화될 수 있습니다.</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">이 공식을 사용하면 Kafka 핫 티어 요구 사항에 맞는 적절한 ONTAP 플랫폼을 선택할 수 있습니다.</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">다음 표는 다양한 복제 요소를 적용한 A900의 예상 생산자 처리량을 설명합니다.</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">복제 인자</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">생산자 처리량(GPps)</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3(측정됨)</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3.4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10.2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">NetApp NFS에 스토리지 계층이 탑재된 Kafka 클러스터의 성능이 AWS 클라우드에서 벤치마킹되었습니다.  벤치마킹 사례는 다음 섹션에 설명되어 있습니다.</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">AWS FSx ONTAP 의 성능 개요 및 검증</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">NetApp NFS에 스토리지 계층이 장착된 Kafka 클러스터는 AWS FSx ONTAP 에서 성능을 벤치마킹했습니다.  벤치마킹 사례는 다음 섹션에 설명되어 있습니다.</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">AWS FSx ONTAP 의 Apache Kafka</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">네트워크 파일 시스템(NFS)은 대량의 데이터를 저장하는 데 널리 사용되는 네트워크 파일 시스템입니다.  대부분의 조직에서는 Apache Kafka와 같은 스트리밍 애플리케이션을 통해 데이터가 생성되는 경우가 점점 늘어나고 있습니다.  이러한 작업에는 확장성, 낮은 지연 시간, 최신 스토리지 기능을 갖춘 강력한 데이터 수집 아키텍처가 필요합니다.  실시간 분석을 가능하게 하고 실행 가능한 통찰력을 제공하려면 잘 설계되고 성능이 뛰어난 인프라가 필요합니다.</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka는 설계상 POSIX 호환 파일 시스템에서 작동하며 파일 작업을 처리하기 위해 해당 파일 시스템에 의존하지만, NFSv3 파일 시스템에 데이터를 저장하는 경우 Kafka 브로커 NFS 클라이언트는 XFS나 Ext4와 같은 로컬 파일 시스템과 다르게 파일 작업을 해석할 수 있습니다.  흔한 예로는 NFS Silly 이름 변경으로 인해 클러스터를 확장하고 파티션을 재할당할 때 Kafka 브로커가 실패하는 경우가 있습니다.  이러한 과제를 해결하기 위해 NetApp 오픈 소스 Linux NFS 클라이언트를 업데이트하여 현재 RHEL8.7, RHEL9.1에서 일반적으로 사용할 수 있는 변경 사항을 적용했으며, 현재 FSx ONTAP 릴리스인 ONTAP 9.12.1에서 지원됩니다.</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP 클라우드에서 완벽하게 관리되고 확장 가능하며 성능이 뛰어난 NFS 파일 시스템을 제공합니다.  FSx ONTAP 의 Kafka 데이터는 대량의 데이터를 처리하고 내결함성을 보장하도록 확장될 수 있습니다.  NFS는 중요하고 민감한 데이터 세트에 대한 중앙 집중식 스토리지 관리 및 데이터 보호를 제공합니다.</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">이러한 향상된 기능을 통해 AWS 고객은 AWS 컴퓨팅 서비스에서 Kafka 워크로드를 실행할 때 FSx ONTAP 의 이점을 활용할 수 있습니다.  이러한 이점은 다음과 같습니다. * CPU 사용률을 줄여 I/O 대기 시간을 줄입니다. * Kafka 브로커 복구 시간이 더 빠릅니다.  * 신뢰성과 효율성.  * 확장성 및 성능.  * 다중 이용 가능 구역 이용 가능.  * 데이터 보호.</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">AWS FSx ONTAP 의 카프카</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">AWS FSx ONTAP 탑재된 Kafka 클러스터는 AWS 클라우드에서 성능을 벤치마킹했습니다.  다음 섹션에서는 이 벤치마킹에 대해 설명합니다.</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">건축적 설정</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">다음 표는 AWS FSx ONTAP 사용하는 Kafka 클러스터의 환경 구성을 보여줍니다.</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">플랫폼 구성 요소</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">환경 구성</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">카프카 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">3 x 동물원 관리인 – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">3개의 브로커 서버 - i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x 그라파나 – c5n.2xlarge</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x 생산자/소비자 -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">모든 노드의 운영 체제</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">4GB/초 처리량과 160000 IOPS를 갖춘 다중 AZ</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">NetApp FSx ONTAP 설정</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">초기 테스트를 위해 2TB 용량과 2GB/초 처리량을 위한 40000 IOPS를 갖춘 FSx ONTAP 파일 시스템을 만들었습니다.</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">우리의 예에서는 AWS CLI를 통해 FSx ONTAP 배포합니다.  필요에 따라 사용자 환경에서 명령을 추가로 사용자 지정해야 합니다.  FSx ONTAP AWS 콘솔을 통해 배포 및 관리할 수 있으므로 명령줄 입력을 줄여 더 쉽고 간소화된 배포 환경을 제공합니다.</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">FSx ONTAP 에서 테스트 지역(US-East-1)의 처리량 2GB/초 파일 시스템에서 달성 가능한 최대 IOPS는 80,000 iops입니다.  FSx ONTAP 파일 시스템의 총 최대 IOPS는 160,000 IOPS이며, 이를 달성하려면 4GB/초의 처리량 배포가 필요합니다. 이에 대해서는 이 문서의 뒷부분에서 설명하겠습니다.</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">FSx ONTAP 성능 사양에 대한 자세한 내용은 여기에서 AWS FSx ONTAP 설명서를 참조하세요.<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> .</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">FSx "create-file-system"에 대한 자세한 명령줄 구문은 여기에서 확인할 수 있습니다.<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">예를 들어, KMS 키가 지정되지 않은 경우 사용되는 기본 AWS FSx 마스터 키 대신 특정 KMS 키를 지정할 수 있습니다.</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">FSx ONTAP 파일 시스템을 생성하는 동안 다음과 같이 파일 시스템을 설명한 후 JSON 반환에서 "LifeCycle" 상태가 "AVAILABLE"로 변경될 때까지 기다리세요.</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">fsxadmin 사용자로 FSx ONTAP SSH에 로그인하여 자격 증명을 확인합니다. Fsxadmin은 FSx ONTAP 파일 시스템을 생성할 때 사용되는 기본 관리자 계정입니다.  fsxadmin의 비밀번호는 1단계에서 완료한 대로 AWS 콘솔이나 AWS CLI를 사용하여 파일 시스템을 처음 생성할 때 구성한 비밀번호입니다.</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">자격 증명이 검증되면 FSx ONTAP 파일 시스템에 스토리지 가상 머신을 생성합니다.</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">SVM(Storage Virtual Machine)은 FSx ONTAP 볼륨의 데이터를 관리하고 액세스하기 위한 자체 관리 자격 증명과 엔드포인트를 갖춘 격리된 파일 서버이며 FSx ONTAP 다중 테넌시를 제공합니다.</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">기본 스토리지 가상 머신을 구성한 후 새로 만든 FSx ONTAP 파일 시스템에 SSH를 실행하고 아래 샘플 명령을 사용하여 스토리지 가상 머신에 볼륨을 생성합니다. 마찬가지로 이 검증을 위해 6개의 볼륨을 생성합니다.  우리의 검증에 따르면, 카프카에 더 나은 성능을 제공하는 기본 구성 요소(8) 또는 그 이하의 구성 요소를 유지합니다.</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">테스트를 위해서는 볼륨에 추가 용량이 필요합니다.  볼륨 크기를 2TB로 확장하고 연결 경로에 마운트합니다.</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">FSx ONTAP 에서는 볼륨을 씬 프로비저닝할 수 있습니다.  예시에서 총 확장 볼륨 용량이 총 파일 시스템 용량을 초과하므로 추가 프로비저닝 볼륨 용량을 잠금 해제하려면 총 파일 시스템 용량을 확장해야 합니다. 이는 다음 단계에서 보여드리겠습니다.</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">다음으로, 추가적인 성능 및 용량을 위해 FSx ONTAP 처리량 용량을 2GB/초에서 4GB/초로, IOPS를 160000으로, 용량을 5TB로 확장합니다.</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">FSx "update-file-system"에 대한 자세한 명령줄 구문은 여기에서 확인할 수 있습니다.<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">FSx ONTAP 볼륨은 Kafka 브로커의 nconnect 및 기본 옵션으로 마운트됩니다.</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">다음 그림은 FSx ONTAP 기반 Kafka 클러스터의 최종 아키텍처를 보여줍니다.</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">이 이미지는 FSx ONTAP 기반 Kafka 클러스터의 아키텍처를 보여줍니다.</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">계산하다.  우리는 전용 서버에서 실행되는 3노드 Zookeeper 앙상블과 함께 3노드 Kafka 클러스터를 사용했습니다.  각 브로커는 FSx ONTAP 인스턴스의 6개 볼륨에 대해 6개의 NFS 마운트 포인트를 갖고 있었습니다.</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">모니터링.  우리는 Prometheus-Grafana 조합을 위해 두 개의 노드를 사용했습니다.  워크로드를 생성하기 위해 이 Kafka 클러스터에서 워크로드를 생성하고 소비할 수 있는 별도의 3노드 클러스터를 사용했습니다.</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">저장.  우리는 6개의 2TB 볼륨이 마운트된 FSx ONTAP 사용했습니다.  그런 다음 볼륨은 NFS 마운트를 통해 Kafka 브로커로 내보내졌습니다. FSx ONTAP 볼륨은 16개의 nconnect 세션과 Kafka 브로커의 기본 옵션으로 마운트됩니다.</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">OpenMessage 벤치마킹 구성.</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">NetApp Cloud Volumes ONTAP 에 사용된 것과 동일한 구성을 사용했으며 자세한 내용은 여기에 있습니다. 링크:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">테스트 방법론</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">위에 설명된 사양에 따라 Terraform과 Ansible을 사용하여 Kafka 클러스터를 프로비저닝했습니다.  Terraform은 Kafka 클러스터용 AWS 인스턴스를 사용하여 인프라를 구축하는 데 사용되고, Ansible은 해당 인스턴스에 Kafka 클러스터를 구축합니다.</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">위에 설명된 워크로드 구성과 Sync 드라이버를 사용하여 OMB 워크로드가 트리거되었습니다.</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">동일한 작업 부하 구성을 사용하는 Throughput 드라이버로 또 다른 작업 부하가 트리거되었습니다.</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">관찰</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">NFS에서 실행되는 Kafka 인스턴스의 성능을 벤치마킹하기 위한 워크로드를 생성하기 위해 두 가지 유형의 드라이버가 사용되었습니다.  드라이버 간의 차이점은 로그 플러시 속성입니다.</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">Kafka 복제 요소 1 및 FSx ONTAP 의 경우:</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Sync 드라이버에서 지속적으로 생성된 총 처리량은 ~3218MBps이고 최대 성능은 ~3652MBps입니다.</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">Throughput 드라이버에서 지속적으로 생성된 총 처리량은 ~3679MBps이고 최대 성능은 ~3908MBps입니다.</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">복제 계수 3과 FSx ONTAP 있는 Kafka의 경우:</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Sync 드라이버에서 지속적으로 생성된 총 처리량은 ~1252MBps이고 최대 성능은 ~1382MBps입니다.</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">Throughput 드라이버에서 지속적으로 생성된 총 처리량은 ~1218MBps이고 최대 성능은 ~1328MBps입니다.</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">Kafka 복제 요소 3에서는 읽기 및 쓰기 작업이 FSx ONTAP 에서 3번 발생했고, Kafka 복제 요소 1에서는 읽기 및 쓰기 작업이 FSx ONTAP 에서 한 번 발생했으므로 두 가지 검증에서 모두 최대 처리량인 4GB/초에 도달할 수 있었습니다.</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">Sync 드라이버는 로그가 디스크에 즉시 플러시되므로 일관된 처리량을 생성할 수 있는 반면, Throughput 드라이버는 로그가 대량으로 디스크에 커밋되므로 처리량이 급증합니다.</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">이러한 처리량 수치는 주어진 AWS 구성에 대해 생성됩니다.  더 높은 성능이 필요한 경우 인스턴스 유형을 확장하고 조정하여 처리량을 더욱 높일 수 있습니다.  총 처리량 또는 총 속도는 생산자 속도와 소비자 속도를 합친 것입니다.</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">이 이미지는 RF1과 RF3를 사용한 카프카의 성능을 보여줍니다.</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">아래 차트는 Kafka 복제 요소 3에 대한 2GB/초 FSx ONTAP 및 4GB/초 성능을 보여줍니다.  복제 요소 3은 FSx ONTAP 스토리지에서 읽기 및 쓰기 작업을 세 번 수행합니다.  처리량 드라이버의 총 속도는 881MB/초이고, 2GB/초 FSx ONTAP 파일 시스템에서 Kafka 작업을 읽고 쓰는 데 약 2.64GB/초가 소요됩니다. 처리량 드라이버의 총 속도는 1328MB/초이고, Kafka 작업을 읽고 쓰는 데 약 3.98GB/초가 소요됩니다.  Kafka 성능은 FSx ONTAP 처리량에 따라 선형적이고 확장 가능합니다.</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">이 이미지는 2GB/초와 4GB/초의 확장 성능을 보여줍니다.</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">아래 차트는 EC2 인스턴스와 FSx ONTAP (Kafka 복제 계수: 3) 간의 성능을 보여줍니다.</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">이 이미지는 RF3에서 EC2와 FSx ONTAP 의 성능을 비교한 것입니다.</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">AWS에서의 성능 개요 및 검증</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">NetApp Cloud Volumes ONTAP (고가용성 쌍 및 단일 노드)을 사용한 AWS 클라우드의 Kafka</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">NetApp Cloud Volumes ONTAP (HA 쌍)이 포함된 Kafka 클러스터는 AWS 클라우드에서 성능을 벤치마킹했습니다.  다음 섹션에서는 이 벤치마킹에 대해 설명합니다.</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">다음 표는 NAS를 사용하는 Kafka 클러스터의 환경 구성을 보여줍니다.</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">NetApp Cloud Volumes ONTAP 인스턴스</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">HA 쌍 인스턴스 - m5dn.12xLarge x 2노드 단일 노드 인스턴스 - m5dn.12xLarge x 1노드</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">NetApp 클러스터 볼륨 ONTAP 설정</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Cloud Volumes ONTAP HA 쌍의 경우 각 스토리지 컨트롤러에서 각 집계에 3개의 볼륨이 있는 2개의 집계를 생성했습니다.  단일 Cloud Volumes ONTAP 노드의 경우 집계된 6개의 볼륨을 생성합니다.</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">이 이미지는 aggr3와 aggr22의 속성을 보여줍니다.</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">이 이미지는 aggr2의 속성을 보여줍니다.</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">더 나은 네트워크 성능을 달성하기 위해 HA 쌍과 단일 노드 모두에 고속 네트워킹을 구현했습니다.</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">이 이미지는 고속 네트워킹을 활성화하는 방법을 보여줍니다.</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">ONTAP NVRAM IOPS가 더 높다는 것을 알았으므로 Cloud Volumes ONTAP 루트 볼륨의 IOPS를 2350으로 변경했습니다.  Cloud Volumes ONTAP 의 루트 볼륨 디스크 크기는 47GB입니다.  다음 ONTAP 명령은 HA 쌍을 위한 것이며, 동일한 단계가 단일 노드에도 적용됩니다.</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">이 이미지는 볼륨 속성을 수정하는 방법을 보여줍니다.</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">다음 그림은 NAS 기반 Kafka 클러스터의 아키텍처를 보여줍니다.</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*계산합니다.*  우리는 전용 서버에서 실행되는 3노드 Zookeeper 앙상블과 함께 3노드 Kafka 클러스터를 사용했습니다.  각 브로커는 전용 LIF를 통해 Cloud Volumes ONTAP 인스턴스의 단일 볼륨에 대한 두 개의 NFS 마운트 지점을 가졌습니다.</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*모니터링.*  우리는 Prometheus-Grafana 조합을 위해 두 개의 노드를 사용했습니다.  워크로드를 생성하기 위해 이 Kafka 클러스터에서 워크로드를 생성하고 소비할 수 있는 별도의 3노드 클러스터를 사용했습니다.</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*저장.*  우리는 인스턴스에 마운트된 6TB GP3 AWS-EBS 볼륨 1개가 있는 HA 쌍 Cloud Volumes ONTAP 인스턴스를 사용했습니다.  그런 다음 볼륨은 NFS 마운트를 통해 Kafka 브로커로 내보내졌습니다.</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">이 그림은 NAS 기반 Kafka 클러스터의 아키텍처를 보여줍니다.</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">OpenMessage 벤치마킹 구성</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">더 나은 NFS 성능을 위해서는 NFS 서버와 NFS 클라이언트 사이에 더 많은 네트워크 연결이 필요한데, 이는 nconnect를 사용하여 생성할 수 있습니다.  다음 명령을 실행하여 nconnect 옵션으로 브로커 노드에 NFS 볼륨을 마운트합니다.</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Cloud Volumes ONTAP 에서 네트워크 연결을 확인하세요.  다음 ONTAP 명령은 단일 Cloud Volumes ONTAP 노드에서 사용됩니다.  동일한 단계는 Cloud Volumes ONTAP HA 쌍에도 적용됩니다.</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">우리는 다음의 카프카를 사용합니다<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> Cloud Volumes ONTAP HA 쌍에 대한 모든 Kafka 브로커에서.  그만큼<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 각 중개인마다 취급하는 부동산의 종류가 다르고, 나머지 부동산은 중개인들이 공통적으로 취급합니다.  브로커1의 경우<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 값은 다음과 같습니다.</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">브로커2의 경우<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 재산 가치는 다음과 같습니다.</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">브로커3의 경우<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 재산 가치는 다음과 같습니다.</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">단일 Cloud Volumes ONTAP 노드의 경우 Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> Cloud Volumes ONTAP HA 쌍의 경우와 동일하지만<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 재산.</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">브로커1의 경우<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 값은 다음과 같습니다.</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">브로커2의 경우<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block> 값은 다음과 같습니다.</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">OMB의 작업 부하는 다음 속성으로 구성됩니다.<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> .</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">그만큼<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block> 각 사용 사례마다 다를 수 있습니다.  성능 테스트에서는 3K를 사용했습니다.</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">우리는 OMB의 Sync와 Throughput이라는 두 가지 드라이버를 사용하여 Kafka 클러스터에서 작업 부하를 생성했습니다.</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">동기화 드라이버 속성에 사용되는 yaml 파일은 다음과 같습니다.<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block> :</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">Throughput 드라이버 속성에 사용되는 yaml 파일은 다음과 같습니다.<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block> :</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">Terraform과 Ansible을 사용하여 위에 설명된 사양에 따라 Kafka 클러스터가 프로비저닝되었습니다.  Terraform은 Kafka 클러스터용 AWS 인스턴스를 사용하여 인프라를 구축하는 데 사용되고 Ansible은 해당 인스턴스에 Kafka 클러스터를 구축합니다.</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Cloud Volumes ONTAP HA 쌍의 경우:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Sync 드라이버에서 지속적으로 생성된 총 처리량: ~1236MBps.</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">Throughput 드라이버에 대해 생성된 총 처리량: 최대 ~1412MBps.</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">단일 Cloud Volumes ONTAP 노드의 경우:</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Sync 드라이버에서 지속적으로 생성된 총 처리량: ~ 1962MBps.</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">Throughput 드라이버에서 생성된 총 처리량: 최대 ~1660MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">여기에는 네 가지 다른 그래프가 제시되어 있습니다.  CVO-HA 쌍 처리량 드라이버.  CVO-HA 쌍 동기화 드라이버.  CVO-단일 노드 처리량 드라이버.  CVO-단일 노드 동기화 드라이버.</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">처리량이나 동기화 드라이버 벤치마킹을 수행할 때는 반드시 저장소 처리량을 확인하세요.</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">이 그래프는 지연 시간, IOPS, 처리량 측면에서의 성능을 보여줍니다.</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">이 섹션에서는 어리석은 이름 변경 문제와 이 문제를 해결하기 위해 NFS 서버와 NFS 클라이언트에 필요한 변경 사항에 대해 설명합니다.</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">NFS에서 Kafka 워크로드로의 어리석은 이름 변경 문제에 대한 NetApp 솔루션</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">카프카는 기본 파일 시스템이 POSIX 호환이라는 가정 하에 구축되었습니다(예: XFS 또는 Ext4).  카프카 리소스 재조정은 애플리케이션이 파일을 계속 사용하는 동안 해당 파일을 제거합니다.  POSIX 호환 파일 시스템에서는 unlink가 계속 진행됩니다.  하지만 파일에 대한 모든 참조가 사라진 후에야 파일을 제거합니다.  기본 파일 시스템이 네트워크에 연결되어 있으면 NFS 클라이언트가 연결 해제 호출을 가로채서 워크플로를 관리합니다.  연결 해제되는 파일에 보류 중인 열려 있는 작업이 있기 때문에 NFS 클라이언트는 NFS 서버로 이름 변경 요청을 보내고, 연결 해제된 파일을 마지막으로 닫을 때 이름이 변경된 파일에 대한 제거 작업을 실행합니다.  이러한 동작은 일반적으로 NFS Silly Rename이라고 불리며, NFS 클라이언트에 의해 조정됩니다.</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">NFSv3 서버의 저장소를 사용하는 모든 Kafka 브로커는 이러한 동작으로 인해 문제에 직면합니다.  그러나 NFSv4.x 프로토콜에는 서버가 열려 있지만 연결되지 않은 파일에 대한 책임을 맡을 수 있도록 하여 이 문제를 해결하는 기능이 있습니다.  이 옵션 기능을 지원하는 NFS 서버는 파일을 열 때 NFS 클라이언트에 소유권 기능을 전달합니다.  그러면 NFS 클라이언트는 보류 중인 열기가 있는 경우 연결 해제 관리를 중단하고 서버가 흐름을 관리하도록 허용합니다.  NFSv4 사양은 구현에 대한 지침을 제공하지만 지금까지 이 선택적 기능을 지원하는 알려진 NFS 서버 구현은 없었습니다.</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">다음은 어리석은 이름 바꾸기 문제를 해결하기 위해 NFS 서버와 NFS 클라이언트에 필요한 변경 사항입니다.</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*NFS 클라이언트(Linux)에 대한 변경 사항.*  파일을 여는 시점에 NFS 서버는 플래그로 응답하여 열린 파일의 연결을 해제할 수 있는 기능을 나타냅니다.  NFS 클라이언트 측 변경을 통해 NFS 서버가 플래그가 있는 경우 연결 해제를 처리할 수 있습니다.  NetApp 이러한 변경 사항으로 오픈 소스 Linux NFS 클라이언트를 업데이트했습니다.  업데이트된 NFS 클라이언트는 이제 RHEL8.7 및 RHEL9.1에서 일반적으로 사용할 수 있습니다.</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*NFS 서버 변경.*  NFS 서버는 오픈을 추적합니다.  기존에 열려 있는 파일의 연결을 해제하는 작업은 이제 POSIX 의미 체계와 일치하도록 서버에서 관리됩니다.  마지막으로 열린 파일이 닫히면 NFS 서버는 파일의 실제 제거를 시작하여 어리석은 이름 바꾸기 과정을 피합니다.  ONTAP NFS 서버는 최신 릴리스인 ONTAP 9.12.1에서 이 기능을 구현했습니다.</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">NFS 클라이언트와 서버에 위와 같은 변경 사항을 적용하면 Kafka는 네트워크에 연결된 NFS 스토리지의 모든 이점을 안전하게 얻을 수 있습니다.</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">기능적 검증을 위해, 저장소로 NFSv3를 마운트한 Kafka 클러스터는 파티션 재분배와 같은 Kafka 작업을 수행하지 못하는 반면, 수정 사항을 적용한 NFSv4에 마운트된 다른 클러스터는 아무런 중단 없이 동일한 작업을 수행할 수 있음을 보여주었습니다.</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">기능 검증 - 어리석은 이름 바꾸기 수정</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">검증 설정</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">설정은 AWS에서 실행됩니다.  다음 표는 검증에 사용된 다양한 플랫폼 구성 요소와 환경 구성을 보여줍니다.</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Confluent 플랫폼 버전 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">3 x 동물원 관리인 – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4 x 브로커 서버 – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">1 x 제어 센터 – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x 생산자/소비자</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7 이상</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">단일 노드 인스턴스 – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">다음 그림은 이 솔루션의 아키텍처 구성을 보여줍니다.</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">이 이미지는 각각 프로듀서 스웜, 카프카 클러스터, CVO 인스턴스가 있는 3개의 개인 서브넷을 포함하는 VPC가 포함된 AWS 토폴로지를 보여줍니다.</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">건축 흐름</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*계산합니다.*  우리는 전용 서버에서 실행되는 3노드 Zookeeper 앙상블과 함께 4노드 Kafka 클러스터를 사용했습니다.</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*모니터링.*  우리는 Prometheus-Grafana 조합을 위해 두 개의 노드를 사용했습니다.</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*작업량.*  워크로드를 생성하기 위해 Kafka 클러스터에서 워크로드를 생산하고 소비할 수 있는 별도의 3노드 클러스터를 사용했습니다.</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*저장.*  우리는 두 개의 500GB GP2 AWS-EBS 볼륨이 인스턴스에 연결된 단일 노드 NetApp Cloud Volumes ONTAP 인스턴스를 사용했습니다.  이러한 볼륨은 LIF를 통해 단일 NFSv4.1 볼륨으로 Kafka 클러스터에 노출되었습니다.</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">모든 서버에 대해 Kafka의 기본 속성이 선택되었습니다.  동물원 관리인 떼에도 똑같은 일이 이루어졌습니다.</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">업데이트<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block> 카프카 볼륨에 다음과 같이 표시됩니다.</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">두 개의 유사한 Kafka 클러스터가 다음과 같은 차이점을 가지고 생성되었습니다.</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*클러스터 1.*  프로덕션에 바로 사용할 수 있는 ONTAP 버전 9.12.1을 실행하는 백엔드 NFS v4.1 서버는 NetApp CVO 인스턴스에 의해 호스팅되었습니다.  브로커에 RHEL 8.7/RHEL 9.1이 설치되었습니다.</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*클러스터 2.*  백엔드 NFS 서버는 수동으로 생성된 일반 Linux NFSv3 서버였습니다.</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">두 Kafka 클러스터 모두에 데모 주제가 생성되었습니다.</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">클러스터 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">이 스크린샷은 클러스터 1에서 생성된 데모 주제를 보여줍니다.</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">클러스터 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">이 스크린샷은 클러스터 2에서 생성된 데모 주제를 보여줍니다.</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">두 클러스터 모두의 새로 생성된 주제에 데이터가 로드되었습니다.  이 작업은 기본 Kafka 패키지에 포함된 producer-perf-test 툴킷을 사용하여 수행되었습니다.</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">Telnet을 사용하여 각 클러스터의 브로커-1에 대한 상태 점검을 수행했습니다.</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">텔넷<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">텔넷<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">다음 스크린샷에는 두 클러스터의 브로커에 대한 성공적인 상태 검사가 표시됩니다.</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">이 스크린샷은 두 브로커의 성공적인 상태 점검에 대한 결과를 보여줍니다.</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">NFSv3 스토리지 볼륨을 사용하는 Kafka 클러스터가 충돌하는 오류 조건을 트리거하기 위해 두 클러스터 모두에서 파티션 재할당 프로세스를 시작했습니다.  파티션 재할당은 다음을 사용하여 수행되었습니다.<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block> .  자세한 과정은 다음과 같습니다.</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Kafka 클러스터의 주제에 대한 파티션을 재할당하기 위해 제안된 재할당 구성 JSON을 생성했습니다(이 작업은 두 클러스터 모두에서 수행되었습니다).</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">생성된 재할당 JSON은 다음에 저장되었습니다.<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block> .</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">실제 파티션 재할당 프로세스는 다음 명령에 의해 트리거되었습니다.</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">재할당이 완료된 후 몇 분 후에 브로커에서 실시한 또 다른 상태 점검에서 NFSv3 스토리지 볼륨을 사용하는 클러스터가 어리석은 이름 바꾸기 문제에 부딪혀 충돌했지만, 수정된 NetApp ONTAP NFSv4.1 스토리지 볼륨을 사용하는 클러스터 1은 중단 없이 작업을 계속 진행한 것으로 나타났습니다.</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">이 스크린샷은 충돌한 브로커의 출력을 보여줍니다.</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1은 활성화되어 있습니다.</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1이 죽었습니다.</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Kafka 로그 디렉터리를 확인한 결과, NetApp ONTAP NFSv4.1 스토리지 볼륨을 수정하여 사용하는 클러스터 1은 파티션이 깔끔하게 할당되었지만, 일반 NFSv3 스토리지를 사용하는 클러스터 2는 어리석은 이름 변경 문제로 인해 파티션이 깔끔하게 할당되지 않아 충돌이 발생한 것이 분명했습니다.  다음 그림은 클러스터 2의 파티션 재조정을 보여주는데, 이로 인해 NFSv3 스토리지에서 어리석은 이름 변경 문제가 발생했습니다.</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">이 스크린샷은 클러스터 2 충돌에 대한 로그 출력을 보여줍니다.</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">다음 그림은 NetApp NFSv4.1 스토리지를 사용하여 클러스터 1의 깔끔한 파티션 재조정을 보여줍니다.</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">이 스크린샷은 클러스터 1에 대한 성공적인 클린 파티션 할당에 대한 로그 출력을 보여줍니다.</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">이제 Kafka를 사용하여 NFS 스토리지의 어리석은 이름 변경 문제에 대한 솔루션이 있으므로 Kafka 워크로드에 NetApp ONTAP 스토리지를 활용하는 강력한 배포를 만들 수 있습니다.  이렇게 하면 운영 오버헤드가 크게 줄어들 뿐만 아니라, Kafka 클러스터에 다음과 같은 이점도 제공됩니다.</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">Kafka 워크로드에 NetApp NFS를 사용해야 하는 이유는 무엇입니까?</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">이제 Kafka를 사용하여 NFS 스토리지의 어리석은 이름 변경 문제에 대한 솔루션이 있으므로 Kafka 워크로드에 NetApp ONTAP 스토리지를 활용하는 강력한 배포를 만들 수 있습니다.  이렇게 하면 운영 오버헤드가 크게 줄어들 뿐만 아니라, Kafka 클러스터에 다음과 같은 이점도 제공됩니다.</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Kafka 브로커의 CPU 사용률이 감소했습니다.*  분산된 NetApp ONTAP 스토리지를 사용하면 디스크 I/O 작업이 브로커에서 분리되어 CPU 사용량이 줄어듭니다.</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*더 빠른 브로커 복구 시간.*  분산된 NetApp ONTAP 스토리지는 Kafka 브로커 노드 전체에서 공유되므로, 기존 Kafka 배포에 비해 데이터를 다시 빌드하지 않고도 새로운 컴퓨팅 인스턴스가 언제든지 잘못된 브로커를 대체할 수 있는 시간이 훨씬 단축됩니다.</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*저장 효율성.* 이제 애플리케이션의 스토리지 계층이 NetApp ONTAP 통해 프로비저닝되므로 고객은 인라인 데이터 압축, 중복 제거, 압축과 같은 ONTAP 이 제공하는 모든 스토리지 효율성 이점을 활용할 수 있습니다.</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">이러한 이점은 이 섹션에서 자세히 설명하는 테스트 사례에서 테스트되고 검증되었습니다.</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Kafka 브로커의 CPU 사용률 감소</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">기술 사양은 동일하지만 저장 기술이 다른 두 개의 별도의 Kafka 클러스터에서 유사한 작업 부하를 실행했을 때, 전반적인 CPU 사용률이 DAS 대응 제품보다 낮다는 것을 발견했습니다.  Kafka 클러스터가 ONTAP 스토리지를 사용하면 전반적인 CPU 사용률이 낮을 뿐만 아니라 CPU 사용률의 증가 폭도 DAS 기반 Kafka 클러스터보다 완만했습니다.</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">다음 표는 CPU 사용률을 낮추는 데 사용된 환경 구성을 보여줍니다.</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Kafka 3.2.3 벤치마킹 도구: OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x 생산자/소비자 -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7 이상</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">단일 노드 인스턴스 – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">벤치마킹 도구</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">오픈메시징</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">이 테스트 케이스에서 사용된 벤치마킹 도구는 다음과 같습니다.<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block> 뼈대.  OpenMessaging은 공급업체와 언어에 구애받지 않습니다. 금융, 전자상거래, IoT, 빅데이터에 대한 산업 가이드라인을 제공하며, 이기종 시스템과 플랫폼에서 메시징 및 스트리밍 애플리케이션을 개발하는 데 도움이 됩니다.  다음 그림은 OpenMessaging 클라이언트와 Kafka 클러스터의 상호작용을 보여줍니다.</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">이 이미지는 OpenMessaging 클라이언트와 Kafka 클러스터의 상호작용을 보여줍니다.</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*계산합니다.*  우리는 전용 서버에서 실행되는 3노드 Zookeeper 앙상블과 함께 3노드 Kafka 클러스터를 사용했습니다.  각 브로커는 전용 LIF를 통해 NetApp CVO 인스턴스의 단일 볼륨에 대한 두 개의 NFSv4.1 마운트 포인트를 가졌습니다.</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*모니터링.*  우리는 Prometheus-Grafana 조합을 위해 두 개의 노드를 사용했습니다.  워크로드를 생성하기 위해 Kafka 클러스터에서 워크로드를 생산하고 소비할 수 있는 별도의 3노드 클러스터가 있습니다.</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*저장.*  6개의 250GB GP2 AWS-EBS 볼륨이 인스턴스에 마운트된 단일 노드 NetApp Cloud Volumes ONTAP 인스턴스를 사용했습니다.  이러한 볼륨은 전용 LIF를 통해 6개의 NFSv4.1 볼륨으로 Kafka 클러스터에 노출되었습니다.</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*구성.*  이 테스트 사례에서 구성 가능한 두 가지 요소는 Kafka 브로커와 OpenMessaging 워크로드였습니다.</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*브로커 구성.*  다음은 Kafka 브로커에 대해 선택된 사양입니다.  아래에 강조된 것처럼 모든 측정에 대해 복제 계수 3을 사용했습니다.</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">이 이미지는 카프카 브로커에 대해 선택된 사양을 보여줍니다.</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*OpenMessaging 벤치마크(OMB) 워크로드 구성.*  다음과 같은 사양이 제공되었습니다.  우리는 아래에 강조된 목표 생산자 요율을 지정했습니다.</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">이 이미지는 OpenMessaging 벤치마크 워크로드 구성을 위해 선택된 사양을 보여줍니다.</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">두 개의 유사한 클러스터가 생성되었으며, 각각 고유한 벤치마킹 클러스터 군집이 있습니다.</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*클러스터 1.*  NFS 기반 카프카 클러스터.</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*클러스터 2.*  DAS 기반 카프카 클러스터.</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">OpenMessaging 명령을 사용하여 각 클러스터에서 유사한 작업 부하가 트리거되었습니다.</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">생산율 구성은 4번의 반복을 거쳐 증가하였고, Grafana를 사용하여 CPU 사용률을 기록했습니다.  생산율은 다음 수준으로 설정되었습니다.</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10,000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40,000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80,000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100,000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">Kafka와 함께 NetApp NFS 스토리지를 사용하면 두 가지 주요 이점이 있습니다.</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*CPU 사용량을 약 1/3까지 줄일 수 있습니다.*  유사한 작업 부하에서 NFS의 전반적인 CPU 사용량은 DAS SSD보다 낮았습니다. 생성률이 낮을수록 절감 효과가 5%, 생성률이 높을수록 절감 효과가 32%에 달했습니다.</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*생산 속도가 높을수록 CPU 사용률 변동이 3배 감소합니다.*  예상대로, 생산율이 증가함에 따라 CPU 활용도가 위쪽으로 증가했습니다.  그러나 DAS를 사용하는 Kafka 브로커의 CPU 사용률은 낮은 생성률의 경우 31%에서 높은 생성률의 경우 70%로 39% 증가했습니다.  하지만 NFS 스토리지 백엔드를 사용하면 CPU 사용률이 26%에서 38%로 12% 증가했습니다.</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">이 그래프는 DAS 기반 클러스터의 동작을 나타냅니다.</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">이 그래프는 NFS 기반 클러스터의 동작을 나타냅니다.</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">또한 100,000개의 메시지에서 DAS는 NFS 클러스터보다 CPU 사용률이 더 높습니다.</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">이 그래프는 100,000개의 메시지에서 DAS 기반 클러스터의 동작을 나타냅니다.</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">이 그래프는 100,000개의 메시지에서 NFS 기반 클러스터의 동작을 나타냅니다.</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">더 빠른 브로커 회복</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">Kafka 브로커가 공유 NetApp NFS 스토리지를 사용할 경우 복구 속도가 더 빨라진다는 것을 발견했습니다.  Kafka 클러스터에서 브로커가 충돌하는 경우, 이 브로커는 동일한 브로커 ID를 가진 정상적인 브로커로 교체될 수 있습니다.  이 테스트 사례를 수행한 결과, DAS 기반 Kafka 클러스터의 경우 클러스터가 새로 추가된 정상적인 브로커에서 데이터를 다시 구축하는데, 이는 시간이 많이 소요되는 작업이라는 것을 발견했습니다.  NetApp NFS 기반 Kafka 클러스터의 경우, 교체 브로커는 이전 로그 디렉토리에서 데이터를 계속 읽고 훨씬 빠르게 복구합니다.</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x 생산자/소비자 -- c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x 백업 Kafka 노드 – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7 이상</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*계산합니다.*  전용 서버에서 실행되는 3노드 Zookeeper 앙상블을 갖춘 3노드 Kafka 클러스터입니다.  각 브로커는 전용 LIF를 통해 NetApp CVO 인스턴스의 단일 볼륨에 대한 두 개의 NFS 마운트 지점을 갖습니다.</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*모니터링.*  Prometheus-Grafana 조합을 위한 두 개의 노드.  워크로드를 생성하기 위해 이 Kafka 클러스터에서 워크로드를 생성하고 소비할 수 있는 별도의 3노드 클러스터를 사용합니다.</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*저장.*  6개의 250GB GP2 AWS-EBS 볼륨이 인스턴스에 마운트된 단일 노드 NetApp Cloud Volumes ONTAP 인스턴스입니다.  이러한 볼륨은 전용 LIF를 통해 6개의 NFS 볼륨으로 Kafka 클러스터에 노출됩니다.</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*브로커 구성.*  이 테스트 사례에서 구성 가능한 요소 중 하나는 Kafka 브로커입니다.  다음은 Kafka 브로커에 대해 선택된 사양입니다.  그만큼<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block> 특정 노드가 ISR 목록에서 얼마나 빨리 제거되는지를 결정하기 때문에 높은 값으로 설정됩니다.  불량 노드와 정상 노드 사이를 전환할 때 해당 브로커 ID가 ISR 목록에서 제외되는 것을 원하지 않을 것입니다.</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">이 이미지는 카프카 브로커에 대해 선택된 사양을 보여줍니다.</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">두 개의 유사한 클러스터가 생성되었습니다.</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">EC2 기반 합류 클러스터.</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">NetApp NFS 기반 합류 클러스터.</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">원래 Kafka 클러스터의 노드와 동일한 구성을 가진 대기 Kafka 노드 하나가 생성되었습니다.</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">각 클러스터에서 샘플 토픽이 생성되었고, 각 브로커에 약 110GB의 데이터가 채워졌습니다.</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*EC2 기반 클러스터.*  Kafka 브로커 데이터 디렉토리는 다음에 매핑됩니다.<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (다음 그림에서 cluster1의 Broker-1[왼쪽 터미널]).</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">* NetApp NFS 기반 클러스터.*  Kafka 브로커 데이터 디렉토리는 NFS 지점에 마운트됩니다.<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block> (다음 그림에서 클러스터2의 Broker-1[오른쪽 터미널]).</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">이 이미지는 두 개의 터미널 화면을 보여줍니다.</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">각 클러스터에서 Broker-1이 종료되어 실패한 브로커 복구 프로세스가 시작되었습니다.</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">브로커가 종료된 후 브로커 IP 주소는 대기 브로커의 보조 IP로 할당되었습니다.  이는 Kafka 클러스터의 브로커가 다음으로 식별되기 때문에 필요했습니다.</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*IP 주소.*  실패한 브로커 IP를 대기 브로커에 재할당하여 할당됩니다.</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*브로커 ID.*  이는 대기 브로커에서 구성되었습니다.<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> .</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">IP 할당 시, 대기 브로커에서 Kafka 서비스가 시작되었습니다.</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">얼마 후, 클러스터의 교체 노드에서 데이터를 빌드하는 데 걸리는 시간을 확인하기 위해 서버 로그를 뽑았습니다.</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">카프카 브로커 복구가 거의 9배 더 빨랐습니다.  Kafka 클러스터에서 DAS SSD를 사용하는 것보다 NetApp NFS 공유 스토리지를 사용하면 실패한 브로커 노드를 복구하는 데 걸리는 시간이 훨씬 빠른 것으로 나타났습니다.  1TB의 주제 데이터에 대해 DAS 기반 클러스터의 복구 시간은 48분이었고, NetApp-NFS 기반 Kafka 클러스터의 경우 5분 미만이었습니다.</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">EC2 기반 클러스터는 새로운 브로커 노드에서 110GB의 데이터를 재구축하는 데 10분이 걸렸지만, NFS 기반 클러스터는 3분 만에 복구를 완료했습니다.  또한 EC2의 파티션에 대한 소비자 오프셋이 0인 반면, NFS 클러스터에서는 소비자 오프셋이 이전 브로커에서 수집된 것을 로그에서 확인했습니다.</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">DAS 기반 클러스터</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">백업 노드는 08:55:53,730에 시작되었습니다.</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">이 이미지는 DAS 기반 클러스터의 로그 출력을 보여줍니다.</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">데이터 재구축 프로세스는 09:05:24,860에 종료되었습니다.  110GB의 데이터를 처리하는 데 약 10분이 걸렸습니다.</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">NFS 기반 클러스터</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">백업 노드는 09:39:17,213에 시작되었습니다.  시작 로그 항목은 아래에 강조 표시되어 있습니다.</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">이 이미지는 NFS 기반 클러스터의 로그 출력을 보여줍니다.</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">데이터 재구축 프로세스는 09:42:29,115에 종료되었습니다.  110GB의 데이터를 처리하는 데 약 3분이 걸렸습니다.</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">약 1TB의 데이터를 담고 있는 브로커에 대해 테스트를 반복한 결과, DAS의 경우 약 48분, NFS의 경우 3분이 걸렸습니다.  결과는 다음 그래프에 나타나 있습니다.</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">이 그래프는 DAS 기반 클러스터 또는 NFS 기반 클러스터의 브로커에 로드된 데이터 양에 따라 브로커 복구에 걸리는 시간을 보여줍니다.</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">스토리지 효율성</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Kafka 클러스터의 스토리지 계층은 NetApp ONTAP 통해 프로비저닝되었기 때문에 ONTAP 의 모든 스토리지 효율성 기능을 얻을 수 있었습니다.  이는 Cloud Volumes ONTAP 에 프로비저닝된 NFS 스토리지를 사용하여 Kafka 클러스터에서 상당한 양의 데이터를 생성하여 테스트되었습니다.  ONTAP 기능으로 인해 상당한 공간 감소가 발생했음을 알 수 있었습니다.</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">단일 노드 인스턴스 – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*계산합니다.*  우리는 전용 서버에서 실행되는 3노드 Zookeeper 앙상블과 함께 3노드 Kafka 클러스터를 사용했습니다.  각 브로커는 전용 LIF를 통해 NetApp CVO 인스턴스의 단일 볼륨에 대한 두 개의 NFS 마운트 지점을 갖고 있었습니다.</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*저장.*  우리는 6개의 250GB GP2 AWS-EBS 볼륨이 인스턴스에 마운트된 단일 노드 NetApp Cloud Volumes ONTAP 인스턴스를 사용했습니다.  이러한 볼륨은 전용 LIF를 통해 6개의 NFS 볼륨으로 Kafka 클러스터에 노출되었습니다.</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*구성.*  이 테스트 사례에서 구성 가능한 요소는 Kafka 브로커였습니다.</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">생산자 측에서는 압축을 해제하여 생산자가 높은 처리량을 창출할 수 있게 했습니다.  대신 저장 효율성은 컴퓨팅 계층에서 처리되었습니다.</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">카프카 클러스터는 위에 언급된 사양에 따라 제공되었습니다.</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">클러스터에서는 OpenMessaging 벤치마킹 도구를 사용하여 약 350GB의 데이터가 생성되었습니다.</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">작업 부하가 완료된 후 ONTAP System Manager와 CLI를 사용하여 스토리지 효율성 통계를 수집했습니다.</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">OMB 도구를 사용하여 생성된 데이터의 경우 저장 효율성 비율이 1.70:1로 약 33%의 공간 절약 효과를 보였습니다.  다음 그림에서 볼 수 있듯이, 생성된 데이터가 사용하는 논리적 공간은 420.3GB이고, 데이터를 보관하는 데 사용된 물리적 공간은 281.7GB였습니다.</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">이 이미지는 VMDISK의 공간 절약을 보여줍니다.</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">스크린샷</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">이 문서에서는 계층형 스토리지 벤치마킹 키트를 사용하여 NetApp ONTAP 에서 Confluent 플랫폼의 성능 벤치마크를 설명합니다.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: NetApp ONTAP 스토리지 컨트롤러와 Confluent</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">Confluent 플랫폼을 더 확장 가능하고 탄력적으로 만들려면 작업 부하를 매우 빠르게 확장하고 균형을 맞출 수 있어야 합니다.  계층형 스토리지를 사용하면 이러한 운영 부담을 줄여 Confluent에 엄청난 양의 데이터를 저장하는 것이 쉬워집니다.</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">기본적인 아이디어는 데이터 저장과 데이터 처리를 분리하는 것인데, 이를 통해 각각을 독립적으로 확장하기가 훨씬 쉬워집니다.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">업계를 선도하는 혁신 기술이 탑재된 NetApp ONTAP 데이터 관리 소프트웨어는 데이터가 있는 곳 어디에서나 Confluent에 많은 이점을 제공합니다.</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">NetApp StorageGRID 설정을 사용하여 생산 및 소비자 워크로드에 대한 3~4개 노드로 계층형 스토리지 테스트를 수행했습니다.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">확장성을 갖춘 성능 테스트</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">NetApp StorageGRID 설정을 사용하여 프로듀서 및 소비자 워크로드에 대한 3~4개 노드로 계층형 스토리지 테스트를 수행했습니다.  테스트에 따르면 완료 시간과 성능 결과는 StorageGRID 노드 수에 직접적으로 비례했습니다.  StorageGRID 설정에는 최소 3개의 노드가 필요했습니다.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">저장 노드 수가 증가함에 따라 생산 및 소비자 작업을 완료하는 데 걸리는 시간이 선형적으로 감소했습니다.</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">s3 검색 작업의 성능은 StorageGRID 노드 수에 따라 선형적으로 증가했습니다.  StorageGRID 최대 200개의 StorgeGRID 노드를 지원합니다.</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">이 테스트는 클러스터 토폴로지 변경이나 부하 불균형에 따라 자동으로 재균형을 조정하는 셀프 밸런싱 클러스터 기능을 기반으로 합니다.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Confluent 자체 균형 클러스터</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">이전에 카프카 클러스터를 관리한 적이 있다면 클러스터 전체에서 작업 부하가 균형을 이루도록 여러 브로커에 파티션을 수동으로 재할당하는 데 따르는 과제에 대해 잘 알고 있을 것입니다.  대규모 Kafka 배포를 운영하는 조직의 경우, 대량의 데이터를 재조정하는 일은 어렵고 지루하며 위험할 수 있습니다. 특히, 미션 크리티컬 애플리케이션이 클러스터 위에 구축된 경우 더욱 그렇습니다.  그러나 가장 작은 카프카 사용 사례라 하더라도 이 과정은 시간이 많이 걸리고 인간의 실수가 발생하기 쉽습니다.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">저희 연구실에서는 클러스터 토폴로지 변경이나 부하 불균형에 따라 자동으로 재조정하는 Confluent 셀프 밸런싱 클러스터 기능을 테스트했습니다.  Confluent 재균형 테스트는 노드 장애가 발생하거나 확장 노드에서 브로커 간에 데이터를 재균형화해야 할 때 새로운 브로커를 추가하는 데 걸리는 시간을 측정하는 데 도움이 됩니다.  클래식 카프카 구성에서는 클러스터가 커짐에 따라 재조정해야 할 데이터 양이 늘어나지만, 계층형 스토리지에서는 재조정이 적은 양의 데이터로 제한됩니다.  검증 결과에 따르면, 클래식 카프카 아키텍처에서 계층형 스토리지의 재조정은 몇 초 또는 몇 분이 걸리고 클러스터가 커짐에 따라 선형적으로 증가합니다.</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">셀프 밸런싱 클러스터에서는 파티션 재조정이 완전히 자동화되어 Kafka의 처리량을 최적화하고, 브로커 확장을 가속화하고, 대규모 클러스터를 실행하는 데 따른 운영 부담을 줄입니다.  정상 상태에서 자체 균형 클러스터는 브로커 전체의 데이터 불균형을 모니터링하고 클러스터 성능을 최적화하기 위해 지속적으로 파티션을 재할당합니다.  플랫폼을 확장하거나 축소할 때 셀프 밸런싱 클러스터는 자동으로 새로운 브로커의 존재 또는 기존 브로커의 제거를 인식하고 후속 파티션 재할당을 트리거합니다.  이를 통해 브로커를 쉽게 추가하고 해제할 수 있어 Kafka 클러스터가 근본적으로 더 탄력적으로 작동합니다.  이러한 이점은 파티션 재할당에 일반적으로 수반되는 수동 개입, 복잡한 수학 또는 인간 오류의 위험 없이 제공됩니다.  결과적으로 데이터 재조정이 훨씬 짧은 시간 안에 완료되고, 클러스터를 지속적으로 감독할 필요 없이 더 높은 가치의 이벤트 스트리밍 프로젝트에 집중할 수 있습니다.</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">이 설정에서는 Kafka S3 싱크 커넥터를 사용하여 Kafka에서 개체 스토리지의 주제를 직접 읽고 쓰는 방법을 보여드립니다.  이 테스트에서는 독립형 Confluent 클러스터를 사용했지만, 이 설정은 분산 클러스터에도 적용할 수 있습니다.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Confluent S3 커넥터</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink 커넥터는 Apache Kafka 토픽의 데이터를 Avro, JSON 또는 Bytes 형식으로 S3 객체로 내보냅니다.  Amazon S3 싱크 커넥터는 주기적으로 Kafka에서 데이터를 폴링하고 이를 다시 S3에 업로드합니다.  파티셔너는 모든 카프카 파티션의 데이터를 청크로 분할하는 데 사용됩니다.  각 데이터 덩어리는 S3 객체로 표현됩니다.  키 이름은 주제, 카프카 파티션, 이 데이터 청크의 시작 오프셋을 인코딩합니다.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Confluent 웹사이트에서 Confluent Kafka를 다운로드하세요.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">서버의 폴더에 패키지를 압축 해제합니다.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">두 개의 변수를 내보냅니다.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">독립 실행형 Confluent Kafka 설정의 경우 클러스터는 임시 루트 폴더를 생성합니다.<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block> 또한 Zookeeper, Kafka, 스키마 레지스트리, Connect, ksql-server 및 Control-Center 폴더를 생성하고 해당 구성 파일을 다음에서 복사합니다.<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block> .  다음 예를 참조하세요.</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">Zookeeper를 구성합니다.  기본 매개변수를 사용하는 경우 아무것도 변경할 필요가 없습니다.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">위의 구성에서 우리는 다음을 업데이트했습니다.<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block> 재산.  기본적으로 Kafka 리더 선택을 위해서는 3명의 Zookeeper가 필요합니다.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">우리는 myid 파일을 생성했습니다<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block> 고유 ID로:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">우리는 myid 파일에 마지막 IP 주소 번호를 사용했습니다.  Kafka, connect, control-center, Kafka, Kafka-rest, ksql-server 및 schema-registry 구성에 기본값을 사용했습니다.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">카프카 서비스를 시작합니다.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">각 구성에는 문제 해결에 도움이 되는 로그 폴더가 있습니다.  어떤 경우에는 서비스를 시작하는 데 시간이 더 오래 걸립니다.  모든 서비스가 정상적으로 작동하고 있는지 확인하세요.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Kafka Connect를 사용하여 설치하세요<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block> .</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">다음을 사용하여 특정 버전을 설치할 수도 있습니다.<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block> .</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">기본적으로,<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> 에 설치됨<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block> .</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">플러그인 경로를 새 것으로 업데이트합니다.<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block> .</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Confluent 서비스를 중지했다가 다시 시작합니다.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">액세스 ID 및 비밀 키를 구성하세요.<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block> 파일.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">버킷에 접근 가능한지 확인하세요.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">S3 및 버킷 구성을 위해 S3-싱크 속성 파일을 구성합니다.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">몇 개의 레코드를 S3 버킷으로 가져옵니다.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">s3-싱크 커넥터를 로드합니다.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">s3-sink 상태를 확인하세요.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">s3-sink가 토픽을 수락할 준비가 되었는지 확인하려면 로그를 확인하세요.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">카프카의 주제를 확인하세요.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">s3 버킷의 객체를 확인하세요.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">내용을 확인하려면 다음 명령을 실행하여 각 파일을 S3에서 로컬 파일 시스템으로 복사합니다.</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">아파치 아카이브</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">레코드를 인쇄하려면 avro-tools-1.11.0.1.jar(다음에서 사용 가능)를 사용하세요.<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block> ).</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">이 페이지에서는 이 솔루션의 성능을 개선하기 위한 모범 사례를 설명합니다.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">성능 모범 사례 지침</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">ONTAP 의 경우 가능하면 GET 크기 &gt;=1MB를 사용하세요.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">증가하다<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> 그리고<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> ~에<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block> 브로커 노드에서 S3 계층으로 계층화 활동을 늘릴 수 있습니다.  이러한 결과는 다음과 같습니다.<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block> 그리고<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block> 32로 설정.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3 버킷은 멤버 집계당 8개의 구성 요소를 타겟으로 해야 합니다.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">S3 트래픽을 구동하는 이더넷 링크는 가능한 경우 저장소와 클라이언트 모두에서 9k의 MTU를 사용해야 합니다.</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">이 검증 테스트에서는 NetApp ONTAP 스토리지 컨트롤러가 있는 Confluent에서 31.74GBps의 계층화 처리량을 달성했습니다.</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">이 검증 테스트에서는 NetApp ONTAP 스토리지 컨트롤러가 있는 Confluent에서 31.74GBps의 계층화 처리량을 달성했습니다.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Confluent란 무엇인가요?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">ONTAP 의 S3 모범 사례</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3 객체 스토리지 관리</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">이 페이지에서는 이 솔루션의 매개변수 내에서 Confluent의 성능 검증을 설명합니다.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Confluent 성능 검증</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">NetApp ONTAP 의 계층형 스토리지에 대해 Confluent Platform을 사용하여 검증을 수행했습니다.  NetApp 과 Confluent 팀은 이 검증 작업을 함께 수행했으며 이에 필요한 테스트 사례를 실행했습니다.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Confluent 설정</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">설정을 위해 256GB RAM과 16개 CPU를 갖춘 3개의 동물원 관리자, 5개의 브로커, 5개의 테스트 서버를 사용했습니다.  NetApp 스토리지의 경우 AFF A900 HA 쌍이 있는 ONTAP 사용했습니다.  저장소와 브로커는 100GbE 연결을 통해 연결되었습니다.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">다음 그림은 계층형 스토리지 검증에 사용되는 구성의 네트워크 토폴로지를 보여줍니다.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">이 그래픽은 계층형 스토리지 검증에 사용되는 구성의 네트워크 토폴로지를 보여줍니다.</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">도구 서버는 Confluent 노드와 이벤트를 주고받는 애플리케이션 클라이언트 역할을 합니다.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">우리는 다음과 같은 테스트 매개변수를 사용했습니다.</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">검증을 위해 HTTP 프로토콜을 사용하는 ONTAP 사용했지만 HTTPS도 작동했습니다.  액세스 키와 비밀 키는 제공된 파일 이름에 저장됩니다.<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block> 매개변수.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetApp 스토리지 컨트롤러 – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">검증을 위해 ONTAP 에서 단일 HA 쌍 구성을 구성했습니다.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">이 그래픽은 검증을 위해 환경이 단일 HA 쌍으로 구성된 방식을 보여줍니다.</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">검증 결과</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">우리는 검증을 위해 다음의 5가지 테스트 사례를 완료했습니다.  처음 두 가지는 기능 테스트였고 나머지 세 가지는 성능 테스트였습니다.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">이 테스트는 API 호출을 사용하여 계층형 스토리지에 사용되는 객체 저장소에서 get, put, delete와 같은 기본 작업을 수행합니다.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">이 테스트는 개체 스토리지의 종단 간 기능을 확인합니다.  주제를 생성하고, 새로 생성된 주제에 대한 이벤트 스트림을 생성하고, 브로커가 세그먼트를 개체 스토리지에 보관할 때까지 기다리고, 이벤트 스트림을 사용하고, 사용된 스트림이 생성된 스트림과 일치하는지 검증합니다.  우리는 객체 저장소 오류 주입을 적용한 경우와 적용하지 않은 경우로 이 테스트를 수행했습니다.  ONTAP 의 노드 중 하나에서 서비스 관리자 서비스를 중지하고 엔드투엔드 기능이 개체 스토리지에서 작동하는지 검증하여 노드 장애를 시뮬레이션했습니다.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">생산-소비 작업 생성기</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">이 테스트는 세그먼트 보관을 통해 개체 저장소에 대한 쓰기 작업 부하를 간접적으로 생성합니다.  소비자 그룹이 세그먼트를 가져올 때 개체 스토리지에서 읽기 작업 부하(세그먼트 읽기)가 생성되었습니다.  이 작업 부하는 TOCC 스크립트에 의해 생성되었습니다.  이 테스트는 병렬 스레드에서 개체 스토리지의 읽기 및 쓰기 성능을 확인했습니다.  우리는 계층화 기능 정확성 테스트에서 했던 것처럼 객체 저장소 오류 주입을 적용한 경우와 적용하지 않은 경우를 테스트했습니다.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">보존 작업량 생성기</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">이 테스트는 주제 보존 작업 부하가 큰 상황에서 개체 스토리지의 삭제 성능을 점검했습니다.  보존 작업 부하는 테스트 주제와 병렬로 많은 메시지를 생성하는 TOCC 스크립트를 사용하여 생성되었습니다.  테스트 주제는 이벤트 스트림이 개체 저장소에서 지속적으로 제거되도록 하는 공격적인 크기 기반 및 시간 기반 보존 설정으로 구성되었습니다.  그런 다음 세그먼트는 보관되었습니다.  이로 인해 브로커가 개체 저장소에서 많은 삭제를 수행하게 되었고 개체 저장소 삭제 작업의 성능이 저하되었습니다.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">지류</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">확인 세부 사항은 다음을 참조하세요.<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> 웹사이트.</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">우리는 하나의 AFF A900 HA 쌍 NetApp 스토리지 컨트롤러를 사용하여 생산-소비 워크로드 동안 5개 또는 8개의 브로커 노드로 계층형 스토리지 테스트를 수행했습니다.  테스트에 따르면, AFF A900 리소스 사용률이 100%에 도달할 때까지 완료 시간과 성능 결과는 브로커 노드 수에 따라 조정되었습니다.  ONTAP 스토리지 컨트롤러 설정에는 최소 1개의 HA 쌍이 필요했습니다.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">생산-소비 워크로드 생성기를 사용한 성능 테스트</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">S3 검색 작업의 성능은 Confluent 브로커 노드 수에 따라 선형적으로 증가했습니다.  ONTAP 스토리지 컨트롤러는 단일 배포에서 최대 12개의 HA 쌍을 지원합니다.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">다음 그래프는 5개 또는 8개의 브로커 노드가 있는 결합된 S3 계층화 트래픽을 보여줍니다.  우리는 AFF A900 단일 HA 쌍의 성능을 극대화했습니다.</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">이 데이터 그래프는 5개 또는 8개의 브로커 노드가 포함된 S3 계층화 트래픽을 결합한 것을 보여줍니다.</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">다음 그래프는 약 31.74GBps의 Kafka 처리량을 보여줍니다.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">이 데이터 그래프는 카프카 처리량이 약 31.74GBps임을 보여줍니다.</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">또한 ONTAP 스토리지 컨트롤러에서도 유사한 처리량을 관찰했습니다.<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block> 보고서.</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">이 섹션에서는 계층형 스토리지를 위한 NetApp ONTAP 사용하여 Confluent Platform을 구축할 때 성능 검증에 사용되는 하드웨어와 소프트웨어에 대해 설명합니다.  다음 표에서는 솔루션 아키텍처와 기본 구성 요소를 설명합니다.</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">ONTAP 기반의 Confluent 및 NetApp AFF A900 스토리지 컨트롤러는 데이터 스트림을 위해 설계된 분산 시스템입니다.  두 제품 모두 수평적 확장이 가능하고, 내결함성이 뛰어나며, 부하 상황에서도 뛰어난 성능을 제공합니다.  이러한 기술은 데이터 감소 기술을 통해 데이터 공간을 최소화하고 저장 비용을 낮추어 분산 데이터 스트리밍 및 스트림 처리에서 서로 보완됩니다.  AFF A900 스토리지 컨트롤러는 뛰어난 성능을 제공하는 동시에 컴퓨팅 및 데이터 스토리지 리소스를 분리할 수 있습니다.  이를 통해 시스템 관리가 간소화되고 리소스를 독립적으로 확장할 수 있습니다.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">솔루션 개요를 묘사한 이미지입니다.</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent 플랫폼 버전 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">동물원 관리인 3명</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">8개의 브로커 서버</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5 x 도구 서버</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">1 x 그라파나</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">1 x 제어 센터</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">따뜻한 버킷을 위한 NetApp ONTAP</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 x AFF A900 고가용성(HA) 쌍</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2개의 CPU, 총 16개의 물리적 코어</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">인텔 제온</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256GB 물리적 메모리</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbE 듀얼 포트</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">이 페이지에서는 이 솔루션에 사용된 기술을 설명합니다.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">기술 개요</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP 스토리지 컨트롤러</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP 은 고성능 엔터프라이즈급 스토리지 운영 체제입니다.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8은 Amazon Simple Storage Service(S3) API에 대한 지원을 도입합니다.  ONTAP Amazon Web Services(AWS) S3 API 작업의 하위 집합을 지원하고 클라우드 공급업체(AWS, Azure, GCP)와 온프레미스에서 ONTAP 기반 시스템의 객체로 데이터를 표현할 수 있도록 합니다.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">NetApp StorageGRID 소프트웨어는 객체 스토리지를 위한 NetApp 의 대표적인 솔루션입니다.  ONTAP 에지에서 수집 및 사전 처리 지점을 제공하고, NetApp 이 제공하는 객체 데이터에 대한 데이터 패브릭을 확장하고, NetApp 제품 포트폴리오의 가치를 높여 StorageGRID 보완합니다.</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">S3 버킷에 대한 액세스는 권한이 있는 사용자와 클라이언트 애플리케이션을 통해 제공됩니다.  다음 다이어그램은 애플리케이션이 S3 버킷에 액세스하는 것을 보여줍니다.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">이 그래픽은 애플리케이션이 S3 버킷에 액세스하는 모습을 보여줍니다.</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">주요 사용 사례</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">S3 API를 지원하는 주요 목적은 ONTAP 에서 객체 액세스를 제공하는 것입니다.  ONTAP 통합 스토리지 아키텍처는 이제 파일(NFS 및 SMB), 블록(FC 및 iSCSI), 객체(S3)를 지원합니다.</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">네이티브 S3 애플리케이션</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">점점 더 많은 애플리케이션이 S3를 사용하여 개체 액세스를 위해 ONTAP 지원을 활용할 수 있습니다.  대용량 보관 작업에는 적합하지만 네이티브 S3 애플리케이션에서 고성능에 대한 요구가 빠르게 증가하고 있으며 여기에는 다음이 포함됩니다.</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">해석학</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">인공지능</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">에지-투-코어 수집</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">이제 고객은 ONTAP System Manager와 같은 익숙한 관리 도구를 사용하여 ONTAP 에서 개발 및 운영을 위한 고성능 개체 스토리지를 빠르게 프로비저닝하고, 이를 통해 ONTAP 스토리지 효율성과 보안의 이점을 누릴 수 있습니다.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool 엔드포인트</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">ONTAP 9.8부터 FabricPool ONTAP 의 버킷 계층화를 지원하여 ONTAP ONTAP 계층화를 허용합니다.  이는 기존 FAS 인프라를 객체 저장소 엔드포인트로 재활용하려는 고객에게 매우 좋은 옵션입니다.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool 두 가지 방법으로 ONTAP 계층화를 지원합니다.</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*로컬 클러스터 계층화.*  비활성 데이터는 클러스터 LIF를 사용하여 로컬 클러스터에 있는 버킷에 계층화됩니다.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*원격 클러스터 계층화.*  비활성 데이터는 FabricPool 클라이언트의 IC LIF와 ONTAP 개체 저장소의 데이터 LIF를 사용하는 기존 FabricPool 클라우드 계층과 유사한 방식으로 원격 클러스터에 있는 버킷에 계층화됩니다.</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3는 추가 하드웨어 및 관리 없이 기존 클러스터에서 S3 기능을 원하는 경우에 적합합니다.  300TB가 넘는 배포의 경우 NetApp StorageGRID 소프트웨어는 여전히 개체 스토리지를 위한 NetApp 의 주력 솔루션입니다.  ONTAP 또는 StorageGRID 클라우드 계층으로 사용하는 경우 FabricPool 라이선스가 필요하지 않습니다.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">Confluent 계층형 스토리지용 NetApp ONTAP</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">모든 데이터 센터는 비즈니스에 중요한 애플리케이션을 계속 실행하고 중요한 데이터를 안전하게 사용할 수 있어야 합니다.  새로운 NetApp AFF A900 시스템은 ONTAP Enterprise Edition 소프트웨어와 고탄력성 설계를 기반으로 합니다.  당사의 새로운 초고속 NVMe 스토리지 시스템은 미션 크리티컬 운영의 중단을 없애고, 성능 조정을 최소화하며, 랜섬웨어 공격으로부터 데이터를 보호합니다.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">초기 배포부터 Confluent 클러스터 확장까지, 귀사의 환경은 비즈니스에 중요한 애플리케이션을 중단시키지 않는 변화에 신속하게 적응해야 합니다.  ONTAP 엔터프라이즈 데이터 관리, 서비스 품질(QoS), 성능을 통해 환경에 맞게 계획하고 적응할 수 있습니다.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">NetApp ONTAP 과 Confluent Tiered Storage를 함께 사용하면 ONTAP 확장형 스토리지 대상으로 활용하여 Apache Kafka 클러스터 관리를 간소화하고 Confluent의 컴퓨팅 및 스토리지 리소스를 독립적으로 확장할 수 있습니다.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">ONTAP S3 서버는 ONTAP 의 성숙한 확장형 스토리지 기능을 기반으로 구축되었습니다.  ONTAP 클러스터에 새로 추가된 노드를 사용하도록 S3 버킷을 확장하면 ONTAP 클러스터를 원활하게 확장할 수 있습니다.</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">ONTAP System Manager를 통한 간편한 관리</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP 시스템 관리자는 브라우저 기반 그래픽 인터페이스로, 전 세계에 분산된 위치에 있는 ONTAP 스토리지 컨트롤러를 단일 창에서 구성, 관리 및 모니터링할 수 있습니다.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">이 그래픽은 ONTAP 시스템 관리자 작업 공간을 보여줍니다.</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">System Manager와 ONTAP CLI를 사용하여 ONTAP S3를 구성하고 관리할 수 있습니다.  S3를 활성화하고 System Manager를 사용하여 버킷을 생성하면 ONTAP 단순화된 구성에 대한 모범 사례 기본값을 제공합니다.  CLI에서 S3 서버와 버킷을 구성하는 경우에도 원하는 경우 System Manager를 사용하여 관리할 수 있으며 그 반대의 경우도 가능합니다.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">System Manager를 사용하여 S3 버킷을 생성하면 ONTAP 시스템에서 사용 가능한 가장 높은 기본 성능 서비스 수준을 구성합니다.  예를 들어, AFF 시스템에서 기본 설정은 Extreme입니다.  성능 서비스 수준은 사전 정의된 적응형 QoS 정책 그룹입니다.  기본 서비스 수준 중 하나를 지정하는 대신 사용자 지정 QoS 정책 그룹을 지정하거나 정책 그룹을 지정하지 않을 수 있습니다.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">미리 정의된 적응형 QoS 정책 그룹에는 다음이 포함됩니다.</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*극심한.*  가장 낮은 지연 시간과 가장 높은 성능이 필요한 애플리케이션에 사용됩니다.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*성능.*  적당한 성능 요구와 지연 시간이 필요한 애플리케이션에 사용됩니다.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*값.*  지연 시간보다 처리량과 용량이 더 중요한 애플리케이션에 사용됩니다.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*관습.*  사용자 정의 QoS 정책을 지정하거나 QoS 정책을 지정하지 않습니다.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">*계층화에 사용*을 선택하면 성능 서비스 수준이 선택되지 않으며, 시스템은 계층화된 데이터에 대해 최적의 성능을 제공하는 저비용 미디어를 선택하려고 합니다.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP 선택한 서비스 수준을 충족하면서 가장 적합한 디스크가 있는 로컬 계층에 이 버킷을 프로비저닝하려고 시도합니다.  하지만 버킷에 포함할 디스크를 지정해야 하는 경우 로컬 계층(집계)을 지정하여 CLI에서 S3 개체 스토리지를 구성하는 것을 고려하세요.  CLI에서 S3 서버를 구성하는 경우에도 원하는 경우 시스템 관리자를 사용하여 관리할 수 있습니다.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">버킷에 어떤 집계를 사용할지 지정하는 기능을 원하는 경우 CLI를 사용해서만 가능합니다.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform은 연속적이고 실시간 스트림으로 데이터에 쉽게 액세스하고 저장하고 관리할 수 있는 본격적인 데이터 스트리밍 플랫폼입니다.  Apache Kafka의 최초 개발자가 개발한 Confluent는 Kafka의 이점을 엔터프라이즈급 기능으로 확장하는 동시에 Kafka 관리나 모니터링의 부담을 제거합니다.  오늘날 Fortune 100 기업 중 80% 이상이 데이터 스트리밍 기술을 사용하고 있으며, 대부분이 Confluent를 사용합니다.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">왜 Confluent를 선택해야 할까요?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Confluent는 과거 데이터와 실시간 데이터를 단일의 중앙 진실 소스로 통합하여 완전히 새로운 종류의 최신 이벤트 중심 애플리케이션을 쉽게 구축하고, 보편적인 데이터 파이프라인을 확보하고, 완전한 확장성, 성능, 안정성을 갖춘 강력한 새로운 사용 사례를 창출할 수 있도록 지원합니다.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Confluent는 무엇에 사용되나요?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform을 사용하면 여러 시스템 간에 데이터가 전송되거나 통합되는 방식과 같은 기본적인 메커니즘에 대해 걱정하는 대신 데이터에서 비즈니스 가치를 도출하는 방법에 집중할 수 있습니다.  특히, Confluent Platform은 Kafka에 대한 데이터 소스 연결, 스트리밍 애플리케이션 구축, Kafka 인프라의 보안, 모니터링 및 관리를 간소화합니다.  오늘날 Confluent Platform은 금융 서비스, 옴니채널 소매, 자율주행차부터 사기 탐지, 마이크로서비스, IoT까지 다양한 산업에 걸쳐 광범위한 사용 사례에 사용되고 있습니다.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">다음 그림은 Confluent Platform의 구성 요소를 보여줍니다.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">이 그래픽은 Confluent Platform의 구성 요소를 보여줍니다.</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Confluent 이벤트 스트리밍 기술 개요</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">카프카</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Confluent 플랫폼의 핵심은 다음과 같습니다.<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block> 가장 인기 있는 오픈소스 분산 스트리밍 플랫폼입니다.  카프카의 주요 기능은 다음과 같습니다.</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">레코드 스트림을 게시하고 구독합니다.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">장애에 견딜 수 있는 방식으로 레코드 스트림을 저장합니다.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">레코드 스트림을 처리합니다.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Confluent Platform에는 기본적으로 스키마 레지스트리, REST 프록시, 100개 이상의 사전 구축된 Kafka 커넥터, ksqlDB가 포함되어 있습니다.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Confluent 플랫폼 엔터프라이즈 기능 개요</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Confluent 제어 센터.*  Kafka를 관리하고 모니터링하기 위한 UI 기반 시스템입니다.  Kafka Connect를 쉽게 관리하고 다른 시스템에 대한 연결을 생성, 편집, 관리할 수 있습니다.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Kubernetes용 Confluent.*  Kubernetes용 Confluent는 Kubernetes 운영자입니다.  쿠버네티스 운영자는 특정 플랫폼 애플리케이션에 대한 고유한 기능과 요구 사항을 제공하여 쿠버네티스의 오케스트레이션 기능을 확장합니다.  Confluent Platform의 경우, 여기에는 Kubernetes에서 Kafka의 배포 프로세스를 크게 단순화하고 일반적인 인프라 수명 주기 작업을 자동화하는 것이 포함됩니다.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Kafka Connect 커넥터.*  커넥터는 Kafka Connect API를 사용하여 Kafka를 데이터베이스, 키-값 저장소, 검색 인덱스, 파일 시스템 등의 다른 시스템에 연결합니다.  Confluent Hub에는 가장 인기 있는 데이터 소스와 싱크에 대한 다운로드 가능한 커넥터가 있으며, 여기에는 Confluent Platform에서 이러한 커넥터의 완전히 테스트되고 지원되는 버전이 포함됩니다.  더 자세한 내용은 다음을 참조하세요.<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*자체 균형 클러스터.*  자동화된 부하 분산, 장애 감지 및 자체 복구 기능을 제공합니다.  또한 필요에 따라 브로커를 추가하거나 해제하는 기능을 제공하며, 수동으로 조정할 필요가 없습니다.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*합류 클러스터 연결.*  링크 브리지를 통해 클러스터를 직접 연결하고 한 클러스터의 주제를 다른 클러스터로 미러링합니다.  클러스터 연결을 통해 다중 데이터 센터, 다중 클러스터 및 하이브리드 클라우드 배포 설정이 간소화됩니다.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Confluent 자동 데이터 밸런서.*  클러스터 내의 브로커 수, 파티션 크기, 파티션 수, 리더 수를 모니터링합니다.  이 기능을 사용하면 클러스터 전체에서 균일한 작업 부하를 생성하기 위해 데이터를 이동할 수 있으며, 재조정하는 동안 프로덕션 작업 부하에 미치는 영향을 최소화하기 위해 재조정 트래픽을 조절할 수 있습니다.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*합류 복제기.*  여러 데이터 센터에서 여러 Kafka 클러스터를 유지 관리하는 것이 그 어느 때보다 쉬워졌습니다.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*계층화된 스토리지.*  선호하는 클라우드 공급업체를 사용하여 대용량의 Kafka 데이터를 저장할 수 있는 옵션을 제공하므로 운영 부담과 비용이 줄어듭니다.  계층형 스토리지를 사용하면 비용 효율적인 개체 스토리지에 데이터를 보관하고, 더 많은 컴퓨팅 리소스가 필요할 때만 확장 브로커를 사용할 수 있습니다.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Confluent JMS 클라이언트.*  Confluent Platform에는 Kafka용 JMS 호환 클라이언트가 포함되어 있습니다.  이 Kafka 클라이언트는 Kafka 브로커를 백엔드로 사용하여 JMS 1.1 표준 API를 구현합니다.  이 기능은 JMS를 사용하는 레거시 애플리케이션이 있고 기존 JMS 메시지 브로커를 Kafka로 교체하려는 경우에 유용합니다.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Confluent MQTT 프록시.*  중간에 MQTT 브로커가 필요 없이 MQTT 장치 및 게이트웨이에서 Kafka로 직접 데이터를 게시하는 방법을 제공합니다.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Confluent 보안 플러그인.*  Confluent 보안 플러그인은 다양한 Confluent Platform 도구와 제품에 보안 기능을 추가하는 데 사용됩니다.  현재 Confluent REST 프록시에 사용할 수 있는 플러그인이 있는데, 이 플러그인은 들어오는 요청을 인증하고 인증된 주체를 Kafka에 대한 요청에 전파하는 데 도움이 됩니다.  이를 통해 Confluent REST 프록시 클라이언트는 Kafka 브로커의 멀티테넌트 보안 기능을 활용할 수 있습니다.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID 는 고성능, 비용 효율적인 객체 스토리지 플랫폼입니다.  계층형 스토리지를 사용하면 브로커의 로컬 스토리지나 SAN 스토리지에 저장된 Confluent Kafka의 대부분 데이터가 원격 개체 저장소로 오프로드됩니다.  이 구성은 클러스터를 재조정, 확장 또는 축소하거나 실패한 브로커를 교체하는 데 드는 시간과 비용을 줄여 운영을 크게 개선합니다.  개체 스토리지는 개체 스토리지 계층에 있는 데이터를 관리하는 데 중요한 역할을 하므로 올바른 개체 스토리지를 선택하는 것이 중요합니다.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID 분산된 노드 기반 그리드 아키텍처를 사용하여 지능적이고 정책 기반의 글로벌 데이터 관리를 제공합니다.  유비쿼터스 글로벌 객체 네임스페이스와 정교한 데이터 관리 기능을 결합하여 페타바이트 규모의 비정형 데이터와 수십억 개의 객체를 간편하게 관리할 수 있습니다.  단일 호출 객체 액세스는 여러 사이트로 확장되어 고가용성 아키텍처를 단순화하는 동시에 사이트나 인프라 중단에 관계없이 지속적인 객체 액세스를 보장합니다.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">멀티테넌시를 통해 여러 개의 비정형 클라우드 및 엔터프라이즈 데이터 애플리케이션을 동일한 그리드 내에서 안전하게 서비스할 수 있어 NetApp StorageGRID 의 ROI와 사용 사례가 늘어납니다.  메타데이터 기반 개체 수명 주기 정책을 통해 여러 서비스 수준을 생성하여 여러 지역에 걸쳐 내구성, 보호, 성능 및 지역성을 최적화할 수 있습니다.  사용자는 끊임없이 변화하는 IT 환경에서 요구 사항이 바뀌더라도 데이터 관리 정책을 조정하고 트래픽 제한을 모니터링하여 데이터 환경에 맞게 중단 없이 재조정할 수 있습니다.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Grid Manager를 통한 간편한 관리</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager는 브라우저 기반 그래픽 인터페이스로, 단일 창에서 전 세계에 분산된 위치에 있는 StorageGRID 시스템을 구성, 관리 및 모니터링할 수 있습니다.</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">StorageGRID Grid Manager 인터페이스를 사용하여 다음 작업을 수행할 수 있습니다.</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">이미지, 비디오, 기록 등의 객체가 담긴 페타바이트 규모의 글로벌 분산 저장소를 관리합니다.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">그리드 노드와 서비스를 모니터링하여 객체 가용성을 보장합니다.</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">정보 수명 주기 관리(ILM) 규칙을 사용하여 시간 경과에 따른 개체 데이터의 배치를 관리합니다.  이러한 규칙은 객체 데이터가 수집된 후 어떻게 처리되는지, 데이터가 손실로부터 어떻게 보호되는지, 객체 데이터가 어디에 저장되는지, 얼마 동안 저장되는지를 관리합니다.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">시스템 내에서 거래, 성능 및 운영을 모니터링합니다.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">정보 수명 주기 관리 정책</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRID 개체의 복제본을 보관하고 2+1, 4+2 등과 같은 EC(삭제 코딩) 방식을 사용하여 특정 성능 및 데이터 보호 요구 사항에 따라 개체를 저장하는 등 유연한 데이터 관리 정책을 제공합니다.  시간이 지남에 따라 작업 부하와 요구 사항이 바뀌므로 ILM 정책도 시간이 지남에 따라 변경해야 하는 것이 일반적입니다.  ILM 정책을 수정하는 것은 StorageGRID 고객이 끊임없이 변화하는 환경에 빠르고 쉽게 적응할 수 있도록 하는 핵심 기능입니다.</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">성능</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 또는 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID VM, 베어 메탈 또는 특수 목적 어플라이언스와 같은 더 많은 스토리지 노드를 추가하여 성능을 확장합니다.<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block> .  테스트 결과, SGF6024 어플라이언스를 사용하여 최소 크기의 3노드 그리드로 Apache Kafka의 주요 성능 요구 사항을 충족했습니다.  고객이 추가 브로커를 사용하여 Kafka 클러스터를 확장하면 더 많은 스토리지 노드를 추가하여 성능과 용량을 늘릴 수 있습니다.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">로드 밸런서 및 엔드포인트 구성</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID 의 관리 노드는 StorageGRID 시스템을 보고, 구성하고, 관리할 수 있는 Grid Manager UI(사용자 인터페이스)와 REST API 엔드포인트를 제공하며, 시스템 활동을 추적하기 위한 감사 로그를 제공합니다.  Confluent Kafka 계층형 스토리지에 고가용성 S3 엔드포인트를 제공하기 위해 관리 노드와 게이트웨이 노드에서 서비스로 실행되는 StorageGRID 로드 밸런서를 구현했습니다.  또한, 로드 밸런서는 로컬 트래픽을 관리하고 GSLB(글로벌 서버 로드 밸런싱)와 통신하여 재해 복구를 지원합니다.</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">엔드포인트 구성을 더욱 향상시키기 위해 StorageGRID 관리 노드에 내장된 트래픽 분류 정책을 제공하고, 워크로드 트래픽을 모니터링하고, 워크로드에 다양한 서비스 품질(QoS) 제한을 적용할 수 있도록 합니다.  트래픽 분류 정책은 게이트웨이 노드와 관리 노드에 대한 StorageGRID 부하 분산 서비스의 엔드포인트에 적용됩니다.  이러한 정책은 트래픽 조절 및 모니터링에 도움이 될 수 있습니다.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID 의 트래픽 분류</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID 에는 QoS 기능이 내장되어 있습니다.  트래픽 분류 정책은 클라이언트 애플리케이션에서 발생하는 다양한 유형의 S3 트래픽을 모니터링하는 데 도움이 될 수 있습니다.  그런 다음 입출력 대역폭, 동시 읽기/쓰기 요청 수 또는 읽기/쓰기 요청 속도를 기준으로 이 트래픽에 제한을 두는 정책을 만들고 적용할 수 있습니다.</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka는 Java와 Scala로 작성된 스트림 처리를 사용하는 소프트웨어 버스의 프레임워크 구현입니다.  실시간 데이터 피드를 처리하기 위한 통합적이고 처리량이 높으며 지연 시간이 짧은 플랫폼을 제공하는 것이 목표입니다.  Kafka는 Kafka Connect를 통해 외부 시스템에 연결하여 데이터를 내보내고 가져올 수 있으며, Java 스트림 처리 라이브러리인 Kafka 스트림을 제공합니다.  카프카는 효율성을 위해 최적화된 바이너리 TCP 기반 프로토콜을 사용하며, 네트워크 왕복 오버헤드를 줄이기 위해 자연스럽게 메시지를 그룹화하는 "메시지 세트" 추상화에 의존합니다.  이를 통해 더 큰 순차적 디스크 작업, 더 큰 네트워크 패킷, 연속적인 메모리 블록이 가능해져서 Kafka는 무작위 메시지 쓰기의 버스트 스트림을 선형 쓰기로 전환할 수 있습니다.  다음 그림은 Apache Kafka의 기본적인 데이터 흐름을 보여줍니다.</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">카프카는 프로듀서라고 불리는 임의의 수의 프로세스에서 나온 키-값 메시지를 저장합니다.  데이터는 다양한 주제 내에서 여러 파티션으로 분할될 수 있습니다.  파티션 내에서 메시지는 오프셋(파티션 내 메시지의 위치)에 따라 엄격하게 정렬되고, 타임스탬프와 함께 인덱싱되어 저장됩니다.  소비자라고 불리는 다른 프로세스는 파티션에서 메시지를 읽을 수 있습니다.  스트림 처리를 위해 Kafka는 Kafka에서 데이터를 사용하고 결과를 Kafka로 다시 쓰는 Java 애플리케이션을 작성할 수 있는 Streams API를 제공합니다.  Apache Kafka는 Apache Apex, Apache Flink, Apache Spark, Apache Storm, Apache NiFi와 같은 외부 스트림 처리 시스템과도 호환됩니다.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">카프카는 하나 이상의 서버(브로커라고 함)로 구성된 클러스터에서 실행되며, 모든 토픽의 파티션은 클러스터 노드에 분산됩니다.  또한 파티션은 여러 브로커에 복제됩니다.  이 아키텍처를 통해 Kafka는 장애 허용 방식으로 대량의 메시지 스트림을 전달할 수 있었고, Java Message Service(JMS), Advanced Message Queuing Protocol(AMQP) 등 기존 메시징 시스템 중 일부를 대체할 수 있었습니다.  0.11.0.0 릴리스 이후 Kafka는 Streams API를 사용하여 정확히 한 번의 스트림 처리를 제공하는 트랜잭션 쓰기 기능을 제공합니다.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">카프카는 일반 토픽과 압축 토픽의 두 가지 유형을 지원합니다.  일반 주제는 보존 시간이나 공간 제한을 사용하여 구성할 수 있습니다.  지정된 보존 시간보다 오래된 레코드가 있거나 파티션의 공간 제한을 초과하는 경우 Kafka는 오래된 데이터를 삭제하여 저장 공간을 확보할 수 있습니다.  기본적으로 주제는 7일의 보존 기간으로 구성되지만, 무기한으로 데이터를 저장하는 것도 가능합니다.  압축된 주제의 경우 레코드는 시간이나 공간 경계에 따라 만료되지 않습니다.  대신, 카프카는 이후 메시지를 동일한 키를 가진 이전 메시지의 업데이트로 처리하고 키별로 최신 메시지를 삭제하지 않도록 보장합니다.  사용자는 특정 키에 null 값을 지정하여 소위 '툼스톤' 메시지를 작성하여 메시지를 완전히 삭제할 수 있습니다.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka에는 5가지 주요 API가 있습니다.</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*생산자 API.*  레코드 스트림을 게시할 수 있는 애플리케이션을 허용합니다.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*소비자 API.*  애플리케이션이 주제를 구독하고 레코드 스트림을 처리할 수 있도록 허용합니다.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*커넥터 API.*  주제를 기존 애플리케이션에 연결할 수 있는 재사용 가능한 생산자 및 소비자 API를 실행합니다.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*스트림 API.*  이 API는 입력 스트림을 출력으로 변환하고 결과를 생성합니다.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*관리자 API.*  Kafka 토픽, 브로커 및 기타 Kafka 객체를 관리하는 데 사용됩니다.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">소비자 및 생산자 API는 Kafka 메시징 프로토콜을 기반으로 구축되었으며 Java로 작성된 Kafka 소비자 및 생산자 클라이언트에 대한 참조 구현을 제공합니다.  기본 메시징 프로토콜은 개발자가 어떤 프로그래밍 언어로든 자체 소비자 또는 생산자 클라이언트를 작성하는 데 사용할 수 있는 바이너리 프로토콜입니다.  이렇게 하면 Kafka가 Java Virtual Machine(JVM) 생태계에서 해제됩니다.  사용 가능한 비Java 클라이언트 목록은 Apache Kafka 위키에서 관리됩니다.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka 사용 사례</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka는 메시징, 웹사이트 활동 추적, 메트릭, 로그 집계, 스트림 처리, 이벤트 소싱 및 커밋 로깅에 가장 많이 사용됩니다.</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">카프카는 처리량이 개선되었고, 분할 기능, 복제 기능, 내결함성 등이 내장되어 있어 대규모 메시지 처리 애플리케이션에 적합한 솔루션입니다.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">카프카는 사용자 활동(페이지 뷰, 검색)을 추적 파이프라인에서 실시간 게시-구독 피드 세트로 재구성할 수 있습니다.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">카프카는 종종 운영 모니터링 데이터에 사용됩니다.  여기에는 분산된 애플리케이션의 통계를 집계하여 운영 데이터의 중앙 집중식 피드를 생성하는 작업이 포함됩니다.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">많은 사람들이 로그 집계 솔루션의 대체 솔루션으로 Kafka를 사용합니다.  로그 집계는 일반적으로 서버에서 물리적인 로그 파일을 수집하여 처리를 위해 중앙 장소(예: 파일 서버나 HDFS)에 저장합니다.  카프카는 파일 세부 정보를 추상화하고 로그나 이벤트 데이터를 메시지 스트림으로 더욱 깔끔하게 추상화합니다.  이를 통해 처리 지연 시간을 줄이고 여러 데이터 소스와 분산된 데이터 소비에 대한 지원을 보다 쉽게 할 수 있습니다.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">많은 카프카 사용자는 여러 단계로 구성된 처리 파이프라인에서 데이터를 처리합니다. 여기서 원시 입력 데이터는 카프카 토픽에서 소비된 후 집계, 강화되거나 추가 소비 또는 후속 처리를 위해 새로운 토픽으로 변환됩니다.  예를 들어, 뉴스 기사를 추천하는 처리 파이프라인은 RSS 피드에서 기사 콘텐츠를 크롤링하여 "기사" 주제에 게시할 수 있습니다.  추가 처리 단계에서는 이 콘텐츠를 정규화하거나 중복을 제거하고 정리된 기사 콘텐츠를 새로운 주제에 게시할 수 있으며, 최종 처리 단계에서는 이 콘텐츠를 사용자에게 추천하려고 시도할 수 있습니다.  이러한 처리 파이프라인은 개별 주제를 기반으로 실시간 데이터 흐름의 그래프를 생성합니다.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">이벤트 소싱은 상태 변경 사항을 시간순으로 기록하는 애플리케이션 디자인 스타일입니다.  Kafka는 매우 큰 규모의 저장된 로그 데이터를 지원하므로 이 스타일로 구축된 애플리케이션에 적합한 백엔드입니다.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">카프카는 분산 시스템에 대한 일종의 외부 커밋 로그 역할을 할 수 있습니다.  로그는 노드 간에 데이터를 복제하는 데 도움이 되며, 실패한 노드가 데이터를 복원할 수 있는 재동기화 메커니즘 역할을 합니다.  Kafka의 로그 압축 기능은 이러한 사용 사례를 지원하는 데 도움이 됩니다.</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform은 Kafka를 고급 기능으로 완성하여 애플리케이션 개발 및 연결을 가속화하고, 스트림 처리를 통해 변환을 지원하고, 대규모 기업 운영을 단순화하고, 엄격한 아키텍처 요구 사항을 충족하는 엔터프라이즈급 플랫폼입니다.  Apache Kafka의 최초 개발자가 개발한 Confluent는 Kafka의 이점을 엔터프라이즈급 기능으로 확장하는 동시에 Kafka 관리나 모니터링의 부담을 제거합니다.  오늘날 Fortune 100 기업 중 80% 이상이 데이터 스트리밍 기술을 사용하고 있으며, 그 중 대부분은 Confluent를 사용합니다.</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform을 사용하면 여러 시스템 간에 데이터가 전송되거나 통합되는 방식과 같은 기본적인 메커니즘에 대해 걱정하는 대신 데이터에서 비즈니스 가치를 도출하는 방법에 집중할 수 있습니다.  특히, Confluent Platform은 Kafka에 대한 데이터 소스 연결, 스트리밍 애플리케이션 구축, Kafka 인프라의 보안, 모니터링 및 관리를 간소화합니다.  오늘날 Confluent Platform은 금융 서비스, 옴니채널 소매, 자율주행차부터 사기 탐지, 마이크로서비스, IoT까지 다양한 산업에 걸쳐 광범위한 사용 사례에 사용되고 있습니다.</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">다음 그림은 Confluent Kafka 플랫폼 구성 요소를 보여줍니다.</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Confluent의 이벤트 스트리밍 기술 개요</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Confluent 플랫폼의 핵심은 다음과 같습니다.<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block> 가장 인기 있는 오픈소스 분산 스트리밍 플랫폼입니다.  카프카의 주요 기능은 다음과 같습니다.</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Confluent 플랫폼의 엔터프라이즈 기능 개요</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Confluent 제어 센터.*  Kafka를 관리하고 모니터링하기 위한 GUI 기반 시스템입니다.  Kafka Connect를 쉽게 관리하고 다른 시스템에 대한 연결을 생성, 편집, 관리할 수 있습니다.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Kafka에 대한 합류 커넥터.*  커넥터는 Kafka Connect API를 사용하여 Kafka를 데이터베이스, 키-값 저장소, 검색 인덱스, 파일 시스템 등의 다른 시스템에 연결합니다.  Confluent Hub에는 가장 인기 있는 데이터 소스와 싱크에 대한 다운로드 가능한 커넥터가 있으며, 여기에는 Confluent Platform에서 이러한 커넥터의 완전히 테스트되고 지원되는 버전이 포함됩니다.  더 자세한 내용은 다음을 참조하세요.<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block> .</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*자체 균형 클러스터.*  자동화된 부하 분산, 장애 감지 및 자체 복구 기능을 제공합니다.  필요에 따라 브로커를 추가하거나 해제하는 데 대한 지원을 제공하며, 수동 조정은 필요하지 않습니다.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Confluent 자동 데이터 밸런서.*  클러스터 내의 브로커 수, 파티션 크기, 파티션 수, 리더 수를 모니터링합니다.  이 기능을 사용하면 클러스터 전체에서 균일한 작업 부하를 생성하기 위해 데이터를 이동할 수 있으며, 재조정하는 동안 프로덕션 작업 부하에 미치는 영향을 최소화하기 위해 재조정 트래픽을 조절할 수 있습니다.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: NetApp 스토리지 솔루션을 사용한 Apache Spark 워크로드</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY는 NetApp NFS AFF 스토리지 시스템에서 Apache Spark SQL의 성능과 기능 검증에 대해 설명합니다.  다양한 시나리오에 따른 구성, 아키텍처, 성능 테스트를 검토하고 NetApp ONTAP 데이터 관리 소프트웨어와 함께 Spark를 사용하기 위한 권장 사항도 살펴봅니다.  또한 NetApp AFF A800 스토리지 컨트롤러와 비교하여 여러 디스크(JBOD)만을 기반으로 한 테스트 결과도 다룹니다.</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">최신 데이터 분석 - 다양한 분석 전략에 맞는 다양한 솔루션</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">이 백서에서는 NetApp 최신 데이터 분석 솔루션 전략을 설명합니다.  여기에는 비즈니스 성과, 고객 과제, 기술 동향, 경쟁 레거시 아키텍처, 최신 워크플로, 사용 사례, 산업, 클라우드, 기술 파트너, 데이터 이동자, NetApp Active IQ Digital Advisor ( Digital Advisor 라고도 함), NetApp DataOps Toolkit, Hadoop to Spark, NetApp Trident Protect를 통한 소프트웨어 정의 스토리지, 컨테이너, 엔터프라이즈 데이터 관리, 보관 및 계층화를 통해 AI와 분석 목표를 달성하는 방법에 대한 세부 정보가 포함되어 있으며, NetApp 과 고객이 함께 데이터 아키텍처를 현대화하는 방법도 설명합니다.</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">이 TR에서는 다음 참고문헌이 사용되었습니다.</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark 아키텍처 및 구성 요소</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Apache Spark 사용 사례</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">버트</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">광고 클릭 예측을 위한 심층 및 교차 네트워크</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">스트리밍 ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Hadoop을 위한 NetApp E-Series 솔루션</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">NetApp 최신 데이터 분석 솔루션</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">데이터 분석 솔루션</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">엑스피</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">BlueXP 복사 및 동기화</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOps 툴킷</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">이 페이지에서는 주요 AI, ML, DL 사용 사례와 아키텍처를 더 자세히 설명합니다.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">주요 AI, ML 및 DL 사용 사례 및 아키텍처</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">주요 AI, ML, DL 사용 사례와 방법론은 다음 섹션으로 나눌 수 있습니다.</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Spark NLP 파이프라인 및 TensorFlow 분산 추론</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">다음 목록은 다양한 개발 수준에서 데이터 과학 커뮤니티에서 채택된 가장 인기 있는 오픈소스 NLP 라이브러리를 포함합니다.</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">자연어 툴킷(NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> . 모든 NLP 기술을 위한 완벽한 툴킷입니다.  2000년대 초반부터 유지되어 왔습니다.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">텍스트블롭</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> . NLTK와 Pattern을 기반으로 구축된 사용하기 쉬운 NLP 도구 Python API입니다.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">스탠포드 코어 NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> . Stanford NLP Group에서 개발한 Java로 작성된 NLP 서비스와 패키지입니다.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">젠심</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> . 인간을 위한 주제 모델링은 체코 디지털 수학 도서관 프로젝트를 위한 Python 스크립트 모음으로 시작되었습니다.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">스파시</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> . GPU 가속을 탑재한 Python 및 Cython을 사용한 엔드투엔드 산업용 NLP 워크플로우로 변압기를 구현합니다.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">패스트텍스트</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> . Facebook의 AI 연구(FAIR) 랩에서 만든 단어 임베딩 학습과 문장 분류를 위한 무료, 가벼운 오픈 소스 NLP 라이브러리입니다.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">스파크 ML</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP는 모든 NLP 작업과 요구 사항을 위한 단일 통합 솔루션으로, 실제 생산 사용 사례에서 확장 가능하고 성능이 뛰어나며 정확도가 높은 NLP 기반 소프트웨어를 구현합니다.  이는 전이 학습을 활용하고 연구와 산업 전반에 걸쳐 최신 첨단 알고리즘과 모델을 구현합니다.  Spark에서 위 라이브러리에 대한 완전한 지원이 부족하기 때문에 Spark NLP는 다음 라이브러리를 기반으로 구축되었습니다.<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> 미션 크리티컬 프로덕션 워크플로를 위한 엔터프라이즈급 NLP 라이브러리로 Spark의 범용 인메모리 분산 데이터 처리 엔진을 활용합니다.  주석자는 규칙 기반 알고리즘, 머신 러닝, TensorFlow를 활용해 딥 러닝 구현을 지원합니다.  여기에는 토큰화, 레마토제닉, 어간 추출, 품사 태깅, 명명된 엔터티 인식, 철자 검사, 감정 분석 등을 포함하되 이에 국한되지 않는 일반적인 NLP 작업이 포함됩니다.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">BERT(Bidirectional Encoder Representations from Transformers)는 NLP를 위한 변환기 기반 머신 러닝 기술입니다.  이를 통해 사전 학습과 미세 조정이라는 개념이 대중화되었습니다.  BERT의 변환기 아키텍처는 기계 번역에서 유래되었는데, 기계 번역은 RNN(Recurrent Neural Network) 기반 언어 모델보다 장기 종속성을 더 잘 모델링합니다.  또한 모든 토큰 중 무작위로 15%를 마스크 처리하고 모델이 이를 예측하여 진정한 양방향성을 구현하는 MLM(Masked Language Modelling) 작업을 도입했습니다.</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">로이터 TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">금융 문구 은행</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">문서 DL 설명</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">금융 감정 분석은 해당 분야의 전문 용어와 라벨이 지정된 데이터의 부족으로 인해 어렵습니다.  사전 학습된 BERT를 기반으로 하는 언어 모델인 FinBERT는 도메인에 적응되었습니다.<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> , 금융 자산 및 레이블이 지정된 데이터로 미세 조정됨(<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ) 금융 감정 분류를 위해.  연구자들은 금융 용어가 포함된 뉴스 기사에서 4,500개의 문장을 추출했습니다.  그런 다음 금융 분야 경력이 있는 16명의 전문가와 석사과정 학생들이 문장을 긍정적, 중립적, 부정적으로 분류했습니다.  우리는 FinBERT와 두 개의 다른 사전 훈련된 파이프라인을 사용하여 2016년부터 2020년까지 상위 10개 NASDAQ 회사 수익 전화 회의록에 대한 감정을 분석하기 위한 종단 간 Spark 워크플로를 구축했습니다.<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ) Spark NLP에서.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Spark NLP의 기반이 되는 딥 러닝 엔진은 TensorFlow입니다. TensorFlow는 머신 러닝을 위한 종단 간 오픈 소스 플랫폼으로, 쉬운 모델 구축, 어디서나 강력한 ML 생산, 연구를 위한 강력한 실험을 가능하게 합니다.  따라서 Spark에서 파이프라인을 실행할 때<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block> 모드에서는 기본적으로 하나의 마스터 노드와 여러 개의 워커 노드, 그리고 클러스터에 마운트된 네트워크 연결 스토리지에서 데이터와 모델을 병렬화하여 분산형 TensorFlow를 실행했습니다.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod 분산 훈련</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">Hadoop을 위한 NetApp E-Series 솔루션</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">MapReduce 관련 성능에 대한 핵심 Hadoop 검증은 TeraGen, TeraSort, TeraValidate 및 DFSIO(읽기 및 쓰기)를 사용하여 수행됩니다.  TeraGen 및 TeraSort 검증 결과는 다음과 같습니다.<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block> AFF 의 "스토리지 계층화" 섹션에 있습니다.</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">스파크의 호보로드</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">고객 요청에 따라, 우리는 Spark를 활용한 분산 학습을 다양한 사용 사례 중 가장 중요한 것 중 하나로 생각합니다.  이 문서에서는 다음을 사용했습니다.<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> NetApp All Flash FAS (AFF) 스토리지 컨트롤러, Azure NetApp Files 및 StorageGRID 사용하여 NetApp 온프레미스, 클라우드 네이티브 및 하이브리드 클라우드 솔루션으로 Spark 성능을 검증합니다.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Spark 패키지의 Horovod는 Horovod를 둘러싼 편리한 래퍼를 제공하여 Spark 클러스터에서 분산형 학습 워크로드를 간편하게 실행하고, 데이터 처리, 모델 학습, 모델 평가가 모두 학습 및 추론 데이터가 있는 Spark에서 수행되는 긴밀한 모델 설계 루프를 구현합니다.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kaggle Rossmann 매장 판매</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Spark에서 Horovod를 실행하기 위한 두 가지 API가 있습니다. 상위 수준 Estimator API와 하위 수준 Run API입니다.  둘 다 Spark 실행자에서 Horovod를 실행하기 위해 동일한 기본 메커니즘을 사용하지만 Estimator API는 데이터 처리, 모델 학습 루프, 모델 검사점, 메트릭 수집 및 분산 학습을 추상화합니다.  우리는 종단 간 데이터 준비 및 분산 학습 워크플로를 위해 Horovod Spark Estimators, TensorFlow 및 Keras를 사용했습니다.<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> 경쟁.</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">대본<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> 섹션에서 찾을 수 있습니다<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block> 이 글은 세 부분으로 구성되어 있습니다.</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">첫 번째 부분에서는 Kaggle에서 제공하고 커뮤니티에서 수집한 초기 CSV 파일 세트에 대해 다양한 데이터 전처리 단계를 수행합니다.  입력 데이터는 다음과 같은 훈련 세트로 분리됩니다.<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block> 하위 집합과 테스트 데이터 세트.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">두 번째 부분에서는 로그 시그모이드 활성화 함수와 Adam 옵티마이저를 갖춘 Keras 딥 신경망(DNN) 모델을 정의하고, Spark에서 Horovod를 사용하여 모델의 분산 학습을 수행합니다.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">세 번째 부분에서는 검증 세트의 전체 평균 절대 오차를 최소화하는 최상의 모델을 사용하여 테스트 데이터 세트에 대한 예측을 수행합니다.  그런 다음 출력 CSV 파일을 생성합니다.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">머신 러닝</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">섹션을 참조하세요<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block> 다양한 런타임 비교 결과를 위해.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">CTR 예측을 위한 Keras를 사용한 멀티 워커 딥 러닝</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">최근 ML 플랫폼과 애플리케이션이 발전함에 따라 대규모 학습에 많은 관심이 쏠리고 있습니다.  클릭률(CTR)은 온라인 광고 노출 100회당 평균 클릭 수(백분율로 표시)로 정의됩니다.  이는 디지털 마케팅, 소매, 전자상거래, 서비스 제공업체를 포함한 다양한 산업 분야와 사용 사례에서 핵심 지표로 널리 채택되고 있습니다.  CTR 및 분산형 교육 성능 결과의 적용에 대한 자세한 내용은 다음을 참조하세요.<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block> 부분.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo 테라바이트 클릭 로그 데이터 세트</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">이 기술 보고서에서는 다음 변형을 사용했습니다.<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (TR-4904 참조) Keras를 사용하여 다중 작업자 분산 딥 러닝을 통해 딥 및 교차 네트워크(DCN) 모델을 포함하는 Spark 워크플로를 구축하고, 로그 손실 오차 함수 측면에서 기준 Spark ML 로지스틱 회귀 모델과 성능을 비교합니다.  DCN은 제한된 차수의 효과적인 기능 상호작용을 효율적으로 포착하고, 높은 비선형 상호작용을 학습하며, 수동 기능 엔지니어링이나 철저한 검색이 필요 없고, 계산 비용이 낮습니다.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">웹 규모 추천 시스템에 사용되는 데이터는 대부분 이산적이고 범주형이어서 기능 탐색이 어려운 크고 희소한 기능 공간이 발생합니다.  이로 인해 대부분의 대규모 시스템은 로지스틱 회귀와 같은 선형 모델로 제한되었습니다.  그러나 자주 예측 가능한 특징을 식별하고 동시에 보이지 않거나 드문 교차 특징을 탐색하는 것이 좋은 예측을 하는 데 중요합니다.  선형 모델은 간단하고, 해석 가능하며, 확장하기 쉽지만, 표현력이 제한적입니다.</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">반면, 교차 특징은 모델의 표현력을 향상시키는 데 중요한 것으로 나타났습니다.  안타깝게도 이러한 기능을 식별하려면 수동 기능 엔지니어링이나 철저한 검색이 필요한 경우가 많습니다.  보이지 않는 특징의 상호작용을 일반화하는 것은 종종 어렵습니다.  DCN과 같은 교차 신경망을 사용하면 자동으로 기능 교차를 명시적으로 적용하여 작업별 기능 엔지니어링을 피할 수 있습니다.  교차 네트워크는 여러 계층으로 구성되어 있으며, 가장 높은 수준의 상호작용은 계층 깊이에 의해 결정됩니다.  각 계층은 기존 계층의 상호작용을 기반으로 고차원 상호작용을 생성하고 이전 계층의 상호작용은 유지합니다.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">심층 신경망(DNN)은 여러 기능 간의 매우 복잡한 상호작용을 포착할 수 있는 잠재력을 가지고 있습니다.  그러나 DCN과 비교하면 거의 10배 더 많은 매개변수가 필요하고, 교차 특징을 명확하게 형성할 수 없으며, 일부 유형의 특징 상호 작용을 효율적으로 학습하지 못할 수 있습니다.  크로스 네트워크는 메모리 효율성이 높고 구현하기 쉽습니다.  교차 분석과 DNN 구성 요소를 함께 공동으로 훈련하면 예측 기능 상호작용을 효율적으로 포착하고 Criteo CTR 데이터 세트에서 최첨단 성능을 제공합니다.</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">딥CTR</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">DCN 모델은 임베딩 및 스태킹 계층으로 시작하여, 이어서 교차 네트워크와 딥 네트워크가 병렬로 이어집니다.  이어서 두 네트워크의 출력을 결합하는 최종 결합 계층이 이어집니다.  입력 데이터는 희소 특성과 밀집 특성을 모두 갖춘 벡터일 수 있습니다.  Spark에서는 라이브러리에 다음 유형이 포함되어 있습니다.<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> .  따라서 사용자는 두 가지를 구별하고 각각의 함수와 메서드를 호출할 때 주의하는 것이 중요합니다.  CTR 예측과 같은 웹 규모 추천 시스템에서 입력은 대부분 범주형 기능입니다.<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block> .  이러한 기능은 종종 원핫 벡터로 인코딩됩니다. 예를 들어,<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> .  One-hot-encoding(OHE)<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block> 끊임없이 변화하고 증가하는 어휘를 포함하는 실제 데이터 세트를 다룰 때 유용합니다.  우리는 예를 수정했습니다<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> 대규모 어휘를 처리하여 DCN의 임베딩 및 스태킹 계층에서 임베딩 벡터를 생성합니다.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo 디스플레이 광고 데이터 세트</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">그만큼<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> 광고 클릭률을 예측합니다.  13개의 정수 특성과 26개의 범주형 특성이 있으며, 각 범주는 높은 카디널리티를 갖습니다.  이 데이터 세트의 경우 입력 크기가 크기 때문에 logloss가 0.001 향상되는 것은 실질적으로 의미가 있습니다.  대규모 사용자 기반의 예측 정확도가 약간만 향상되어도 회사 수익이 크게 증가할 가능성이 있습니다.  이 데이터 세트에는 7일간의 사용자 로그 11GB가 포함되어 있으며, 이는 약 4,100만 개의 레코드에 해당합니다.  우리는 Spark를 사용했습니다<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block> 데이터를 무작위로 분할하여 학습(80%), 교차 검증(10%), 나머지 10%를 테스트에 사용합니다.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN은 Keras를 사용하여 TensorFlow에서 구현되었습니다.  DCN을 사용하여 모델 학습 프로세스를 구현하는 데는 4가지 주요 구성 요소가 있습니다.</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*데이터 처리 및 임베딩.*  실수 값의 특징은 로그 변환을 적용하여 정규화됩니다.  범주형 특성의 경우 차원 6×(범주 카디널리티)1/4의 밀집 벡터에 특성을 포함합니다.  모든 임베딩을 연결하면 차원이 1026인 벡터가 생성됩니다.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*최적화.*  우리는 Adam 최적화 도구를 사용하여 미니 배치 확률적 최적화를 적용했습니다.  배치 크기는 512로 설정되었습니다.  딥 네트워크에 배치 정규화를 적용하고 그래디언트 클립 노름을 100으로 설정했습니다.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*정규화.*  L2 정규화나 드롭아웃이 효과적이지 않은 것으로 나타났기 때문에 조기 중단을 사용했습니다.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*하이퍼매개변수*  우리는 숨겨진 계층의 수, 숨겨진 계층의 크기, 초기 학습률, 교차 계층의 수에 대한 그리드 검색을 기반으로 결과를 보고합니다.  숨겨진 레이어의 수는 2~5개이고, 숨겨진 레이어의 크기는 32~1024개입니다.  DCN의 경우 교차 레이어의 수는 1~6입니다.  초기 학습률은 0.0001에서 0.001까지 0.0001씩 증가하며 조정되었습니다.  모든 실험은 150,000번째 훈련 단계에서 조기에 중단되었으며, 그 단계를 넘어서면 과잉 맞춤이 발생하기 시작했습니다.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">딥FM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">자동 Int</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">DCN 외에도 CTR 예측을 위한 다른 인기 있는 딥러닝 모델도 테스트했습니다.<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block> ,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> , 그리고<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block> .</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">검증에 사용되는 아키텍처</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">이러한 검증을 위해 우리는 AFF-A800 HA 쌍을 갖춘 4개의 워커 노드와 1개의 마스터 노드를 사용했습니다.  모든 클러스터 구성원은 10GbE 네트워크 스위치를 통해 연결되었습니다.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">이 NetApp Spark 솔루션 검증을 위해 E5760, E5724, AFF-A800의 세 가지 스토리지 컨트롤러를 사용했습니다.  E-시리즈 스토리지 컨트롤러는 12Gbps SAS 연결을 통해 5개의 데이터 노드에 연결되었습니다.  AFF HA 쌍 스토리지 컨트롤러는 10GbE 연결을 통해 Hadoop 워커 노드에 내보낸 NFS 볼륨을 제공합니다.  Hadoop 클러스터 멤버는 E-Series, AFF 및 StorageGRID Hadoop 솔루션에서 10GbE 연결을 통해 연결되었습니다.</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">검증에 사용되는 아키텍처.</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">최신 기업 데이터 센터는 일관된 운영 모델을 갖춘 지속적인 데이터 관리 평면을 통해 여러 분산 인프라 환경을 온프레미스 및/또는 여러 퍼블릭 클라우드에 연결하는 하이브리드 클라우드입니다.  하이브리드 클라우드를 최대한 활용하려면 데이터 변환이나 애플리케이션 리팩토링이 필요 없이 온프레미스와 멀티클라우드 환경 간에 데이터를 원활하게 이동할 수 있어야 합니다.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">하이브리드 클라우드 솔루션</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">고객들은 데이터 보호와 같은 사용 사례를 위해 보조 스토리지를 클라우드로 옮기거나 애플리케이션 개발 및 DevOps와 같은 비즈니스에 덜 중요한 워크로드를 클라우드로 옮기는 것으로 하이브리드 클라우드 여정을 시작한다고 밝혔습니다.  그런 다음 더 중요한 작업으로 넘어갑니다.  웹 및 콘텐츠 호스팅, DevOps 및 애플리케이션 개발, 데이터베이스, 분석, 컨테이너화된 앱은 가장 인기 있는 하이브리드 클라우드 워크로드에 속합니다.  기업 AI 프로젝트의 복잡성, 비용, 위험은 역사적으로 실험 단계에서 생산 단계로 AI 도입을 방해해 왔습니다.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">NetApp 하이브리드 클라우드 솔루션을 통해 고객은 분산 환경 전반에서 데이터 및 워크플로 관리를 위한 단일 제어판을 통해 통합 보안, 데이터 거버넌스 및 규정 준수 도구의 이점을 누릴 수 있으며, 소비량에 따라 총 소유 비용을 최적화할 수 있습니다.  다음 그림은 고객의 빅데이터 분석 데이터에 대한 멀티클라우드 연결을 제공하는 업무를 맡은 클라우드 서비스 파트너의 솔루션 사례입니다.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">클라우드 서비스 파트너의 솔루션 예.</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">이 시나리오에서는 다양한 소스에서 AWS로 수신된 IoT 데이터가 NetApp Private Storage(NPS)의 중앙 위치에 저장됩니다.  NPS 스토리지는 AWS와 Azure에 있는 Spark 또는 Hadoop 클러스터에 연결되어 여러 클라우드에서 실행되는 빅데이터 분석 애플리케이션이 동일한 데이터에 액세스할 수 있도록 합니다.  이 사용 사례에 대한 주요 요구 사항과 과제는 다음과 같습니다.</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">데이터는 다양한 센서와 허브를 통해 온프레미스 및 클라우드 환경 등 다양한 소스에서 수신되어야 합니다.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">해결책은 효율적이고 비용 효율적이어야 합니다.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">가장 큰 과제는 온프레미스와 클라우드 환경 간에 하이브리드 분석 서비스를 제공하는 비용 효율적이고 효과적인 솔루션을 구축하는 것입니다.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">당사의 데이터 보호 및 멀티클라우드 연결 솔루션은 여러 하이퍼스케일러에 걸쳐 클라우드 분석 애플리케이션을 운영하는 데 따르는 문제점을 해결합니다.  위 그림에서 볼 수 있듯이, 센서의 데이터는 Kafka를 통해 AWS Spark 클러스터로 스트리밍되고 수집됩니다.  데이터는 클라우드 제공자 외부의 Equinix 데이터 센터 내에 있는 NPS에 있는 NFS 공유에 저장됩니다.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">NetApp NPS는 Direct Connect 및 Express Route 연결을 통해 각각 Amazon AWS 및 Microsoft Azure에 연결되어 있으므로 고객은 In-Place Analytics Module을 활용하여 Amazon 및 AWS 분석 클러스터의 데이터에 액세스할 수 있습니다.  따라서 온프레미스와 NPS 스토리지 모두 ONTAP 소프트웨어를 실행하기 때문에<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> NPS 데이터를 온프레미스 클러스터로 미러링하여 온프레미스와 여러 클라우드에서 하이브리드 클라우드 분석을 제공할 수 있습니다.</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">최상의 성능을 위해 NetApp 일반적으로 여러 네트워크 인터페이스와 직접 연결 또는 고속 경로를 사용하여 클라우드 인스턴스의 데이터에 액세스할 것을 권장합니다.  다음을 포함한 다른 데이터 이동 솔루션이 있습니다.<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> 그리고<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block> 고객이 애플리케이션 인식, 보안 및 비용 효율적인 하이브리드 클라우드 Spark 클러스터를 구축할 수 있도록 지원합니다.</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">다음 세 가지 Python 스크립트는 테스트된 세 가지 주요 사용 사례에 해당합니다.  첫 번째는<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block> .</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">두 번째 스크립트는<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> .</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">세 번째 스크립트는<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block> .</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp 에는 FAS/ AFF, E-Series, Cloud Volumes ONTAP 세 가지 스토리지 포트폴리오가 있습니다.  우리는 Apache Spark를 기반으로 Hadoop 솔루션을 위한 ONTAP 스토리지 시스템을 갖춘 AFF 와 E-시리즈를 검증했습니다.  NetApp 이 지원하는 데이터 패브릭은 데이터 액세스, 제어, 보호 및 보안을 위한 데이터 관리 서비스와 애플리케이션(빌딩 블록)을 통합합니다.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Spark 솔루션 개요</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp FAS/ AFF, E-Series, Cloud Volumes ONTAP 세 가지 스토리지 포트폴리오가 있습니다.  우리는 Apache Spark를 기반으로 Hadoop 솔루션을 위한 ONTAP 스토리지 시스템을 갖춘 AFF 와 E-시리즈를 검증했습니다.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">데이터 패브릭은 데이터 관리 서비스와 애플리케이션을 제공합니다.</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS 직접 액세스.*  추가 소프트웨어나 드라이버가 필요하지 않고 최신 Hadoop 및 Spark 클러스터에서 NetApp NFS 볼륨에 직접 액세스할 수 있습니다.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirror 기술.*  온프레미스와 ONTAP Cloud 또는 NPS 인스턴스 간의 데이터 보호 기능을 제공합니다.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">다음 그림은 NetApp 스토리지를 사용한 Spark 솔루션을 보여줍니다.</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">NetApp 스토리지를 갖춘 Spark 솔루션.</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">ONTAP Spark 솔루션은 기존 프로덕션 데이터에 대한 액세스를 활용하여 현장 분석 및 AI, ML, DL 워크플로를 위한 NetApp NFS 직접 액세스 프로토콜을 사용합니다.  Hadoop 노드에서 사용할 수 있는 프로덕션 데이터는 현장 분석 및 AI, ML, DL 작업을 수행하는 데 내보내집니다.  NetApp NFS 직접 액세스를 사용하거나 사용하지 않고도 Hadoop 노드에서 처리할 데이터에 액세스할 수 있습니다.  Spark에서 독립형 또는<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> 클러스터 관리자를 사용하여 NFS 볼륨을 구성할 수 있습니다.<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block> .  우리는 서로 다른 데이터 세트를 사용하여 세 가지 사용 사례를 검증했습니다.  이러한 검증에 대한 세부 사항은 "테스트 결과" 섹션에 나와 있습니다.  (xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">다음 그림은 NetApp Apache Spark/Hadoop 스토리지 포지셔닝을 보여줍니다.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark/Hadoop 스토리지 포지셔닝.</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">우리는 E-Series Spark 솔루션, AFF/ FAS ONTAP Spark 솔루션, StorageGRID Spark 솔루션의 고유한 기능을 파악하고 자세한 검증 및 테스트를 수행했습니다.  당사의 관찰에 따르면 NetApp 그린필드 설치 및 새로운 확장형 배포의 경우 E-Series 솔루션을, 기존 NFS 데이터를 사용하는 현장 분석, AI, ML, DL 워크로드의 경우 AFF/ FAS 솔루션을, 객체 스토리지가 필요한 경우 AI, ML, DL 및 최신 데이터 분석의 경우 StorageGRID 권장합니다.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Spark에 권장되는 NetApp 솔루션입니다.</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">데이터 레이크는 분석, AI, ML, DL 작업에 사용할 수 있는 기본 형태의 대규모 데이터 세트를 저장하는 저장소입니다.  우리는 E-Series, AFF/ FAS, StorageGRID SG6060 Spark 솔루션을 위한 데이터 레이크 저장소를 구축했습니다.  E-시리즈 시스템은 Hadoop Spark 클러스터에 HDFS 액세스를 제공하는 반면, 기존 프로덕션 데이터는 Hadoop 클러스터에 대한 NFS 직접 액세스 프로토콜을 통해 액세스됩니다.  개체 스토리지에 있는 데이터 세트의 경우 NetApp StorageGRID S3 및 S3a 보안 액세스를 제공합니다.</block>
  <block id="881214767967db331c99550277ceb793" category="summary">이 페이지에서는 Splunk 아키텍처에 대해 설명합니다. 여기에는 주요 정의, Splunk 분산 배포, Splunk SmartStore, 데이터 흐름, 하드웨어 및 소프트웨어 요구 사항, 단일 및 다중 사이트 요구 사항 등이 포함됩니다.</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunk 아키텍처</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">이 섹션에서는 Splunk 아키텍처에 대해 설명합니다. 여기에는 주요 정의, Splunk 분산 배포, Splunk SmartStore, 데이터 흐름, 하드웨어 및 소프트웨어 요구 사항, 단일 및 다중 사이트 요구 사항 등이 포함됩니다.</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">주요 정의</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">다음 두 표에는 분산형 Splunk 배포에 사용되는 Splunk 및 NetApp 구성 요소가 나열되어 있습니다.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">이 표에는 분산형 Splunk Enterprise 구성을 위한 Splunk 하드웨어 구성 요소가 나열되어 있습니다.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunk 구성 요소</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">일</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">인덱서</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Splunk Enterprise 데이터 저장소</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">유니버설 포워더</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">데이터 수집 및 인덱서에 데이터 전달을 담당합니다.</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">검색 헤드</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">인덱서에서 데이터를 검색하는 데 사용되는 사용자 프런트 엔드</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">클러스터 마스터</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">인덱서 및 검색 헤드의 Splunk 설치를 관리합니다.</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">모니터링 콘솔</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">전체 배포에 사용되는 중앙 모니터링 도구</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">라이센스 마스터</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">라이선스 마스터는 Splunk Enterprise 라이선스를 처리합니다.</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">배포 서버</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">구성을 업데이트하고 앱을 처리 구성 요소에 배포합니다.</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">저장 구성요소</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">핫 티어 데이터를 관리하는 데 사용되는 올플래시 스토리지입니다.  로컬 스토리지라고도 함.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">웜 티어 데이터를 관리하는 데 사용되는 S3 개체 스토리지입니다.  SmartStore에서 핫 티어와 웜 티어 간에 데이터를 이동하는 데 사용됩니다.  원격 저장소라고도 함.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">이 표는 Splunk 스토리지 아키텍처의 구성 요소를 나열합니다.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">책임 구성 요소</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">스마트스토어</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">인덱서에게 로컬 스토리지에서 개체 스토리지로 데이터를 계층화하는 기능을 제공합니다.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">스플렁크</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">더운</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">유니버설 포워더가 새로 작성된 데이터를 저장하는 도착 지점입니다.  저장소는 쓰기가 가능하며, 데이터는 검색이 가능합니다.  이 데이터 계층은 일반적으로 SSD나 빠른 HDD로 구성됩니다.</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">캐시 관리자</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">인덱싱된 데이터의 로컬 캐시를 관리하고, 검색이 발생하면 원격 저장소에서 웜 데이터를 가져오고, 가장 덜 자주 사용되는 데이터를 캐시에서 제거합니다.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">따뜻한</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">데이터는 논리적으로 버킷에 롤링되고, 먼저 핫 티어에서 웜 티어로 이름이 변경됩니다.  이 계층의 데이터는 보호되며, 핫 계층과 마찬가지로 더 큰 용량의 SSD나 HDD로 구성될 수 있습니다.  일반적인 데이터 보호 솔루션을 사용하여 증분 백업과 전체 백업이 모두 지원됩니다.</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Splunk 분산 배포</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">많은 컴퓨터에서 데이터가 생성되는 대규모 환경을 지원하려면 대량의 데이터를 처리해야 합니다.  많은 사용자가 데이터를 검색해야 하는 경우 Splunk Enterprise 인스턴스를 여러 컴퓨터에 분산하여 배포를 확장할 수 있습니다.  이를 분산 배포라고 합니다.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">일반적인 분산 배포에서 각 Splunk Enterprise 인스턴스는 특수화된 작업을 수행하며 주요 처리 기능에 해당하는 3개의 처리 계층 중 하나에 상주합니다.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">다음 표에는 Splunk Enterprise 처리 계층이 나열되어 있습니다.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">층</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">요소</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">설명</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">데이터 입력</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">포워더</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">포워더는 데이터를 사용한 후 해당 데이터를 인덱서 그룹에 전달합니다.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">인덱싱</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">인덱서는 일반적으로 여러 포워더로부터 수신하는 수신 데이터를 인덱싱합니다.  인덱서는 데이터를 이벤트로 변환하고 이벤트를 인덱스에 저장합니다.  인덱서는 검색 헤드의 검색 요청에 응답하여 인덱싱된 데이터를 검색합니다.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">검색 관리</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">검색 헤드는 검색을 위한 중앙 리소스 역할을 합니다.  클러스터의 검색 헤드는 상호 교환이 가능하며 검색 헤드 클러스터의 모든 멤버에서 동일한 검색, 대시보드, 지식 개체 등에 액세스할 수 있습니다.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">다음 표는 분산형 Splunk Enterprise 환경에서 사용되는 중요한 구성 요소를 나열합니다.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">책임</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">인덱스 클러스터 마스터</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">인덱서 클러스터의 활동 및 업데이트를 조정합니다.</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">인덱스 관리</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">인덱스 클러스터</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">서로 데이터를 복제하도록 구성된 Splunk Enterprise 인덱서 그룹</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">검색 헤드 배포자</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">클러스터 마스터에 대한 배포 및 업데이트를 처리합니다.</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">검색 헤드 관리</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">검색 헤드 클러스터</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">검색을 위한 중앙 리소스 역할을 하는 검색 헤드 그룹</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">로드 밸런서</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">클러스터된 구성 요소에서 검색 헤드, 인덱서 및 S3 대상의 증가하는 수요를 처리하여 클러스터된 구성 요소 전반에 걸쳐 부하를 분산하는 데 사용됩니다.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">클러스터된 구성 요소에 대한 로드 관리</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Splunk Enterprise 분산 배포의 이점은 다음과 같습니다.</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">다양하거나 분산된 데이터 소스에 접근</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">모든 규모와 복잡성을 갖춘 기업의 데이터 요구 사항을 처리할 수 있는 기능을 제공합니다.</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">데이터 복제 및 다중 사이트 배포를 통해 고가용성을 달성하고 재해 복구를 보장합니다.</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">스플렁크 스마트스토어</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore는 Amazon S3와 같은 원격 객체 저장소가 인덱싱된 데이터를 저장할 수 있도록 하는 인덱서 기능입니다.  배포의 데이터 볼륨이 증가함에 따라 일반적으로 스토리지에 대한 수요가 컴퓨팅 리소스에 대한 수요를 앞지릅니다.  SmartStore를 사용하면 리소스를 별도로 확장하여 인덱서 스토리지와 컴퓨팅 리소스를 비용 효율적으로 관리할 수 있습니다.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore는 원격 스토리지 계층과 캐시 관리자를 소개합니다.  이러한 기능을 사용하면 데이터를 인덱서의 로컬 저장소나 원격 저장소 계층에 저장할 수 있습니다.  캐시 관리자는 인덱서와 인덱서에 구성된 원격 스토리지 계층 간의 데이터 이동을 관리합니다.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">SmartStore를 사용하면 인덱서 저장소 공간을 최소한으로 줄이고 I/O 최적화된 컴퓨팅 리소스를 선택할 수 있습니다.  대부분의 데이터는 원격 저장소에 저장됩니다.  인덱서는 최소한의 데이터(핫 버킷, 활성 또는 최근 검색에 참여하는 웜 버킷의 복사본, 버킷 메타데이터)가 포함된 로컬 캐시를 유지 관리합니다.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStore 데이터 흐름</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">다양한 소스에서 들어오는 데이터가 인덱서에 도달하면 데이터는 인덱싱되어 핫 버킷에 로컬로 저장됩니다.  인덱서는 핫 버킷 데이터를 대상 인덱서에 복제하기도 합니다.  지금까지 데이터 흐름은 SmartStore가 아닌 인덱스의 데이터 흐름과 동일합니다.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">뜨거운 양동이가 따뜻해지는 경우, 데이터 흐름이 갈라집니다.  소스 인덱서는 기존 복사본을 캐시에 남겨두고 따뜻한 버킷을 원격 개체 저장소(원격 스토리지 계층)에 복사합니다. 이는 검색이 최근에 인덱싱된 데이터를 대상으로 실행되는 경향이 있기 때문입니다.  그러나 원격 저장소는 여러 개의 로컬 복사본을 유지하지 않고도 높은 가용성을 제공하므로 대상 인덱서는 자신의 복사본을 삭제합니다.  버킷의 마스터 사본은 이제 원격 저장소에 있습니다.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">다음 이미지는 Splunk SmartStore 데이터 흐름을 보여줍니다.</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">인덱서의 캐시 관리자는 SmartStore 데이터 흐름의 핵심입니다.  검색 요청을 처리하기 위해 필요에 따라 원격 저장소에서 버킷 사본을 가져옵니다.  또한, 검색에 참여할 가능성이 시간이 지남에 따라 감소하기 때문에 오래되었거나 검색 빈도가 낮은 버킷 사본을 캐시에서 제거합니다.</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">캐시 관리자의 역할은 사용 가능한 캐시의 사용을 최적화하는 동시에 검색에서 필요한 버킷에 즉시 액세스할 수 있도록 하는 것입니다.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">아래 표에는 솔루션을 구현하는 데 필요한 소프트웨어 구성 요소가 나열되어 있습니다.  솔루션 구현에 사용되는 소프트웨어 구성 요소는 고객 요구 사항에 따라 달라질 수 있습니다.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">제품군</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">제품명</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">제품 버전</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">운영 체제</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID 객체 스토리지</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">해당 없음</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">센트OS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">센트OS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">스플렁크 엔터프라이즈</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">SmartStore가 포함된 Splunk Enterprise</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">단일 및 다중 사이트 요구 사항</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">데이터가 여러 컴퓨터에서 생성되고 많은 사용자가 데이터를 검색해야 하는 Enterprise Splunk 환경(중간 및 대규모 배포)에서는 Splunk Enterprise 인스턴스를 단일 및 여러 사이트에 분산하여 배포를 확장할 수 있습니다.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">다음 표는 분산형 Splunk Enterprise 환경에서 사용되는 구성 요소를 나열합니다.</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">서로의 데이터를 복제하도록 구성된 Splunk Enterprise 인덱서 그룹</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">로드 밸런서</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">클러스터된 구성 요소에 대한 로드 관리</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">이 그림은 단일 사이트 분산 배포의 예를 보여줍니다.</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">이 그림은 다중 사이트 분산 배포의 예를 보여줍니다.</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 최소 하드웨어 구성 요소 수가 나열되어 있습니다.  솔루션의 특정 구현에 사용되는 하드웨어 구성 요소는 고객 요구 사항에 따라 달라질 수 있습니다.</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">Splunk SmartStore와 StorageGRID 단일 사이트에 배포했든 여러 사이트에 배포했든 모든 시스템은 단일 창에서 StorageGRID GRID Manager를 통해 관리됩니다.  자세한 내용은 "Grid Manager를 사용한 간편한 관리" 섹션을 참조하세요.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">이 표는 단일 사이트에 사용된 하드웨어를 나열합니다.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">디스크</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">사용 가능 용량</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">참고</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">관리 노드 및 로드 밸런서</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48, 8TB(NL-SAS HDD)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">원격 저장소</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">이 표는 다중 사이트 구성에 사용되는 하드웨어를 나열합니다(사이트별).</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">관리 노드 및 로드 밸런서</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID 로드 밸런서: SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">개체 스토리지에는 클라우드 스토리지 네임스페이스를 제공하기 위해 로드 밸런서를 사용해야 합니다.  StorageGRID F5 및 Citrix와 같은 주요 공급업체의 타사 로드 밸런서를 지원하지만 많은 고객은 단순성, 복원력 및 고성능을 위해 엔터프라이즈급 StorageGRID 밸런서를 선택합니다.  StorageGRID 로드 밸런서는 VM, 컨테이너 또는 특수 목적 어플라이언스로 사용할 수 있습니다.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000은 S3 데이터 경로 연결을 위한 고가용성(HA) 그룹과 지능형 부하 분산을 쉽게 사용할 수 있도록 해줍니다.  다른 온프레미스 개체 스토리지 시스템은 사용자 정의형 로드 밸런서를 제공하지 않습니다.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">SG1000 어플라이언스는 다음과 같은 기능을 제공합니다.</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">StorageGRID 시스템을 위한 로드 밸런서 및 선택적으로 관리 노드 기능</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">노드 배포 및 구성을 단순화하는 StorageGRID Appliance 설치 프로그램</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">S3 엔드포인트 및 SSL의 간소화된 구성</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">전용 대역폭(다른 애플리케이션과 타사 로드 밸런서를 공유하는 것과 대비)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">최대 4 x 100Gbps의 총 이더넷 대역폭</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">다음 이미지는 SG1000 Gateway Services 어플라이언스를 보여줍니다.</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">StorageGRID SG6060 어플라이언스에는 컴퓨팅 컨트롤러(SG6060)와 스토리지 컨트롤러 셸프(E-Series E2860)가 포함되어 있으며, 스토리지 컨트롤러 셸프에는 스토리지 컨트롤러 2개와 드라이브 60개가 들어 있습니다.  이 기기는 다음과 같은 기능을 제공합니다.</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">단일 네임스페이스에서 최대 400PB까지 확장 가능합니다.</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">최대 4x 25Gbps의 총 이더넷 대역폭.</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">노드 배포 및 구성을 단순화하기 위해 StorageGRID Appliance Installer가 포함되어 있습니다.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">각 SG6060 어플라이언스는 1~2개의 추가 확장 선반을 장착하여 총 180개의 드라이브를 장착할 수 있습니다.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">스토리지 컨트롤러 장애 조치 지원을 제공하기 위한 2개의 E-시리즈 E2800 컨트롤러(듀플렉스 구성)</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">60개의 3.5인치 드라이브(2개의 솔리드 스테이트 드라이브와 58개의 NL-SAS 드라이브)를 보관할 수 있는 5개 서랍 드라이브 선반입니다.</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">다음 이미지는 SG6060 기기를 보여줍니다.</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">스플렁크 디자인</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">다음 표에는 단일 사이트에 대한 Splunk 구성이 나열되어 있습니다.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">코어</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">운영 체제</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16개의 코어</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32GB 램</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">센트OS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">사용자 데이터를 관리합니다</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">사용자 프런트 엔드는 인덱서에서 데이터를 검색합니다.</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">검색 헤드 클러스터에 대한 업데이트를 처리합니다.</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Splunk 설치 및 인덱서를 관리합니다.</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">모니터링 콘솔 및 라이센스 마스터</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Splunk 배포 전체에 대한 중앙 모니터링을 수행하고 Splunk 라이선스를 관리합니다.</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">다음 표에서는 다중 사이트 구성을 위한 Splunk 구성을 설명합니다.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">이 표는 다중 사이트 구성(사이트 A)에 대한 Splunk 구성을 나열합니다.</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">데이터를 수집하고 인덱서에게 데이터를 전달하는 역할을 담당합니다.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Splunk 배포 전체에 대한 중앙 모니터링을 수행하고 Splunk 라이선스를 관리합니다.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">이 표는 다중 사이트 구성(사이트 B)에 대한 Splunk 구성을 나열합니다.</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise는 보안, IT, DevOps 팀 전반에 걸쳐 성과를 이끌어내는 시장 선도적인 SIEM 솔루션입니다.</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise는 보안, IT, DevOps 팀 전반에 걸쳐 성과를 이끌어내는 시장 선도적인 SIEM 솔루션입니다.  우리 고객의 조직 전반에서 Splunk 사용이 상당히 증가했습니다.  따라서 더 많은 데이터 소스를 추가하는 동시에 더 오랜 기간 동안 데이터를 보관해야 하며, 이로 인해 Splunk 인프라에 부담이 가해집니다.</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Splunk SmartStore와 NetApp StorageGRID 의 조합은 조직이 SmartStore와 StorageGRID 개체 스토리지를 통해 수집 성능을 개선하고 여러 지리적 지역에 걸쳐 Splunk 환경에 대한 확장성을 높일 수 있는 확장 가능한 아키텍처를 제공하도록 설계되었습니다.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">NetApp StorageGRID 문서 리소스</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Splunk Enterprise 문서</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise SmartStore 정보</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Splunk Enterprise 분산 배포 매뉴얼</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise 인덱서 및 인덱서 클러스터 관리</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">이 기술 보고서는 NetApp 이 Splunk SmartStore 솔루션에 제공하는 이점을 간략하게 설명하고 사용자 환경에서 Splunk SmartStore를 설계하고 크기를 조정하기 위한 프레임워크를 보여줍니다.  그 결과, 매력적인 TCO를 제공하는 간단하고 확장 가능하며 탄력적인 솔루션이 탄생했습니다.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: Splunk SmartStore를 탑재한 NetApp StorageGRID</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise는 보안, IT, DevOps 팀 전반에서 성과를 이끌어내는 시장 선도적인 보안 정보 및 이벤트 관리(SIEM) 솔루션입니다.</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">개요</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">데이터 양은 기하급수적으로 증가하고 있으며, 이 방대한 리소스를 활용할 수 있는 기업에게는 엄청난 기회가 창출되고 있습니다.  Splunk Enterprise는 더욱 다양한 사용 사례에서 채택이 확대되고 있습니다.  사용 사례가 증가함에 따라 Splunk Enterprise가 수집하고 처리하는 데이터 양도 늘어납니다.  Splunk Enterprise의 기존 아키텍처는 뛰어난 데이터 접근성과 가용성을 제공하는 분산형 확장형 디자인입니다.  그러나 이러한 아키텍처를 사용하는 기업은 급증하는 데이터 양을 수용하기 위해 확장하는 데 드는 비용 증가에 직면하게 됩니다.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">NetApp StorageGRID 탑재된 Splunk SmartStore는 컴퓨팅과 스토리지를 분리하는 새로운 배포 모델을 제공하여 이러한 과제를 해결합니다.  이 솔루션은 고객이 단일 및 여러 사이트에 걸쳐 확장할 수 있도록 하여 Splunk Enterprise 환경에 대한 탁월한 확장성과 탄력성을 제공하는 동시에 컴퓨팅과 스토리지를 독립적으로 확장하고 비용 효율적인 클라우드 기반 S3 개체 스토리지에 지능형 계층화를 추가하여 비용을 절감합니다.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">이 솔루션은 검색 성능을 유지하는 동시에 로컬 스토리지의 데이터 양을 최적화하여 컴퓨팅과 스토리지를 수요에 따라 확장할 수 있도록 합니다.  SmartStore는 데이터 액세스 패턴을 자동으로 평가하여 실시간 분석을 위해 어떤 데이터에 액세스해야 하는지, 어떤 데이터를 비용이 덜 드는 S3 개체 스토리지에 저장해야 하는지 판별합니다.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">이 기술 보고서는 NetApp 이 Splunk SmartStore 솔루션에 제공하는 이점을 간략하게 설명하고 사용자 환경에서 Splunk SmartStore를 설계하고 크기를 조정하기 위한 프레임워크를 보여줍니다.  그 결과, 매력적인 TCO를 제공하는 간단하고 확장 가능하며 탄력적인 솔루션이 탄생했습니다.  StorageGRID 확장 가능하고 비용 효율적인 S3 프로토콜/API 기반 개체 스토리지(원격 스토리지라고도 함)를 제공하여 조직이 복원력을 높이는 동시에 더 낮은 비용으로 Splunk 솔루션을 확장할 수 있도록 합니다.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore는 개체 스토리지를 원격 저장소 또는 원격 스토리지 계층이라고 합니다.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">NetApp StorageGRID 정보</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID 대규모 아카이브, 미디어 저장소, 웹 데이터 저장소를 위한 소프트웨어 정의 객체 스토리지 솔루션입니다.  NetApp StorageGRID 통해 업계를 선도하는 혁신과 데이터 관리 솔루션을 제공하는 데 있어 20년의 경험을 활용하고 있으며, 조직이 온프레미스와 퍼블릭, 프라이빗 또는 하이브리드 클라우드 배포에서 정보의 가치를 관리하고 극대화할 수 있도록 지원합니다.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID 대규모 비정형 데이터를 위한 안전하고 내구성 있는 스토리지를 제공합니다.  통합된 메타데이터 기반 수명 주기 관리 정책은 데이터 수명 전반에 걸쳐 데이터가 저장되는 위치를 최적화합니다.  비용을 줄이기 위해 콘텐츠를 적절한 위치, 적절한 시간, 적절한 저장 계층에 배치합니다.  단일 네임스페이스를 사용하면 StorageGRID 스토리지의 지리적 위치에 관계없이 단일 호출을 통해 데이터에 액세스할 수 있습니다.  고객은 데이터 센터와 클라우드 인프라 간에 여러 StorageGRID 인스턴스를 배포하고 관리할 수 있습니다.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">StorageGRID 시스템은 기존 및 차세대 클라이언트 애플리케이션과 통합 가능한 글로벌 분산형, 중복성, 이기종 노드로 구성됩니다.</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape는 최근 최신 보고서인 IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment에서 NetApp 리더로 선정했습니다.  가장 까다로운 산업 분야에서 20년 가까이 생산 배포 경험을 바탕으로 StorageGRID 비정형 데이터 분야에서 인정받는 선두주자로 자리매김했습니다.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">StorageGRID 사용하면 다음과 같은 이점을 얻을 수 있습니다.</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">단일 네임스페이스를 통해 데이터 센터와 클라우드 사이의 모든 위치에서 데이터에 액세스하기 위해 여러 StorageGRID 인스턴스를 배포하면 수백 페타바이트까지 쉽게 확장할 수 있습니다.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">인프라 전반에 걸쳐 배포하고 중앙에서 관리할 수 있는 유연성을 제공합니다.</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">계층화된 Erasure Coding(EC)을 활용하여 15나인 내구성으로 탁월한 내구성을 제공합니다.</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Amazon S3 Glacier 및 Azure Blob과의 검증된 통합을 통해 더욱 다양한 하이브리드 멀티클라우드 기능을 구현하세요.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">독점 API나 공급업체 종속 없이 변조 방지 데이터 보존을 통해 규제 의무를 충족하고 규정 준수를 용이하게 합니다.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID 홈페이지</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">StorageGRID 가장 복잡한 비정형 데이터 관리 문제를 해결하는 데 어떻게 도움이 될 수 있는지에 대한 자세한 내용은 다음을 참조하세요.<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block> .</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Splunk Enterprise 소개</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise는 데이터를 실제 업무로 전환하는 플랫폼입니다.  로그 파일, 웹사이트, 장치, 센서, 애플리케이션 등 다양한 소스에서 생성된 데이터는 Splunk 인덱서로 전송되어 구문 분석되므로 데이터에서 풍부한 통찰력을 얻을 수 있습니다.  이를 통해 데이터 침해를 식별하고, 고객 및 제품 동향을 파악하고, 인프라를 최적화할 수 있는 기회를 찾거나 다양한 사용 사례에 걸쳐 실행 가능한 통찰력을 창출할 수 있습니다.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Splunk SmartStore 소개</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore는 Splunk 아키텍처의 이점을 확장하는 동시에 비용 효율적인 확장 기능을 단순화합니다.  컴퓨팅 및 스토리지 리소스를 분리하면 I/O에 최적화된 인덱서 노드가 생성되고, 캐시로 데이터의 하위 집합만 저장하므로 스토리지 요구 사항이 크게 줄어듭니다.  해당 리소스 중 하나만 필요한 경우 별도의 컴퓨팅이나 스토리지를 추가할 필요가 없으므로 상당한 비용 절감 효과를 얻을 수 있습니다.  비용 효율적이고 쉽게 확장 가능한 S3 기반 객체 스토리지를 사용하면 환경이 더욱 간소화되고 비용이 절감되며 더 방대한 데이터 세트를 유지 관리할 수 있습니다.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore는 다음을 포함한 조직에 상당한 가치를 제공합니다.</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">따뜻한 데이터를 비용 최적화된 S3 개체 스토리지로 이동하여 스토리지 비용 절감</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">스토리지와 컴퓨팅을 분리하여 원활하게 확장</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">탄력적인 클라우드 기반 스토리지를 활용하여 비즈니스 연속성을 간소화합니다.</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">이 페이지에서는 NetApp StorageGRID 컨트롤러에서의 Splunk SmartStore 성능을 설명합니다.</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">단일 사이트 SmartStore 성능</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">이 섹션에서는 NetApp StorageGRID 컨트롤러에서의 Splunk SmartStore 성능에 대해 설명합니다.  Splunk SmartStore는 따뜻한 데이터를 원격 스토리지로 이동합니다. 이 경우 성능 검증에서 이는 StorageGRID 개체 스토리지입니다.</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">핫/캐시 스토리지에는 EF600을, 원격 스토리지에는 StorageGRID 6060을 사용했습니다.  성능 검증을 위해 다음과 같은 아키텍처를 사용했습니다.  우리는 2개의 검색 헤드와 4개의 대형 포워더를 사용하여 데이터를 인덱서로 전달하고, 7개의 Splunk 이벤트 생성기(Eventgens)를 사용하여 실시간 데이터를 생성하고, 18개의 인덱서를 사용하여 데이터를 저장했습니다.</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">구성</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">이 표는 SmartStorage 성능 검증에 사용된 하드웨어를 나열합니다.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">헤비 포워더</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16개의 코어</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">슬레드 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">사용자 프런트엔드는 인덱서에서 데이터를 검색합니다.</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStore 원격 매장 성능 검증</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">이 성능 검증에서는 모든 인덱서의 로컬 스토리지에 10일 분의 데이터를 저장하는 SmartStore 캐시를 구성했습니다.  우리는 가능하게 했습니다<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (버킷 크기 750MB) Splunk 클러스터 관리자에서 모든 인덱서에 변경 사항을 푸시했습니다.  업로드 성능을 측정하기 위해 10일 동안 매일 10TB를 수집하고 모든 핫 버킷을 동시에 워밍업 버킷으로 전환한 다음 SmartStore 모니터링 콘솔 대시보드에서 인스턴스별 및 배포 전반의 최대 및 평균 처리량을 파악했습니다.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">이 이미지는 하루에 수집된 데이터를 보여줍니다.</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">클러스터 마스터에서 다음 명령을 실행했습니다(인덱스 이름은 다음과 같습니다.<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block> ).  그런 다음 SmartStore 모니터링 콘솔 대시보드를 통해 인스턴스별 및 배포 전반의 최대 및 평균 업로드 처리량을 파악했습니다.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">클러스터 마스터는 모든 인덱서(rtp-idx0001…rtp-idx0018)에 대해 암호 없는 인증을 갖습니다.</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">다운로드 성능을 측정하기 위해 다음 명령을 사용하여 evict CLI를 두 번 실행하여 캐시에서 모든 데이터를 제거했습니다.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">클러스터 마스터에서 다음 명령을 실행하고 StorageGRID 의 원격 저장소에 있는 10일 분의 데이터를 기반으로 검색 헤드에서 검색을 실행했습니다.  그런 다음 SmartStore 모니터링 콘솔 대시보드를 통해 인스턴스별 및 배포 전반의 최대 및 평균 업로드 처리량을 파악했습니다.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">인덱서 구성은 SmartStore 클러스터 마스터에서 푸시되었습니다.  클러스터 마스터는 인덱서에 대해 다음과 같은 구성을 가졌습니다.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">성과 매트릭스를 수집하기 위해 검색 헤드에서 다음 검색 쿼리를 실행했습니다.</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">우리는 클러스터 마스터로부터 성능 정보를 수집했습니다.  최대 성능은 61.34GBps였습니다.</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">평균 성능은 약 29GBps였습니다.</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRID 성능</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">이벤트젠</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">SmartStore의 성능은 대량의 데이터에서 특정 패턴과 문자열을 검색하는 데 기반합니다.  이 검증에서는 이벤트가 다음을 사용하여 생성됩니다.<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> 검색 헤드를 통해 특정 Splunk 인덱스(eventgen-test)에 대한 검색이 수행되고, 대부분의 쿼리에 대한 요청은 StorageGRID 로 이동합니다.  다음 이미지는 쿼리 데이터의 적중과 미적중을 보여줍니다.  히트 데이터는 로컬 디스크에서 가져오고, 미스 데이터는 StorageGRID 컨트롤러에서 가져옵니다.</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">녹색은 적중 데이터를 보여주고, 주황색은 미스 데이터를 보여줍니다.</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">StorageGRID 에서 검색을 위해 쿼리를 실행하면 StorageGRID 에서 S3를 검색하는 속도가 다음 이미지에 표시됩니다.</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRID 하드웨어 사용</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">StorageGRID 인스턴스에는 로드 밸런서 1개와 StorageGRID 컨트롤러 3개가 있습니다.  세 개의 컨트롤러 모두의 CPU 사용률은 75%에서 100%입니다.</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">NetApp 스토리지 컨트롤러를 탑재한 SmartStore - 고객 혜택</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*컴퓨팅과 스토리지 분리.*  Splunk SmartStore는 컴퓨팅과 스토리지를 분리하여 독립적으로 확장할 수 있도록 도와줍니다.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*주문형 데이터.*  SmartStore는 필요에 따라 데이터를 컴퓨팅에 가깝게 가져오고 컴퓨팅 및 스토리지 탄력성과 비용 효율성을 제공하여 대규모로 더 오랫동안 데이터를 보존할 수 있도록 해줍니다.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*AWS S3 API 호환.*  SmartStore는 AWS S3 API를 사용하여 AWS S3 및 S3 API 호환 객체 저장소(예: StorageGRID) 인 복원 스토리지와 통신합니다.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*보관 요구 사항과 비용이 줄어듭니다.*  SmartStore는 오래된 데이터(웜/콜드)에 대한 저장 요구 사항을 줄여줍니다.  NetApp 스토리지는 데이터 보호, 장애 처리 및 고가용성 처리를 제공하므로 데이터의 단일 사본만 필요합니다.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*하드웨어 오류.*  SmartStore 배포에서 노드 장애가 발생해도 데이터에 액세스할 수 없는 것은 아니며 하드웨어 장애나 데이터 불균형으로 인해 인덱서가 훨씬 빠르게 복구됩니다.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">애플리케이션 및 데이터 인식 캐시.</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">필요에 따라 인덱서를 추가-제거하고 클러스터를 설정-해제합니다.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">스토리지 계층은 더 이상 하드웨어에 구속되지 않습니다.</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">이 솔루션을 사용하면 단일 및 다중 사이트 배포에서 사용자 수나 수집 속도 측면에서 증가하는 수요를 충족하기 위해 컴퓨팅, 핫 스토리지 또는 S3 리소스를 추가할 수 있습니다.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">이 솔루션의 이점</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*성능.*  Splunk SmartStore와 NetApp StorageGRID 결합하면 객체 스토리지를 사용하여 핫 버킷과 웜 버킷 간에 데이터를 빠르게 마이그레이션할 수 있습니다.  StorageGRID 대규모 객체 작업 부하에 대해 빠른 성능을 제공하여 마이그레이션 프로세스를 가속화합니다.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*다중 사이트 준비 완료.*  StorageGRID 분산 아키텍처를 사용하면 Splunk SmartStore가 단일 글로벌 네임스페이스를 통해 단일 사이트와 여러 사이트에 배포를 확장할 수 있으며, 데이터가 어디에 있든 관계없이 모든 사이트에서 데이터에 액세스할 수 있습니다.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*확장성이 향상되었습니다.*  Splunk 환경에서 변화하는 요구 사항과 수요를 충족하기 위해 컴퓨팅 리소스와 별도로 스토리지 리소스를 확장하여 TCO를 개선합니다.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*용량.*  StorageGRID 사용하여 단일 네임스페이스를 560PB 이상으로 확장하여 Splunk 배포에서 빠르게 증가하는 볼륨을 처리하세요.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*데이터 가용성.*  데이터의 비즈니스 가치가 변화함에 따라 동적으로 조정할 수 있는 메타데이터 기반 정책을 통해 데이터 가용성, 성능, 지리적 분포, 보존, 보호 및 저장 비용을 최적화하세요.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Splunk에서 제공하는 가이드라인</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">로컬(핫) 및 원격(웜) 스토리지 간 버킷 복사본 전송을 처리하는 인덱서의 구성 요소인 SmartStore 캐시를 사용하여 성능을 향상시킵니다.  이 솔루션에 대한 Splunk 크기 조정은 다음을 기반으로 합니다.<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block> .  이 솔루션을 사용하면 단일 및 다중 사이트 배포에서 사용자 수나 수집 속도 측면에서 증가하는 수요를 충족하기 위해 컴퓨팅, 핫 스토리지 또는 S3 리소스를 추가할 수 있습니다.</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">이 페이지에서는 NetApp StorageGRID, Splunk Enterprise, Splunk SmartStore를 비롯하여 이 솔루션을 완성하는 데 사용된 구성 요소에 대해 설명합니다.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">솔루션 개요</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID 는 고성능이고 비용 효율적인 객체 스토리지 플랫폼입니다.  분산형 노드 기반 그리드 아키텍처를 사용하여 지능적이고 정책 기반의 글로벌 데이터 관리를 제공합니다.  유비쿼터스 글로벌 객체 네임스페이스와 정교한 데이터 관리 기능을 결합하여 페타바이트 규모의 비정형 데이터와 수십억 개의 객체를 간편하게 관리할 수 있습니다.  단일 호출 객체 액세스는 여러 사이트로 확장되어 고가용성 아키텍처를 단순화하는 동시에 사이트나 인프라 중단에 관계없이 지속적인 객체 액세스를 보장합니다.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">멀티테넌시를 통해 여러 클라우드 및 엔터프라이즈 비정형 데이터 애플리케이션을 동일한 그리드 내에서 안전하게 서비스할 수 있어 StorageGRID 의 ROI와 사용 사례가 늘어납니다.  메타데이터 기반 개체 수명 주기 정책을 사용하면 여러 서비스 수준을 생성하여 여러 지역에 걸쳐 내구성, 보호, 성능 및 지역성을 최적화할 수 있습니다.  사용자는 요구 사항이 변경됨에 따라 중단 없이 정책을 조정하고 데이터 환경을 재정비할 수 있습니다.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore는 원격 스토리지 계층으로 StorageGRID 활용하고 고객이 지리적으로 분산된 여러 사이트를 배포하여 강력한 가용성과 내구성을 확보할 수 있도록 하며, 이는 단일 개체 네임스페이스로 제공됩니다.  이를 통해 Splunk SmartStore는 StorageGRID 의 고성능, 고밀도 용량, 단일 URL을 사용하여 여러 물리적 사이트에 걸쳐 수백 개의 노드로 확장하는 기능을 활용하여 개체와 상호 작용할 수 있습니다.  이 단일 URL을 사용하면 단일 사이트를 넘어서도 중단 없이 저장소 확장, 업그레이드 및 수리를 수행할 수 있습니다.  StorageGRID 의 고유한 데이터 관리 정책 엔진은 최적화된 수준의 성능과 내구성을 제공하며 데이터 지역성 요구 사항을 준수합니다.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">기계에서 생성된 데이터의 수집 및 분석 분야를 선도하는 Splunk는 운영 분석 기능을 통해 IT를 간소화하고 현대화하는 데 도움을 줍니다.  또한 비즈니스 분석, 보안, IoT 사용 사례로 확장됩니다.  스토리지는 Splunk 소프트웨어를 성공적으로 배포하는 데 중요한 요소입니다.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">기계에서 생성된 데이터는 가장 빠르게 성장하는 빅데이터 유형입니다.  이 형식은 예측 불가능하며 다양한 출처에서 나오는 경우가 많고, 종종 빠른 속도로 대량으로 발생합니다.  이러한 작업 부하 특성은 종종 디지털 배기라고 불립니다.  Splunk SmartStore는 이러한 데이터를 이해하는 데 도움이 되며, 가장 비용 효율적인 스토리지 계층에 핫 데이터와 웜 데이터를 최적으로 배치하기 위한 스마트한 데이터 계층화를 제공합니다.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore는 StorageGRID 와 같은 개체 스토리지(원격 스토리지 또는 원격 스토리지 계층이라고도 함)를 사용하여 S3 프로토콜을 사용하여 웜 데이터를 저장하는 인덱서 기능입니다.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">배포된 데이터 볼륨이 증가함에 따라 일반적으로 저장소에 대한 수요가 컴퓨터 리소스에 대한 수요를 앞지릅니다.  SmartStore를 사용하면 컴퓨팅과 스토리지를 별도로 확장하여 인덱서 스토리지와 컴퓨팅 리소스를 비용 효율적으로 관리할 수 있습니다.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore는 S3 프로토콜과 캐시 관리자를 사용하여 원격 스토리지 계층을 도입했습니다.  이러한 기능을 사용하면 데이터를 인덱서나 원격 저장소에 로컬로 저장할 수 있습니다.  인덱서에 있는 캐시 관리자는 인덱서와 원격 스토리지 계층 간의 데이터 이동을 관리합니다.  데이터는 버킷 메타데이터와 함께 버킷(핫 및 웜)에 저장됩니다.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">SmartStore를 사용하면 인덱서 저장소 공간을 최소한으로 줄이고 대부분의 데이터가 원격 저장소 계층에 있으므로 I/O 최적화된 컴퓨팅 리소스를 선택할 수 있습니다.  인덱서는 요청되고 예측된 결과를 반환하는 데 필요한 최소한의 데이터 양을 나타내는 로컬 캐시를 유지 관리합니다.  로컬 캐시에는 핫 버킷, 활성 또는 최근 검색에 참여하는 웜 버킷의 사본 및 버킷 메타데이터가 포함되어 있습니다.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">StorageGRID 탑재된 Splunk SmartStore를 사용하면 고객은 고성능 및 비용 효율적인 원격 스토리지를 통해 환경을 점진적으로 확장할 수 있으며, 동시에 전체 솔루션에 높은 수준의 탄력성을 제공합니다.  이를 통해 고객은 더 많은 인덱서가 필요하거나, 데이터 보존 기간을 변경하거나, 중단 없이 수집 속도를 높여야 하는 경우, 언제든지 원하는 수량만큼 구성 요소(핫 스토리지 및/또는 웜 S3 스토리지)를 추가할 수 있습니다.</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID 사용자가 끊임없이 변화하는 환경에 맞게 활용하고 사용자 정의할 수 있는 다양한 기능을 제공합니다.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Splunk SmartStore를 위한 유연한 StorageGRID 기능</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID 사용자가 끊임없이 변화하는 환경에 맞게 활용하고 사용자 정의할 수 있는 다양한 기능을 제공합니다.  Splunk SmartStore를 배포하거나 확장하는 과정에서 환경에는 변화에 대한 신속한 적응이 필요하며 Splunk를 중단시키지 않아야 합니다.  StorageGRID 유연한 데이터 관리 정책(ILM)과 트래픽 분류기(QoS)를 사용하면 환경에 맞게 계획을 세우고 적응할 수 있습니다.</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager는 다음 이미지에서 볼 수 있듯이 단일 창에서 전 세계에 분산된 위치에 있는 StorageGRID 시스템을 구성, 관리 및 모니터링할 수 있는 브라우저 기반 그래픽 인터페이스입니다.</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Grid Manager 인터페이스를 사용하여 다음 작업을 수행합니다.</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Splunk용 NetApp StorageGRID 앱</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">Splunk용 NetApp StorageGRID 앱은 Splunk Enterprise에 특화된 애플리케이션입니다.  이 앱은 Splunk용 NetApp StorageGRID 애드온과 함께 작동합니다.  StorageGRID 상태, 계정 사용 정보, 보안 감사 세부 정보, 리소스 사용 및 모니터링 등에 대한 가시성을 제공합니다.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">다음 이미지는 Splunk용 StorageGRID 앱을 보여줍니다.</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILM 정책</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID 객체의 여러 사본을 보관하고 2+1, 4+2(및 기타 여러 방식)와 같은 EC(삭제 코딩) 방식을 사용하여 특정 성능 및 데이터 보호 요구 사항에 따라 객체를 저장하는 등 유연한 데이터 관리 정책을 제공합니다.  시간이 지남에 따라 작업 부하와 요구 사항이 바뀌므로 ILM 정책도 시간이 지남에 따라 변경해야 하는 것이 일반적입니다.  ILM 정책을 수정하는 것은 StorageGRID 고객이 끊임없이 변화하는 환경에 빠르고 쉽게 적응할 수 있도록 하는 핵심 기능입니다.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID SG5712, SG5760, SG6060 또는 SGF6024와 같은 VM이나 베어메탈 또는 특수 목적 어플라이언스를 더 추가하여 성능을 확장합니다.  테스트 결과, SG6060 어플라이언스를 사용하여 최소 크기의 3노드 그리드로 SmartStore의 주요 성능 요구 사항을 초과했습니다.  고객이 추가 인덱서를 사용하여 Splunk 인프라를 확장하면 더 많은 스토리지 노드를 추가하여 성능과 용량을 늘릴 수 있습니다.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">로드 밸런서 및 엔드포인트 구성</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">StorageGRID 의 관리 노드는 StorageGRID 시스템을 보고, 구성하고, 관리할 수 있는 Grid Manager UI(사용자 인터페이스)와 REST API 엔드포인트를 제공하며, 감사 로그를 통해 시스템 활동을 추적합니다.  Splunk SmartStore 원격 스토리지에 고가용성 S3 엔드포인트를 제공하기 위해 관리 노드와 게이트웨이 노드에서 서비스로 실행되는 StorageGRID 로드 밸런서를 구현했습니다.  또한, 로드 밸런서는 로컬 트래픽을 관리하고 GSLB(글로벌 서버 로드 밸런싱)와 통신하여 재해 복구를 지원합니다.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">엔드포인트 구성을 더욱 향상시키기 위해 StorageGRID 관리 노드에 내장된 트래픽 분류 정책을 제공하고, 이를 통해 워크로드 트래픽을 모니터링하고, 워크로드에 다양한 서비스 품질(QoS) 제한을 적용할 수 있습니다.  트래픽 분류 정책은 게이트웨이 노드와 관리 노드에 대한 StorageGRID 부하 분산 서비스의 엔드포인트에 적용됩니다.  이러한 정책은 교통 제한 및 모니터링에 도움이 될 수 있습니다.</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">고객들은 Splunk 데이터 분석의 강력함과 편리함을 깨닫고, 자연스럽게 점점 더 많은 양의 데이터를 인덱싱하고자 합니다.  데이터 양이 증가함에 따라 이를 처리하는 데 필요한 컴퓨팅 및 스토리지 인프라도 함께 증가합니다.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">지능형 계층화 및 비용 절감</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">고객들은 Splunk 데이터 분석의 강력함과 편리함을 깨닫고, 자연스럽게 점점 더 많은 양의 데이터를 인덱싱하고자 합니다.  데이터 양이 증가함에 따라 이를 처리하는 데 필요한 컴퓨팅 및 스토리지 인프라도 함께 증가합니다.  오래된 데이터는 참조 빈도가 낮아지기 때문에 동일한 양의 컴퓨팅 리소스를 투입하고 값비싼 기본 저장소를 사용하는 것은 점점 더 비효율적이 됩니다.  대규모로 운영하기 위해 고객은 따뜻한 데이터를 더 비용 효율적인 계층으로 이동하여 컴퓨팅과 기본 스토리지를 뜨거운 데이터에 사용할 수 있는 이점을 얻습니다.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">StorageGRID 탑재된 Splunk SmartStore는 조직에 확장 가능하고 성능이 뛰어나며 비용 효율적인 솔루션을 제공합니다.  SmartStore는 데이터를 인식하므로 데이터 액세스 패턴을 자동으로 평가하여 실시간 분석을 위해 액세스해야 하는 데이터(핫 데이터)와 비용이 적게 드는 장기 저장소에 저장해야 하는 데이터(웜 데이터)를 판별합니다.  SmartStore는 업계 표준인 AWS S3 API를 동적이고 지능적으로 사용하여 StorageGRID 제공하는 S3 스토리지에 데이터를 저장합니다.  StorageGRID 의 유연한 확장형 아키텍처를 통해 필요에 따라 웜 데이터 계층을 비용 효율적으로 확장할 수 있습니다.  StorageGRID 의 노드 기반 아키텍처는 성능 및 비용 요구 사항이 최적으로 충족되도록 보장합니다.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">다음 이미지는 Splunk와 StorageGRID 계층화를 보여줍니다.</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">Splunk SmartStore와 NetApp StorageGRID 의 업계 최고 조합은 풀스택 솔루션을 통해 분리된 아키텍처의 이점을 제공합니다.</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp E-Series E5700 및 Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">미치 블랙번, NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623은 NetApp E-Series와 Splunk 디자인의 통합 아키텍처를 설명합니다.  노드 스토리지 균형, 안정성, 성능, 스토리지 용량 및 밀도에 최적화된 이 디자인은 더 높은 확장성과 더 낮은 TCO를 제공하는 Splunk 클러스터형 인덱스 노드 모델을 채택합니다.  스토리지와 컴퓨팅을 분리하면 각각을 별도로 확장할 수 있으므로 한쪽을 과도하게 프로비저닝하는 데 드는 비용을 절감할 수 있습니다.  또한, 이 문서에서는 Splunk 머신 로그 이벤트 시뮬레이션 도구에서 얻은 성능 테스트 결과를 요약합니다.</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">학습, 재학습, 미세 조정, 추론 및 생성 AI 모델 모니터링을 위해 AI 파이프라인 전반에서 원활한 데이터 관리 및 데이터 이동을 지원하는 NetApp AI 기능입니다.</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">생성적 AI와 NetApp 가치</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">생성적 인공지능(AI)에 대한 수요는 산업 전반에 걸쳐 혁신을 촉진하고, 비즈니스 창의성과 제품 혁신을 강화하고 있습니다.</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">많은 조직에서 생성적 AI를 사용하여 새로운 제품 기능을 구축하고, 엔지니어링 생산성을 개선하고, 더 나은 결과와 고객 경험을 제공하는 AI 기반 애플리케이션의 프로토타입을 개발하고 있습니다.  GPT(Generative Pre-trained Transformers)와 같은 생성적 AI는 신경망을 사용하여 텍스트, 오디오, 비디오 등 다양한 새로운 콘텐츠를 생성합니다.  대규모 언어 모델(LLM)과 관련된 극단적인 규모와 엄청난 양의 데이터 세트를 고려할 때, 기업이 AI 솔루션을 설계하기 전에 온프레미스, 하이브리드 및 멀티클라우드 배포 옵션의 매력적인 데이터 저장 기능을 활용하고 데이터 이동성, 데이터 보호 및 거버넌스와 관련된 위험을 줄이는 강력한 AI 인프라를 구축하는 것이 중요합니다.  이 논문에서는 이러한 고려 사항과 학습, 재학습, 미세 조정 및 생성 AI 모델 추론을 위한 AI 데이터 파이프라인 전반의 원활한 데이터 관리 및 데이터 이동을 가능하게 하는 해당 NetApp AI 기능에 대해 설명합니다.</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">요약</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">가장 최근에는 2022년 11월 GPT-3의 분사 기업인 ChatGPT가 출시된 이후, 사용자 프롬프트에 따라 텍스트, 코드, 이미지, 심지어 치료용 단백질까지 생성하는 데 사용되는 새로운 AI 도구가 상당한 명성을 얻었습니다.  이는 사용자가 자연어를 사용하여 요청을 하면 AI가 사용자 요청을 반영하는 뉴스 기사나 제품 설명과 같은 텍스트를 해석하고 생성하거나, 이미 존재하는 데이터로 훈련된 알고리즘을 사용하여 코드, 음악, 음성, 시각 효과, 3D 자산을 생성한다는 것을 의미합니다.  그 결과, 안정적 확산, 환각, 신속한 엔지니어링, 가치 정렬과 같은 문구가 AI 시스템 설계에 빠르게 등장하고 있습니다.  이러한 자기 지도 또는 반지도 머신 러닝(ML) 모델은 클라우드 서비스 공급업체와 기타 AI 회사 공급업체를 통해 사전 학습된 기반 모델(FM)로 널리 제공되고 있으며, 다양한 산업 전반의 기업에서 광범위한 다운스트림 NLP(자연어 처리) 작업에 채택되고 있습니다.  맥킨지와 같은 연구 분석 회사가 주장한 것처럼 "생성적 AI가 생산성에 미치는 영향은 글로벌 경제에 수조 달러의 가치를 더할 수 있습니다."  기업들이 AI를 인간의 사고 파트너로 재구성하고, FM이 기업과 기관이 생성적 AI를 통해 할 수 있는 일을 확대하는 동시에, 엄청난 양의 데이터를 관리할 수 있는 기회도 계속해서 늘어날 것입니다.  이 문서에서는 온프레미스와 하이브리드 또는 멀티클라우드 환경 모두에서 NetApp 고객에게 가치를 제공하는 NetApp 기능과 관련된 생성적 AI 및 설계 개념에 대한 소개 정보를 제공합니다.</block>
  <block id="8bcfe22a3d7c5edf904444893704a8de" category="paragraph">*그렇다면 고객이 AI 환경에서 NetApp 사용하면 어떤 이점이 있을까요?*  NetApp 조직이 급속한 데이터 및 클라우드 성장, 멀티 클라우드 관리, AI와 같은 차세대 기술 도입으로 인해 발생하는 복잡성을 해결할 수 있도록 지원합니다.  NetApp 다양한 기능을 지능형 데이터 관리 소프트웨어와 스토리지 인프라로 결합했으며, 이는 AI 워크로드에 최적화된 고성능과 균형을 이루고 있습니다.  LLM과 같은 생성적 AI 솔루션은 지능을 강화하기 위해 저장소에서 소스 데이터 세트를 여러 번 읽어 메모리로 처리해야 합니다.  NetApp 엣지에서 코어, 클라우드에 이르는 생태계 전반에 걸쳐 데이터 이동성, 데이터 거버넌스 및 데이터 보안 기술을 선도해 왔으며, 기업 고객에게 대규모 AI 솔루션을 구축할 수 있는 서비스를 제공합니다.  강력한 파트너 네트워크를 갖춘 NetApp 은 최고 데이터 책임자, AI 엔지니어, 엔터프라이즈 아키텍트, 데이터 과학자가 AI 모델 학습 및 추론에 대한 데이터 준비, 데이터 보호, 전략적 데이터 관리 책임을 위한 자유로운 데이터 파이프라인을 설계하고 AI/ML 수명 주기의 성능과 확장성을 최적화하도록 지원해 왔습니다.  NetApp ONTAP AI ( 딥 러닝 데이터 파이프라인), NetApp SnapMirror( 스토리지 엔드포인트 간에 데이터를 원활하고 효율적으로 전송), NetApp FlexCache( 배치에서 실시간으로 데이터 흐름이 전환되고 데이터 엔지니어링이 신속하게 수행될 때 실시간 렌더링)와 같은 NetApp 데이터 기술과 기능은 실시간 생성 AI 모델 배포에 가치를 더해줍니다.  모든 유형의 기업이 새로운 AI 도구를 도입함에 따라 엣지에서 데이터 센터, 클라우드에 이르기까지 확장 가능하고 책임감 있으며 설명 가능한 AI 솔루션을 요구하는 데이터 과제에 직면하게 됩니다.  하이브리드 및 멀티 클라우드 분야의 데이터 기관으로서 NetApp 생성적 AI 모델 학습(사전 학습), 미세 조정, 컨텍스트 기반 추론 및 LLM의 모델 붕괴 모니터링을 위한 데이터 파이프라인 및 데이터 레이크 구축의 모든 측면을 지원할 수 있는 파트너 및 공동 솔루션 네트워크를 구축하는 데 전념하고 있습니다.</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">생성적 AI란 무엇인가?</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">생성적 AI는 콘텐츠를 만드는 방식, 새로운 디자인 컨셉을 창출하는 방식, 참신한 구성을 탐구하는 방식을 바꾸고 있습니다.  여기에는 텍스트, 코드, 이미지, 오디오, 비디오 및 합성 데이터와 같은 새로운 콘텐츠를 생성할 수 있는 GAN(Generative Adversarial Network), VAE(Variational Autoencoders), GPT(Generative Pre-Trained Transformers)와 같은 신경망 프레임워크가 설명되어 있습니다.  OpenAI의 Chat-GPT, Google의 Bard, Hugging Face의 BLOOM, Meta의 LLaMA와 같은 트랜스포머 기반 모델은 대규모 언어 모델의 많은 발전을 뒷받침하는 기반 기술로 떠올랐습니다.  마찬가지로 OpenAI의 Dall-E, Meta의 CM3leon, Google의 Imagen은 텍스트-이미지 확산 모델의 예입니다. 이러한 모델은 고객에게 데이터 세트 증강 및 텍스트-이미지 합성을 사용하여 텍스트와 시각적 의미를 연결하여 고품질의 상황 인식 이미지를 생성하거나 기존 이미지를 편집하여 새롭고 복잡한 이미지를 처음부터 만들 수 있는 전례 없는 수준의 포토리얼리즘을 제공합니다.  디지털 아티스트는 NeRF(Neural Radiance Field)와 같은 렌더링 기술과 생성 AI를 결합하여 정적인 2D 이미지를 몰입형 3D 장면으로 변환하기 시작했습니다.  일반적으로 LLM은 크게 4가지 매개변수로 특징지어집니다. (1) 모델 크기(일반적으로 수십억 개의 매개변수), (2) 학습 데이터 세트 크기, (3) 학습 비용, (4) 학습 후 모델 성능.  LLM도 주로 3가지 변압기 아키텍처로 분류됩니다.  (i) 인코더 전용 모델.  예: BERT(Google, 2018); (ii) 인코더-디코더 예: BART(Meta, 2020) 및 (iii) 디코더 전용 모델.  예를 들어 LLaMA(Meta, 2023), PaLM-E(Google, 2023).  비즈니스 요구 사항에 따라, 회사가 어떤 아키텍처를 선택하든 일반적으로 학습 데이터 세트의 모델 매개변수 수(N)와 토큰 수(D)에 따라 LLM 학습(사전 학습) 또는 미세 조정의 기준 비용이 결정됩니다.</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">엔터프라이즈 사용 사례 및 다운스트림 NLP 작업</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">다양한 산업의 기업들은 AI가 기존 데이터에서 비즈니스 운영, 판매, 마케팅, 법률 서비스를 위한 새로운 형태의 가치를 추출하고 생산할 수 있는 잠재력을 점점 더 많이 발견하고 있습니다.  IDC(International Data Corporation)의 글로벌 생성적 AI 활용 사례 및 투자에 대한 시장 정보에 따르면, 소프트웨어 개발 및 제품 설계 분야의 지식 관리가 가장 큰 영향을 받을 것으로 예상되며, 그 다음으로 마케팅을 위한 스토리라인 생성과 개발자를 위한 코드 생성이 영향을 받을 것으로 예상됩니다.  의료 분야에서 임상 연구 기관은 의학의 새로운 영역을 개척하고 있습니다.  ProteinBERT와 같은 사전 학습된 모델은 유전자 온톨로지(GO) 주석을 통합하여 의약품의 단백질 구조를 빠르게 설계하며, 이는 약물 발견, 생물정보학, 분자생물학 분야에서 중요한 이정표를 나타냅니다.  바이오 기술 회사들은 폐 조직에 돌이킬 수 없는 상처를 남기는 폐 질환인 폐 섬유증(IPF)과 같은 질병을 치료하는 것을 목표로 하는 생성적 AI 기반 의학에 대한 인체 실험을 시작했습니다.</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">그림 1: 생성적 AI를 구동하는 사용 사례</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">생성적 AI로 인한 자동화 도입 증가는 많은 직업에 대한 업무 활동의 수요와 공급에도 변화를 가져오고 있습니다.  맥킨지에 따르면 미국 노동 시장(아래 다이어그램)은 빠른 변화를 겪었으며, AI의 영향을 고려하면 이러한 변화는 계속될 가능성이 있습니다.</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">출처: 맥킨지앤컴퍼니</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">그림 2: 출처: McKinsey &amp; Company</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">생성적 AI에서 스토리지의 역할</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">LLM은 딥러닝, GPU, 컴퓨팅에 크게 의존합니다.  하지만 GPU 버퍼가 가득 차면 데이터를 저장소에 빠르게 기록해야 합니다.  일부 AI 모델은 메모리에서 실행할 만큼 작은 반면, LLM은 대용량 데이터 세트에 빠르게 액세스하려면 높은 IOPS와 높은 처리량의 스토리지가 필요합니다. 특히 수십억 개의 토큰이나 수백만 개의 이미지가 포함된 경우 더욱 그렇습니다.  LLM의 일반적인 GPU 메모리 요구 사항의 경우, 10억 개의 매개변수로 모델을 학습하는 데 필요한 메모리는 32비트 전체 정밀도에서 최대 80GB까지 늘어날 수 있습니다.  이 경우, 70억에서 700억 개의 매개변수 규모를 가진 LLM 제품군인 Meta의 LLaMA 2에는 약 70x80, 5600GB 또는 5.6TB의 GPU RAM이 필요할 수 있습니다.  게다가 필요한 메모리 양은 생성하려는 토큰의 최대 수에 직접 비례합니다.  예를 들어 최대 512개 토큰(약 380개 단어)의 출력을 생성하려면 다음이 필요합니다.<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block> .  별로 중요하지 않은 것처럼 보일 수도 있지만, 대량으로 처리하려고 하면 비용이 늘어나기 시작합니다.  따라서 조직이 메모리에서 LLM을 훈련하거나 미세 조정하는 데 드는 비용이 매우 많이 들고, 따라서 저장은 생성적 AI의 초석이 됩니다.</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">LLM에 대한 세 가지 주요 접근 방식</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">하버드 비즈니스 리뷰</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">대부분의 기업의 경우, 현재 추세를 바탕으로 LLM을 배포하는 접근 방식은 3가지 기본 시나리오로 요약될 수 있습니다.  최근에 설명된 바와 같이<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block> 기사: (1) LLM을 처음부터 학습(사전 학습) - 비용이 많이 들고 전문적인 AI/ML 기술이 필요함; (2) 기업 데이터를 사용하여 기초 모델 미세 조정 - 복잡하지만 실행 가능; (3) 검색 증강 생성(RAG)을 사용하여 회사 데이터가 포함된 문서 저장소, API 및 벡터 데이터베이스를 쿼리함.  이들 각각은 구현 과정에서 노력, 반복 속도, 비용 효율성, 모델 정확도 간에 상충 관계가 있으며, 이는 다양한 유형의 문제를 해결하는 데 사용됩니다(아래 다이어그램).</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">그림 3: 문제 유형</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">기초 모델</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">기초 모델(FM)은 기본 모델이라고도 하며, 대규모의 레이블이 지정되지 않은 데이터로 학습된 대규모 AI 모델(LLM)로, 대규모 자체 감독을 사용하여 일반적으로 광범위한 다운스트림 NLP 작업에 맞게 조정됩니다.  훈련 데이터에 사람이 레이블을 지정하지 않으므로 모델이 명시적으로 인코딩된 것이 아니라 자연스럽게 나타납니다.  즉, 모델은 명시적으로 프로그래밍되지 않고도 자체적으로 스토리나 내러티브를 생성할 수 있습니다.  따라서 FM의 중요한 특징은 동질화인데, 이는 많은 영역에서 동일한 방법이 사용된다는 것을 의미합니다.  하지만 개인화와 미세 조정 기술을 통해 요즘 출시되는 제품에 통합된 FM은 텍스트 생성, 텍스트-이미지 변환, 텍스트-코드 변환에만 유용한 것이 아니라 도메인별 작업을 설명하거나 코드를 디버깅하는 데도 유용합니다.  예를 들어, OpenAI의 Codex나 Meta의 Code Llama와 같은 FM은 프로그래밍 작업에 대한 자연어 설명을 기반으로 여러 프로그래밍 언어로 코드를 생성할 수 있습니다.  이러한 모델은 Python, C#, JavaScript, Perl, Ruby, SQL을 포함한 12개 이상의 프로그래밍 언어에 능숙합니다.  그들은 사용자의 의도를 이해하고 소프트웨어 개발, 코드 최적화, 프로그래밍 작업 자동화에 유용한 원하는 작업을 수행하는 특정 코드를 생성합니다.</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">미세 조정, 도메인 특이성 및 재교육</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">메타의 라마 2</block>
  <block id="3983fea9bc2f220141201994aa6cf9de" category="paragraph">데이터 준비 및 데이터 전처리 후 LLM 배포와 관련된 일반적인 관행 중 하나는 대규모의 다양한 데이터 세트에서 학습된 사전 학습된 모델을 선택하는 것입니다.  미세 조정의 맥락에서 이는 다음과 같은 오픈 소스 대규모 언어 모델이 될 수 있습니다.<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block> 700억 개의 매개변수와 2조 개의 토큰을 통해 학습되었습니다.  사전 학습된 모델을 선택하면 다음 단계는 도메인별 데이터에 맞춰 세부적으로 조정하는 것입니다.  여기에는 모델의 매개변수를 조정하고 새로운 데이터로 모델을 훈련하여 특정 도메인과 작업에 적응시키는 작업이 포함됩니다.  예를 들어, BloombergGPT는 금융 산업에 서비스를 제공하는 광범위한 금융 데이터에 대한 교육을 받은 독점 LLM입니다.  특정 작업을 위해 설계되고 훈련된 도메인별 모델은 일반적으로 해당 범위 내에서 정확도와 성능이 더 높지만, 다른 작업이나 도메인으로의 이전 가능성이 낮습니다.  비즈니스 환경과 데이터가 일정 기간 동안 변경되면 FM의 예측 정확도는 테스트 시의 성능에 비해 떨어지기 시작할 수 있습니다.  모델을 재교육하거나 미세 조정하는 것이 중요해지는 시점입니다.  기존 AI/ML에서 모델 재교육은 배포된 ML 모델을 새로운 데이터로 업데이트하는 것을 말하며, 일반적으로 발생하는 두 가지 유형의 드리프트를 제거하기 위해 수행됩니다.  (1) 개념 드리프트 - 입력 변수와 대상 변수 간의 연결이 시간이 지남에 따라 변경되면 예측하려는 내용에 대한 설명이 변경되므로 모델이 부정확한 예측을 생성할 수 있습니다.  (2) 데이터 드리프트 - 입력 데이터의 특성이 변경될 때 발생합니다. 예를 들어 시간이 지남에 따라 고객 습관이나 행동이 변경되어 모델이 이러한 변경에 대응할 수 없게 되는 경우입니다.  비슷한 방식으로 재교육은 FM/LLM에도 적용되지만 비용이 훨씬 많이 들 수 있으므로(수백만 달러) 대부분의 조직에서는 고려하지 않는 사항입니다.  이는 활발하게 연구 중이며, LLMOps 분야에서는 아직 새로운 분야로 떠오르고 있습니다.  따라서 미세 조정된 FM에서 모델 쇠퇴가 발생하면 기업은 재교육을 하는 대신 새로운 데이터 세트를 사용하여 다시 미세 조정을 (훨씬 저렴하게) 선택할 수 있습니다.  비용 관점에서 볼 때, 아래는 Azure-OpenAI 서비스의 모델 가격표 예입니다.  각 작업 범주에 대해 고객은 특정 데이터 세트에 대한 모델을 미세 조정하고 평가할 수 있습니다.</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">출처: Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">신속한 엔지니어링 및 추론</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">신속한 엔지니어링은 모델 가중치를 업데이트하지 않고도 원하는 작업을 수행하기 위해 LLM과 통신하는 효과적인 방법을 말합니다.  NLP 애플리케이션에 있어 AI 모델 학습과 미세 조정이 중요한 만큼, 학습된 모델이 사용자 프롬프트에 응답하는 추론도 마찬가지로 중요합니다.  추론에 필요한 시스템 요구 사항은 일반적으로 LLM에서 GPU로 데이터를 공급하는 AI 저장 시스템의 읽기 성능에 훨씬 더 중점을 둡니다. 최상의 응답을 생성하기 위해 수십억 개의 저장된 모델 매개변수를 적용할 수 있어야 하기 때문입니다.</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps, 모델 모니터링 및 벡터스토어</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">기존의 머신 러닝 운영(MLOps)과 마찬가지로 대규모 언어 모델 운영(LLMOps)에도 프로덕션 환경에서 LLM을 관리하기 위한 도구와 모범 사례를 갖춘 데이터 과학자와 DevOps 엔지니어의 협업이 필요합니다.  그러나 LLM의 워크플로와 기술 스택은 여러 면에서 다를 수 있습니다.  예를 들어, LangChain과 같은 프레임워크를 사용하여 구축된 LLM 파이프라인은 벡터스토어나 벡터 데이터베이스와 같은 외부 임베딩 엔드포인트에 대한 여러 LLM API 호출을 연결합니다.  다운스트림 커넥터(예: 벡터 데이터베이스)에 임베딩 엔드포인트와 벡터스토어를 사용하는 것은 데이터가 저장되고 액세스되는 방식에 있어서 중요한 발전을 나타냅니다.  처음부터 개발되는 기존 ML 모델과 달리 LLM은 종종 전이 학습에 의존합니다. 이는 이러한 모델이 새로운 데이터로 미세 조정된 FM으로 시작하여 보다 구체적인 도메인에서 성능을 개선하기 때문입니다.  따라서 LLMOps가 위험 관리 및 모델 붕괴 모니터링 기능을 제공하는 것이 중요합니다.</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">생성적 AI 시대의 위험과 윤리</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">"ChatGPT – 매끄럽지만 여전히 말도 안 되는 소리를 낸다."– MIT Tech Review.  쓰레기를 넣으면 쓰레기가 나오는 것은 컴퓨팅에서 항상 어려운 문제였습니다.  생성적 AI와의 유일한 차이점은 쓰레기를 매우 신뢰할 만하게 만들어서 부정확한 결과를 낳는 데 탁월하다는 것입니다.  LLM은 자신이 만들고 있는 이야기에 맞게 사실을 만들어내는 경향이 있습니다.  따라서 생성적 AI를 AI 대응 제품의 비용을 절감할 수 있는 좋은 기회로 보는 기업은 딥페이크를 효율적으로 감지하고, 편견을 줄이고, 위험을 낮춰 시스템의 정직성과 윤리성을 유지해야 합니다.  종단 간 암호화와 AI 가드레일을 통해 데이터 이동성, 데이터 품질, 데이터 거버넌스 및 데이터 보호를 지원하는 강력한 AI 인프라를 갖춘 자유롭게 흐르는 데이터 파이프라인은 책임감 있고 설명 가능한 생성적 AI 모델을 설계하는 데 매우 중요합니다.</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">고객 시나리오 및 NetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">그림 3: 머신 러닝/대규모 언어 모델 워크플로</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*우리는 훈련을 하고 있는가, 아니면 미세조정을 하고 있는가?*  (a) LLM 모델을 처음부터 학습시킬지, 미리 학습된 FM을 미세 조정할지, RAG를 사용하여 기초 모델 외부의 문서 저장소에서 데이터를 검색하고 프롬프트를 증강할지, (b) 오픈 소스 LLM(예: Llama 2)이나 독점 FM(예: ChatGPT, Bard, AWS Bedrock)을 활용할지 여부는 조직이 내려야 할 전략적 결정입니다.  각 접근 방식은 비용 효율성, 데이터 중력, 운영, 모델 정확도 및 LLM 관리 간에 상충 관계가 있습니다.</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">NetApp 회사 내부적으로 업무 문화와 제품 설계 및 엔지니어링 노력에 대한 접근 방식에 AI를 도입했습니다.  예를 들어, NetApp의 자율형 랜섬웨어 보호 기능은 AI와 머신 러닝을 사용하여 구축되었습니다.  이 기능은 파일 시스템 이상을 조기에 감지하여 운영에 영향을 미치기 전에 위협을 식별하는 데 도움이 됩니다.  둘째, NetApp 판매 및 재고 예측과 같은 비즈니스 운영에 예측 AI를 활용하고, 챗봇을 통해 콜센터 제품 지원 서비스, 기술 사양, 보증, 서비스 매뉴얼 등에서 고객을 지원합니다.  셋째, NetApp NetApp ONTAP AI, NetApp SnapMirror, NetApp FlexCache와 같은 NetApp 제품 및 기능을 통해 수요 예측, 의료 영상, 감정 분석, 제조 분야의 산업 이미지 이상 탐지 및 은행 및 금융 서비스의 자금 세탁 방지 및 사기 탐지와 같은 생성 AI 솔루션과 같은 예측 AI 솔루션을 구축하는 고객에게 서비스 NetApp 제품과 솔루션을 통해 AI ONTAP NetApp SnapMirror / NetApp FlexCache 에 고객 가치를 제공합니다.</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">NetApp 기능</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">챗봇, 코드 생성, 이미지 생성 또는 게놈 모델 표현과 같은 생성적 AI 애플리케이션에서 데이터의 이동과 관리가 엣지, 프라이빗 데이터 센터 및 하이브리드 멀티클라우드 생태계 전반에 걸쳐 이루어질 수 있습니다.  예를 들어, ChatGPT와 같은 사전 훈련된 모델의 API를 통해 노출된 최종 사용자 앱에서 승객의 항공권을 비즈니스 클래스로 업그레이드하도록 돕는 실시간 AI 봇은 승객 정보가 인터넷에 공개적으로 제공되지 않기 때문에 그 자체로 해당 작업을 달성할 수 없습니다.  API는 하이브리드 또는 멀티클라우드 생태계에 존재할 수 있는 항공사의 승객 개인 정보 및 항공권 정보에 대한 액세스가 필요합니다.  유사한 시나리오는 LLM을 사용하여 일대다 생물의학 연구 기관이 참여하는 약물 발견 전반에 걸쳐 임상 시험을 수행하는 최종 사용자 애플리케이션을 통해 약물 분자와 환자 데이터를 공유하는 과학자에게도 적용될 수 있습니다.  FM이나 LLM에 전달되는 민감한 데이터에는 PII, 재무 정보, 건강 정보, 생체 인식 데이터, 위치 데이터, 통신 데이터, 온라인 행동 및 법률 정보가 포함될 수 있습니다.  실시간 렌더링, 즉각적인 실행 및 에지 추론이 발생하는 경우 오픈 소스 또는 독점 LLM 모델을 통해 최종 사용자 앱에서 스토리지 엔드포인트로 데이터가 이동하고, 이를 온프레미스 또는 퍼블릭 클라우드 플랫폼의 데이터 센터로 전송합니다.  이러한 모든 시나리오에서 데이터 이동성과 데이터 보호는 대규모 학습 데이터 세트와 이러한 데이터의 이동에 의존하는 LLM과 관련된 AI 작업에 매우 중요합니다.</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">그림 4: 생성 AI - LLM 데이터 파이프라인</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">그림 4: 생성 AI-LLM 데이터 파이프라인</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">NetApp의 스토리지 인프라, 데이터 및 클라우드 서비스 포트폴리오는 지능형 데이터 관리 소프트웨어로 구동됩니다.</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*데이터 준비*: LLM 기술 스택의 첫 번째 기둥은 기존의 전통적인 ML 스택과 크게 다르지 않습니다.  AI 파이프라인에서 데이터 전처리는 학습이나 미세 조정에 앞서 데이터를 정규화하고 정리하는 데 필요합니다.  이 단계에는 Amazon S3 계층 형태나 파일 저장소 또는 NetApp StorageGRID 와 같은 온프레미스 스토리지 시스템 형태에 있는 데이터를 수집하기 위한 커넥터가 포함됩니다.</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP*은 데이터 센터와 클라우드에서 NetApp의 핵심 스토리지 솔루션을 뒷받침하는 기반 기술입니다.  ONTAP 에는 사이버 공격에 대한 자동 랜섬웨어 보호, 내장형 데이터 전송 기능, 온프레미스, 하이브리드, 멀티클라우드, NAS, SAN, 객체 및 소프트웨어 정의 스토리지(SDS) 상황의 LLM 배포 등 다양한 아키텍처에 대한 스토리지 효율성 기능을 포함하여 다양한 데이터 관리 및 보호 기능이 포함되어 있습니다.</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* 딥 러닝 모델 학습을 위한 NetApp ONTAP AI*  NetApp ONTAP ONTAP 스토리지 클러스터와 NVIDIA DGX 컴퓨트 노드를 사용하는 NetApp 고객을 위해 RDMA를 통한 NFS를 사용하여 NVIDIA GPU 직접 스토리지를 지원합니다.  저장소에서 소스 데이터 세트를 여러 번 읽어 메모리로 처리하는 비용 효율적인 성능을 제공하여 지능성을 강화하고, 조직이 LLM에 대한 교육, 미세 조정 및 확장을 수행할 수 있도록 지원합니다.</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache*는 파일 배포를 간소화하고 적극적으로 읽은 데이터만 캐싱하는 원격 캐싱 기능입니다.  이는 LLM 교육, 재교육 및 미세 조정에 유용할 수 있으며, 실시간 렌더링 및 LLM 추론과 같은 비즈니스 요구 사항을 가진 고객에게 가치를 제공합니다.</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror *는 두 개의 ONTAP 시스템 간에 볼륨 스냅샷을 복제하는 ONTAP 기능입니다.  이 기능은 엣지에서 온프레미스 데이터 센터나 클라우드로 데이터를 최적으로 전송합니다.  고객이 기업 데이터가 포함된 RAG를 사용하여 클라우드에서 생성적 AI를 개발하려는 경우, SnapMirror 사용하면 온프레미스와 하이퍼스케일러 클라우드 간에 데이터를 안전하고 효율적으로 이동할 수 있습니다.  변경 사항만 효율적으로 전송하여 대역폭을 절약하고 복제 속도를 높여 FM 또는 LLM의 교육, 재교육 및 미세 조정 작업 중에 필수적인 데이터 이동성 기능을 제공합니다.</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock*은 ONTAP 기반 스토리지 시스템에 변경 불가능한 디스크 기능을 제공하여 데이터 세트 버전을 관리합니다.  마이크로코어 아키텍처는 FPolicy Zero Trust 엔진을 통해 고객 데이터를 보호하도록 설계되었습니다.  NetApp 공격자가 특히 리소스를 많이 소모하는 방식으로 LLM과 상호 작용할 때 서비스 거부(DoS) 공격을 저항하여 고객 데이터의 가용성을 보장합니다.</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense*는 기업 데이터 세트에 존재하는 개인 정보를 식별, 매핑 및 분류하고, 정책을 시행하고, 온프레미스 또는 클라우드에서 개인 정보 보호 요구 사항을 충족하고, 보안 태세를 개선하고 규정을 준수하는 데 도움이 됩니다.</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* NetApp BlueXP* 분류, Cloud Data Sense 기반.  고객은 데이터 자산 전반에 걸쳐 데이터를 자동으로 스캔, 분석, 분류하고 조치를 취할 수 있으며, 보안 위험을 탐지하고, 스토리지를 최적화하고, 클라우드 배포를 가속화할 수 있습니다.  통합 제어 평면을 통해 스토리지와 데이터 서비스를 결합합니다. 고객은 컴퓨팅에 GPU 인스턴스를 사용하고, 콜드 스토리지 계층화와 보관 및 백업에 하이브리드 멀티클라우드 환경을 사용할 수 있습니다.</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* NetApp 파일-객체 이중성*.  NetApp ONTAP NFS 및 S3에 대한 이중 프로토콜 액세스를 지원합니다.  이 솔루션을 사용하면 고객은 NetApp Cloud Volumes ONTAP 의 S3 버킷을 통해 Amazon AWS SageMaker 노트북에서 NFS 데이터에 액세스할 수 있습니다.  이 기능은 NFS와 S3 모두에서 데이터를 공유할 수 있는 기능을 통해 이기종 데이터 소스에 쉽게 액세스해야 하는 고객에게 유연성을 제공합니다.  예를 들어, SageMaker에서 파일 객체 버킷에 대한 액세스를 통해 Meta의 Llama 2 텍스트 생성 모델과 같은 FM을 미세 조정합니다.</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">* NetApp Cloud Sync* 서비스는 클라우드나 온프레미스의 모든 대상으로 데이터를 마이그레이션하는 간단하고 안전한 방법을 제공합니다.  Cloud Sync 온프레미스 또는 클라우드 스토리지, NAS, 개체 저장소 간에 데이터를 원활하게 전송하고 동기화합니다.</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP*는 빠르고 안정적인 any-to- NetApp 및 NetApp-to- NetApp 데이터 마이그레이션을 가능하게 하는 클라이언트 소프트웨어입니다.  XCP는 Hadoop HDFS 파일 시스템에서 ONTAP NFS, S3 또는 StorageGRID 로 대량 데이터를 효율적으로 이동하는 기능을 제공하며, XCP 파일 분석은 파일 시스템에 대한 가시성을 제공합니다.</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit*은 데이터 과학자, DevOps 및 데이터 엔지니어가 다양한 데이터 관리 작업을 간편하게 수행할 수 있도록 해주는 Python 라이브러리로, 고성능 확장형 NetApp 스토리지로 지원되는 데이터 볼륨이나 JupyterLab 작업 공간을 거의 즉각적으로 프로비저닝, 복제 또는 스냅샷하는 등의 작업이 가능합니다.</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*NetApp의 제품 보안*.  LLM은 실수로 답변에서 기밀 데이터를 공개할 수 있으므로 LLM을 활용하는 AI 애플리케이션과 관련된 취약성을 연구하는 CISO에게는 우려스러운 일입니다.  OWASP(Open Worldwide Application Security Project)에서 설명한 대로, 데이터 오염, 데이터 유출, 서비스 거부, LLM 내의 즉각적인 주입과 같은 보안 문제는 데이터 노출부터 공격자의 무단 접근까지 기업에 영향을 미칠 수 있습니다.  데이터 저장 요구 사항에는 구조화된 데이터, 반구조화된 데이터, 구조화되지 않은 데이터에 대한 무결성 검사와 변경 불가능한 스냅샷이 포함되어야 합니다.  NetApp Snapshots와 SnapLock 데이터 세트 버전 관리에 사용됩니다.  엄격한 역할 기반 액세스 제어(RBAC)와 보안 프로토콜, 업계 표준 암호화를 제공하여 저장 중인 데이터와 전송 중인 데이터를 모두 보호합니다.  Cloud Insights 와 Cloud Data Sense는 함께 위협의 근원을 법의학적으로 식별하고 복원할 데이터의 우선순위를 지정하는 데 도움이 되는 기능을 제공합니다.</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* DGX BasePOD를 탑재한 ONTAP AI*</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">NVIDIA DGX BasePOD 탑재한 NetApp ONTAP AI 참조 아키텍처는 머신 러닝(ML) 및 인공 지능(AI) 워크로드를 위한 확장 가능한 아키텍처입니다.  LLM의 중요한 교육 단계에서는 일반적으로 데이터가 정기적으로 데이터 저장소에서 교육 클러스터로 복사됩니다.  이 단계에서 사용되는 서버는 GPU를 사용하여 계산을 병렬화하여 엄청난 데이터 수요를 생성합니다.  GPU 활용도를 높게 유지하려면 원시 I/O 대역폭 요구 사항을 충족하는 것이 중요합니다.</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* NVIDIA AI Enterprise를 탑재한 ONTAP AI*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise는 NVIDIA 인증 시스템을 통해 VMware vSphere에서 실행되도록 NVIDIA 에서 최적화, 인증 및 지원하는 엔드 투 엔드 클라우드 기반 AI 및 데이터 분석 소프트웨어 제품군입니다.  이 소프트웨어는 최신 하이브리드 클라우드 환경에서 AI 워크로드를 간단하고 빠르게 배포, 관리, 확장할 수 있도록 지원합니다.  NetApp 과 VMware 기반의 NVIDIA AI Enterprise는 간소화되고 친숙한 패키지로 엔터프라이즈급 AI 워크로드와 데이터 관리를 제공합니다.</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*1P 클라우드 플랫폼*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">완전 관리형 클라우드 스토리지 제품은 Microsoft Azure에서 Azure NetApp Files (ANF), AWS에서 Amazon FSx for NetApp ONTAP (FSx ONTAP) 및 Google에서 Google Cloud NetApp Volumes (GNCV)로 기본적으로 제공됩니다.  1P는 고객이 퍼블릭 클라우드에서 향상된 데이터 보안으로 고가용성 AI 워크로드를 실행하고 AWS SageMaker, Azure-OpenAI 서비스, Google의 Vertex AI와 같은 클라우드 기반 ML 플랫폼을 사용하여 LLM/FM을 미세 조정할 수 있도록 하는 관리형 고성능 파일 시스템입니다.</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">NetApp 파트너 솔루션 제품군</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">NetApp 핵심 데이터 제품, 기술 및 기능 외에도 강력한 AI 파트너 네트워크와 긴밀히 협력하여 고객에게 부가가치를 제공합니다.</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* AI 시스템의 NVIDIA 가드레일*은 AI 기술의 윤리적이고 책임감 있는 사용을 보장하는 안전 장치 역할을 합니다.  AI 개발자는 LLM 기반 애플리케이션의 동작을 특정 주제에 대해 정의하고 원치 않는 주제에 대한 토론에 참여하지 못하도록 방지할 수 있습니다.  오픈 소스 툴킷인 가드레일은 LLM을 다른 서비스에 원활하고 안전하게 연결하여 신뢰할 수 있고 안전하며 보안성이 높은 LLM 대화형 시스템을 구축할 수 있는 기능을 제공합니다.</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab*은 빠르고 안전하며 경제적인 Generative AI를 구축하고 제품화하기 위한 다목적 엔터프라이즈급 도구를 제공합니다. AI 여정의 어느 단계에 있든 상관없습니다.  Domino's Enterprise MLOps 플랫폼을 사용하면 데이터 과학자는 선호하는 도구와 모든 데이터를 사용하고, 어디서나 쉽게 모델을 훈련하고 배포하고, 위험을 관리하고 비용 효율적으로 관리할 수 있습니다. 이 모든 것이 하나의 제어 센터에서 가능합니다.</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*Edge AI를 위한 Modzy*.  NetApp 과 Modzy는 이미지, 오디오, 텍스트, 표를 포함한 모든 유형의 데이터에 대규모 AI를 제공하기 위해 협력했습니다.  Modzy는 AI 모델을 배포, 통합, 실행하기 위한 MLOps 플랫폼으로, 데이터 과학자에게 모델 모니터링, 드리프트 감지, 설명 가능성 기능을 제공하며, 원활한 LLM 추론을 위한 통합 솔루션을 제공합니다.</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI*와 NetApp Run:AI 클러스터 관리 플랫폼을 통해 AI 워크로드 오케스트레이션을 간소화하는 NetApp ONTAP AI 솔루션의 고유한 기능을 보여주기 위해 파트너십을 맺었습니다.  이 솔루션은 Spark, Ray, Dask, Rapids를 위한 기본 통합 프레임워크를 통해 수백 대의 머신으로 데이터 처리 파이프라인을 확장하도록 설계되어 GPU 리소스를 자동으로 분할하고 결합합니다.</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">생성적 AI는 모델이 대량의 고품질 데이터를 통해 훈련될 때에만 효과적인 결과를 낼 수 있습니다.  LLM은 놀라운 이정표를 달성했지만 데이터 이동성과 데이터 품질과 관련된 한계, 설계상의 과제 및 위험을 인식하는 것이 중요합니다.  LLM은 다양한 데이터 소스의 방대하고 다양한 교육 데이터 세트에 의존합니다.  모델에서 생성된 부정확한 결과나 편향된 결과는 기업과 소비자 모두를 위험에 빠뜨릴 수 있습니다.  이러한 위험은 데이터 품질, 데이터 보안, 데이터 이동성과 관련된 데이터 관리 과제로 인해 잠재적으로 LLM에 발생하는 제약에 해당할 수 있습니다.  NetApp 조직이 급속한 데이터 증가, 데이터 이동성, 멀티 클라우드 관리 및 AI 도입으로 인해 발생하는 복잡성을 해결할 수 있도록 지원합니다.  대규모 AI 인프라와 효율적인 데이터 관리는 생성 AI와 같은 AI 애플리케이션의 성공을 정의하는 데 매우 중요합니다.  고객이 비용 효율성, 데이터 거버넌스, 윤리적인 AI 관행을 통제하는 동시에 기업의 필요에 따라 확장할 수 있는 능력을 저하시키지 않고 모든 배포 시나리오를 포괄하는 것이 중요합니다.  NetApp 고객이 AI 배포를 간소화하고 가속화할 수 있도록 끊임없이 노력하고 있습니다.</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN: NVIDIA OVX를 위한 Lenovo가 포함된 NetApp AIPod</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">바비 움멘, 아비나브 싱, 로니 다니엘, NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">이 참조 아키텍처는 NVIDIA L40S GPU로 구동되는 NVIDIA 인증 OVX Lenovo ThinkSystem 서버와 NVIDIA Spectrum 네트워킹을 결합하여 LLM(대규모 언어 모델)을 최적화하고 배포하기 위한 최적의 인프라 솔루션을 제공합니다.  이 문서의 목적은 OVX 구성의 저장과 관련된 지침을 제공하는 것입니다.  이 플랫폼은 RAG(검색 증강 생성), 미세 조정, 경량 모델 학습을 포함한 다양한 생성적 AI 워크로드에 적합합니다.</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN: NVIDIA OVX를 위한 Lenovo 기반 NetApp AIPod 설계 가이드</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 아키텍처</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVIDIA DGX H100 시스템을 탑재한 NVA-1173 NetApp AIPod - 솔루션 아키텍처</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">이 섹션에서는 NVIDIA DGX 시스템을 탑재한 NetApp AIPod 의 아키텍처에 중점을 둡니다.</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">DGX 시스템을 갖춘 NetApp AIPod</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">이 참조 아키텍처는 컴퓨팅 노드 간에 400Gb/s InfiniBand(IB) 연결을 통해 컴퓨팅 클러스터 상호 연결 및 스토리지 액세스를 위해 별도의 패브릭을 활용합니다.  아래 그림은 DGX H100 시스템이 포함된 NetApp AIPod 의 전체 솔루션 토폴로지를 보여줍니다.</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">_NetApp AIpod 솔루션 토폴로지_</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">네트워크 디자인</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">이 구성에서 컴퓨팅 클러스터 패브릭은 높은 가용성을 위해 서로 연결된 한 쌍의 QM9700 400Gb/s IB 스위치를 사용합니다.  각 DGX H100 시스템은 8개의 연결을 사용하여 스위치에 연결되며, 짝수 포트는 한 스위치에 연결되고 홀수 포트는 다른 스위치에 연결됩니다.</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">스토리지 시스템 액세스, 대역 내 관리 및 클라이언트 액세스를 위해 SN4600 이더넷 스위치 한 쌍이 사용됩니다.  스위치는 스위치 간 링크로 연결되고 여러 VLAN으로 구성되어 다양한 트래픽 유형을 분리합니다.  특정 VLAN 간에 기본 L3 라우팅이 활성화되어 동일한 스위치에 있는 클라이언트와 스토리지 인터페이스 간, 그리고 고가용성을 위한 스위치 간 다중 경로가 가능합니다.  대규모 배포의 경우, 필요에 따라 스파인 스위치용 추가 스위치 쌍과 추가 리프를 추가하여 이더넷 네트워크를 리프-스파인 구성으로 확장할 수 있습니다.</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">배포 세부 정보</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">컴퓨팅 상호 연결 및 고속 이더넷 네트워크 외에도 모든 물리적 장치는 대역 외 관리를 위해 하나 이상의 SN2201 이더넷 스위치에 연결됩니다.  를 참조하십시오<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> 네트워크 구성에 대한 자세한 내용은 페이지를 참조하세요.</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">DGX H100 시스템의 스토리지 액세스 개요</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">각 DGX H100 시스템에는 관리 및 스토리지 트래픽을 위한 듀얼 포트 ConnectX-7 어댑터 2개가 제공되며, 이 솔루션의 경우 각 카드의 두 포트가 동일한 스위치에 연결됩니다.  각 카드의 한 포트는 LACP MLAG 본드로 구성되고, 한 포트는 각 스위치에 연결되며, 대역 내 관리, 클라이언트 액세스, 사용자 수준 스토리지 액세스를 위한 VLAN이 이 본드에 호스팅됩니다.</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">각 카드의 다른 포트는 AFF A90 스토리지 시스템에 연결하는 데 사용되며, 작업 부하 요구 사항에 따라 여러 구성으로 사용할 수 있습니다.  NVIDIA Magnum IO GPUDirect 스토리지를 지원하기 위해 RDMA를 통한 NFS를 사용하는 구성의 경우, 포트는 별도의 VLAN에 있는 IP 주소와 함께 개별적으로 사용됩니다.  RDMA가 필요하지 않은 배포의 경우 스토리지 인터페이스를 LACP 본딩으로 구성하여 높은 가용성과 추가 대역폭을 제공할 수도 있습니다.  RDMA 사용 여부와 관계없이 클라이언트는 NFS v4.1 pNFS 및 세션 트렁킹을 사용하여 스토리지 시스템을 마운트하여 클러스터의 모든 스토리지 노드에 대한 병렬 액세스를 활성화할 수 있습니다.  를 참조하십시오<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block> 클라이언트 구성에 대한 자세한 내용은 페이지를 참조하세요.</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">NVIDIA BasePOD 문서</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">DGX H100 시스템 연결에 대한 자세한 내용은 다음을 참조하세요.<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">저장 시스템 설계</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">각 AFF A90 스토리지 시스템은 각 컨트롤러에서 6개의 200GbE 포트를 사용하여 연결됩니다.  각 컨트롤러의 4개 포트는 DGX 시스템의 워크로드 데이터 액세스에 사용되고, 각 컨트롤러의 2개 포트는 클러스터 관리 아티팩트 및 사용자 홈 디렉토리에 대한 관리 플레인 서버의 액세스를 지원하기 위해 LACP 인터페이스 그룹으로 구성됩니다.  스토리지 시스템의 모든 데이터 액세스는 NFS를 통해 제공되며, AI 워크로드 액세스에 전담된 스토리지 가상 머신(SVM)과 클러스터 관리 용도에 전담된 별도의 SVM이 있습니다.</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">관리 SVM에는 각 컨트롤러에 구성된 2포트 인터페이스 그룹에 호스팅되는 단일 LIF만 필요합니다.  다른 FlexGroup 볼륨은 클러스터 노드 이미지, 시스템 모니터링 기록 데이터, 최종 사용자 홈 디렉토리와 같은 클러스터 관리 아티팩트를 보관하기 위해 관리 SVM에 프로비저닝됩니다.  아래 그림은 저장 시스템의 논리적 구성을 보여줍니다.</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">_NetApp A90 스토리지 클러스터 논리적 구성_</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">관리 플레인 서버</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">이 참조 아키텍처에는 관리 플레인용으로 사용되는 5개의 CPU 기반 서버도 포함되어 있습니다.  이 시스템 중 두 개는 클러스터 배포 및 관리를 위한 NVIDIA Base Command Manager의 헤드 노드로 사용됩니다.  나머지 세 시스템은 Slurm을 사용하여 작업 스케줄링을 수행하는 배포를 위한 Kubernetes 마스터 노드나 로그인 노드와 같은 추가 클러스터 서비스를 제공하는 데 사용됩니다.  Kubernetes를 활용한 배포에서는 NetApp Trident CSI 드라이버를 활용하여 AFF A900 스토리지 시스템에서 관리 및 AI 워크로드를 위한 영구 스토리지와 함께 자동화된 프로비저닝 및 데이터 서비스를 제공할 수 있습니다.</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">각 서버는 클러스터 배포 및 관리를 가능하게 하기 위해 IB 스위치와 이더넷 스위치에 물리적으로 연결되며, 앞서 설명한 대로 클러스터 관리 아티팩트를 저장하기 위해 관리 SVM을 통해 스토리지 시스템에 NFS 마운트로 구성됩니다.</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 추가 정보를 찾을 수 있는 곳</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 결론 및 추가 정보</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">이 섹션에는 NVIDIA DGX 시스템을 탑재한 NetApp AIPod 에 대한 추가 정보에 대한 참조가 포함되어 있습니다.</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">DGX BasePOD 아키텍처는 동등하게 고급 스토리지 및 데이터 관리 기능을 요구하는 차세대 딥 러닝 플랫폼입니다.  DGX BasePOD를 NetApp AFF 시스템과 결합하면 NetApp AIPod 와 DGX 시스템 아키텍처를 거의 모든 규모로 구현할 수 있습니다.  NetApp ONTAP 의 탁월한 클라우드 통합 및 소프트웨어 정의 기능과 결합된 AFF 성공적인 DL 프로젝트를 위해 에지, 코어 및 클라우드를 아우르는 광범위한 데이터 파이프라인을 지원합니다.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">추가 정보</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹사이트를 참조하세요.</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어 - ONTAP 정보 라이브러리</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">NetApp AFF A90 스토리지 시스템-</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">NetApp ONTAP RDMA 정보-</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetApp Trident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">NetApp GPUDirect 스토리지 블로그-</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">NVIDIA DGX H100 시스템</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">NVIDIA 네트워킹</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">NVIDIA Magnum IO&amp;#8482; GPUDirect&amp;#174; 스토리지</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">NVIDIA 베이스 명령</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">NVIDIA Base Command Manager</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AI 엔터프라이즈</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">이 문서는 NetApp Solutions 및 ONTAP Engineering 팀(David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar, Raghuram Sudhaakar)의 작품입니다.  저자는 또한 지속적인 지원을 해주신 NVIDIA 와 NVIDIA DGX BasePOD 엔지니어링 팀에 감사드리고 싶습니다.</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 배포</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 배포 세부 정보</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">이 섹션에서는 이 솔루션의 검증 과정에 사용된 배포 세부 정보를 설명합니다.  사용된 IP 주소는 예시이며 배포 환경에 따라 수정해야 합니다.  이 구성을 구현하는 데 사용된 특정 명령에 대한 자세한 내용은 해당 제품 설명서를 참조하세요.</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">아래 다이어그램은 1개의 DGX H100 시스템과 1개의 HA 쌍의 AFF A90 컨트롤러에 대한 자세한 네트워크 및 연결 정보를 보여줍니다.  다음 섹션의 배포 지침은 이 다이어그램의 세부 정보를 기반으로 합니다.</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">_NetApp AIpod 네트워크 구성_</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">다음 표는 최대 16개의 DGX 시스템과 2개의 AFF A90 HA 쌍에 대한 케이블 할당의 예를 보여줍니다.</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">스위치 및 포트</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">장치</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">장치 포트</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">switch1 포트 1-16</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01부터 -16까지</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0, 슬롯1 포트 1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">switch1 포트 17-32</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1, 슬롯1 포트 2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">switch1 포트 33-36</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01부터 -04까지</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">포트 e6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">switch1 포트 37-40</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">포트 e11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">switch1 포트 41-44</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">포트 e2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">switch1 포트 57-64</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISL에서 switch2로</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">포트 57-64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">스위치2 포트 1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0, 슬롯 2 포트 1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">스위치2 포트 17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1, 슬롯 2 포트 2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">스위치2 포트 33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">포트 e6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">스위치2 포트 37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">포트 e11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">스위치2 포트 41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">포트 e2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">스위치2 포트 57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISL에서 switch1로</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">다음 표는 이 검증에 사용된 다양한 구성 요소의 소프트웨어 버전을 보여줍니다.</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">소프트웨어 버전</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">NVIDIA SN4600 스위치</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">큐물러스 리눅스 v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">NVIDIA DGX 시스템</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">DGX OS v6.2.1(우분투 22.04 LTS)</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">멜라녹스 OFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24.01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">스토리지 네트워크 구성</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">NVIDIA Cumulus Linux 문서</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">이 섹션에서는 이더넷 저장 네트워크 구성에 대한 주요 세부 정보를 설명합니다.  InfiniBand 컴퓨팅 네트워크 구성에 대한 정보는 다음을 참조하세요.<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> .  스위치 구성에 대한 자세한 내용은 다음을 참조하세요.<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block> .</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">SN4600 스위치를 구성하는 데 사용되는 기본 단계는 아래와 같습니다.  이 프로세스에서는 케이블 연결과 기본 스위치 설정(관리 IP 주소, 라이선싱 등)이 완료되었다고 가정합니다.</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">스위치 간 ISL 본드를 구성하여 다중 링크 집계(MLAG) 및 장애 조치 트래픽을 활성화합니다.</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">이 검증에서는 테스트 중인 스토리지 구성에 충분한 대역폭을 제공하기 위해 8개의 링크를 사용했습니다.</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">MLAG 활성화에 대한 구체적인 지침은 Cumulus Linux 문서를 참조하세요.</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">두 스위치의 각 클라이언트 포트와 스토리지 포트 쌍에 대해 LACP MLAG를 구성합니다.</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">DGX-H100-01의 경우 각 스위치에 포트 swp17(enp170s0f1np1 및 enp41s0f1np1), DGX-H100-02의 경우 포트 swp18 등(bond1-16)</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">AFF-A90-01(e2a 및 e2b)의 경우 각 스위치에 포트 swp41, AFF-A90-02의 경우 포트 swp42 등(bond17-20)</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv set interface bondX bond member swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv set interface bondx bond mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">모든 포트와 MLAG 본드를 기본 브리지 도메인에 추가합니다.</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv set int swp1-16,33-40 브리지 도메인 br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv set int bond1-20 브리지 도메인 br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">각 스위치에서 RoCE 활성화</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv 세트 로체 모드 무손실</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">VLAN 구성 - 클라이언트 포트용 2개, 스토리지 포트용 2개, 관리용 1개, L3 스위치 간 스위치용 1개</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">스위치 1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">클라이언트 NIC 장애 발생 시 L3 스위치 간 라우팅을 위한 VLAN 3</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">각 DGX 시스템의 스토리지 포트 1에 대한 VLAN 101(enp170s0f0np0, slot1 포트 1)</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">각 AFF A90 스토리지 컨트롤러의 포트 e6a 및 e11a에 대한 VLAN 102</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">각 DGX 시스템 및 스토리지 컨트롤러에 대한 MLAG 인터페이스를 사용하여 관리하기 위한 VLAN 301</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">스위치 2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">각 DGX 시스템의 스토리지 포트 2에 대한 VLAN 201(enp41s0f0np0, slot2 포트 1)</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">각 AFF A90 스토리지 컨트롤러의 포트 e6b 및 e11b에 대한 VLAN 202</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">클라이언트 VLAN의 클라이언트 포트, 스토리지 VLAN의 스토리지 포트 등 각 VLAN에 적절한 물리적 포트를 할당합니다.</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv set int &lt;swpX&gt; 브리지 도메인 br_default 액세스 &lt;vlan id&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">필요에 따라 본딩된 인터페이스를 통해 여러 VLAN을 활성화하기 위해 MLAG 포트는 트렁크 포트로 유지되어야 합니다.</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">각 VLAN에 SVI(스위치 가상 인터페이스)를 구성하여 게이트웨이 역할을 하고 L3 라우팅을 활성화합니다.</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv set int vlan3 ip 주소 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv set int vlan101 ip 주소 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv set int vlan102 ip 주소 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv set int vlan3 ip 주소 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv set int vlan201 ip 주소 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv set int vlan202 ip 주소 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">정적 경로 생성</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">동일한 스위치의 서브넷에 대해 정적 경로가 자동으로 생성됩니다.</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">클라이언트 링크 장애 발생 시 스위치 간 라우팅을 위해 추가 정적 경로가 필요합니다.</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv set vrf 기본 라우터 정적 100.127.128.0/17 via 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv set vrf 기본 라우터 정적 100.127.0.0/17 via 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">스토리지 시스템 구성</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">ONTAP 문서</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">이 섹션에서는 이 솔루션을 위한 A90 스토리지 시스템 구성에 대한 주요 세부 정보를 설명합니다.  ONTAP 시스템 구성에 대한 자세한 내용은 다음을 참조하세요.<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block> .  아래 다이어그램은 저장 시스템의 논리적 구성을 보여줍니다.</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">저장 시스템을 구성하는 데 사용되는 기본 단계는 아래와 같습니다.  이 프로세스에서는 기본 스토리지 클러스터 설치가 완료되었다고 가정합니다.</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">사용 가능한 모든 파티션에서 1개의 예비 파티션을 뺀 각 컨트롤러에 1개의 집계를 구성합니다.</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;노드&gt; -aggregate &lt;노드&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">각 컨트롤러에서 ifgrps 구성</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">net port ifgrp create -node &lt;노드&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">net port ifgrp add-port -node &lt;노드&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;노드&gt;:e2a,&lt;노드&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">각 컨트롤러의 ifgrp에서 mgmt vlan 포트를 구성합니다.</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">넷 포트 VLAN 생성 -노드 aff-a90-01 -포트 a1a -vlan-id 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">넷 포트 VLAN 생성 -노드 aff-a90-02 -포트 a1a -vlan-id 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">넷 포트 VLAN 생성 -노드 aff-a90-03 -포트 a1a -vlan-id 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">넷 포트 VLAN 생성 -노드 aff-a90-04 -포트 a1a -vlan-id 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">브로드캐스트 도메인 생성</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">브로드캐스트 도메인 생성 -브로드캐스트 도메인 vlan21 -mtu 9000 -포트 aff-a90-01:e6a, aff-a90-01:e11a, aff-a90-02:e6a, aff-a90-02:e11a, aff-a90-03:e6a, aff-a90-03:e11a, aff-a90-04:e6a, aff-a90-04:e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">브로드캐스트 도메인 생성 -브로드캐스트 도메인 vlan22 -mtu 9000 -포트 aaff-a90-01:e6b, aff-a90-01:e11b, aff-a90-02:e6b, aff-a90-02:e11b, aff-a90-03:e6b, aff-a90-03:e11b, aff-a90-04:e6b, aff-a90-04:e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">브로드캐스트 도메인 생성 -브로드캐스트 도메인 vlan31 -mtu 9000 -포트 aff-a90-01:a1a-31,aff-a90-02:a1a-31,aff-a90-03:a1a-31,aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">관리 SVM 생성 *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">관리 SVM 구성</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">LIF 생성</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">FlexGroup 볼륨 생성-</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">vol create -vserver basepod-mgmt -volume home -size 10T -auto-provision-as flexgroup -junction-path /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">vol create -vserver basepod-mgmt -volume cm -size 10T -auto-provision-as flexgroup -junction-path /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">수출 정책 생성</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">export-policy 규칙 생성 -vserver basepod-mgmt -policy default -client-match 192.168.31.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">데이터 SVM 생성 *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">데이터 SVM 구성</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">RDMA 지원을 위한 SVM 구성</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs 수정 -vserver basepod-data -rdma 활성화</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">LIF를 생성하다</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -home-node aff-a90-01 -home-port e11a -address 100.127.102.103 -netmask 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -home-node aff-a90-01 -home-port e11b -address 100.127.202.103 -netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif2 -home-node aff-a90-02 -home-port e11a -address 100.127.102.108 -netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -home-node aff-a90-02 -home-port e11b -address 100.127.202.107 -netmask 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif2 -home-node aff-a90-02 -home-port e11b -address 100.127.202.108 -netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">RDMA 액세스를 위한 LIF 구성</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">ONTAP 9.15.1을 배포하는 경우 물리적 정보에 대한 RoCE QoS 구성에는 ONTAP CLI에서 사용할 수 없는 OS 수준 명령이 필요합니다.  RoCE 지원을 위한 포트 구성과 관련된 도움이 필요하면 NetApp 지원팀에 문의하세요.  RDMA를 통한 NFS는 문제없이 작동합니다.</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">ONTAP 9.16.1부터 물리적 인터페이스는 엔드투엔드 RoCE 지원을 위한 적절한 설정으로 자동으로 구성됩니다.</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int 수정 -vserver basepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">데이터 SVM에서 NFS 매개변수 구성</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs 수정 -vserver basepod-data -v4.1 활성화 -v4.1-pnfs 활성화 -v4.1-trunking 활성화 -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">FlexGroup 볼륨 생성-</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">vol create -vserver basepod-data -volume data -size 100T -auto-provision-as flexgroup -junction-path /data</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">수출 정책 생성</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">export-policy 규칙 생성 -vserver basepod-data -policy default -client-match 100.127.101.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">export-policy 규칙 생성 -vserver basepod-data -policy default -client-match 100.127.201.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">경로 생성</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">경로 추가 -vserver basepod_data -대상 100.127.0.0/17 -게이트웨이 100.127.102.1 메트릭 20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">경로 추가 -vserver basepod_data -대상 100.127.0.0/17 -게이트웨이 100.127.202.1 메트릭 30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">경로 추가 -vserver basepod_data -대상 100.127.128.0/17 -게이트웨이 100.127.202.1 메트릭 20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">경로 추가 -vserver basepod_data -대상 100.127.128.0/17 -게이트웨이 100.127.102.1 메트릭 30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">RoCE 스토리지 액세스를 위한 DGX H100 구성</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">BCM 문서</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">이 섹션에서는 DGX H100 시스템 구성에 대한 주요 세부 정보를 설명합니다.  이러한 구성 항목 중 다수는 DGX 시스템에 배포된 OS 이미지에 포함되거나 부팅 시 Base Command Manager에서 구현될 수 있습니다.  BCM에서 노드 및 소프트웨어 이미지 구성에 대한 자세한 내용은 참조용으로 여기에 나열되어 있습니다.<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block> .</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">추가 패키지 설치</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">아이피미툴</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">파이썬3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">Python 패키지 설치</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">파라미코</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">맷플롯립</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">패키지 설치 후 dpkg 재구성</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg --configure -a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">MOFED 설치</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">성능 튜닝을 위한 mst 값 설정</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; ADVANCED_PCI_SETTINGS=1 NUM_OF_VFS=0 MAX_ACC_OUT_READ=44로 설정</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">설정 수정 후 어댑터 재설정</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y 재설정</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">PCI 장치에 MaxReadReq 설정</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">RX 및 TX 링 버퍼 크기 설정</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; rx 8192 tx 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">mlnx_qos를 사용하여 PFC 및 DSCP 설정</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --케이블_길이=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">네트워크 포트의 RoCE 트래픽에 대한 ToS 설정</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">에코 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/트래픽_클래스</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">적절한 서브넷의 IP 주소로 각 스토리지 NIC를 구성합니다.</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">저장용 NIC 1의 경우 100.127.101.0/24</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">저장용 NIC 2의 경우 100.127.201.0/24</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">LACP 본딩을 위한 인밴드 네트워크 포트 구성(enp170s0f1np1, enp41s0f1np1)</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">각 스토리지 서브넷에 대한 기본 및 보조 경로에 대한 정적 경로를 구성합니다.</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">경로 추가 –net 100.127.0.0/17 gw 100.127.101.1 메트릭 20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">경로 추가 –net 100.127.0.0/17 gw 100.127.201.1 메트릭 30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">경로 추가 –net 100.127.128.0/17 gw 100.127.201.1 메트릭 20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">경로 추가 –net 100.127.128.0/17 gw 100.127.101.1 메트릭 30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">마운트 /home 볼륨</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">mount -o vers=3,nconnect=16,rsize=262144,wsize=262144 192.168.31.X:/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">/데이터 볼륨 마운트</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">데이터 볼륨을 마운트할 때 다음 마운트 옵션이 사용되었습니다.</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # 여러 스토리지 노드에 대한 병렬 액세스를 위해 pNFS를 활성화합니다.</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # 기본 TCP 대신 RDMA로 전송 프로토콜을 설정합니다.</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 # NFS 세션 트렁킹을 활성화하여 스토리지 포트 대역폭을 집계합니다.</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # 버퍼링된 쓰기의 쓰기 성능을 향상시킵니다.</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # I/O 전송 크기를 256k로 설정합니다.</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 하드웨어 구성 요소</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 하드웨어 구성 요소</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">이 섹션에서는 NVIDIA DGX 시스템이 탑재된 NetApp AIPod 의 하드웨어 구성 요소에 대해 중점적으로 설명합니다.</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">NetApp AFF 스토리지 시스템</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">NetApp AFF 최첨단 스토리지 시스템을 사용하면 IT 부서가 업계 최고의 성능, 뛰어난 유연성, 클라우드 통합, 동급 최고의 데이터 관리 기능을 통해 엔터프라이즈 스토리지 요구 사항을 충족할 수 있습니다.  플래시에 맞춰 특별히 설계된 AFF 시스템은 비즈니스에 중요한 데이터를 가속화하고 관리하며 보호하는 데 도움이 됩니다.</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">AFF A90 저장 시스템</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">NetApp ONTAP 데이터 관리 소프트웨어 기반의 NetApp AFF A90 내장형 데이터 보호 기능, 옵션으로 제공되는 랜섬웨어 방지 기능, 가장 중요한 비즈니스 워크로드를 지원하는 데 필요한 높은 성능과 복원력을 제공합니다.  이는 임무 수행에 중요한 운영의 중단을 제거하고, 성능 조정을 최소화하며, 랜섬웨어 공격으로부터 데이터를 보호합니다.  다음을 제공합니다. • 업계 최고의 성능 • 타협 없는 데이터 보안 • 간소화된 중단 없는 업그레이드</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">_NetApp AFF A90 스토리지 시스템_</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">업계 최고의 성능</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">AFF A90 딥 러닝, AI, 고속 분석과 같은 차세대 워크로드는 물론 Oracle, SAP HANA, Microsoft SQL Server, 가상화된 애플리케이션과 같은 기존 엔터프라이즈 데이터베이스도 쉽게 관리합니다.  이 솔루션은 HA 쌍당 최대 240만 IOPS와 최저 100µs의 대기 시간을 제공하여 비즈니스에 중요한 애플리케이션을 최고 속도로 실행하고 이전 NetApp 모델보다 성능을 최대 50%까지 향상시킵니다.  RDMA를 통한 NFS, pNFS 및 세션 트렁킹을 통해 고객은 기존 데이터 센터 네트워킹 인프라를 사용하여 차세대 애플리케이션에 필요한 높은 수준의 네트워크 성능을 달성할 수 있습니다.  고객은 SAN, NAS 및 개체 스토리지에 대한 통합된 다중 프로토콜 지원을 통해 확장하고 성장할 수 있으며, 온프레미스 또는 클라우드의 데이터에 대한 통합된 단일 ONTAP 데이터 관리 소프트웨어를 통해 최대한의 유연성을 제공할 수 있습니다.  또한 Active IQ 와 Cloud Insights 가 제공하는 AI 기반 예측 분석을 통해 시스템 상태를 최적화할 수 있습니다.</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">타협 없는 데이터 보안</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">AFF A90 시스템에는 NetApp 통합 및 애플리케이션 일관성을 갖춘 전체 데이터 보호 소프트웨어가 포함되어 있습니다.  이 솔루션은 사전 예방 및 공격 후 복구를 위한 내장형 데이터 보호 기능과 최첨단 랜섬웨어 방지 솔루션을 제공합니다.  악성 파일이 디스크에 기록되는 것을 차단할 수 있으며, 저장소 이상을 쉽게 모니터링하여 통찰력을 얻을 수 있습니다.</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">간소화된 무중단 업그레이드</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">AFF A90 기존 A800 고객에게 중단 없는 섀시 내부 업그레이드로 제공됩니다.  NetApp 고급 안정성, 가용성, 서비스 용이성 및 관리 용이성(RASM) 기능을 통해 임무 수행에 중요한 운영을 간편하게 갱신하고 중단을 제거할 수 있도록 지원합니다.  또한 NetApp ONTAP 소프트웨어가 모든 시스템 구성 요소에 대한 펌웨어 업데이트를 자동으로 적용하므로 운영 효율성을 더욱 높이고 IT 팀의 일상 업무를 간소화합니다.</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">가장 큰 규모의 배포의 경우, AFF A1K 시스템은 가장 높은 성능과 용량 옵션을 제공하는 반면, AFF A70, AFF C800 과 같은 다른 NetApp 스토리지 시스템은 더 낮은 비용으로 더 작은 규모의 배포를 위한 옵션을 제공합니다.</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD NVIDIA 하드웨어 및 소프트웨어 구성 요소, MLOps 솔루션, 타사 스토리지로 구성된 통합 솔루션입니다.  NVIDIA 제품과 검증된 파트너 솔루션을 통해 확장형 시스템 설계의 모범 사례를 활용함으로써 고객은 AI 개발을 위한 효율적이고 관리하기 쉬운 플랫폼을 구현할 수 있습니다.  그림 1은 NVIDIA DGX BasePOD 의 다양한 구성 요소를 강조하여 보여줍니다.</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">_NVIDIA DGX BasePOD 솔루션_</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">NVIDIA DGX H100 시스템</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">NVIDIA DGX H100&amp;#8482; 시스템은 NVIDIA H100 Tensor Core GPU의 획기적인 성능으로 가속화된 AI 강자입니다.</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">_NVIDIA DGX H100 시스템_</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">DGX H100 시스템의 주요 사양은 다음과 같습니다. • 8개의 NVIDIA H100 GPU.  • GPU당 80GB GPU 메모리, 총 640GB.  • NVIDIA NVSwitch 칩 4개.  • PCIe 5.0을 지원하는 듀얼 56코어 Intel Xeon Platinum 8480 프로세서.  • 2TB DDR5 시스템 메모리.  • 8개의 싱글 포트 NVIDIA ConnectX&amp;#174;-7(InfiniBand/Ethernet) 어댑터와 2개의 듀얼 포트 NVIDIA ConnectX-7(InfiniBand/Ethernet) 어댑터를 제공하는 4개의 OSFP 포트.  • DGX OS용 1.92TB M.2 NVMe 드라이브 2개, 스토리지/캐시용 3.84TB U.2 NVMe 드라이브 8개.  • 최대 전력 10.2kW.  DGX H100 CPU 트레이의 후면 포트는 아래와 같습니다.  OSFP 포트 4개는 InfiniBand 컴퓨팅 패브릭을 위한 8개의 ConnectX-7 어댑터를 지원합니다.  각 듀얼 포트 ConnectX-7 어댑터 쌍은 스토리지 및 관리 패브릭에 대한 병렬 경로를 제공합니다.  대역 외 포트는 BMC 액세스에 사용됩니다.</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_NVIDIA DGX H100 후면 패널_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">NVIDIA Quantum-2 QM9700 스위치</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_NVIDIA Quantum-2 QM9700 InfiniBand 스위치_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">400Gb/s InfiniBand 연결 기능을 갖춘 NVIDIA Quantum-2 QM9700 스위치는 NVIDIA Quantum-2 InfiniBand BasePOD 구성의 컴퓨팅 패브릭에 전원을 공급합니다.  ConnectX-7 단일 포트 어댑터는 InfiniBand 컴퓨팅 패브릭에 사용됩니다.  각 NVIDIA DGX 시스템은 각 QM9700 스위치에 이중으로 연결되어 있어 시스템 간에 여러 개의 고대역폭, 저지연 경로를 제공합니다.</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">NVIDIA Spectrum-3 SN4600 스위치</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_NVIDIA Spectrum-3 SN4600 스위치_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">NVIDIA Spectrum&amp;#8482;-3 SN4600 스위치는 총 128개의 포트(스위치당 64개)를 제공하여 DGX BasePOD의 대역 내 관리를 위한 중복 연결을 제공합니다.  NVIDIA SN4600 스위치는 1GbE~200GbE 사이의 속도를 제공할 수 있습니다.  이더넷을 통해 연결된 스토리지 어플라이언스의 경우 NVIDIA SN4600 스위치도 사용됩니다.  NVIDIA DGX 듀얼 포트 ConnectX-7 어댑터의 포트는 대역 내 관리와 스토리지 연결에 모두 사용됩니다.</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">NVIDIA Spectrum SN2201 스위치</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">_NVIDIA Spectrum SN2201 스위치_</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">NVIDIA Spectrum SN2201 스위치는 대역 외 관리를 위한 연결을 제공하기 위해 48개의 포트를 제공합니다.  대역 외 관리 기능은 DGX BasePOD의 모든 구성 요소에 대한 통합 관리 연결을 제공합니다.</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">NVIDIA ConnectX-7 어댑터</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_NVIDIA ConnectX-7 어댑터_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">NVIDIA ConnectX-7 어댑터는 25/50/100/200/400G의 처리량을 제공할 수 있습니다.  NVIDIA DGX 시스템은 단일 및 이중 포트 ConnectX-7 어댑터를 모두 사용하여 400Gb/s InfiniBand 및 이더넷을 통한 DGX BasePOD 배포에 유연성을 제공합니다.</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">NVIDIA DGX 시스템이 탑재된 NetApp AIPod 는 NetApp ONTAP AFF 스토리지 시스템과 NVIDIA 네트워킹 및 DGX 시스템을 사용하여 딥 러닝 및 인공 지능을 위한 NVIDIA BasePOD 기반의 엔터프라이즈급 참조 아키텍처입니다.</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 소개</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200, 오류: 그래픽 이미지가 없습니다</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">NetApp 솔루션 엔지니어링</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">NVIDIA DGX™ 시스템과 NetApp 클라우드 연결 스토리지 시스템을 탑재한 NetApp&amp;#8482; AIPod 설계 복잡성과 추측을 제거하여 머신 러닝(ML) 및 인공 지능(AI) 워크로드를 위한 인프라 배포를 간소화합니다.  차세대 워크로드에 탁월한 컴퓨팅 성능을 제공하도록 설계된 NVIDIA DGX BasePOD&amp;#8482;를 기반으로 하는 NVIDIA DGX 시스템을 탑재한 AIPod 는 NetApp AFF 스토리지 시스템을 추가하여 고객이 소규모로 시작하여 중단 없이 확장할 수 있도록 하는 동시에 엣지에서 코어, 클라우드로 데이터를 지능적으로 관리할 수 있도록 합니다.  NetApp AIPod 아래 그림에 표시된 대로 NetApp AI 솔루션의 더 큰 포트폴리오의 일부입니다.</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_NetApp AI 솔루션 포트폴리오_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">이 문서에서는 AIPod 참조 아키텍처의 주요 구성 요소, 시스템 연결 및 구성 정보, 검증 테스트 결과, 솔루션 크기 조정 지침을 설명합니다.  이 문서는 ML/DL 및 분석 워크로드를 위한 고성능 인프라를 구축하는 데 관심이 있는 NetApp 및 파트너 솔루션 엔지니어와 고객 전략적 의사 결정자를 대상으로 합니다.</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 소프트웨어 구성 요소</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 소프트웨어 구성 요소</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">이 섹션에서는 NVIDIA DGX 시스템이 탑재된 NetApp AIPod 의 소프트웨어 구성 요소에 대해 중점적으로 설명합니다.</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">NVIDIA 소프트웨어</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command&amp;#8482;는 모든 DGX BasePOD를 구동하여 조직이 NVIDIA 소프트웨어 혁신의 장점을 최대한 활용할 수 있도록 지원합니다.  기업은 엔터프라이즈급 오케스트레이션 및 클러스터 관리, 컴퓨팅, 스토리지 및 네트워크 인프라를 가속화하는 라이브러리, AI 워크로드에 최적화된 운영 체제(OS)를 포함하는 검증된 플랫폼을 통해 투자의 잠재력을 최대한 발휘할 수 있습니다.</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_NVIDIA BaseCommand 솔루션_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU 클라우드(NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC는 다양한 수준의 AI 전문 지식을 갖춘 데이터 과학자, 개발자, 연구자의 요구를 충족하는 소프트웨어를 제공합니다.  NGC에 호스팅된 소프트웨어는 공통적인 취약성 및 노출(CVE), 암호 및 개인 키의 집계된 집합에 대한 검사를 거칩니다.  DGX 시스템은 여러 GPU에 확장 가능하고, 많은 경우 다중 노드에 확장 가능하도록 테스트 및 설계되어 사용자가 DGX 시스템에 대한 투자를 극대화할 수 있도록 보장합니다.</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_NVIDIA GPU 클라우드_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise는 모든 기업이 생성적 AI를 활용할 수 있도록 하는 엔드 투 엔드 소프트웨어 플랫폼으로, NVIDIA DGX 플랫폼에서 실행되도록 최적화된 생성적 AI 기반 모델을 위한 가장 빠르고 효율적인 런타임을 제공합니다.  프로덕션 수준의 보안, 안정성, 관리 용이성을 갖춰 생성적 AI 솔루션 개발을 간소화합니다.  NVIDIA AI Enterprise는 DGX BasePOD에 포함되어 기업 개발자가 사전 학습된 모델, 최적화된 프레임워크, 마이크로서비스, 가속 라이브러리 및 기업 지원에 액세스할 수 있도록 합니다.</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">NetApp 소프트웨어</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">NetApp 의 최신 스토리지 관리 소프트웨어인 ONTAP 9를 사용하면 기업이 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다.  ONTAP 업계 최고의 데이터 관리 역량을 활용하여 데이터가 어디에 있든 단일 도구 세트를 사용하여 데이터를 관리하고 보호할 수 있도록 지원합니다.  또한 필요한 곳, 즉 엣지, 코어, 클라우드로 데이터를 자유롭게 이동할 수 있습니다.  ONTAP 9에는 데이터 관리를 간소화하고, 중요 데이터를 가속화하고 보호하며, 하이브리드 클라우드 아키텍처 전반에서 차세대 인프라 기능을 구현하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">데이터 가속화 및 보호</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP 뛰어난 수준의 성능과 데이터 보호 기능을 제공하며 다음과 같은 방식으로 이러한 기능을 확장합니다.</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">성능과 낮은 지연 시간.  ONTAP RDMA를 통한 NFS, 병렬 NFS(pNFS), NFS 세션 트렁킹을 사용하는 NVIDIA GPUDirect Storage(GDS)에 대한 지원을 포함하여 가능한 가장 낮은 지연 시간으로 가능한 가장 높은 처리량을 제공합니다.</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">데이터 보호.  ONTAP 모든 플랫폼에서 공통적으로 관리 가능하며, 내장형 데이터 보호 기능과 업계에서 가장 강력한 랜섬웨어 방지 기능을 제공합니다.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetApp 볼륨 암호화(NVE).  ONTAP 온보드 및 외부 키 관리 지원을 통해 기본 볼륨 수준 암호화를 제공합니다.</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">스토리지 멀티테넌시 및 다중 요소 인증.  ONTAP 최고 수준의 보안을 통해 인프라 리소스를 공유할 수 있도록 합니다.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">데이터 관리 간소화</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">적절한 리소스가 AI 애플리케이션과 AI/ML 데이터 세트 교육에 사용될 수 있도록 기업 IT 운영과 데이터 과학자에게 데이터 관리가 매우 중요합니다.  NetApp 기술에 대한 다음 추가 정보는 이 검증 범위를 벗어나지만 배포에 따라 관련이 있을 수 있습니다.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">ONTAP 데이터 관리 소프트웨어에는 다음과 같은 기능이 포함되어 있어 운영을 간소화하고 단순화하며 총 운영 비용을 절감할 수 있습니다.</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">스냅샷과 클론을 사용하면 ML/DL 워크플로에 대한 협업, 병렬 실험 및 향상된 데이터 거버넌스가 가능합니다.</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror 하이브리드 클라우드와 다중 사이트 환경에서 원활한 데이터 이동을 지원하여 필요한 곳에 필요한 시간에 데이터를 제공합니다.</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">인라인 데이터 압축 및 확장된 중복 제거.  데이터 압축은 저장 블록 내부의 낭비되는 공간을 줄이고, 중복 제거는 효과적인 용량을 크게 증가시킵니다.  이는 로컬에 저장된 데이터와 클라우드에 계층화된 데이터 모두에 적용됩니다.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">최소, 최대 및 적응형 서비스 품질(AQoS).  세분화된 서비스 품질(QoS) 제어는 공유 빈도가 높은 환경에서 중요한 애플리케이션의 성능 수준을 유지하는 데 도움이 됩니다.</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">NetApp FlexGroups를 사용하면 스토리지 클러스터의 모든 노드에 데이터를 분산하여 대규모 데이터 세트에 대해 막대한 용량과 더 높은 성능을 제공할 수 있습니다.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: FabricPool 모범 사례</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool.  Amazon Web Services(AWS), Azure, NetApp StorageGRID 스토리지 솔루션을 포함한 퍼블릭 및 프라이빗 클라우드 스토리지 옵션에 콜드 데이터의 자동 계층화를 제공합니다.  FabricPool 에 대한 자세한 내용은 다음을 참조하세요.<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block> .</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache.  파일 배포를 간소화하고, WAN 지연 시간을 줄이고, WAN 대역폭 비용을 낮추는 원격 볼륨 캐싱 기능을 제공합니다.  FlexCache 사용하면 여러 사이트에 걸쳐 분산된 제품 개발을 수행할 수 있을 뿐만 아니라 원격 위치에서도 회사 데이터 세트에 더 빨리 액세스할 수 있습니다.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">미래 지향적 인프라</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP 다음과 같은 기능을 통해 까다롭고 끊임없이 변화하는 비즈니스 요구 사항을 충족하는 데 도움이 됩니다.</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">원활한 확장과 중단 없는 운영.  ONTAP 기존 컨트롤러와 확장형 클러스터에 용량을 온라인으로 추가하는 것을 지원합니다.  고객은 비용이 많이 드는 데이터 마이그레이션이나 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">클라우드 연결.  ONTAP 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지(ONTAP Select)와 클라우드 기반 인스턴스(Google Cloud NetApp Volumes)에 대한 옵션을 제공하는 가장 클라우드에 연결된 스토리지 관리 소프트웨어입니다.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">새로운 애플리케이션과의 통합.  ONTAP 기존 엔터프라이즈 앱을 지원하는 동일한 인프라를 사용하여 자율주행차, 스마트 시티, 산업 4.0과 같은 차세대 플랫폼과 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">NetApp DataOps Toolkit은 고성능, 확장형 NetApp 스토리지에 의해 지원되는 개발/교육 작업 공간과 추론 서버의 관리를 간소화하는 Python 기반 도구입니다.  DataOps Toolkit은 독립형 유틸리티로 작동할 수 있으며 NetApp Trident 활용하여 스토리지 작업을 자동화하는 Kubernetes 환경에서 더욱 효과적입니다.  주요 기능은 다음과 같습니다.</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">고성능, 확장형 NetApp 스토리지로 지원되는 새로운 대용량 JupyterLab 작업 공간을 빠르게 프로비저닝하세요.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">엔터프라이즈급 NetApp 스토리지로 지원되는 새로운 NVIDIA Triton Inference Server 인스턴스를 빠르게 프로비저닝하세요.</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">실험이나 빠른 반복을 가능하게 하기 위해 대용량 JupyterLab 작업 공간을 거의 즉각적으로 복제합니다.</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">대용량 JupyterLab 작업 공간의 거의 즉각적인 스냅샷을 백업 및/또는 추적/기준 설정에 사용할 수 있습니다.</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">대용량, 고성능 데이터 볼륨에 대한 거의 즉각적인 프로비저닝, 복제 및 스냅샷이 가능합니다.</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident Anthos를 포함한 컨테이너와 Kubernetes 배포판을 위한 완벽하게 지원되는 오픈 소스 스토리지 오케스트레이터입니다. Trident NetApp ONTAP 포함한 전체 NetApp 스토리지 포트폴리오와 호환되며 NFS, NVMe/TCP 및 iSCSI 연결도 지원합니다. Trident 최종 사용자가 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝하고 관리할 수 있도록 하여 DevOps 워크플로를 가속화합니다.</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 솔루션 검증 및 크기 조정 지침</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 솔루션 검증 및 크기 조정 지침</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">이 섹션에서는 NVIDIA DGX 시스템을 사용하는 NetApp AIPod 에 대한 솔루션 검증 및 크기 조정 지침에 중점을 둡니다.</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">솔루션 검증</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">이 솔루션의 스토리지 구성은 오픈 소스 도구인 FIO를 사용하여 일련의 합성 워크로드를 통해 검증되었습니다.  이러한 테스트에는 DGX 시스템이 딥 러닝 학습 작업을 수행하면서 생성되는 스토리지 작업 부하를 시뮬레이션하기 위한 읽기 및 쓰기 I/O 패턴이 포함됩니다.  DGX 시스템 클러스터를 시뮬레이션하기 위해 FIO 워크로드를 동시에 실행하는 2소켓 CPU 서버 클러스터를 사용하여 스토리지 구성을 검증했습니다.  각 클라이언트는 이전에 설명한 것과 동일한 네트워크 구성으로 구성되었으며, 다음 세부 정보가 추가되었습니다.</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">이 검증에는 다음 마운트 옵션이 사용되었습니다.</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">버전=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">여러 스토리지 노드에 대한 병렬 액세스를 위해 pNFS를 활성화합니다.</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">프로토=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">기본 TCP 대신 RDMA로 전송 프로토콜을 설정합니다.</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">포트=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">RDMA NFS 서비스에 대한 올바른 포트를 지정하세요</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">최대 연결=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">NFS 세션 트렁킹을 통해 스토리지 포트 대역폭을 집계할 수 있습니다.</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">쓰기=열망</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">버퍼링된 쓰기의 쓰기 성능을 향상시킵니다.</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144, wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">I/O 전송 크기를 256k로 설정합니다.</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">또한 클라이언트는 NFS max_session_slots 값이 1024로 구성되었습니다.  NFS over RDMA를 사용하여 솔루션을 테스트했으므로 스토리지 네트워크 포트는 액티브/패시브 본드로 구성되었습니다.  이 검증에는 다음과 같은 결합 매개변수가 사용되었습니다.</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">모드=활성 백업</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">결합을 활성/수동 모드로 설정합니다</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primary=&lt;인터페이스 이름&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">모든 클라이언트의 기본 인터페이스는 스위치에 분산되었습니다.</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">mii-모니터-간격=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">100ms의 모니터링 간격을 지정합니다.</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">fail-over-mac-policy=active</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">활성 링크의 MAC 주소가 본드의 MAC임을 지정합니다.  이는 본딩된 인터페이스를 통한 RDMA의 적절한 작동에 필요합니다.</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">스토리지 시스템은 각 HA 쌍에 24개의 1.9TB NVMe 디스크 드라이브가 연결된 2개의 NS224 디스크 셸프와 함께 2개의 A900 HA 쌍(컨트롤러 4개)으로 구성된 것과 같이 구성되었습니다.  아키텍처 섹션에서 설명한 대로 모든 컨트롤러의 저장 용량은 FlexGroup 볼륨을 사용하여 결합되었으며 모든 클라이언트의 데이터는 클러스터의 모든 컨트롤러에 분산되었습니다.</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">스토리지 시스템 크기 지침</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp DGX BasePOD 인증을 성공적으로 완료했으며, 테스트된 두 개의 A90 HA 쌍은 16개의 DGX H100 시스템 클러스터를 쉽게 지원할 수 있습니다.  더 높은 스토리지 성능 요구 사항이 있는 대규모 배포의 경우 NetApp ONTAP 클러스터에 최대 12개의 HA 쌍(24개 노드)까지 추가 AFF 시스템을 추가할 수 있습니다.  이 솔루션에 설명된 FlexGroup 기술을 사용하면 24노드 클러스터가 단일 네임스페이스에서 79PB 이상과 최대 552GBps의 처리량을 제공할 수 있습니다.  AFF A400 , A250 및 C800과 같은 다른 NetApp 스토리지 시스템은 더 낮은 비용으로 더 작은 규모의 배포에 대해 더 낮은 성능 및/또는 더 큰 용량 옵션을 제공합니다.  ONTAP 9는 혼합 모델 클러스터를 지원하므로 고객은 처음에는 작은 공간으로 시작한 후 용량과 성능 요구 사항이 증가함에 따라 클러스터에 더 많거나 더 큰 스토리지 시스템을 추가할 수 있습니다.  아래 표는 각 AFF 모델에서 지원되는 A100 및 H100 GPU의 수를 대략적으로 추정한 것입니다.</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">_NetApp 스토리지 시스템 크기 조정 지침_</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">E-Series 스토리지를 갖춘 NetApp 의 BeeGFS</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">E-Series 스토리지가 탑재된 NetApp 의 BeeGFS는 간단하고, 안정적이며, 확장 가능하고, 비용 효율적인 HPC 인프라를 갖춘 검증된 통합 솔루션으로, 가장 극한의 작업 부하에도 대응할 수 있습니다.</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY: NetApp E-Series 시스템을 사용한 Quantum StorNext 배포 가이드</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">Ryan Rodine, NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">이 문서에서는 NetApp E-Series 스토리지 시스템에 StorNext 병렬 파일 시스템 솔루션을 배포하는 방법에 대한 자세한 내용을 제공합니다.  이 솔루션은 NetApp EF280 올플래시 어레이, NetApp EF300 올플래시 NVMe 어레이, NetApp EF600 올플래시 NVMe 어레이 및 NetApp E5760 하이브리드 시스템을 포함합니다.  이 솔루션은 미디어 및 엔터테인먼트 산업에서 테스트에 널리 사용되는 도구인 Frametest 벤치마킹을 기반으로 성능 특성을 제공합니다.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN: NetApp E-Series 시스템을 탑재한 Quantum StorNext 설계 가이드</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">이 문서에서는 NetApp E-Series 스토리지 시스템을 사용하여 StorNext 병렬 파일 시스템 솔루션을 설계하는 방법에 대한 자세한 내용을 제공합니다.  이 솔루션은 NetApp EF280 올플래시 어레이, NetApp EF300 올플래시 NVMe 어레이, EF600 올플래시 NVMe 어레이 및 NetApp E5760 하이브리드 시스템을 포함합니다.  이 솔루션은 미디어 및 엔터테인먼트 산업에서 테스트에 널리 사용되는 도구인 Frametest 벤치마킹을 기반으로 성능 특성을 제공합니다.</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: NetApp E-Series 스토리지를 사용한 IBM Spectrum Scale 배포 - 설치 및 검증</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">크리스 세이러, NetApp</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859는 IBM의 Spectrum Scale 소프트웨어 스택을 기반으로 전체 병렬 파일 시스템 솔루션을 배포하는 프로세스를 설명합니다.  TR-4859는 Spectrum Scale을 설치하는 방법, 인프라를 검증하는 방법, 구성을 관리하는 방법에 대한 세부 정보를 제공하도록 설계되었습니다.</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">이 NetApp 검증 아키텍처는 NetApp BeeGFS 구성 요소를 갖춘 NVIDIA DGX SuperPOD 의 디자인을 설명합니다.  이 솔루션은 NVIDIA 의 전담 수용 클러스터에서 검증된 풀스택 데이터 센터 플랫폼입니다.</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NetApp 탑재한 NVIDIA DGX SuperPOD - 디자인 가이드</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">이 NetApp 검증 아키텍처는 NetApp BeeGFS 구성 요소를 갖춘 NVIDIA DGX SuperPOD 의 디자인을 설명합니다.  이 솔루션은 NVIDIA 의 전담 수용 클러스터에서 검증된 풀스택 데이터 센터 플랫폼입니다.</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200,200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">아민 베나니, 크리스찬 화이트사이드, 데이비드 아넷, 사티시 티아가라잔, NetApp</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">요약</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">오늘날 빠르게 변화하는 기술 환경 속에서 AI는 소비자 경험을 혁신하고 모든 산업 분야에서 혁신을 주도하고 있습니다.  그러나 이는 AI 워크로드의 엄청난 수요를 처리할 수 있는 고성능 컴퓨팅(HPC) 솔루션을 구축해야 하는 압박을 받는 IT 부서에 상당한 과제를 안겨줍니다.  조직들이 AI의 힘을 활용하기 위해 경쟁함에 따라, 배포, 확장, 관리가 쉬운 솔루션에 대한 시급성이 커지고 있습니다.</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPOD 오늘날 기업이 직면한 가장 복잡한 AI 워크로드를 지원하는 턴키 솔루션으로 IT 부서에 제공되는 AI 데이터 센터 인프라 플랫폼입니다.  정확한 딥 러닝(DL) 모델의 핵심은 방대한 양의 데이터이며, 이 데이터를 효율적으로 제공하고 다시 저장할 수 있는 고처리량 저장 솔루션이 필요합니다.  NetApp EF600 스토리지 어레이와 BeeGFS 병렬 파일 시스템으로 구성된 NetApp BeeGFS 솔루션을 통해 NVIDIA DGX SuperPOD 모든 기능을 최대한 활용할 수 있습니다.  NetApp BeeGFS 솔루션은 NVIDIA 로부터 SuperPOD 아키텍처와 통합되고 확장 가능한 것으로 검증되었습니다.  그 결과, 성능과 용량 측면에서 사실상 무제한적인 확장성을 제공하는 동시에 AI 데이터 센터 구축 및 관리가 간소화되었습니다.</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">고성능 NetApp EF600 NVMe 스토리지 시스템과 확장 가능한 BeeGFS 병렬 파일 시스템으로 구동되는 NetApp BeeGFS 솔루션은 까다로운 AI 워크로드를 위한 강력하고 효율적인 스토리지 기반을 제공합니다.  공유 디스크 아키텍처는 시스템 문제에도 불구하고 높은 가용성을 보장하고 일관된 성능과 접근성을 유지합니다.  이 솔루션은 다양한 스토리지 요구 사항을 충족하도록 사용자 정의가 가능한 확장 가능하고 유연한 아키텍처를 제공합니다.  고객은 추가 스토리지 구성 요소를 통합하여 가장 까다로운 작업 부하도 처리할 수 있으므로 스토리지 성능과 용량을 쉽게 확장할 수 있습니다.</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD 검증된 외부 연결 공유 스토리지를 갖춘 DGX H100 및 H200 시스템을 활용합니다.</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">각 DGX SuperPOD 확장 가능 유닛(SU)은 32개의 DGX 시스템으로 구성되어 있으며 FP8 정밀도에서 640페타플롭스의 AI 성능을 구현할 수 있습니다.  NetApp 단일 DGX SuperPOD 구성에 대해 최소 2개의 빌딩 블록으로 NetApp BeeGFS 스토리지 솔루션의 크기를 조정할 것을 권장합니다.</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_솔루션에 대한 상위 수준 보기_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">NVIDIA DGX SuperPOD 사용한 NetApp BeeGFS 솔루션의 개요를 보여주는 그림입니다.</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">NetApp BeeGFS 구성 요소는 두 개의 NetApp EF600 어레이와 두 개의 x86 서버로 구성됩니다.</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">NVIDIA DGX SuperPOD 의 기반이 되는 NetApp EF600 올플래시 어레이를 통해 고객은 99.999%의 가동 시간을 보장하는 안정적인 스토리지 기반을 확보할 수 있습니다.</block>
  <block id="23830778b135794055062035d895d122" category="list-text">NetApp EF600과 NVIDIA DGX 시스템 사이의 파일 시스템 계층은 BeeGFS 병렬 파일 시스템입니다.  BeeGFS는 독일의 Fraunhofer 고성능 컴퓨팅 센터에서 기존 병렬 파일 시스템의 문제점을 해결하기 위해 만들어졌습니다.  그 결과, ThinkParQ가 개발하여 제공하고 많은 슈퍼컴퓨팅 환경에서 사용되는 현대적인 사용자 공간 아키텍처를 갖춘 파일 시스템이 탄생했습니다.</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">BeeGFS에 대한 NetApp 지원은 NetApp의 탁월한 지원 조직을 성능 및 가동 시간에 대한 고객 요구 사항에 맞춰 조정합니다.  고객은 우수한 지원 리소스, BeeGFS 릴리스에 대한 조기 액세스, 할당량 적용 및 고가용성(HA)과 같은 일부 BeeGFS 엔터프라이즈 기능에 대한 액세스 권한을 얻습니다.</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">NVIDIA SuperPOD SU와 NetApp BeeGFS 구성 요소를 결합하면 컴퓨팅이나 스토리지가 쉽고 원활하게 확장되는 민첩한 AI 솔루션이 제공됩니다.</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">_NetApp BeeGFS 구성 요소_</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">단일 NetApp BeeGFS 빌딩 블록을 보여주는 그림입니다.</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">사용 사례 요약</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">이 솔루션은 다음과 같은 사용 사례에 적용됩니다.</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">머신 러닝(ML), 딥 러닝(DL), 자연어 처리(NLP), 자연어 이해(NLU), 생성 AI(GenAI)를 포함한 인공 지능(AI)입니다.</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">중대규모 AI 훈련</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">컴퓨터 비전, 음성, 오디오 및 언어 모델</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">MPI(메시지 전달 인터페이스) 및 기타 분산 컴퓨팅 기술을 통해 가속화된 애플리케이션을 포함하는 HPC</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">다음과 같은 특징을 갖는 애플리케이션 작업 부하:</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">1GB보다 큰 파일을 읽거나 쓰기</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">여러 클라이언트(10대, 100대, 1000대)가 동일한 파일을 읽거나 쓰는 경우</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">멀티테라바이트 또는 멀티페타바이트 규모의 데이터 세트</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">크고 작은 파일의 혼합에 최적화할 수 있는 단일 스토리지 네임스페이스가 필요한 환경</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">이 섹션에서는 NetApp 솔루션이 포함된 NVIDIA DGX SuperPOD 에 대한 기술 요구 사항을 다룹니다.</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">NVIDIA DGX H100 SuperPOD 참조 아키텍처</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN: NetApp NVA Design의 BeeGFS</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">아래 표 1은 단일 SU에 대한 솔루션을 구현하는 데 필요한 하드웨어 구성 요소를 나열합니다.  솔루션 규모는 32개의 NVIDIA DGX H100 시스템과 2~3개의 NetApp BeeGFS 빌딩 블록으로 시작됩니다.  단일 NetApp BeeGFS 빌딩 블록은 두 개의 NetApp EF600 어레이와 두 개의 x86 서버로 구성됩니다.  고객은 배포 규모가 커짐에 따라 추가 빌딩 블록을 추가할 수 있습니다.  자세한 내용은 다음을 참조하세요.<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block> 그리고<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block> .</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 또는 H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">NVIDIA Quantum QM9700 스위치</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">잎 8개, 가시 4개</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">NetApp BeeGFS 구성 요소</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">아래 표 2는 솔루션을 구현하는 데 필요한 소프트웨어 구성 요소를 나열합니다.  솔루션의 특정 구현에 사용되는 소프트웨어 구성 요소는 고객 요구 사항에 따라 달라질 수 있습니다.</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">NVIDIA DGX 소프트웨어 스택</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">ThinkParQ BeeGFS 병렬 파일 시스템</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">솔루션 검증</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD: NetApp EF600 및 BeeGFS 참조 아키텍처</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NetApp 탑재된 NVIDIA DGX SuperPOD NetApp BeeGFS 구성 요소를 사용하여 NVIDIA 의 전담 수용 클러스터에서 검증되었습니다.  승인 기준은 NVIDIA 가 수행한 일련의 애플리케이션, 성능 및 스트레스 테스트를 기반으로 합니다. 자세한 내용은 다음을 참조하세요.<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block> .</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetApp 과 NVIDIA 시장에 AI 솔루션 포트폴리오를 제공하기 위해 오랫동안 협력해 왔습니다.  NetApp EF600 올플래시 어레이를 탑재한 NVIDIA DGX SuperPOD 고객이 확신을 가지고 배포할 수 있는 검증되고 확인된 솔루션입니다.  완벽하게 통합된 턴키 아키텍처는 배포 시 발생하는 위험을 제거하고 누구나 AI 리더십 경쟁에서 승리할 수 있는 길로 나아갈 수 있도록 해줍니다.</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">NVIDIA DGX SuperPOD 참조 아키텍처</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">NVIDIA DGX SuperPOD 데이터 센터 설계 참조 가이드</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD: NetApp EF600 및 BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">AI 기반 자동화 및 엣지 컴퓨팅은 기업 조직이 디지털 전환을 달성하고 운영 효율성과 안전성을 극대화하는 데 도움이 되는 선도적인 접근 방식입니다.  엣지 컴퓨팅을 사용하면 데이터가 데이터 센터로 이동하거나 데이터 센터에서 전송되지 않으므로 훨씬 빠르게 처리됩니다.  따라서 데이터 센터나 클라우드로 데이터를 주고받는 데 드는 비용이 절감됩니다.</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">AI 기반 자동화 및 엣지 컴퓨팅은 기업 조직이 디지털 전환을 달성하고 운영 효율성과 안전성을 극대화하는 데 도움이 되는 선도적인 접근 방식입니다.  엣지 컴퓨팅을 사용하면 데이터가 데이터 센터로 이동하거나 데이터 센터에서 전송되지 않으므로 훨씬 빠르게 처리됩니다.  따라서 데이터 센터나 클라우드로 데이터를 주고받는 데 드는 비용이 절감됩니다.  기업이 엣지에 구축된 AI 추론 모델을 사용하여 거의 실시간으로 의사 결정을 내려야 하는 경우, 지연 시간을 줄이고 속도를 높이는 것이 유익할 수 있습니다.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp 스토리지 시스템은 로컬 SSD 스토리지와 동일하거나 더 나은 성능을 제공하며 데이터 과학자, 데이터 엔지니어, AI/ML 개발자, 비즈니스 또는 IT 의사 결정권자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">AI 시스템, 분석 및 기타 중요 비즈니스 시스템 간에 데이터를 손쉽게 공유할 수 있습니다.  이러한 데이터 공유를 통해 인프라 오버헤드가 줄어들고, 성능이 향상되며, 기업 전체의 데이터 관리가 간소화됩니다.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">비용을 최소화하고 리소스 사용을 개선하기 위해 독립적으로 확장 가능한 컴퓨팅 및 스토리지.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">즉각적이고 공간 효율적인 사용자 작업 공간, 통합 버전 제어, 자동화된 배포를 위한 통합 스냅샷 복사본과 복제를 사용하여 개발 및 배포 워크플로를 간소화합니다.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">재해 복구 및 비즈니스 연속성을 위한 엔터프라이즈급 데이터 보호.  이 문서에 소개된 NetApp 과 Lenovo 솔루션은 엣지에서 엔터프라이즈급 AI 추론을 배포하는 데 이상적인 유연하고 확장 가능한 아키텍처입니다.</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">감사의 말</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">제이제이  Falkanger, Lenovo HPC 및 AI 솔루션 수석 관리자</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, NetApp 기술 마케팅 엔지니어</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, NetApp E-Series AI 솔루션 기술 책임자</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">코디 해리먼, NetApp QA 엔지니어</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹사이트를 참조하세요.</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A-시리즈 어레이 제품 페이지</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어 ONTAP 9 정보 라이브러리</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: NetApp EF 시리즈 소개</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E-시리즈 SANtricity 소프트웨어 데이터시트</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">컨테이너용 NetApp 영구 스토리지 NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow 벤치마크</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">레노버 ThinkSystem SE350 엣지 서버</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">레노버 ThinkSystem DM5100F 통합 플래시 스토리지 어레이</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">이 섹션에서는 테스트된 구성, 네트워크 인프라, SE350 서버 및 스토리지 프로비저닝 세부 정보를 설명합니다.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">테스트 구성</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">다음 그림은 테스트 구성을 보여줍니다.  NetApp AFF C190 스토리지 시스템과 두 대의 Lenovo ThinkSystem SE350 서버(각각 NVIDIA T4 가속기 1개 장착)를 사용했습니다.  이러한 구성 요소는 10GbE 네트워크 스위치를 통해 연결됩니다.  네트워크 저장소에는 검증/테스트 데이터 세트와 사전 학습된 모델이 보관됩니다.  서버는 컴퓨팅 기능을 제공하고, 저장소는 NFS 프로토콜을 통해 접근합니다.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">이 섹션에서는 테스트된 구성, 네트워크 인프라, SE350 서버 및 스토리지 프로비저닝 세부 정보를 설명합니다.  다음 표에는 솔루션 아키텍처의 기본 구성 요소가 나열되어 있습니다.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">레노버 ThinkSystem 서버</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">각각 NVIDIA T4 GPU 카드 1개가 장착된 2개의 SE350 서버</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">각 서버에는 2.20GHz에서 실행되는 4개의 물리적 코어와 128GB RAM을 갖춘 Intel Xeon D-2123IT CPU가 하나 포함되어 있습니다.</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">엔트리 레벨 NetApp AFF 스토리지 시스템(HA 쌍)</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 소프트웨어</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24개의 960GB SSD</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS 프로토콜</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">컨트롤러당 하나의 인터페이스 그룹, 마운트 지점에 대한 4개의 논리적 IP 주소</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">다음 표는 스토리지 구성을 보여줍니다: 2RU, 24개 드라이브 슬롯이 있는 AFF C190 .</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">제어 장치</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">골재</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup 볼륨</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">집계 크기</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">볼륨 크기</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">운영 체제 마운트 지점</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">Controller1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">Aggr1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/넷애플노보_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/넷앱_레노버_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">Controller2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">Aggr2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_fg 폴더에는 모델 검증에 사용되는 데이터 세트가 포함되어 있습니다.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">아래 그림은 테스트 구성을 보여줍니다.  NetApp EF280 스토리지 시스템과 두 대의 Lenovo ThinkSystem SE350 서버(각각 NVIDIA T4 가속기 1개 장착)를 사용했습니다.  이러한 구성 요소는 10GbE 네트워크 스위치를 통해 연결됩니다.  네트워크 저장소에는 검증/테스트 데이터 세트와 사전 학습된 모델이 보관됩니다.  서버는 컴퓨팅 기능을 제공하고, 저장소는 NFS 프로토콜을 통해 접근합니다.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">다음 표는 EF280의 스토리지 구성을 나열합니다.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">볼륨 그룹</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">용량</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDP 크기</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">연결 방법</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">제1권</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1에서 iSCSI LUN 0으로</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">제2권</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2에서 iSCSI LUN 1로</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">이 문서에서는 새로운 애플리케이션 시나리오를 충족하는 엣지 환경에서 NetApp 스토리지 컨트롤러와 Lenovo ThinkSystem 서버에 GPU 기반 인공 지능(AI) 추론을 배포하기 위한 컴퓨팅 및 스토리지 아키텍처를 설명합니다.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: 엣지에서의 AI 추론 - NetApp 과 Lenovo ThinkSystem - 솔루션 설계</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">요약</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">첨단 운전자 보조 시스템(ADAS), 산업 4.0, 스마트 시티, 사물 인터넷(IoT)과 같은 여러 가지 새로운 애플리케이션 시나리오에서는 거의 0에 가까운 지연 시간으로 연속적인 데이터 스트림을 처리해야 합니다.  이 문서에서는 이러한 요구 사항을 충족하는 엣지 환경에서 NetApp 스토리지 컨트롤러와 Lenovo ThinkSystem 서버에 GPU 기반 인공 지능(AI) 추론을 배포하기 위한 컴퓨팅 및 스토리지 아키텍처를 설명합니다.  이 문서에서는 NVIDIA T4 GPU가 장착된 엣지 서버에서 다양한 추론 작업을 평가하는 업계 표준 MLPerf 추론 벤치마크에 대한 성능 데이터도 제공합니다.  오프라인, 단일 스트림, 다중 스트림 추론 시나리오의 성능을 조사하고, 비용 효율적인 공유 네트워크 스토리지 시스템을 갖춘 아키텍처가 매우 성능이 뛰어나고 여러 에지 서버의 데이터 및 모델 관리를 위한 중앙 지점을 제공한다는 것을 보여줍니다.</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">기업들은 네트워크 엣지에서 점점 더 엄청난 양의 데이터를 생성하고 있습니다.  스마트 센서와 IoT 데이터에서 최대 가치를 얻기 위해 기업들은 엣지 컴퓨팅을 지원하는 실시간 이벤트 스트리밍 솔루션을 찾고 있습니다.  따라서 계산적으로 많은 것을 요구하는 작업은 데이터 센터 외부의 엣지에서 수행되는 경우가 점점 더 많아지고 있습니다.  AI 추론은 이러한 추세를 주도하는 요인 중 하나입니다.  엣지 서버는 특히 가속기를 사용할 때 이러한 작업 부하에 충분한 컴퓨팅 성능을 제공하지만, 제한된 저장 용량은 특히 다중 서버 환경에서 종종 문제가 됩니다.  이 문서에서는 엣지 환경에서 공유 스토리지 시스템을 배포하는 방법과 성능 저하 없이 AI 추론 워크로드에 어떤 이점을 제공하는지 보여줍니다.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">이 문서에서는 엣지에서의 AI 추론을 위한 참조 아키텍처를 설명합니다.  여러 대의 Lenovo ThinkSystem 엣지 서버와 NetApp 스토리지 시스템을 결합하여 배포와 관리가 쉬운 솔루션을 만듭니다.  이 가이드는 여러 카메라와 산업용 센서가 설치된 공장 현장, 소매 거래에서의 POS(판매 시점 관리) 시스템, 자율주행차에서 시각적 이상을 식별하는 FSD(완전 자율 주행) 시스템 등 다양한 상황에서 실제 배포를 위한 기준 가이드를 제공하고자 작성되었습니다.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">이 문서에서는 Lenovo ThinkSystem SE350 Edge 서버와 엔트리 레벨 NetApp AFF 및 EF 시리즈 스토리지 시스템으로 구성된 컴퓨팅 및 스토리지 구성의 테스트와 검증에 대해 설명합니다.  참조 아키텍처는 NetApp ONTAP 및 NetApp SANtricity 데이터 관리 소프트웨어를 통해 포괄적인 데이터 서비스, 통합 데이터 보호, 원활한 확장성, 클라우드 연결 데이터 스토리지를 제공하는 동시에 AI 배포를 위한 효율적이고 비용 효율적인 솔루션을 제공합니다.</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">이 문서는 다음과 같은 독자를 대상으로 합니다.</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">엣지에서 AI를 상품화하고자 하는 비즈니스 리더와 엔터프라이즈 아키텍트.</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">데이터 과학자, 데이터 엔지니어, AI/머신러닝(ML) 연구자, AI 시스템 개발자.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">AI/ML 모델과 애플리케이션 개발을 위한 솔루션을 설계하는 엔터프라이즈 아키텍트입니다.</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">딥 러닝(DL) 및 ML 모델을 배포하는 효율적인 방법을 찾고 있는 데이터 과학자와 AI 엔지니어.</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">에지 추론 모델의 배포와 관리를 담당하는 에지 장치 관리자와 에지 서버 관리자입니다.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">솔루션 아키텍처</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">이 Lenovo ThinkSystem 서버와 NetApp ONTAP 또는 NetApp SANtricity 스토리지 솔루션은 기존 CPU와 함께 GPU의 처리 능력을 활용하여 대규모 데이터 세트에 대한 AI 추론을 처리하도록 설계되었습니다.  이 검증은 다음 두 그림에서 볼 수 있듯이 단일 NetApp AFF 스토리지 시스템과 상호 연결된 단일 또는 여러 개의 Lenovo SR350 엣지 서버를 사용하는 아키텍처를 통해 높은 성능과 최적의 데이터 관리를 보여줍니다.</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">다음 그림의 논리적 아키텍처 개요는 이 아키텍처에서 컴퓨팅 및 스토리지 요소의 역할을 보여줍니다.  구체적으로는 다음 사항을 보여줍니다.</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">카메라, 센서 등에서 수신한 데이터에 대한 추론을 수행하는 엣지 컴퓨팅 장치입니다.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">여러 가지 목적을 제공하는 공유 저장 요소:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">추론을 수행하는 데 필요한 추론 모델 및 기타 데이터의 중앙 위치를 제공합니다.  컴퓨팅 서버는 저장소에 직접 액세스하고 로컬에 복사할 필요 없이 네트워크 전반에서 추론 모델을 사용합니다.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">업데이트된 모델이 여기에 게시됩니다.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">나중에 분석하기 위해 에지 서버가 수신하는 입력 데이터를 보관합니다.  예를 들어, 에지 장치가 카메라에 연결된 경우, 저장 요소는 카메라가 촬영한 비디오를 보관합니다.</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">빨간색</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">파란색</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">레노버 컴퓨팅 시스템</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF 스토리지 시스템</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">카메라, 센서 등에서 입력된 내용에 대한 추론을 수행하는 에지 장치입니다.</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">추후 분석을 위해 에지 디바이스의 추론 모델과 데이터를 보관하는 공유 스토리지입니다.</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">NetApp 과 Lenovo 솔루션은 다음과 같은 주요 이점을 제공합니다.</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">엣지에서의 GPU 가속 컴퓨팅.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">공유 스토리지에서 지원 및 관리되는 여러 개의 엣지 서버를 배포합니다.</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">데이터 손실 없이 낮은 복구 지점 목표(RPO) 및 복구 시간 목표(RTO)를 충족하는 강력한 데이터 보호 기능을 제공합니다.</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">NetApp 스냅샷 복사본과 복제본을 사용하여 데이터 관리를 최적화하고 개발 워크플로를 간소화합니다.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">이 아키텍처를 사용하는 방법</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">이 문서는 제안된 아키텍처의 설계와 성능을 검증합니다.  그러나 컨테이너, 워크로드, 모델 관리 및 온프레미스 클라우드나 데이터 센터와의 데이터 동기화 등 특정 소프트웨어 수준의 부분은 배포 시나리오에 따라 달라지기 때문에 테스트하지 않았습니다.  여기에는 여러 가지 선택이 있습니다.</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">NetApp AI 제어 평면</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">컨테이너 관리 수준에서 Kubernetes 컨테이너 관리가 좋은 선택이며, 완전한 업스트림 버전(Canonical)이나 엔터프라이즈 배포에 적합한 수정된 버전(Red Hat)에서 모두 잘 지원됩니다.  그만큼<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block> NetApp Trident 와 새로 추가된 기능을 사용하는<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> 데이터 과학자와 데이터 엔지니어가 NetApp 스토리지와 통합할 수 있는 내장형 추적 기능, 데이터 관리 기능, 인터페이스 및 도구를 제공합니다.  Kubernetes용 ML 툴킷인 Kubeflow는 TensorFlow Serving이나 NVIDIA Triton Inference Server 등 여러 플랫폼에서 모델 버전 관리 및 KFServing을 지원하는 것과 함께 추가적인 AI 기능을 제공합니다.  또 다른 옵션은 GPU 지원 AI 추론 컨테이너 카탈로그에 대한 액세스와 함께 워크로드 관리를 제공하는 NVIDIA EGX 플랫폼입니다.  그러나 이러한 옵션을 프로덕션에 적용하려면 상당한 노력과 전문 지식이 필요할 수 있으며, 제3자 독립 소프트웨어 공급업체(ISV)나 컨설턴트의 도움이 필요할 수도 있습니다.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">솔루션 영역</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 추론과 엣지 컴퓨팅의 주요 이점은 장치가 지연 없이 높은 수준의 품질로 데이터를 계산, 처리 및 분석할 수 있는 능력입니다.  이 문서에서 설명하기에는 엣지 컴퓨팅 사용 사례가 너무 많지만, 몇 가지 대표적인 사례를 소개하겠습니다.</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">자동차: 자율주행차</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">엣지 컴퓨팅의 대표적인 예는 자율주행차(AV)의 첨단 운전자 지원 시스템(ADAS)입니다.  자율주행차에 사용되는 AI는 카메라와 센서에서 수집한 방대한 데이터를 빠르게 처리해야 안전하게 주행할 수 있습니다.  물체와 사람 간의 정보를 해석하는 데 너무 오랜 시간이 걸리면 생사가 결정될 수 있으므로, 차량에 최대한 가까운 곳에서 해당 데이터를 처리하는 것이 중요합니다.  이 경우, 하나 이상의 엣지 컴퓨팅 서버가 카메라, RADAR, LiDAR 및 기타 센서의 입력을 처리하는 반면, 공유 스토리지는 추론 모델을 보관하고 센서의 입력 데이터를 저장합니다.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">의료: 환자 모니터링</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">AI와 엣지 컴퓨팅의 가장 큰 영향 중 하나는 재택 치료와 중환자실(ICU) 모두에서 만성 질환 환자의 지속적인 모니터링을 강화할 수 있는 능력입니다.  인슐린 수치, 호흡, 신경 활동, 심장 리듬, 위장 기능을 모니터링하는 에지 디바이스에서 수집된 데이터는 즉각적인 분석이 필요하며, 누군가의 생명을 구하기 위해 조치를 취할 시간이 제한되어 있기 때문에 즉각적인 조치가 필요합니다.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">소매: 계산원 없는 결제</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">엣지 컴퓨팅은 AI와 ML을 구동하여 소매업체가 결제 시간을 줄이고 고객 수를 늘리는 데 도움이 될 수 있습니다.  무계산 시스템은 다음과 같은 다양한 구성 요소를 지원합니다.</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">인증 및 접근.  실제 쇼핑객을 검증된 계정에 연결하고 소매 공간에 대한 접근을 허용합니다.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">재고 모니터링.  센서, RFID 태그, 컴퓨터 비전 시스템을 사용하여 쇼핑객이 품목을 선택하거나 선택 취소한 것을 확인하는 데 도움을 줍니다.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">여기에서는 각 엣지 서버가 각 체크아웃 카운터를 처리하고 공유 저장 시스템이 중앙 동기화 지점 역할을 합니다.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">금융 서비스: 키오스크에서의 인적 안전 및 사기 방지</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">은행 기관들은 AI와 엣지 컴퓨팅을 활용해 혁신을 이루고 개인화된 은행 경험을 창출하고 있습니다.  실시간 데이터 분석과 AI 추론을 활용하는 대화형 키오스크를 통해 ATM은 고객이 돈을 인출하는 것을 도울 뿐만 아니라 카메라에서 촬영한 이미지를 통해 키오스크를 사전에 모니터링하여 인간의 안전에 대한 위험이나 사기 행위를 파악할 수 있습니다.  이 시나리오에서는 엣지 컴퓨팅 서버와 공유 스토리지 시스템이 대화형 키오스크와 카메라에 연결되어 은행이 AI 추론 모델을 사용하여 데이터를 수집하고 처리하는 데 도움이 됩니다.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">제조업: 산업 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">스마트 팩토리, 3D 프린팅 등의 새로운 트렌드와 함께 제4차 산업혁명(Industry 4.0)이 시작되었습니다.  데이터 중심의 미래에 대비하기 위해 대규모 M2M(기계 간 통신)과 IoT가 통합되어 인간의 개입 없이도 자동화가 더욱 강화됩니다.  제조업은 이미 높은 수준으로 자동화되어 있으며, AI 기능을 추가하는 것은 이러한 장기적 추세의 자연스러운 지속입니다.  AI는 컴퓨터 비전과 기타 AI 기능의 도움으로 자동화할 수 있는 작업을 자동화할 수 있습니다.  공장 현장의 조립 라인에서 재료를 더 빠르게 분석하여 품질 관리나 인간의 시각 또는 의사 결정에 의존하는 작업을 자동화하여 제조 공장이 안전 및 품질 관리에 대한 필수 ISO 표준을 충족하도록 도울 수 있습니다.  여기에서 각 컴퓨팅 엣지 서버는 제조 공정을 모니터링하는 센서 어레이에 연결되고, 필요에 따라 업데이트된 추론 모델이 공유 스토리지에 푸시됩니다.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">통신: 녹 탐지, 타워 검사 및 네트워크 최적화</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">통신 산업에서는 컴퓨터 비전과 AI 기술을 사용하여 이미지를 처리하여 녹을 자동으로 감지하고 부식이 있는 셀 타워를 식별하여 추가 검사가 필요합니다.  최근 몇 년 동안 드론 이미지와 AI 모델을 사용하여 타워의 특정 영역을 식별하고 녹, 표면 균열 및 부식을 분석하는 방식이 증가했습니다.  통신 인프라와 셀 타워를 효율적으로 검사하고, 정기적으로 성능 저하 여부를 평가하고, 필요할 경우 신속하게 수리할 수 있는 AI 기술에 대한 수요는 계속해서 증가하고 있습니다.</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">또한, 통신 분야에서 떠오르는 또 다른 활용 사례는 AI와 ML 알고리즘을 사용하여 데이터 트래픽 패턴을 예측하고, 5G 지원 장치를 감지하고, 다중 입력 및 다중 출력(MIMO) 에너지 관리를 자동화하고 증강하는 것입니다.  MIMO 하드웨어는 네트워크 용량을 늘리기 위해 무선 타워에 사용됩니다. 그러나 여기에는 추가 에너지 비용이 발생합니다.  셀 사이트에 배치된 "MIMO 슬립 모드"를 위한 ML 모델은 무선 장치의 효율적인 사용을 예측하고 이동통신 사업자(MNO)의 에너지 소비 비용을 줄이는 데 도움이 될 수 있습니다.  AI 추론 및 엣지 컴퓨팅 솔루션은 MNO가 데이터 센터로 전송되는 데이터 양을 줄이고, TCO를 낮추고, 네트워크 운영을 최적화하고, 최종 사용자를 위한 전반적인 성능을 개선하는 데 도움이 됩니다.</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">이 문서는 MLPerf Inference v0.7 코드, MLPerf Inference v1.1 코드와 규칙을 따릅니다.  이 섹션에 제시된 표에 정의된 대로 에지에서의 추론을 위해 설계된 벤치마크를 실행했습니다.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">테스트 계획</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">암호</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">규칙</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">이 문서는 MLPerf Inference v0.7을 따릅니다.<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> , MLPerf 추론 v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> , 그리고<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block> .  다음 표에 정의된 대로 에지에서의 추론을 위해 설계된 MLPerf 벤치마크를 실행했습니다.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">영역</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">모델</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">데이터 세트</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL 크기</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">품질</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">멀티스트림 지연 제약</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">비전</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">이미지 분류</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">이미지넷(224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32의 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">객체 감지(대형)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD- ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">코코 (1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">객체 감지(소형)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD- 모바일넷스v1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">코코(300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">의료 영상 분할</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D 유넷</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">브라TS 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32의 99% 및 99.9%</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">연설</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">음성-텍스트 변환</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech 개발 정리</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">언어</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">언어 처리</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">SQuAD v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">다음 표는 Edge 벤치마크 시나리오를 보여줍니다.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">시나리오</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">이미지 분류</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">단일 스트림, 오프라인, 멀티스트림</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">단일 스트림, 오프라인</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">음성-텍스트 변환</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">이 검증 과정에서 개발된 네트워크 스토리지 아키텍처를 사용하여 이러한 벤치마크를 수행했으며, MLPerf에 이전에 제출된 엣지 서버에서 로컬로 실행한 결과와 결과를 비교했습니다.  비교의 목적은 공유 스토리지가 추론 성능에 얼마나 많은 영향을 미치는지 확인하는 것입니다.</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">이 섹션에서는 이 솔루션의 유효성을 검증하는 데 사용된 테스트 절차를 설명합니다.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">테스트 절차</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">운영 체제 및 AI 추론 설정</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">AFF C190 의 경우 NVIDIA 드라이버와 NVIDIA GPU를 지원하는 Docker가 포함된 Ubuntu 18.04를 사용했으며 MLPerf를 사용했습니다.<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> Lenovo가 MLPerf Inference v0.7에 제출한 내용의 일부로 제공됩니다.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">EF280의 경우 NVIDIA 드라이버와 NVIDIA GPU 및 MLPerf를 지원하는 Docker가 포함된 Ubuntu 20.04를 사용했습니다.<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> Lenovo가 MLPerf Inference v1.1에 제출한 내용의 일부로 제공됩니다.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">AI 추론을 설정하려면 다음 단계를 따르세요.</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">등록이 필요한 데이터세트, ImageNet 2012 검증 세트, Criteo 테라바이트 데이터세트, BraTS 2019 훈련 세트를 다운로드한 다음 파일의 압축을 풉니다.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">최소 1TB의 작업 디렉토리를 생성하고 환경 변수를 정의합니다.<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block> 디렉토리를 참조합니다.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">네트워크 스토리지 사용 사례의 경우 공유 스토리지에서 이 디렉토리를 공유해야 하고, 로컬 데이터로 테스트하는 경우 로컬 디스크에서 공유해야 합니다.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">메이크를 실행하다<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block> 필요한 추론 작업을 위해 Docker 컨테이너를 빌드하고 시작하는 명령입니다.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">다음 명령은 모두 실행 중인 Docker 컨테이너 내에서 실행됩니다.</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">MLPerf 추론 작업을 위해 사전 학습된 AI 모델을 다운로드하세요.<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">무료로 다운로드할 수 있는 추가 데이터 세트를 다운로드하세요.<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">데이터 전처리: 만들기<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">달리다:<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> .</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">컴퓨팅 서버에서 GPU에 최적화된 추론 엔진을 구축하세요.<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">추론 워크로드를 실행하려면 다음 명령 하나를 실행하세요.</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI 추론 실행</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">세 가지 유형의 실행이 실행되었습니다.</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">로컬 스토리지를 사용한 단일 서버 AI 추론</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">네트워크 스토리지를 활용한 단일 서버 AI 추론</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">네트워크 스토리지를 활용한 멀티 서버 AI 추론</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">제안된 아키텍처의 성능을 평가하기 위해 다양한 테스트가 실행되었습니다.  6가지의 서로 다른 워크로드(이미지 분류, 객체 감지[소규모], 객체 감지[대규모], 의료 영상, 음성-텍스트 변환, 자연어 처리[NLP])가 있으며, 오프라인, 단일 스트림, 멀티 스트림의 세 가지 시나리오에서 실행할 수 있습니다.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">테스트 결과</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">제안된 아키텍처의 성능을 평가하기 위해 다양한 테스트가 실행되었습니다.</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">오프라인, 단일 스트림, 멀티 스트림의 세 가지 시나리오에서 실행할 수 있는 6가지 워크로드(이미지 분류, 객체 감지[소규모], 객체 감지[대규모], 의료 영상, 음성-텍스트 변환, 자연어 처리[NLP])가 있습니다.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">마지막 시나리오는 이미지 분류와 객체 감지에만 구현됩니다.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">이는 세 가지 다른 설정에서 모두 테스트된 15가지 가능한 작업 부하를 제공합니다.</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">단일 서버/로컬 스토리지</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">단일 서버/네트워크 스토리지</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">다중 서버/네트워크 스토리지</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">결과는 다음 섹션에 설명되어 있습니다.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF 를 위한 오프라인 시나리오에서의 AI 추론</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">이 시나리오에서는 모든 데이터를 서버에서 사용할 수 있었고 모든 샘플을 처리하는 데 걸리는 시간을 측정했습니다.  우리는 테스트 결과로 초당 샘플 수의 대역폭을 보고합니다.  두 개 이상의 컴퓨팅 서버가 사용된 경우 모든 서버의 총 대역폭을 합산하여 보고합니다.  세 가지 사용 사례에 대한 결과는 아래 그림에 나와 있습니다.  두 대의 서버인 경우 두 서버의 결합된 대역폭을 보고합니다.</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">결과는 네트워크 스토리지가 성능에 부정적인 영향을 미치지 않는다는 것을 보여줍니다. 변화는 미미하고 일부 작업에서는 아무런 변화가 발견되지 않았습니다.  두 번째 서버를 추가하면 총 대역폭이 정확히 두 배가 되거나 최악의 경우 변화가 1% 미만이 됩니다.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFF 위한 단일 스트림 시나리오에서의 AI 추론</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">이 벤치마크는 지연 시간을 측정합니다.  여러 개의 계산 서버가 있는 경우의 평균 지연 시간을 보고합니다.  각 작업에 대한 결과는 아래 그림과 같습니다.  두 대의 서버 사례에서는 두 서버의 평균 지연 시간을 보고합니다.</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">결과는 네트워크 스토리지가 작업을 처리하기에 충분하다는 것을 다시 한번 보여줍니다.  하나의 서버 케이스에서 로컬 스토리지와 네트워크 스토리지의 차이는 미미하거나 전혀 없습니다.  마찬가지로, 두 서버가 동일한 저장소를 사용하는 경우 두 서버의 지연 시간은 동일하게 유지되거나 매우 약간만 변경됩니다.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFF 위한 멀티스트림 시나리오에서의 AI 추론</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">이 경우 결과는 QoS 제약 조건을 충족하면서 시스템이 처리할 수 있는 스트림 수입니다.  따라서 결과는 항상 정수입니다.  두 개 이상의 서버에 대해 모든 서버에서 합산된 총 스트림 수를 보고합니다.  모든 워크로드가 이 시나리오를 지원하는 것은 아니지만, 지원하는 워크로드는 실행해 보았습니다. 테스트 결과는 아래 그림에 요약되어 있습니다.  두 대의 서버 사례에서는 두 서버에서 발생한 스트림의 개수를 합산하여 보고합니다.</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">결과는 이 설정이 완벽한 성능을 보임을 보여줍니다. 로컬 및 네트워킹 스토리지는 동일한 결과를 제공하며, 두 번째 서버를 추가하면 제안된 설정이 처리할 수 있는 스트림 수가 두 배가 됩니다.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF에 대한 테스트 결과</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">제안된 아키텍처의 성능을 평가하기 위해 다양한 테스트가 실행되었습니다.  6가지 서로 다른 작업 부하(이미지 분류, 객체 감지[소규모], 객체 감지[대규모], 의료 영상, 음성-텍스트 변환, 자연어 처리[NLP])가 오프라인 및 단일 스트림의 두 가지 시나리오에서 실행되었습니다.  결과는 다음 섹션에 설명되어 있습니다.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF를 위한 오프라인 시나리오에서의 AI 추론</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">이 시나리오에서는 모든 데이터를 서버에서 사용할 수 있었고 모든 샘플을 처리하는 데 걸리는 시간을 측정했습니다.  우리는 테스트 결과로 초당 샘플 수의 대역폭을 보고합니다.  단일 노드 실행의 경우 두 서버의 평균을 보고하는 반면, 두 개의 서버를 실행하는 경우 모든 서버에서 합산된 총 대역폭을 보고합니다.  사용 사례에 대한 결과는 아래 그림에 나와 있습니다.</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF를 위한 단일 스트림 시나리오에서의 AI 추론</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">이 벤치마크는 지연 시간을 측정합니다.  모든 사례에서 실행에 참여한 모든 서버의 평균 지연 시간을 보고합니다.  일련의 작업에 대한 결과가 제공됩니다.</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">결과는 네트워크 스토리지가 작업을 처리하기에 충분하다는 것을 다시 한번 보여줍니다.  하나의 서버 케이스에서 로컬 스토리지와 네트워크 스토리지의 차이는 미미하거나 전혀 없습니다.  마찬가지로, 두 서버가 동일한 저장소를 사용하는 경우 두 서버의 지연 시간은 동일하게 유지되거나 매우 약간만 변경됩니다.</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">다른 사용 사례에 맞게 검증에 사용된 설정을 조정할 수 있습니다.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">아키텍처 크기 조정 옵션</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">컴퓨팅 서버</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">SE350에서 지원하는 가장 낮은 수준의 CPU인 Intel Xeon D-2123IT CPU를 사용했습니다. 이 CPU는 물리적 코어가 4개이고 TDP가 60W입니다.  이 서버는 CPU 교체를 지원하지 않지만, 더 강력한 CPU를 주문할 수는 있습니다.  지원되는 최고 CPU는 2.20GHz에서 실행되는 16코어, 100W의 Intel Xeon D-2183IT입니다.  이를 통해 CPU의 계산 능력이 상당히 향상됩니다.  CPU는 추론 작업 자체를 실행하는 데 병목 현상이 아니지만 데이터 처리 및 추론과 관련된 기타 작업에는 도움이 됩니다.  현재 NVIDIA T4는 엣지 사용 사례에 사용할 수 있는 유일한 GPU입니다. 따라서 현재로서는 GPU를 업그레이드하거나 다운그레이드할 수 없습니다.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">공유 스토리지</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">이 문서의 목적상 테스트 및 검증을 위해 NetApp AFF C190 시스템이 사용되었습니다. 이 시스템은 최대 저장 용량이 50.5TB이고, 순차 읽기 처리량이 4.4GBps이며, 소규모 랜덤 읽기 처리량이 230K IOPS입니다. 이 시스템은 에지 추론 워크로드에 적합한 것으로 입증되었습니다.</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">하지만 더 많은 저장 용량이나 더 빠른 네트워킹 속도가 필요한 경우 NetApp AFF A220 또는 NetApp AFF A250 스토리지 시스템을 사용해야 합니다.  또한, 최대 용량이 1.5PB이고 대역폭이 10GBps인 NetApp EF280 시스템도 이 솔루션 검증 목적으로 사용되었습니다.  더 높은 대역폭으로 더 많은 저장 용량을 원하시면,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> 사용할 수 있습니다.</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">이 섹션에서는 이 AI 솔루션의 기술적 기반을 설명합니다.</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">NetApp AFF 시스템</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">최첨단 NetApp AFF 스토리지 시스템은 업계 최고의 성능, 탁월한 유연성, 클라우드 통합, 동급 최고의 데이터 관리 기능을 통해 기업의 스토리지 요구 사항을 충족하는 에지에서의 AI 추론 배포를 지원합니다.  플래시에 맞춰 특별히 설계된 NetApp AFF 시스템은 비즈니스에 중요한 데이터를 가속화하고 관리하며 보호하는 데 도움이 됩니다.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">엔트리 레벨 NetApp AFF 스토리지 시스템은 FAS2750 하드웨어와 SSD 플래시 미디어를 기반으로 합니다.</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 구성의 두 컨트롤러</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp 엔트리 레벨 AFF C190 스토리지 시스템은 다음 기능을 지원합니다.</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">최대 24개의 960GB SSD 드라이브 수</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">두 가지 가능한 구성:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">이더넷(10GbE): 4x 10GBASE-T(RJ-45) 포트</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">통합(16Gb FC 또는 10GbE): 4개의 통합 대상 어댑터 2(UTA2) 포트</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">최대 50.5TB 유효 용량</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">NAS 워크로드의 경우, 단일 엔트리 레벨 AFF C190 시스템은 1ms 이하의 지연 시간에서 순차 읽기의 경우 4.4GBps의 처리량과 소규모 랜덤 읽기의 경우 230K IOPS의 처리량을 지원합니다.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp 또한 대규모 배포에 더 높은 성능과 확장성을 제공하는 다른 보급형 스토리지 시스템도 제공합니다.  NAS 워크로드의 경우 단일 엔트리 레벨 AFF A220 시스템은 다음을 지원합니다.</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">순차 읽기의 경우 6.2GBps의 처리량</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">1ms 이하의 대기 시간에서 소규모 무작위 읽기에 대한 375K IOPS</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">최대 144개의 960GB, 3.8TB 또는 7.6TB SSD 드라이브 수</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220 1PB 이상의 유효 용량으로 확장 가능합니다.</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">최대 유효 용량은 2~24개 노드(12개 HA 쌍)로 확장 가능한 최대 35PB입니다.</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">AFF A220 보다 ≥ 45% 성능 향상</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS 랜덤 읽기 @1ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">최신 NetApp ONTAP 릴리스 기반: ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">HA 및 클러스터 상호 연결을 위해 2개의 25Gb 이더넷을 활용합니다.</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E-시리즈 EF 시스템</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF 시리즈는 NetApp SANtricity 소프트웨어를 사용하여 데이터에 대한 액세스를 가속화하고 더 빠르게 데이터에서 가치를 창출할 수 있도록 지원하는 엔트리 레벨 및 미드레인지 올플래시 SAN 스토리지 어레이 제품군입니다.  이 시스템은 SAS와 NVMe 플래시 스토리지를 모두 제공하고 저렴한 가격부터 극한의 IOPS, 100마이크로초 미만의 응답 시간, 최대 44GBps의 대역폭을 제공하므로 AI 추론 및 고성능 컴퓨팅(HPC)과 같은 혼합 워크로드와 까다로운 애플리케이션에 이상적입니다.</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">다음 그림은 NetApp EF280 스토리지 시스템을 보여줍니다.</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb/16Gb FC, 25Gb/10Gb iSCSI 및 12Gb SAS 지원</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">최대 유효 용량은 총 96개 드라이브로 총 1.5PB입니다.</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">10GBps의 처리량(순차 읽기)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOP(무작위 읽기)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280은 NetApp 포트폴리오에서 가장 저렴한 올플래시 어레이(AFA)입니다.</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">총 용량 367TB를 위한 24개의 NVMe SSD 드라이브</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">240x NL-SAS HDD, 96x SAS SSD 또는 이들의 조합으로 구성된 확장 옵션</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB, NVMe/RoCE, iSER/IB 및 SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVME/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25Gb iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps(순차 읽기)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOP(무작위 읽기)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF-시리즈 NetApp EF-시리즈 올플래시 어레이 EF600, F300, EF570 및 EF280 데이터시트</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">자세한 내용은 다음을 참조하세요.<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block> .</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">NetApp 의 최신 스토리지 관리 소프트웨어인 ONTAP 9.8.1을 사용하면 기업이 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다.  ONTAP 업계 최고의 데이터 관리 역량을 활용하여 데이터가 어디에 있든 단일 도구 세트를 사용하여 데이터를 관리하고 보호할 수 있도록 지원합니다.  또한 필요한 곳, 즉 엣지, 코어, 클라우드로 데이터를 자유롭게 이동할 수 있습니다.  ONTAP 9.8.1에는 데이터 관리를 간소화하고, 중요 데이터를 가속화하고 보호하며, 하이브리드 클라우드 아키텍처 전반에서 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">적절한 리소스가 애플리케이션과 데이터 세트에 사용되도록 하려면 기업 IT 운영에 데이터 관리가 필수적입니다.  ONTAP 에는 다음과 같은 기능이 포함되어 있어 운영을 간소화하고 단순화하며 총 운영 비용을 절감할 수 있습니다.</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*인라인 데이터 압축 및 확장된 중복 제거.*  데이터 압축은 저장 블록 내부의 낭비되는 공간을 줄이고, 중복 제거는 효과적인 용량을 크게 증가시킵니다.  이는 로컬에 저장된 데이터와 클라우드에 계층화된 데이터 모두에 적용됩니다.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*최소, 최대 및 적응형 서비스 품질(AQoS).*  세분화된 서비스 품질(QoS) 제어는 공유 빈도가 높은 환경에서 중요한 애플리케이션의 성능 수준을 유지하는 데 도움이 됩니다.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool.*  이 기능은 Amazon Web Services(AWS), Azure, NetApp StorageGRID 스토리지 솔루션을 포함한 퍼블릭 및 프라이빗 클라우드 스토리지 옵션에 콜드 데이터를 자동으로 계층화합니다.  FabricPool 에 대한 자세한 내용은 다음을 참조하세요.<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block> .</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9는 뛰어난 수준의 성능과 데이터 보호 기능을 제공하며 다음과 같은 방식으로 이러한 기능을 확장합니다.</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*성능과 낮은 지연 시간.*  ONTAP 가능한 가장 낮은 지연 시간으로 가능한 가장 높은 처리량을 제공합니다.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*데이터 보호.*  ONTAP 모든 플랫폼에서 공통적으로 관리할 수 있는 내장형 데이터 보호 기능을 제공합니다.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetApp 볼륨 암호화(NVE).*  ONTAP 온보드 및 외부 키 관리 지원을 통해 기본 볼륨 수준 암호화를 제공합니다.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*다중 테넌시 및 다중 요소 인증.*  ONTAP 사용하면 최고 수준의 보안으로 인프라 리소스를 공유할 수 있습니다.</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9는 다음과 같은 기능을 통해 까다롭고 끊임없이 변화하는 비즈니스 요구 사항을 충족하는 데 도움이 됩니다.</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*원활한 확장 및 중단 없는 운영.*  ONTAP 기존 컨트롤러와 확장형 클러스터에 중단 없이 용량을 추가할 수 있도록 지원합니다.  고객은 비용이 많이 드는 데이터 마이그레이션이나 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*클라우드 연결.*  ONTAP 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지(ONTAP Select)와 클라우드 기반 인스턴스(Google Cloud NetApp Volumes)에 대한 옵션을 제공하는 가장 클라우드에 연결된 스토리지 관리 소프트웨어입니다.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*새로운 애플리케이션과의 통합.*  ONTAP 기존 엔터프라이즈 앱을 지원하는 동일한 인프라를 사용하여 자율주행차, 스마트 시티, 산업 4.0과 같은 차세대 플랫폼과 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E-시리즈 SANtricity 소프트웨어 데이터시트</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity E-시리즈 하이브리드 플래시 및 EF-시리즈 올플래시 어레이에 업계 최고의 성능, 안정성 및 단순성을 제공하도록 설계되었습니다.  데이터 분석, 비디오 감시, 백업 및 복구를 포함한 고부하 작업 애플리케이션을 위해 E-시리즈 하이브리드 플래시 및 EF-시리즈 올플래시 어레이의 최대 성능과 활용도를 달성하세요.  SANtricity 사용하면 스토리지가 온라인 상태를 유지하는 동안 구성 조정, 유지 관리, 용량 확장 및 기타 작업을 완료할 수 있습니다.  SANtricity 뛰어난 데이터 보호, 사전 모니터링, 인증된 보안 기능을 제공하며, 이 모든 기능은 사용하기 쉬운 온박스 시스템 관리자 인터페이스를 통해 이용할 수 있습니다.  자세한 내용은 다음을 참조하세요.<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block> .</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">성능 최적화</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">성능에 최적화된 SANtricity 소프트웨어는 높은 IOP, 높은 처리량, 낮은 지연 시간으로 모든 데이터 분석, 비디오 감시 및 백업 앱에 데이터를 제공합니다.  높은 IOPS, 낮은 지연 시간의 애플리케이션과 높은 대역폭, 높은 처리량의 애플리케이션에 대한 성능을 가속화합니다.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">가동 시간 극대화</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">스토리지가 온라인 상태를 유지하는 동안 모든 관리 작업을 완료하세요.  I/O를 중단하지 않고 구성을 조정하고, 유지 관리를 수행하고, 용량을 확장하세요.  자동화된 기능, 온라인 구성, 최첨단 동적 디스크 풀(DPP) 기술 등을 통해 동급 최고의 안정성을 실현하세요.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">편히 쉬세요</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity 소프트웨어는 사용하기 쉬운 온박스 시스템 관리자 인터페이스를 통해 뛰어난 데이터 보호, 사전 예방적 모니터링, 인증된 보안을 제공합니다.  저장소 관리 작업을 간소화합니다.  모든 E-시리즈 스토리지 시스템의 고급 튜닝에 필요한 유연성을 확보하세요.  언제 어디서나 NetApp E-Series 시스템을 관리하세요.  당사의 온박스 웹 기반 인터페이스는 관리 워크플로를 간소화합니다.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>NetApp 의 Docker와 Kubernetes를 위한 오픈소스 동적 스토리지 오케스트레이터로, 영구 스토리지의 생성, 관리 및 사용을 간소화합니다.  Kubernetes 기본 애플리케이션인 Trident 는 Kubernetes 클러스터 내에서 직접 실행됩니다.  Trident 사용하면 고객이 DL 컨테이너 이미지를 NetApp 스토리지에 원활하게 배포할 수 있으며 AI 컨테이너 배포를 위한 엔터프라이즈급 환경을 제공합니다.  Kubernetes 사용자(예: ML 개발자 및 데이터 과학자)는 NetApp 기술을 기반으로 하는 NetApp 고급 데이터 관리 기능을 활용하여 오케스트레이션 및 복제를 생성, 관리 및 자동화할 수 있습니다.</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>빠르고 안전한 데이터 동기화를 위한 NetApp 서비스입니다.  온프레미스 NFS 또는 SMB 파일 공유, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service(Amazon S3), Amazon Elastic File System(Amazon EFS), Azure Blob, Google Cloud Storage 또는 IBM Cloud Object Storage 간에 파일을 전송해야 하는 경우 BlueXP Copy and Sync를 사용하면 파일을 필요한 곳으로 빠르고 안전하게 이동할 수 있습니다.  데이터가 전송되면 소스와 타겟 모두에서 자유롭게 사용할 수 있습니다.  BlueXP Copy and Sync는 사전 정의된 일정에 따라 데이터를 지속적으로 동기화하고 델타만 이동하므로 데이터 복제에 소요되는 시간과 비용이 최소화됩니다.  BlueXP Copy and Sync는 설정과 사용이 매우 간단한 SaaS(Software as a Service) 도구입니다.  BlueXP Copy and Sync에 의해 트리거되는 데이터 전송은 데이터 브로커를 통해 수행됩니다.  AWS, Azure, Google Cloud Platform 또는 온프레미스에 BlueXP 복사 및 동기화 데이터 브로커를 배포할 수 있습니다.</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">Lenovo ThinkSystem 서버는 오늘날 고객이 직면한 과제를 해결하는 혁신적인 하드웨어, 소프트웨어 및 서비스를 갖추고 있으며, 미래의 과제를 해결하기 위해 진화적이고 목적에 맞는 모듈식 설계 방식을 제공합니다.  이러한 서버는 업계 표준의 최고 기술과 차별화된 Lenovo 혁신 기술을 결합하여 x86 서버에서 가능한 가장 큰 유연성을 제공합니다.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Lenovo ThinkSystem 서버를 구축하는 주요 이점은 다음과 같습니다.</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">비즈니스 성장에 맞춰 확장 가능한 모듈식 디자인</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">업계 최고의 복원력으로 예상치 못한 고비용 가동 중단 시간을 절약합니다.</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">더 낮은 대기 시간, 더 빠른 응답 시간, 더 스마트한 실시간 데이터 관리를 위한 빠른 플래시 기술</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">AI 분야에서 Lenovo는 기업이 자사 워크로드에 ML과 AI의 이점을 이해하고 도입할 수 있도록 돕기 위해 실용적인 접근 방식을 취하고 있습니다.  Lenovo 고객은 Lenovo AI 혁신 센터에서 Lenovo AI 제품을 탐색하고 평가하여 특정 사용 사례에 대한 가치를 완벽하게 이해할 수 있습니다.  가치 실현 시간을 단축하기 위해 이러한 고객 중심적 접근 방식은 고객에게 AI에 맞게 사용할 준비가 되고 최적화된 솔루션 개발 플랫폼에 대한 개념 증명을 제공합니다.</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">엣지 컴퓨팅을 사용하면 IoT 기기의 데이터를 데이터 센터나 클라우드로 전송하기 전에 네트워크 엣지에서 분석할 수 있습니다.  아래 그림에 표시된 Lenovo ThinkSystem SE350은 엣지에서의 배포에 대한 고유한 요구 사항에 맞게 설계되었으며, 컴팩트하고 견고하며 환경 친화적인 폼 팩터에서 유연성, 연결성, 보안 및 원격 관리에 중점을 두었습니다.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">SE350은 데이터 센터 외부의 다양한 환경에서 서버를 배포할 때 발생하는 과제를 해결하기 위해 특별히 제작되었으며, 엣지 AI 워크로드에 대한 가속을 지원하는 유연성을 갖춘 Intel Xeon D 프로세서를 탑재했습니다.</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf 추론 v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf는 AI 성능을 평가하는 업계 최고의 벤치마크 제품군입니다.  여기에는 이미지 분류, 객체 감지, 의료 영상, 자연어 처리(NLP)를 포함한 응용 AI의 많은 분야가 포함됩니다.  이 검증에서는 MLPerf 추론의 최신 버전인 Inference v0.7 워크로드를 사용했습니다.  그만큼<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> 이 제품군에는 데이터 센터 및 엣지 시스템을 위한 4가지 새로운 벤치마크가 포함되어 있습니다.</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*버트.*  SQuAD 데이터 세트를 사용하여 질문에 대한 답변을 위해 미세 조정된 변환기(BERT)의 양방향 인코더 표현.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM.*  딥러닝 추천 모델(DLRM)은 클릭률(CTR)을 최적화하도록 훈련된 개인화 및 추천 모델입니다.</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-넷.*  3D U-Net 아키텍처는 Brain Tumor Segmentation(BraTS) 데이터 세트를 기반으로 학습되었습니다.</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T.* 순환 신경망 변환기(RNN-T)는 LibriSpeech의 하위 집합을 사용하여 훈련된 자동 음성 인식(ASR) 모델입니다.  MLPerf 추론 결과와 코드는 공개적으로 사용 가능하며 Apache 라이선스에 따라 배포됩니다.  MLPerf Inference에는 다음 시나리오를 지원하는 Edge 부문이 있습니다.</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*단일 스트림.*  이 시나리오는 스마트폰에서 수행되는 오프라인 AI 쿼리와 같이 반응성이 중요한 요소인 시스템을 모방합니다.  개별적인 질의는 시스템으로 전송되고 응답 시간이 기록됩니다.  모든 응답의 90번째 백분위수 지연 시간이 결과로 보고됩니다.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*멀티스트림.*  이 벤치마크는 여러 센서로부터 입력을 처리하는 시스템을 위한 것입니다.  테스트 중에는 고정된 시간 간격으로 쿼리가 전송됩니다.  QoS 제약(허용되는 최대 지연 시간)이 적용됩니다.  테스트는 QoS 제약 조건을 충족하면서 시스템이 처리할 수 있는 스트림 수를 보고합니다.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*오프라인.*  이는 일괄 처리 애플리케이션을 포괄하는 가장 간단한 시나리오이며, 측정 기준은 초당 샘플 처리량입니다.  모든 데이터는 시스템에 제공되고 벤치마크는 모든 샘플을 처리하는 데 걸리는 시간을 측정합니다.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">Lenovo는 이 문서에서 사용된 서버인 T4를 탑재한 SE350에 대한 MLPerf 추론 점수를 게시했습니다.  결과를 확인하세요<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> 항목 #0.7-145의 "Edge, Closed Division" 섹션에 있습니다.</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">검증에 사용된 설정은 다른 사용 사례에 맞게 조정될 수 있습니다.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">아키텍처 조정</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">이 검증에 사용된 설정은 다른 사용 사례에 맞게 조정될 수 있습니다.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">CPU 조정</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">이 검증에는 Lenovo에서 권장하는 Skylake Intel Xeon Platinum 8360Y 프로세서가 사용되었습니다.  이 작업 부하가 CPU에 구속되지 않기 때문에 동등한 Cascade Lake CPU인 Intel Xeon Gold 6330 프로세서가 비슷한 성능을 제공할 것으로 예상됩니다.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">저장 용량 증가</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">추가 디스크 셸프와 컨트롤러 모델이 있는 경우 저장 용량 요구 사항에 따라 공유 저장 공간(NFS 볼륨)을 필요에 따라 늘릴 수 있습니다.  이 작업은 CLI에서 수행하거나 스토리지 컨트롤러의 NetApp 웹 인터페이스에서 관리자 권한으로 수행할 수 있습니다.</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">NetApp 과 Lenovo의 솔루션은 중견기업 AI 도입에 적합한 유연한 확장형 아키텍처입니다.  NetApp 스토리지는 로컬 SSD 스토리지와 동일하거나 더 나은 성능을 제공하며 데이터 과학자, 데이터 엔지니어 및 IT 의사 결정권자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">여기에서 검증된 NetApp 과 Lenovo 솔루션은 중견기업 AI 진입에 적합한 유연한 확장형 아키텍처입니다.</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">NetApp 스토리지는 로컬 SSD 스토리지와 동일하거나 더 나은 성능을 제공하며 데이터 과학자, 데이터 엔지니어 및 IT 의사 결정권자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">비용을 최소화하고 리소스 활용도를 높이기 위해 독립적으로 확장 가능한 컴퓨팅 및 스토리지를 제공합니다.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">통합 스냅샷과 복제본을 사용하여 즉각적이고 공간 효율적인 사용자 작업 공간, 통합 버전 제어 및 자동화된 배포를 제공하는 간소화된 개발 및 배포 워크플로.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">재해 복구 및 비즈니스 연속성을 위한 엔터프라이즈급 데이터 보호.</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam, 기술 마케팅 엔지니어, NetApp</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, Lenovo AI 랩 시스템 관리자</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">NetApp All Flash Arrays 제품 페이지</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">NetApp AFF A400 페이지</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어 제품 페이지</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI(nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">이 섹션에서는 테스트된 구성, 네트워크 인프라, SR670 V2 서버 및 스토리지 프로비저닝 세부 정보를 설명합니다.</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">이 섹션에서는 테스트된 구성, 네트워크 인프라, SR670 V2 서버 및 NetApp 스토리지 프로비저닝 세부 정보를 설명합니다.</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">이 검증을 위해 다음 표에 나열된 솔루션 구성 요소를 사용했습니다.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">각각 8개의 NVIDIA A100 80GB GPU 카드가 장착된 2개의 SR670 V2 서버</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">각 서버에는 2개의 Intel Xeon Platinum 8360Y CPU(28개의 물리적 코어)와 1TB RAM이 포함되어 있습니다.</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux(Ubuntu – CUDA 11.8이 설치된 20.04)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">NetApp AFF 스토리지 시스템(HA 쌍)</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">NetApp ONTAP 9.10.1 소프트웨어</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">컨트롤러당 1개의 인터페이스 그룹(ifgrp), 마운트 지점에 대한 4개의 논리적 IP 주소</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">이 검증에서는 MLPerf v2.0에서 지정한 ImageNet 기반 집합을 사용하는 ResNet v2.0을 사용했습니다.  데이터 세트는 NFS 프로토콜을 사용하는 NetApp AFF 스토리지 시스템에 저장됩니다.  SR670은 100GbE 스위치를 통해 NetApp AFF A400 스토리지 시스템에 연결되었습니다.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet은 자주 사용되는 이미지 데이터 세트입니다.  여기에는 약 130만 개의 이미지가 포함되어 있으며 총 크기는 144GB입니다.  평균 이미지 크기는 108KB입니다.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">다음 그림은 테스트된 구성의 네트워크 토폴로지를 보여줍니다.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">이 그래픽은 컴퓨팅 계층(Lenovo ThinkSystem SR670 V2), 네트워크 계층(Lenovo 이더넷 스위치), 스토리지 계층( NetApp AFF A400 스토리지 컨트롤러)을 보여줍니다.  모든 네트워크 연결이 포함되어 있습니다.</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">다음 표에는 저장소 구성이 나열되어 있습니다.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">총 크기</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">볼륨 크기</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">운영 체제 마운트 지점</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9.9TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">/a400-100g 폴더에는 ResNet 검증에 사용되는 데이터 세트가 들어 있습니다.</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">이 섹션에서는 자세한 테스트 절차 결과를 설명합니다.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">테스트 절차 및 자세한 결과</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">ONTAP 에서 ResNet을 활용한 이미지 인식 훈련</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">우리는 1대와 2대의 SR670 V2 서버를 사용하여 ResNet50 벤치마크를 실행했습니다.  이 테스트에서는 MXNet 22.04-py3 NGC 컨테이너를 사용하여 학습을 실행했습니다.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">이 검증에서는 다음과 같은 테스트 절차를 사용했습니다.</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">스크립트를 실행하기 전에 호스트 캐시를 지워 데이터가 이미 캐시되지 않았는지 확인했습니다.</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">우리는 서버 스토리지(로컬 SSD 스토리지)와 NetApp AFF 스토리지 시스템에서 ImageNet 데이터 세트를 사용하여 벤치마크 스크립트를 실행했습니다.</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">우리는 다음을 사용하여 네트워크 및 로컬 스토리지 성능을 검증했습니다.<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">단일 노드 실행의 경우 다음 명령을 사용했습니다.</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">분산 실행의 경우 매개변수 서버의 병렬화 모델을 사용했습니다.  노드당 두 개의 매개변수 서버를 사용했고, 단일 노드 실행과 동일하게 에포크 수를 설정했습니다.  이렇게 한 이유는 분산 학습이 프로세스 간 동기화가 불완전해 더 많은 에포크가 필요한 경우가 많기 때문입니다.  에포크의 수가 다르면 단일 노드와 분산 케이스 간의 비교가 왜곡될 수 있습니다.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">데이터 읽기 속도: 로컬 스토리지 대 네트워크 스토리지</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">읽기 속도는 다음을 사용하여 테스트되었습니다.<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> ImageNet 데이터 세트의 파일 중 하나에 명령을 실행합니다.  구체적으로, 로컬 데이터와 네트워크 데이터 모두에 대해 다음 명령을 실행했습니다.</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">두 값이 비슷하여 네트워크 스토리지가 로컬 스토리지와 비슷한 속도로 데이터를 전송할 수 있음을 보여줍니다.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">공유 사용 사례: 여러 개의 독립적이고 동시적인 작업</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">이 테스트에서는 이 솔루션에 대한 예상 사용 사례, 즉 다중 작업, 다중 사용자 AI 교육을 시뮬레이션했습니다.  각 노드는 공유 네트워크 스토리지를 사용하면서 자체적인 교육을 실행했습니다.  결과는 다음 그림에 표시되어 있으며, 솔루션 케이스가 모든 작업이 개별 작업과 본질적으로 동일한 속도로 실행되어 뛰어난 성능을 제공했음을 보여줍니다.  총 처리량은 노드 수에 따라 선형적으로 증가합니다.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">이 그림은 초당 집계된 이미지를 보여줍니다.</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">이 그림은 런타임을 분 단위로 보여줍니다.</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">이 그래프는 100GbE 클라이언트 네트워킹에서 각 서버의 GPU 8개를 사용한 컴퓨팅 노드에 대한 분 단위 런타임과 초당 집계 이미지를 나타내며, 동시 학습 모델과 단일 학습 모델을 모두 결합한 것입니다.  학습 모델의 평균 런타임은 35분 9초였습니다.  개별 런타임은 34분 32초, 36분 21초, 34분 37초, 35분 25초, 그리고 34분 31초였습니다.  훈련 모델의 초당 평균 이미지는 22,573개였고, 개별 이미지는 초당 21,764개, 23,438개, 22,556개, 22,564개, 22,547개였습니다.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">당사의 검증에 따르면 NetApp 데이터 런타임을 사용한 하나의 독립적인 교육 모델은 22,231개의 이미지/초로 34분 54초가 소요되었습니다.  로컬 데이터(DAS) 런타임을 갖춘 독립적인 훈련 모델 하나는 22,102개의 이미지/초로 34분 21초가 걸렸습니다.  nvidia-smi에서 관찰한 바에 따르면, 해당 실행 중에 평균 GPU 사용률은 96%였습니다.  이 평균에는 GPU를 사용하지 않은 테스트 단계가 포함되어 있으며, mpstat으로 측정한 결과 CPU 사용률은 40%였습니다.  이는 각각의 경우 데이터 전송 속도가 충분하다는 것을 보여줍니다.</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">이 솔루션은 NetApp 스토리지와 인공 지능 워크로드에 최적화된 Lenovo 서버를 사용하여 엔트리 레벨과 미드레인지 클러스터 아키텍처에 중점을 둡니다.  이는 대부분의 컴퓨팅 작업이 단일 노드(단일 또는 다중 GPU)이거나 몇 개의 컴퓨팅 노드에 분산되어 있는 중소 규모의 팀을 대상으로 합니다.  이는 대부분의 일상적인 AI 학습 작업이 단일 노드이기 때문에 큰 제한은 아닙니다.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: AI 및 ML 모델 학습을 위한 Lenovo ThinkSystem SR670 V2가 탑재된 NetApp AFF A400</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan, David Arnette, NetApp Mircea Troaca, Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">이 솔루션은 NetApp 스토리지와 인공 지능(AI) 워크로드에 최적화된 Lenovo 서버를 사용하는 중급 클러스터 아키텍처를 제공합니다.  이 솔루션은 대부분 컴퓨팅 작업이 단일 노드(단일 또는 다중 GPU)이거나 몇 개의 컴퓨팅 노드에 분산되어 있는 중소기업을 대상으로 합니다.  이 솔루션은 많은 기업의 일상적인 AI 교육 작업에 적합합니다.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">이 문서에서는 8개의 GPU Lenovo SR670V2 서버, 중급 NetApp AFF A400 스토리지 시스템 및 100GbE 상호 연결 스위치로 구성된 컴퓨팅 및 스토리지 구성의 테스트와 검증에 대해 설명합니다.  성능을 측정하기 위해 ImageNet 데이터 세트, 배치 크기 408, 반정밀도, CUDA, cuDNN을 갖춘 ResNet50을 사용했습니다.  이 아키텍처는 NetApp ONTAP 클라우드 연결 데이터 스토리지의 엔터프라이즈급 기능이 필요한 AI 이니셔티브를 막 시작하는 중소 규모 조직에 효율적이고 비용 효과적인 솔루션을 제공합니다.</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">AI 시스템의 데이터 과학자, 데이터 엔지니어, 데이터 관리자 및 개발자</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">AI 모델 개발을 위한 솔루션을 설계하는 엔터프라이즈 아키텍트</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">딥 러닝(DL) 및 머신 러닝(ML) 개발 목표를 달성하기 위한 효율적인 방법을 찾고 있는 데이터 과학자 및 데이터 엔지니어</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">AI 이니셔티브의 시장 출시 시간을 최대한 단축하고자 하는 비즈니스 리더 및 OT/IT 의사 결정권자</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Lenovo ThinkSystem 서버와 AFF 스토리지를 탑재한 NetApp ONTAP 탑재한 이 솔루션은 기존 CPU와 함께 GPU의 처리 능력을 활용하여 대규모 데이터 세트에 대한 AI 교육을 처리하도록 설계되었습니다.  이 검증은 단일 NetApp AFF A400 스토리지 시스템과 함께 1개, 2개 또는 4개의 Lenovo SR670 V2 서버를 사용하는 확장형 아키텍처를 통해 높은 성능과 최적의 데이터 관리를 보여줍니다.  다음 그림은 아키텍처 개요를 제공합니다.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">이 이미지는 관리 서버, 각각 8개의 GPU를 탑재한 4개의 SR670 V2, NetApp ONTAP 스토리지 시스템으로 둘러싸인 이더넷 스위치를 보여줍니다.</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">여러 개의 훈련 작업을 병렬로 실행할 때 매우 효율적이고 비용 효율적인 성능을 발휘합니다.</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">다양한 Lenovo 서버 수와 다양한 NetApp 스토리지 컨트롤러 모델을 기반으로 한 확장 가능한 성능</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">데이터 손실 없이 낮은 복구 지점 목표(RPO) 및 복구 시간 목표(RTO)를 충족하는 강력한 데이터 보호</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">개발 워크플로우를 간소화하기 위한 스냅샷 및 복제를 통한 최적화된 데이터 관리</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">이 검증에서는 MLPerf v2.0에서 지정한 대로 이미지 인식 훈련을 수행했습니다.  구체적으로, 우리는 ImageNet 데이터 세트를 사용하여 ResNet v2.0 모델을 훈련했습니다.  가장 중요한 지표는 원하는 정확도에 도달하는 데 걸리는 시간입니다.  또한, 확장 효율성을 더 잘 판단하기 위해 초당 이미지 수로 교육 대역폭을 보고합니다.</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">이 검증에서는 MLPerf v2.0에서 지정한 대로 이미지 인식 훈련을 수행했습니다.  구체적으로, 우리는 ImageNet 데이터 세트를 사용하여 ResNet v2.0 모델을 훈련하여 정확도가 76.1%에 도달할 때까지 진행했습니다.  가장 중요한 지표는 원하는 정확도에 도달하는 데 걸리는 시간입니다.  또한, 확장 효율성을 더 잘 판단하기 위해 초당 이미지 수로 교육 대역폭을 보고합니다.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">1차 테스트 사례에서는 동시에 실행되는 여러 개의 독립적인 교육 프로세스(노드당 하나)를 평가했습니다.  이는 여러 데이터 과학자가 사용하는 공유 시스템인 주요 사용 사례를 시뮬레이션합니다.  두 번째 테스트 사례에서는 확장 효율성을 평가했습니다.</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">이 섹션에서는 이 솔루션의 테스트 결과를 요약합니다.</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">다음 표는 이 솔루션에 대해 수행된 모든 테스트의 결과를 요약한 것입니다.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">테스트 설명</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">결과 요약</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">이미지 인식 훈련: 여러 동시 작업</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">매우 효율적인 성능.  클러스터가 완전히 사용되었을 때에도 모든 작업은 최대 속도로 실행되었습니다.  NetApp 스토리지 시스템은 로컬 SSD 스토리지와 비슷한 수준의 교육 성능을 제공하는 동시에 서버 간에 데이터를 쉽게 공유할 수 있도록 했습니다.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">이미지 인식 훈련: 확장</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">최대 4개 노드까지 매우 효율적입니다.  그 시점에서는 확장은 덜 효율적이었지만 여전히 실행 가능했습니다.  속도가 더 빠른 계산 네트워크를 사용하면 확장성이 향상됩니다.  NetApp 스토리지 시스템은 로컬 SSD 스토리지와 비슷한 수준의 교육 성능을 제공하는 동시에 서버 간에 데이터를 쉽게 공유할 수 있도록 했습니다.</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">이 섹션에서는 이 솔루션의 주요 구성 요소를 더 자세히 소개합니다.</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">NetApp AFF 스토리지 시스템을 사용하면 업계 최고의 성능, 뛰어난 유연성, 클라우드 통합, 동급 최고의 데이터 관리 기능을 통해 기업의 스토리지 요구 사항을 충족할 수 있습니다.  플래시에 맞춰 특별히 설계된 AFF 시스템은 비즈니스에 중요한 데이터를 가속화하고 관리하며 보호하는 데 도움이 됩니다.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">이 그래픽은 NetApp AFF A400 스토리지 컨트롤러의 전면을 보여줍니다.</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">이 그래픽은 NetApp AFF A400 스토리지 컨트롤러의 뒷면을 보여줍니다.</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400 다음 기능을 포함하는 중급 NVMe 플래시 스토리지 시스템입니다.</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">최대 유효 용량: ~20PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">최대 확장: 2~24개 노드(12개 HA 쌍)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">25GbE 및 16Gb FC 호스트 지원</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">NVMe 확장 스토리지 선반에 대한 100GbE RDMA over Converged Ethernet(RoCE) 연결</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">NVMe 셸프가 연결되지 않은 경우 100GbE RoCE 포트를 호스트 네트워크 연결에 사용할 수 있습니다.</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">전체 12Gbps SAS 연결 확장 스토리지 선반</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">두 가지 구성으로 제공됩니다.</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">이더넷: 4x 25Gb 이더넷(SFP28) 포트</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">파이버 채널: 4x 16Gb FC(SFP+) 포트</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% 8KB 랜덤 읽기 @.4ms 400k IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">엔트리 레벨 AI/ML 배포를 위한 NetApp AFF A250 기능은 다음과 같습니다.</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">최대 유효 용량: 35PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">최대 확장: 2~24개 노드(12개 HA 쌍)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">최신 NetApp ONTAP 릴리스 ONTAP 9.8 이상을 기반으로 구축됨</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">HA 및 클러스터 상호 연결을 위한 2개의 25Gb 이더넷 포트</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp 또한 대규모 AI/ML 배포에 더 높은 성능과 확장성을 제공하는 AFF A800 및 AFF A700 과 같은 다른 스토리지 시스템을 제공합니다.</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">NetApp 의 최신 스토리지 관리 소프트웨어인 ONTAP 9를 사용하면 기업이 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다.  ONTAP 업계 최고의 데이터 관리 역량을 활용하여 데이터가 어디에 있든 단일 도구 세트를 사용하여 데이터를 관리하고 보호할 수 있도록 지원합니다.  데이터는 필요한 곳, 즉 엣지, 코어, 클라우드로 자유롭게 이동할 수 있습니다.  ONTAP 9에는 하이브리드 클라우드 아키텍처 전반에서 데이터 관리를 간소화하고, 중요 데이터를 가속화하고 보호하며, 미래 지향적인 인프라를 구축하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*최소, 최대 및 적응형 서비스 품질(QoS).*  세분화된 QoS 제어는 공유 빈도가 높은 환경에서 중요한 애플리케이션의 성능 수준을 유지하는 데 도움이 됩니다.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool.*  이 기능은 콜드 데이터를 Amazon Web Services(AWS), Azure, NetApp StorageGRID 객체 스토리지를 포함한 퍼블릭 및 프라이빗 클라우드 스토리지 옵션으로 자동으로 계층화합니다.</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*성능과 낮은 지연 시간.*  ONTAP 가능한 가장 낮은 지연 시간으로 가능한 가장 높은 처리량을 제공합니다.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp 볼륨 암호화.*  ONTAP 온보드 및 외부 키 관리 지원을 통해 기본 볼륨 수준 암호화를 제공합니다.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9는 까다롭고 끊임없이 변화하는 비즈니스 요구 사항을 충족하는 데 도움이 됩니다.</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*원활한 확장 및 중단 없는 운영.*  ONTAP 기존 컨트롤러뿐만 아니라 확장형 클러스터에도 중단 없이 용량을 추가할 수 있도록 지원합니다.  고객은 비용이 많이 드는 데이터 마이그레이션이나 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*새로운 애플리케이션과의 통합.*  ONTAP 기존 엔터프라이즈 앱을 지원하는 동일한 인프라를 사용하여 OpenStack, Hadoop, MongoDB와 같은 차세대 플랫폼과 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroup 볼륨</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">훈련 데이터 세트는 일반적으로 잠재적으로 수십억 개의 파일로 구성된 컬렉션입니다.  파일에는 텍스트, 오디오, 비디오 및 기타 형태의 비정형 데이터가 포함될 수 있으며, 이러한 데이터는 병렬로 읽을 수 있도록 저장하고 처리해야 합니다.  저장 시스템은 많은 작은 파일을 저장해야 하며 순차적이고 무작위적인 I/O를 위해 해당 파일을 병렬로 읽어야 합니다.</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">FlexGroup 볼륨(다음 그림)은 여러 구성 멤버 볼륨으로 이루어진 단일 네임스페이스로, 스토리지 관리자에게 NetApp FlexVol volume 처럼 관리되고 작동합니다.  FlexGroup 볼륨의 파일은 개별 멤버 볼륨에 할당되며 볼륨이나 노드에 걸쳐 스트라이프되지 않습니다.  다음과 같은 기능을 제공합니다.</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">최대 20페타바이트의 용량과 높은 메타데이터 워크로드를 위한 예측 가능한 낮은 대기 시간</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">동일한 네임스페이스에 최대 4000억 개의 파일</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">CPU, 노드, 집계 및 구성 FlexVol 볼륨 전반의 NAS 워크로드에서 병렬화된 작업</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">이 이미지는 FlexGroup 내에 주요 파일이 있는 여러 볼륨을 포함하는 HA 스토리지 컨트롤러 쌍을 보여줍니다.</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">레노버 ThinkSystem 포트폴리오</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Lenovo ThinkSystem 서버를 구축하는 주요 이점은 다음과 같습니다.</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">비즈니스와 함께 성장하는 확장성이 뛰어난 모듈식 디자인</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">AI 분야에서 Lenovo는 기업이 자사 워크로드에 ML과 AI의 이점을 이해하고 도입할 수 있도록 돕기 위해 실용적인 접근 방식을 취하고 있습니다.  Lenovo 고객은 Lenovo AI 혁신 센터에서 Lenovo AI 제품을 탐색하고 평가하여 특정 사용 사례에 대한 가치를 완벽하게 이해할 수 있습니다.  가치 실현 시간을 단축하기 위해 이러한 고객 중심적 접근 방식은 고객에게 AI에 맞게 사용할 준비가 되고 최적화된 솔루션 개발 플랫폼에 대한 개념 증명을 제공합니다.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">레노버 SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Lenovo ThinkSystem SR670 V2 랙 서버는 가속화된 AI와 고성능 컴퓨팅(HPC)을 위한 최적의 성능을 제공합니다.  최대 8개의 GPU를 지원하는 SR670 V2는 ML, DL 및 추론의 계산 집약적 워크로드 요구 사항에 적합합니다.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">이 이미지는 SR670의 세 가지 구성을 보여줍니다.  첫 번째는 8개의 2.5인치 HS 드라이브와 2개의 PCIe I/O 슬롯이 있는 4개의 SXM GPU를 보여줍니다.  두 번째는 4개의 더블 폭 또는 8개의 싱글 폭 GPU 슬롯과 8개의 2.5인치 또는 4개의 3.5인치 HS 드라이브가 있는 2개의 PCIe I/O 슬롯을 보여줍니다.  세 번째는 6개의 EDSFF HS 드라이브와 2개의 PCIe I/O 슬롯이 있는 8개의 더블 폭 GPU 슬롯을 보여줍니다.</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">최신 확장 가능한 Intel Xeon CPU를 탑재하고 하이엔드 GPU( NVIDIA A100 80GB PCIe 8x GPU 포함)를 지원하는 ThinkSystem SR670 V2는 AI 및 HPC 워크로드에 최적화되고 가속화된 성능을 제공합니다.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">점점 더 많은 워크로드가 가속기의 성능을 사용하게 되면서 GPU 밀도에 대한 요구도 늘어났습니다.  소매, 금융 서비스, 에너지, 의료 등의 산업에서는 GPU를 사용하여 ML, DL, 추론 기술을 통해 더 많은 통찰력을 추출하고 혁신을 추진하고 있습니다.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2는 차세대 플랫폼을 갖춘 슈퍼컴퓨팅 클러스터의 데이터 센터 밀도를 유지하면서 시스템 성능을 극대화하여 프로덕션에서 가속화된 HPC 및 AI 워크로드를 배포하기 위한 최적화된 엔터프라이즈급 솔루션입니다.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">다른 기능은 다음과 같습니다.</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">고속 네트워크 어댑터가 GPU에 직접 연결되어 I/O 성능을 극대화하는 GPU 직접 RDMA I/O를 지원합니다.</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">NVMe 드라이브가 GPU에 직접 연결되어 스토리지 성능을 극대화하는 GPU 직접 스토리지를 지원합니다.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf는 AI 성능을 평가하는 업계 최고의 벤치마크 제품군입니다.  이 검증에서는 가장 인기 있는 AI 프레임워크 중 하나인 MXNet의 이미지 분류 벤치마크를 사용했습니다.  MXNet_benchmarks 교육 스크립트는 AI 교육을 구동하는 데 사용되었습니다.  이 스크립트는 여러 가지 인기 있는 기존 모델의 구현을 포함하고 있으며 가능한 한 빠르게 실행되도록 설계되었습니다.  단일 머신에서 실행하거나 여러 호스트에 분산 모드로 실행할 수 있습니다.</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">본 논문에서는 Intel Xeon 6 프로세서와 NetApp 데이터 관리 솔루션의 기술과 기능을 결합한 Enterprise RAG용 NetApp AIPod 의 검증된 참조 설계를 제시합니다.  이 솔루션은 대규모 언어 모델을 활용하여 동시 사용자에게 정확하고 상황에 맞는 응답을 제공하는 다운스트림 ChatQnA 애플리케이션을 보여줍니다.  응답은 공기 간격이 있는 RAG 추론 파이프라인을 통해 조직의 내부 지식 저장소에서 검색됩니다.</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini - NetApp 및 Intel을 사용한 엔터프라이즈 RAG 추론</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">인텔 로고</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">점점 더 많은 조직에서 사용자 프롬프트를 해석하고 응답을 생성하기 위해 검색 증강 생성(RAG) 애플리케이션과 대규모 언어 모델(LLM)을 활용하여 생산성과 비즈니스 가치를 높이고 있습니다.  이러한 프롬프트와 응답에는 조직의 내부 지식 기반, 데이터 레이크, 코드 저장소, 문서 저장소에서 검색한 텍스트, 코드, 이미지 또는 치료용 단백질 구조가 포함될 수 있습니다.  이 논문에서는 Intel Xeon 6 프로세서가 탑재된 NetApp AFF 스토리지와 서버로 구성된 NetApp AIPod Mini 솔루션의 참조 설계를 다룹니다.  여기에는 Intel Advanced Matrix Extensions(Intel AMX)와 결합된 NetApp ONTAP 데이터 관리 소프트웨어와 OPEA(Open Platform for Enterprise AI)를 기반으로 구축된 Intel AI for Enterprise Retrieval-augmented Generation(RAG) 소프트웨어가 포함됩니다.  기업용 RAG를 위한 NetApp AIPod Mini를 사용하면 조직에서 공개 LLM을 비공개 생성 AI(GenAI) 추론 솔루션으로 확장할 수 있습니다.  이 솔루션은 기업 규모에서 효율적이고 비용 효율적인 RAG 추론을 보여주며, 신뢰성을 향상시키고 독점 정보에 대한 더 나은 제어력을 제공하도록 설계되었습니다.</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">인텔 스토리지 파트너 검증</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">Intel Xeon 6 프로세서로 구동되는 서버는 최대 성능을 위해 Intel AMX를 사용하여 까다로운 AI 추론 워크로드를 처리하도록 제작되었습니다.  최적의 스토리지 성능과 확장성을 구현하기 위해 NetApp ONTAP 사용하여 솔루션의 검증이 성공적으로 완료되었으며, 이를 통해 기업은 RAG 애플리케이션의 요구 사항을 충족할 수 있습니다.  이 검증은 Intel Xeon 6 프로세서가 장착된 서버에서 수행되었습니다.  Intel과 NetApp 최적화되고 확장 가능하며 고객 비즈니스 요구 사항에 맞는 AI 솔루션을 제공하는 데 중점을 둔 강력한 파트너십을 맺고 있습니다.</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">NetApp 으로 RAG 시스템을 실행하는 이점</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">RAG 애플리케이션은 PDF, 텍스트, CSV, Excel 또는 지식 그래프와 같은 다양한 유형의 회사 문서 저장소에서 지식을 검색하는 것을 포함합니다.  이러한 데이터는 일반적으로 데이터 소스인 S3 개체 스토리지나 온프레미스 NFS와 같은 솔루션에 저장됩니다.  NetApp 엣지, 데이터 센터, 클라우드 생태계 전반에서 데이터 관리, 데이터 이동성, 데이터 거버넌스, 데이터 보안 기술 분야를 선도해 왔습니다.  NetApp ONTAP 데이터 관리 솔루션은 일괄 및 실시간 추론을 포함한 다양한 유형의 AI 워크로드를 지원하는 엔터프라이즈급 스토리지를 제공하며 다음과 같은 이점을 제공합니다.</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">속도와 확장성.  독립적으로 성능과 용량을 확장할 수 있는 기능을 통해 버전 관리를 위해 대용량 데이터 세트를 고속으로 처리할 수 있습니다.</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">데이터 접근.  다중 프로토콜 지원을 통해 클라이언트 애플리케이션은 S3, NFS, SMB 파일 공유 프로토콜을 사용하여 데이터를 읽을 수 있습니다.  ONTAP S3 NAS 버킷은 다중 모드 LLM 추론 시나리오에서 데이터 액세스를 용이하게 할 수 있습니다.</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">신뢰성과 기밀성.  ONTAP 데이터 보호, 내장형 NetApp 자율형 랜섬웨어 보호(ARP), 동적 스토리지 프로비저닝을 제공하며, 소프트웨어 및 하드웨어 기반 암호화를 모두 제공하여 기밀성과 보안을 강화합니다.  ONTAP 은 모든 SSL 연결에 대해 FIPS 140-2를 준수합니다.</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">이 문서는 엔터프라이즈 RAG 및 GenAI 솔루션을 제공하기 위해 구축된 인프라를 활용하고자 하는 AI 의사결정권자, 데이터 엔지니어, 비즈니스 리더 및 부서 임원을 대상으로 합니다.  AI 추론, LLM, Kubernetes, 네트워킹 및 구성 요소에 대한 사전 지식이 있으면 구현 단계에 도움이 됩니다.</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">인텔 AI 기술</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">제온 6 프로세서</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">호스트 CPU로 Xeon 6을 사용하면 가속 시스템은 높은 단일 스레드 성능, 더 높은 메모리 대역폭, 향상된 안정성, 가용성, 서비스 용이성(RAS) 및 더 많은 I/O 레인의 이점을 누릴 수 있습니다.  Intel AMX는 INT8 및 BF16에 대한 추론을 가속화하고 FP16으로 훈련된 모델을 지원하며, INT8의 경우 코어당 사이클당 최대 2,048개의 부동 소수점 연산, BF16/FP16의 경우 코어당 사이클당 최대 1,024개의 부동 소수점 연산을 지원합니다.  Xeon 6 프로세서를 사용하여 RAG 솔루션을 배포하려면 일반적으로 최소 250GB의 RAM과 500GB의 디스크 공간이 권장됩니다.  하지만 이는 LLM 모델 크기에 크게 좌우됩니다.  자세한 내용은 Intel을 참조하세요.<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block> 제품 개요.</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300,300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">그림 1 - Intel Xeon 6 프로세서가 탑재된 컴퓨팅 서버<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">NetApp AFF 스토리지</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">보급형 및 중급형 NetApp AFF A-Series 시스템은 더욱 강력한 성능, 밀도, 그리고 더 높은 효율성을 제공합니다.  NetApp AFF A20, AFF A30 및 AFF A50 시스템은 단일 OS를 기반으로 블록, 파일 및 객체를 지원하는 진정한 통합 스토리지를 제공하여 하이브리드 클라우드 전반에서 가장 낮은 비용으로 RAG 애플리케이션의 데이터를 원활하게 관리, 보호 및 모바일화할 수 있습니다.</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">그림 2 - NetApp AFF A-시리즈 시스템.<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*하드웨어*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*수량*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*논평*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">Intel Xeon 6 기반 서버</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">RAG 추론 노드는 듀얼 소켓 Intel Xeon 6900 시리즈 또는 Intel Xeon 6700 시리즈 프로세서와 DDR5(6400MHz) 또는 MRDIMM(8800MHz)을 갖춘 250GB~3TB RAM을 탑재하고 있습니다.  2U 서버.</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">Intel 프로세서가 탑재된 제어 평면 서버</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">쿠버네티스 제어 평면/1U 서버.</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">100Gb 이더넷 스위치 선택</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">데이터 센터 스위치.</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20(또는 AFF A30; AFF A50)</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">최대 저장 용량: 9.3PB.  참고: 네트워킹: 10/25/100GbE 포트.</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">이 참조 설계의 검증을 위해 Supermicro(222HA-TN-OTO-37)의 Intel Xeon 6 프로세서가 장착된 서버와 Arista(7280R3A)의 100GbE 스위치가 사용되었습니다.</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">엔터프라이즈 AI를 위한 오픈 플랫폼</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">OPEA(Open Platform for Enterprise AI)는 인텔이 생태계 파트너와 협력하여 주도하는 오픈 소스 이니셔티브입니다.  RAG에 중점을 두고 최첨단 생성적 AI 시스템 개발을 가속화하도록 설계된 구성 가능한 구성 요소의 모듈식 플랫폼을 제공합니다.  OPEA에는 LLM, 데이터 저장소, 프롬프트 엔진, RAG 아키텍처 청사진, 성능, 기능, 신뢰성, 기업 준비 상태를 기준으로 생성 AI 시스템을 평가하는 4단계 평가 방법 등을 갖춘 포괄적인 프레임워크가 포함되어 있습니다.</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">OPEA의 핵심은 두 가지 핵심 구성 요소로 구성됩니다.</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps: 마이크로서비스 구성 요소로 구성된 서비스 기반 툴킷</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">GenAIExamples: 실제 사용 사례를 보여주는 ChatQnA와 같은 즉시 배포 가능한 솔루션</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">OPEA 프로젝트 문서</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">자세한 내용은 다음을 참조하세요.<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">OPEA가 지원하는 엔터프라이즈 추론용 Intel AI</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">Intel AI for Enterprise RAG의 OPEA는 기업 데이터를 실행 가능한 통찰력으로 전환하는 과정을 간소화합니다.  Intel Xeon 프로세서를 기반으로, 업계 파트너의 구성 요소를 통합하여 엔터프라이즈 솔루션 배포에 대한 간소화된 접근 방식을 제공합니다.  검증된 오케스트레이션 프레임워크를 통해 원활하게 확장되므로 기업에 필요한 유연성과 선택권을 제공합니다.</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">OPEA의 기반을 바탕으로, Intel AI for Enterprise RAG는 확장성, 보안 및 사용자 경험을 향상시키는 주요 기능으로 이러한 기반을 확장합니다.  이러한 기능에는 최신 서비스 기반 아키텍처와의 원활한 통합을 위한 서비스 메시 기능, 파이프라인 안정성을 위한 프로덕션 준비 검증, 서비스로서의 RAG를 위한 기능이 풍부한 UI가 포함되어 워크플로를 쉽게 관리하고 모니터링할 수 있습니다.  또한, 인텔과 파트너 지원을 통해 안전하고 규정을 준수하는 운영을 위한 UI 및 애플리케이션과 통합된 ID 및 액세스 관리(IAM)와 결합된 광범위한 솔루션 생태계에 대한 액세스를 제공합니다.  프로그래밍 가능한 가드레일은 파이프라인 동작에 대한 세부적인 제어를 제공하여 사용자 정의된 보안 및 규정 준수 설정을 가능하게 합니다.</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">ONTAP S3 구성에 대해 알아보세요</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP 은 NetApp의 중요 데이터 스토리지 솔루션을 뒷받침하는 기반 기술입니다.  ONTAP 에는 사이버 공격에 대한 자동 랜섬웨어 보호, 내장형 데이터 전송 기능, 스토리지 효율성 기능 등 다양한 데이터 관리 및 데이터 보호 기능이 포함되어 있습니다.  이러한 이점은 LLM 배포를 위한 NAS, SAN, 객체 및 소프트웨어 정의 스토리지의 온프레미스부터 하이브리드 멀티클라우드까지 다양한 아키텍처에 적용됩니다.  ONTAP 클러스터에서 ONTAP S3 개체 스토리지 서버를 사용하면 RAG 애플리케이션을 배포하고, 권한이 있는 사용자와 클라이언트 애플리케이션을 통해 제공되는 ONTAP 의 스토리지 효율성과 보안을 활용할 수 있습니다.  자세한 내용은 다음을 참조하세요.<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">Git에서 NetApp Trident</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">NetApp Trident 소프트웨어는 Red Hat OpenShift를 포함하여 컨테이너와 Kubernetes 배포판을 위한 오픈 소스이자 완벽하게 지원되는 스토리지 오케스트레이터입니다.  Trident NetApp ONTAP 포함한 전체 NetApp 스토리지 포트폴리오와 호환되며 NFS 및 iSCSI 연결도 지원합니다.  자세한 내용은 다음을 참조하세요.<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*소프트웨어*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*버전*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">Enterprise RAG용 Intel AI용 OPEA</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">OPEA 마이크로서비스 기반 엔터프라이즈 RAG 플랫폼</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">컨테이너 스토리지 인터페이스(CSI 드라이버)</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetApp Trident 25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">동적 프로비저닝, NetApp 스냅샷 복사본 및 볼륨을 활성화합니다.</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">우분투</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">2노드 클러스터의 OS</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">컨테이너 오케스트레이션</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">쿠버네티스 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">RAG 프레임워크를 실행하기 위한 환경</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">AFF A20의 저장 OS.  Vscan과 ARP가 특징입니다.</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">솔루션 구축</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">소프트웨어 스택</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">이 솔루션은 Intel Xeon 기반 앱 노드로 구성된 Kubernetes 클러스터에 배포됩니다.  Kubernetes 제어 평면의 기본적인 고가용성을 구현하려면 최소 3개의 노드가 필요합니다.  다음 클러스터 레이아웃을 사용하여 솔루션을 검증했습니다.</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">표 3 - 쿠버네티스 클러스터 레이아웃</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">마디</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">역할</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">Intel Xeon 6 프로세서와 1TB RAM을 탑재한 서버</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">앱 노드, 제어 평면 노드</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">일반 서버</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">제어 평면 노드</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600,600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">다음 그림은 솔루션의 "소프트웨어 스택 뷰"를 보여줍니다.<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">배포 단계</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">ONTAP 스토리지 어플라이언스 배포</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">ONTAP 하드웨어 시스템 문서</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">NetApp ONTAP 스토리지 어플라이언스를 배포하고 프로비저닝합니다.  를 참조하세요<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block> 자세한 내용은.</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">NFS 및 S3 액세스를 위한 ONTAP SVM 구성</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">Kubernetes 노드에서 액세스할 수 있는 네트워크에서 NFS 및 S3 액세스를 위한 ONTAP 스토리지 가상 머신(SVM)을 구성합니다.</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">ONTAP 문서.</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">ONTAP System Manager를 사용하여 SVM을 생성하려면 스토리지 &gt; 스토리지 VM으로 이동한 다음 + 추가 버튼을 클릭합니다.  SVM에 대한 S3 액세스를 활성화할 때 시스템에서 생성된 인증서가 아닌 외부 CA(인증 기관) 서명 인증서를 사용하는 옵션을 선택하세요.  자체 서명된 인증서나 공개적으로 신뢰할 수 있는 CA에서 서명한 인증서를 사용할 수 있습니다.  추가 세부 사항은 다음을 참조하세요.<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">다음 스크린샷은 ONTAP 시스템 관리자를 사용하여 SVM을 만드는 방법을 보여줍니다.  사용자의 환경에 맞게 세부 정보를 수정하세요.</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">그림 4 - ONTAP 시스템 관리자를 사용한 SVM 생성.<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">S3 권한 구성</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">이전 단계에서 생성한 SVM에 대한 S3 사용자/그룹 설정을 구성합니다.  해당 SVM에 대한 모든 S3 API 작업에 대한 전체 액세스 권한이 있는 사용자가 있는지 확인하세요.  자세한 내용은 ONTAP S3 문서를 참조하세요.</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">참고: 이 사용자는 Intel AI for Enterprise RAG 애플리케이션의 데이터 수집 서비스에 필요합니다.  ONTAP System Manager를 사용하여 SVM을 생성한 경우 System Manager는 자동으로 다음과 같은 사용자를 생성합니다.<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> 그리고 정책이라는 이름<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> SVM을 생성했을 때 권한이 할당되지 않았습니다.<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> .</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">이 사용자의 권한을 편집하려면 저장소 &gt; 저장소 VM으로 이동한 후 이전 단계에서 만든 SVM의 이름을 클릭하고 설정을 클릭한 다음 "S3" 옆에 있는 연필 아이콘을 클릭합니다.  주다<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> 모든 S3 API 작업에 대한 전체 액세스, 연결하는 새 그룹 생성<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block> 와 함께<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> 다음 스크린샷에 표시된 대로 정책입니다.</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">그림 5 - S3 권한.</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">S3 버킷 생성</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">이전에 만든 SVM 내에 S3 버킷을 만듭니다.  ONTAP 시스템 관리자를 사용하여 SVM을 생성하려면 스토리지 &gt; 버킷으로 이동한 다음 + 추가 버튼을 클릭합니다.  자세한 내용은 ONTAP S3 설명서를 참조하세요.</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">다음 스크린샷은 ONTAP System Manager를 사용하여 S3 버킷을 생성하는 방법을 보여줍니다.</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">그림 6 - S3 버킷을 생성합니다.<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">S3 버킷 권한 구성</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">이전 단계에서 생성한 S3 버킷에 대한 권한을 구성합니다.  이전 단계에서 구성한 사용자에게 다음 권한이 있는지 확인하세요.<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">ONTAP S3 문서</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">ONTAP System Manager를 사용하여 S3 버킷 권한을 편집하려면 저장소 &gt; 버킷으로 이동한 후 버킷 이름을 클릭하고 권한을 클릭한 다음 편집을 클릭합니다.  를 참조하세요<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block> 추가 세부 사항은 다음을 참조하세요.</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">다음 스크린샷은 ONTAP 시스템 관리자에서 필요한 버킷 권한을 보여줍니다.</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">그림 7 - S3 버킷 권한.<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">버킷 교차 출처 리소스 공유 규칙 생성</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">ONTAP CLI를 사용하여 이전 단계에서 만든 버킷에 대한 버킷 CORS(교차 출처 리소스 공유) 규칙을 만듭니다.</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">이 규칙은 Intel AI for Enterprise RAG 웹 애플리케이션의 OPEA가 웹 브라우저 내에서 버킷과 상호 작용할 수 있도록 허용합니다.</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">서버 배포</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">서버를 배포하고 모든 서버에 Ubuntu 22.04 LTS를 설치합니다.  Ubuntu를 설치한 후 모든 서버에 NFS 유틸리티를 설치합니다.  NFS 유틸리티를 설치하려면 다음 명령을 실행하세요.</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">쿠버네티스 설치</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Kubespray 문서</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">Kubespray를 사용하여 서버에 Kubernetes를 설치합니다.  를 참조하세요<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block> 자세한 내용은.</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">Trident CSI 드라이버 설치</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Trident 설치 문서</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">Kubernetes 클러스터에 NetApp Trident CSI 드라이버를 설치합니다.  를 참조하세요<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block> 자세한 내용은.</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">Trident 백엔드 만들기</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Trident 백엔드 문서</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">이전에 만든 SVM에 대한 Trident 백엔드를 만듭니다.  백엔드를 생성할 때 다음을 사용하세요.<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> 운전사.  를 참조하세요<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block> 자세한 내용은.</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">스토리지 클래스 생성</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">이전 단계에서 만든 Trident 백엔드에 해당하는 Kubernetes 스토리지 클래스를 만듭니다.  자세한 내용은 Trident 스토리지 클래스 문서를 참조하세요.</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">엔터프라이즈 RAG 배포를 위한 Intel AI</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">Kubernetes 클러스터에 Intel AI for Enterprise RAG용 OPEA를 설치합니다.  를 참조하세요<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block> 자세한 내용은 문서를 참조하세요.  이 문서의 뒷부분에서 설명하는 필수 구성 파일 수정 사항을 꼭 기록해 두세요.  Intel AI for Enterprise RAG 애플리케이션이 ONTAP 스토리지 시스템에서 올바르게 작동하려면 설치 플레이북을 실행하기 전에 이러한 수정 작업을 해야 합니다.</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">ONTAP S3 사용 활성화</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">Intel AI for Enterprise RAG에 OPEA를 설치할 때, ONTAP S3를 소스 데이터 저장소로 사용할 수 있도록 기본 구성 파일을 편집합니다.</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">ONTAP S3 사용을 활성화하려면 다음 값을 설정하세요.<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block> 부분.</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">참고: 기본적으로 Intel AI for Enterprise RAG 애플리케이션은 SVM의 모든 기존 버킷에서 데이터를 수집합니다.  SVM에 여러 버킷이 있는 경우 다음을 수정할 수 있습니다.<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block> 특정 버킷에서만 데이터가 수집되도록 필드를 설정합니다.</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">예약된 동기화 설정 구성</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">Intel AI for Enterprise RAG 애플리케이션에 OPEA를 설치할 때 다음을 활성화하세요.<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> 그러면 애플리케이션이 S3 버킷에서 새 파일이나 업데이트된 파일을 자동으로 수집합니다.</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">언제<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> 이 기능이 활성화되면 애플리케이션이 자동으로 소스 S3 버킷에 새 파일이나 업데이트된 파일이 있는지 확인합니다.  이 동기화 프로세스의 일부로 발견된 새 파일이나 업데이트된 파일은 자동으로 수집되어 RAG 지식 기반에 추가됩니다.  이 애플리케이션은 미리 설정된 시간 간격에 따라 소스 버킷을 확인합니다.  기본 시간 간격은 60초입니다. 즉, 애플리케이션은 60초마다 변경 사항을 확인합니다.  귀하의 특정 요구 사항에 맞게 이 간격을 변경할 수도 있습니다.</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">활성화하려면<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block> 그리고 동기화 간격을 설정하고 다음 값을 설정하세요.<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">볼륨 액세스 모드 변경</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">~ 안에<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block> , 각 볼륨에 대해<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block> 목록, 변경<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> 에게<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> .</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">(선택 사항) SSL 인증서 확인 비활성화</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">SVM에 대한 S3 액세스를 활성화할 때 자체 서명 인증서를 사용한 경우 SSL 인증서 검증을 비활성화해야 합니다.  공개적으로 신뢰할 수 있는 CA에서 서명한 인증서를 사용한 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">SSL 인증서 검증을 비활성화하려면 다음 값을 설정하세요.<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">Enterprise RAG UI용 Intel AI용 OPEA에 액세스하세요.</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">Enterprise RAG 배포 문서용 Intel AI</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">Enterprise RAG UI를 위한 Intel AI의 OPEA에 접속하세요.  를 참조하세요<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block> 자세한 내용은.</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">그림 8 - Enterprise RAG UI용 Intel AI용 OPEA.<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">RAG에 대한 데이터 수집</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">이제 RAG 기반 쿼리 증강에 포함할 파일을 수집할 수 있습니다.  파일을 수집하는 데에는 여러 가지 옵션이 있습니다.  귀하의 필요에 맞는 적절한 옵션을 선택하세요.</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">참고: 파일이 수집된 후, Intel AI for Enterprise RAG 애플리케이션의 OPEA는 자동으로 파일 업데이트를 확인하고 그에 따라 업데이트를 수집합니다.</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*옵션 1: S3 버킷에 직접 업로드 여러 파일을 한 번에 수집하려면 선택한 S3 클라이언트를 사용하여 S3 버킷(앞서 만든 버킷)에 파일을 업로드하는 것이 좋습니다.  인기 있는 S3 클라이언트로는 AWS CLI, Amazon SDK for Python(Boto3), s3cmd, S3 Browser, Cyberduck, Commander One 등이 있습니다.  파일이 지원되는 유형인 경우 S3 버킷에 업로드하는 모든 파일은 Intel AI for Enterprise RAG 애플리케이션용 OPEA에 의해 자동으로 수집됩니다.</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">참고: 이 글을 쓰는 시점에서 지원되는 파일 형식은 다음과 같습니다: PDF, HTML, TXT, DOC, DOCX, PPT, PPTX, MD, XML, JSON, JSONL, YAML, XLS, XLSX, CSV, TIFF, JPG, JPEG, PNG, SVG.</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">Intel AI for Enterprise RAG UI의 OPEA를 사용하면 파일이 제대로 수집되었는지 확인할 수 있습니다.  자세한 내용은 Intel AI for Enterprise RAG UI 문서를 참조하세요.  애플리케이션이 많은 수의 파일을 수집하는 데 시간이 걸릴 수 있습니다.</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*옵션 2: UI를 사용하여 업로드 적은 수의 파일만 수집해야 하는 경우 OPEA for Intel AI for Enterprise RAG UI를 사용하여 수집할 수 있습니다.  자세한 내용은 Intel AI for Enterprise RAG UI 문서를 참조하세요.</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">그림 9 - 데이터 수집 UI.<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">채팅 쿼리 실행</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">이제 포함된 채팅 UI를 사용하여 Intel AI for Enterprise RAG 애플리케이션의 OPEA와 "채팅"할 수 있습니다.  귀하의 질의에 응답할 때, 해당 애플리케이션은 귀하가 수집한 파일을 사용하여 RAG를 수행합니다.  즉, 해당 애플리케이션은 수집된 파일에서 관련 정보를 자동으로 검색하고 사용자의 질의에 응답할 때 이 정보를 통합합니다.</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">검증 노력의 일환으로 우리는 인텔과 협력하여 성능 테스트를 실시했습니다.  이 테스트를 통해 다음 표에 설명된 크기 지침이 도출되었습니다.</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">특성화</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">가치</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">모델 사이즈</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">200억 개의 매개변수</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">라마-8B, 라마-13B, 미스트랄 7B, 퀀 14B, 딥시크 디스틸 8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">입력 크기</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">~2k 토큰</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">~4페이지</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">출력 크기</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">동시 사용자</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">"동시 사용자"란 동시에 쿼리를 제출하는 프롬프트 요청을 말합니다.</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_참고: 위에 제시된 크기 지침은 96개 코어가 있는 Intel Xeon 6 프로세서를 사용하여 수집된 성능 검증 및 테스트 결과를 기반으로 합니다.  유사한 I/O 토큰과 모델 크기 요구 사항을 가진 고객의 경우 96개 또는 128개 코어가 있는 Xeon 6 프로세서가 장착된 서버를 사용하는 것이 좋습니다.</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">기업 RAG 시스템과 LLM은 조직이 정확하고 상황에 맞는 응답을 제공할 수 있도록 돕는 기술로 함께 작동합니다.  이러한 대응에는 방대한 양의 개인 및 기업 내부 데이터를 기반으로 한 정보 검색이 포함됩니다.  RAG, API, 벡터 임베딩 및 고성능 저장 시스템을 사용하여 회사 데이터가 포함된 문서 저장소를 쿼리하면 데이터가 더 빠르고 안전하게 처리됩니다.  NetApp AIPod Mini는 NetApp의 지능형 데이터 인프라와 ONTAP 데이터 관리 기능, Intel Xeon 6 프로세서, Intel AI for Enterprise RAG, OPEA 소프트웨어 스택을 결합하여 고성능 RAG 애플리케이션을 배포하고 조직이 AI 리더십을 구축할 수 있도록 지원합니다.</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">승인</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">이 문서는 NetApp Solutions Engineering 팀의 멤버인 Sathish Thyagarajan과 Michael Ogelsby가 작성했습니다.  저자는 또한 Intel의 Enterprise AI 제품 팀인 Ajay Mungara, Mikolaj Zyczynski, Igor Konopko, Ramakrishna Karamsetty, Michal Prostko, Shreejan Mistry, Ned Fiori와 NetApp 의 다른 팀원인 Lawrence Bunka, Bobby Oommen, Jeff Liborio에게 이 솔루션의 검증 기간 동안 지속적인 지원과 도움에 감사드리고 싶습니다.</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">재료 목록</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">다음은 이 솔루션의 기능 검증에 사용된 BOM이며 참조로 사용할 수 있습니다.  다음 구성에 맞는 모든 서버나 네트워킹 구성 요소(또는 기존 네트워크(대역폭이 100GbE인 경우))를 사용할 수 있습니다.</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">앱 서버의 경우:</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*부품번호*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*제품 설명*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">하이퍼 슈퍼서버 SYS-222HA-TN /2U</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">숫양</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16)64GB DDR5-6400 2RX4(16Gb) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960GB 1DWPD TLC D, 80mm</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">WS-1K63A-1R(x2)1U 692W/1600W 중복 단일 출력 전원 공급 장치.  최대 온도 59°C(대략)에서 열 방출은 2361 BTU/Hr입니다.</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">제어 서버의 경우:</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">최적화된 1U X13SCH-SYS, CSE-813MF2TS-R0RCNBP, PWS-602A-1R</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16GB DDR5-4800 1Rx8(16Gb) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">네트워크 스위치의 경우:</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">아리스타 7280R3A 28x100GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">NetApp AFF 스토리지:</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">AFF A20 HA 시스템, -C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">점퍼 케이블, 인캡, C13-C14, -C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">전원 공급 장치, 1600W, 티타늄, -C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-N-C</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">케이블, 100GbE, QSFP28-QSFP28, Cu, 2m, -C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-N-C</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">케이블, 25GbE, SFP28-SFP28, Cu, 0.5m, -C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-N-C</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">레일, 4-포스트, 얇은, 라운드/사각형 구멍, 소형, 조정식, 24-32, -C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-A-C</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">드라이브 팩 2X1.92TB, NVMe4, SED, -C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">IO 모듈, 2PT, 100GbE, -C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">IO 모듈, 4PT, 10/25GbE, -C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW, ONTAP 기본 패키지, TB당, 플래시, A20, -C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">OPEA 프로젝트</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">OPEA Enterprise RAG 배포 플레이북</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: 자율 주행 워크로드를 위한 NetApp StorageGRID 데이터 레이크 - 솔루션 설계</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">데이비드 아넷, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851은 머신 러닝(ML) 및 딥 러닝(DL) 소프트웨어 개발을 위한 데이터 저장소 및 관리 시스템으로 NetApp StorageGRID 객체 스토리지를 사용하는 방법을 보여줍니다.  본 논문에서는 자율주행차 소프트웨어 개발의 데이터 흐름과 요구 사항, 그리고 데이터 수명 주기를 간소화하는 StorageGRID 기능에 대해 설명합니다.  이 솔루션은 ML 및 DL 개발 프로세스에서 일반적인 다단계 데이터 파이프라인 워크플로에 적용됩니다.</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">법적 고지 사항</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">법적 고지사항은 저작권 표시, 상표, 특허 등에 대한 정보를 제공합니다.</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">저작권</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">상표</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NETAPP, NETAPP 로고 및 NetApp 상표 페이지에 나열된 마크는 NetApp, Inc.의 상표입니다. 다른 회사 및 제품 이름은 해당 소유자의 상표일 수 있습니다.</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">특허</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">NetApp 이 소유한 현재 특허 목록은 다음에서 확인할 수 있습니다.</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">개인정보 보호정책</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">이러한 검증을 위해, 우리는 일련의 원시 이미지를 사용하여 이미지 감지 사용 사례에 대한 추론을 수행했습니다.  그런 다음 추론 작업을 하기 전에 Protopia 난독화를 추가한 동일한 이미지 세트에 대해 동일한 추론 작업을 수행했습니다.  우리는 Protopia 난독화 구성 요소에 대해 다른 ALPHA 값을 사용하여 작업을 반복했습니다.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">추론 정확도 비교</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">이러한 검증을 위해, 우리는 일련의 원시 이미지를 사용하여 이미지 감지 사용 사례에 대한 추론을 수행했습니다.  그런 다음 추론 작업을 하기 전에 Protopia 난독화를 추가한 동일한 이미지 세트에 대해 동일한 추론 작업을 수행했습니다.  우리는 Protopia 난독화 구성 요소에 대해 다른 ALPHA 값을 사용하여 작업을 반복했습니다.  Protopia 난독화의 맥락에서 ALPHA 값은 적용되는 난독화 양을 나타내며, ALPHA 값이 높을수록 난독화 수준이 높아짐을 나타냅니다.  그런 다음 우리는 이러한 다양한 실행에 걸쳐 추론 정확도를 비교했습니다.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">다음 두 표는 우리의 사용 사례에 대한 세부 정보를 제공하고 결과를 간략하게 설명합니다.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia는 고객과 직접 협력하여 특정 사용 사례에 적합한 ALPHA 값을 결정합니다.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoxes(PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDB 데이터 세트</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">프로토피아 난독화</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">알파</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">정확성</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">아니요</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">해당 없음</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">예</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">추가 정보 및 감사의 말씀을 찾을 수 있는 곳</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">Protopia AI—기밀 추론</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">NVIDIA Triton 추론 서버</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton 추론 서버 설명서</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">PyTorch의 FaceBox</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, NetApp 수석 제품 관리자</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">Sufian Ahmad, 기술 마케팅 엔지니어, NetApp</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, Protopia AI의 최고 기술 책임자 겸 교수</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">데이터는 저장 중, 전송 중, 컴퓨팅 중이라는 세 가지 상태로 존재합니다.  모든 AI 추론 서비스에서 중요한 부분은 전체 프로세스 동안 위협으로부터 데이터를 보호하는 것입니다.  추론 중에 데이터를 보호하는 것은 매우 중요합니다. 추론 과정에서 외부 고객과 추론 서비스를 제공하는 기업에 대한 개인 정보가 노출될 수 있기 때문입니다.</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">데이터는 저장 중, 전송 중, 컴퓨팅 중이라는 세 가지 상태로 존재합니다.  모든 AI 추론 서비스에서 중요한 부분은 전체 프로세스 동안 위협으로부터 데이터를 보호하는 것입니다.  추론 중에 데이터를 보호하는 것은 매우 중요합니다. 추론 과정에서 외부 고객과 추론 서비스를 제공하는 기업에 대한 개인 정보가 노출될 수 있기 때문입니다.  Protopia AI는 오늘날 시장에서 기밀 AI 추론을 위한 눈에 띄지 않는 소프트웨어 전용 솔루션입니다.  Protopia를 사용하면 AI는 현재 AI/ML 작업을 수행하는 데 필수적인 데이터 레코드의 변환된 정보만 공급받고 그 이상은 공급받지 않습니다.  이러한 확률적 변환은 마스킹의 한 형태가 아니며, 큐레이트된 노이즈를 사용하여 데이터의 표현을 수학적으로 변경하는 데 기반을 둡니다.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">ONTAP 기능을 갖춘 NetApp 스토리지 시스템은 로컬 SSD 스토리지와 동일하거나 더 나은 성능을 제공하며, NetApp DataOps Toolkit과 결합하면 데이터 과학자, 데이터 엔지니어, AI/ML 개발자, 비즈니스 또는 기업 IT 의사 결정권자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">재해 복구, 비즈니스 연속성 및 규정 요구 사항을 위한 엔터프라이즈급 데이터 보호 및 데이터 거버넌스.</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">데이터 관리 작업을 간편하게 호출할 수 있습니다. Jupyter Notebook의 NetApp DataOps Toolkit에서 데이터 과학자 작업 공간의 스냅샷 사본을 빠르게 가져와 백업하고 추적할 수 있습니다.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">NetApp 및 Protopia 솔루션은 엔터프라이즈급 AI 추론 배포에 이상적인 유연하고 확장 가능한 아키텍처를 제공합니다.  이를 통해 데이터 보호가 가능해지고 민감한 정보에 대한 개인 정보 보호가 가능해져, 온프레미스와 하이브리드 클라우드 배포 모두에서 책임감 있는 AI 관행을 통해 기밀 AI 추론 요구 사항을 충족할 수 있습니다.</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">이 섹션에서는 솔루션 설계 검증 환경을 간략하게 설명합니다.</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">다음 표는 솔루션 설계 검증 환경을 간략하게 설명합니다.</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">쿠버네티스</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">NetApp Trident CSI 드라이버</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kubernetes용 NetApp DataOps 툴킷</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-파이3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">이 문서에서는 개인 정보 보호 및 책임 있는 AI 솔루션 배포와 관련된 이미지 난독화 유무에 따른 세 가지 시나리오에서 검증된 설계 솔루션을 설명합니다.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: 책임 있는 AI 및 기밀 추론 - Protopia 이미지 및 데이터 변환을 갖춘 NetApp AI</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan, Michael Oglesby, NetApp 안병훈, Jennifer Cwagenberg, Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">이미지 캡처와 이미지 처리의 등장으로 시각적 해석은 의사소통의 필수적인 부분이 되었습니다.  디지털 영상 처리 분야의 인공지능(AI)은 암 및 기타 질병 식별을 위한 의료 분야, 환경적 위험 연구를 위한 지리공간적 시각 분석, 패턴 인식, 범죄와 싸우기 위한 비디오 처리 등 새로운 사업 기회를 가져다줍니다.  하지만 이러한 기회에는 엄청난 책임도 따릅니다.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">조직이 AI에게 더 많은 결정을 맡길수록 데이터 개인정보 보호 및 보안, 법적, 윤리적, 규제적 문제와 관련된 위험을 감수하게 됩니다.  책임 있는 AI는 기업과 정부 기관이 대규모 기업에서 AI를 대규모로 사용하는 데 중요한 신뢰와 거버넌스를 구축할 수 있는 관행을 가능하게 합니다.  이 문서에서는 NetApp 데이터 관리 기술과 Protopia 데이터 난독화 소프트웨어를 사용하여 민감한 데이터를 비공개로 처리하고 위험과 윤리적 문제를 줄이는 세 가지 시나리오에서 NetApp 이 검증한 AI 추론 솔루션을 설명합니다.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">소비자와 기업 모두 다양한 디지털 기기를 통해 매일 수백만 개의 이미지를 생성합니다.  이로 인해 데이터와 컴퓨팅 작업 부하가 엄청나게 늘어나면서 기업은 규모와 효율성을 위해 클라우드 컴퓨팅 플랫폼으로 전환하게 되었습니다.  한편, 이미지 데이터에 포함된 민감한 정보에 대한 개인정보 보호 우려가 퍼블릭 클라우드로 전송되면서 발생합니다.  보안 및 개인정보 보호 보장의 부족은 이미지 처리 AI 시스템 구축의 주요 장애물이 됩니다.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">삭제 권리</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">개인정보보호법</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">또한,<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> GDPR에 따르면 개인은 조직에 자신의 모든 개인 데이터를 삭제하도록 요청할 권리가 있습니다.  또한 있습니다<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block> 공정한 정보 관행에 대한 규정을 제정한 법률입니다.  사진과 같은 디지털 이미지는 GDPR에 따라 개인 데이터로 간주될 수 있습니다. GDPR은 데이터를 수집, 처리, 삭제하는 방법을 규정합니다.  이를 이행하지 않을 경우 GDPR을 준수하지 않는 것으로 간주되어, 규정 위반에 대한 엄청난 벌금이 부과될 수 있으며, 이는 조직에 심각한 피해를 줄 수 있습니다.  개인정보 보호 원칙은 머신 러닝(ML) 및 딥 러닝(DL) 모델 예측의 공정성을 보장하고 개인정보 보호 또는 규정 준수 위반과 관련된 위험을 낮추는 책임 있는 AI 구현의 핵심입니다.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">이 문서에서는 개인 정보 보호 및 책임 있는 AI 솔루션 배포와 관련된 이미지 난독화가 있는 세 가지 시나리오에서 검증된 설계 솔루션을 설명합니다.</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*시나리오 1.*  Jupyter Notebook에서 주문형 추론이 가능합니다.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*시나리오 2.*  Kubernetes에서의 일괄 추론.</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*시나리오 3.*  NVIDIA Triton 추론 서버.</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">이 솔루션을 위해, 우리는 제약 없는 얼굴 감지 문제를 연구하기 위해 설계된 얼굴 영역의 데이터 세트인 FDDB(Face Detection Data Set and Benchmark)를 사용하는데, 이는 FaceBox 구현을 위한 PyTorch 머신 러닝 프레임워크와 결합되었습니다.  이 데이터 세트에는 다양한 해상도의 2845개 이미지 세트에 있는 5171개 얼굴에 대한 주석이 포함되어 있습니다.  또한 이 기술 보고서는 NetApp 고객과 현장 엔지니어로부터 이 솔루션을 적용할 수 있는 상황에서 수집한 일부 솔루션 영역과 관련 사용 사례를 제시합니다.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">이 기술 보고서는 다음 독자를 대상으로 합니다.</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">공공 장소에서 얼굴 이미지 처리와 관련된 데이터 보호 및 개인 정보 보호 문제를 해결하고 책임감 있는 AI를 설계하고 배포하고자 하는 기업 리더와 엔터프라이즈 설계자.</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">개인정보를 보호하고 보존하는 것을 목표로 하는 데이터 과학자, 데이터 엔지니어, AI/머신러닝(ML) 연구자, AI/ML 시스템 개발자.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">GDPR, CCPA, 국방부(DoD) 및 정부 기관의 개인정보 보호법 등의 규제 표준을 준수하는 AI/ML 모델 및 애플리케이션을 위한 데이터 난독화 솔루션을 설계하는 엔터프라이즈 아키텍트입니다.</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">민감한 정보를 보호하는 딥 러닝(DL) 및 AI/ML/DL 추론 모델을 배포하는 효율적인 방법을 찾고 있는 데이터 과학자와 AI 엔지니어.</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">이 솔루션은 기존 CPU와 함께 GPU의 처리 능력을 활용하여 대규모 데이터 세트에 대한 실시간 및 일괄 추론 AI 워크로드를 처리하도록 설계되었습니다.  이 검증은 책임 있는 AI 배포를 추구하는 조직에 필요한 ML의 개인 정보 보호 추론과 최적의 데이터 관리를 보여줍니다.  이 솔루션은 Jupyter Lab 및 CLI 인터페이스를 사용하여 NetApp ONTAP AI(온프레미스 핵심), NetApp DataOps Toolkit, Protopia 난독화 소프트웨어와 상호 연결된 엣지 및 클라우드 컴퓨팅을 위한 단일 또는 다중 노드 Kubernetes 플랫폼에 적합한 아키텍처를 제공합니다.  다음 그림은 NetApp 과 DataOps Toolkit 및 Protopia가 지원하는 데이터 패브릭의 논리적 아키텍처 개요를 보여줍니다.</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Protopia 난독화 소프트웨어는 NetApp DataOps Toolkit 상에서 원활하게 실행되며 스토리지 서버를 떠나기 전에 데이터를 변환합니다.</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">이 섹션에서는 이 솔루션에서 검증된 세 가지 시나리오에 대한 개요를 제공합니다.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">테스트 및 검증 계획</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">이 솔루션 설계를 위해 다음 세 가지 시나리오가 검증되었습니다.</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Kubernetes용 NetApp DataOps Toolkit을 사용하여 조율된 JupyterLab 작업 공간 내에서 Protopia 난독화가 적용된 추론 작업과 적용되지 않은 추론 작업입니다.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Kubernetes에서 NetApp DataOps Toolkit for Kubernetes를 사용하여 데이터 볼륨을 조정한 Protopia 난독화를 적용한 배치 추론 작업과 적용하지 않은 배치 추론 작업입니다.</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Kubernetes용 NetApp DataOps Toolkit을 사용하여 조율된 NVIDIA Triton Inference Server 인스턴스를 사용하는 추론 작업입니다.  네트워크를 통해 전송되는 모든 데이터는 난독화되어야 한다는 일반적인 요구 사항을 시뮬레이션하기 위해 Triton 추론 API를 호출하기 전에 이미지에 Protopia 난독화를 적용했습니다.  이 워크플로는 신뢰할 수 있는 영역 내에서 데이터를 수집했지만 추론을 위해 해당 신뢰할 수 있는 영역 외부로 데이터를 전달해야 하는 사용 사례에 적용할 수 있습니다.  Protopia 난독화 없이는 민감한 데이터가 신뢰 영역을 벗어나지 않고 이러한 유형의 워크플로를 구현하는 것은 불가능합니다.</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">이 섹션에서는 검증을 완료하는 데 필요한 작업을 설명합니다.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">필수 조건</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">이 섹션에 설명된 작업을 실행하려면 다음 도구가 설치 및 구성된 Linux 또는 macOS 호스트에 액세스할 수 있어야 합니다.</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl(기존 Kubernetes 클러스터에 액세스하도록 구성됨)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">설치 및 구성 지침을 찾을 수 있습니다.<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block> .</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">설치 지침을 찾을 수 있습니다<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block> .</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">시나리오 1 – JupyterLab에서의 주문형 추론</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">AI/ML 추론 워크로드를 위한 Kubernetes 네임스페이스를 만듭니다.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">NetApp DataOps Toolkit을 사용하여 추론을 수행할 데이터를 저장할 영구 볼륨을 프로비저닝합니다.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">NetApp DataOps Toolkit을 사용하여 새로운 JupyterLab 작업 공간을 만듭니다.  이전 단계에서 생성된 영구 볼륨을 다음을 사용하여 마운트합니다.<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block> 옵션.  필요에 따라 NVIDIA GPU를 작업 공간에 할당하려면 다음을 사용하십시오.<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block> 옵션.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">다음 예에서는 영구 볼륨<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block> JupyterLab 작업 공간 컨테이너에 마운트됩니다.<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block> .  공식 Project Jupyter 컨테이너 이미지를 사용하는 경우<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> JupyterLab 웹 인터페이스 내의 최상위 디렉토리로 표시됩니다.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">출력에 지정된 URL을 사용하여 JupyterLab 작업 공간에 액세스합니다.<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block> 명령.  데이터 디렉토리는 작업 공간에 마운트된 영구 볼륨을 나타냅니다.</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">열기<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block> 디렉토리로 가서 추론을 수행할 파일을 업로드합니다.  파일이 데이터 디렉토리에 업로드되면 해당 파일은 작업 공간에 마운트된 영구 볼륨에 자동으로 저장됩니다.  파일을 업로드하려면 다음 이미지에 표시된 대로 파일 업로드 아이콘을 클릭하세요.</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">최상위 디렉토리로 돌아가서 새로운 노트북을 만듭니다.</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">노트북에 추론 코드를 추가합니다.  다음 예제는 이미지 감지 사용 사례에 대한 추론 코드를 보여줍니다.</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">추론 코드에 Protopia 난독화를 추가하세요.  Protopia는 고객과 직접 협력하여 사용 사례별 문서를 제공하며, 이는 본 기술 보고서의 범위를 벗어납니다.  다음 예제에서는 Protopia 난독화가 추가된 이미지 감지 사용 사례에 대한 추론 코드를 보여줍니다.</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">시나리오 2 – Kubernetes에서의 일괄 추론</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">추론을 수행할 데이터로 새 영구 볼륨을 채웁니다.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps Toolkit S3 Data Mover 기능</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">PVC에 데이터를 로드하는 방법에는 여러 가지가 있습니다.  데이터가 현재 NetApp StorageGRID 또는 Amazon S3와 같은 S3 호환 개체 스토리지 플랫폼에 저장되어 있는 경우 다음을 사용할 수 있습니다.<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block> .  또 다른 간단한 방법은 JupyterLab 작업 공간을 만든 다음 "3~5단계" 섹션에 설명된 대로 JupyterLab 웹 인터페이스를 통해 파일을 업로드하는 것입니다.<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> ."</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">일괄 추론 작업을 위한 Kubernetes 작업을 만듭니다.  다음 예에서는 이미지 감지 사용 사례에 대한 일괄 추론 작업을 보여줍니다.  이 작업은 이미지 세트의 각 이미지에 대한 추론을 수행하고 추론 정확도 측정 항목을 stdout에 기록합니다.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">추론 작업이 성공적으로 완료되었는지 확인하세요.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">추론 작업에 Protopia 난독화를 추가하세요.  Protopia 난독화를 Protopia에서 직접 추가하는 방법에 대한 사용 사례별 지침은 찾을 수 있지만, 이는 이 기술 보고서의 범위를 벗어납니다.  다음 예제에서는 ALPHA 값 0.8을 사용하여 Protopia 난독화를 추가한 얼굴 감지 사용 사례에 대한 일괄 추론 작업을 보여줍니다.  이 작업은 이미지 세트의 각 이미지에 대한 추론을 수행하기 전에 Protopia 난독화를 적용한 다음 추론 정확도 측정 항목을 stdout에 기록합니다.</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">추론 정확도 비교.</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">우리는 ALPHA 값 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9, 0.95에 대해 이 단계를 반복했습니다.  결과는 다음에서 볼 수 있습니다.<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">시나리오 3 – NVIDIA Triton 추론 서버</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">NetApp DataOps Toolkit을 사용하여 NVIDIA Triton Inference Server의 모델 저장소로 사용할 영구 볼륨을 프로비저닝합니다.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">체재</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">새 영구 볼륨에 모델을 저장합니다.<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> NVIDIA Triton 추론 서버에서 인식됩니다.</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">PVC에 데이터를 로드하는 방법에는 여러 가지가 있습니다.  간단한 방법은 JupyterLab 작업 공간을 만든 다음 "3~5단계"에 설명된 대로 JupyterLab 웹 인터페이스를 통해 파일을 업로드하는 것입니다.<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> .  "</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">NetApp DataOps Toolkit을 사용하여 새로운 NVIDIA Triton Inference Server 인스턴스를 배포합니다.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Triton 클라이언트 SDK를 사용하여 추론 작업을 수행합니다.  다음 Python 코드 발췌 부분은 Triton Python 클라이언트 SDK를 사용하여 얼굴 감지 사용 사례에 대한 추론 작업을 수행합니다.  이 예제에서는 Triton API를 호출하고 추론을 위해 이미지를 전달합니다.  그러면 Triton 추론 서버는 요청을 수신하고, 모델을 호출하고, API 결과의 일부로 추론 출력을 반환합니다.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">추론 코드에 Protopia 난독화를 추가하세요.  Protopia에서 직접 Protopia 난독화를 추가하는 방법에 대한 사용 사례별 지침은 찾을 수 있습니다. 그러나 이 프로세스는 이 기술 보고서의 범위를 벗어납니다.  다음 예제는 이전 단계 5에서 보여준 것과 동일한 Python 코드를 보여주지만, Protopia 난독화가 추가되었습니다.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">Protopia 난독화는 이미지가 Triton API로 전달되기 전에 적용된다는 점에 유의하세요.  따라서 난독화되지 않은 이미지는 로컬 머신을 벗어나지 않습니다.  난독화된 이미지만 네트워크를 통해 전달됩니다.  이 워크플로는 신뢰할 수 있는 영역 내에서 데이터를 수집한 후 추론을 위해 해당 신뢰할 수 있는 영역 외부로 데이터를 전달해야 하는 사용 사례에 적용할 수 있습니다.  Protopia 난독화 없이는 민감한 데이터가 신뢰 영역을 벗어나지 않고 이러한 유형의 워크플로를 구현하는 것은 불가능합니다.</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">이 검증을 위해 1920 x 1080 픽셀 이미지에 Protopia 난독화를 5번 적용하고 난독화 단계가 완료되는 데 걸리는 시간을 매번 측정했습니다.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">난독화 속도</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">단일 NVIDIA V100 GPU에서 실행되는 PyTorch를 사용하여 난독화를 적용하고, 실행 사이에 GPU 캐시를 지웠습니다.  난독화 단계는 5번의 실행에 걸쳐 각각 5.47ms, 5.27ms, 4.54ms, 5.24ms, 4.84ms가 걸렸습니다.  평균 속도는 5.072ms였습니다.</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">이 섹션에서는 이 솔루션을 완성하는 데 필요한 다양한 기술 구성 요소에 대한 개요를 제공합니다.</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">프로토피아</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI는 현재 시장에서 기밀 추론을 위한 눈에 띄지 않는 소프트웨어 전용 솔루션을 제공합니다.  Protopia 솔루션은 민감한 정보의 노출을 최소화하여 추론 서비스에 대한 탁월한 보호 기능을 제공합니다.  AI는 현재 작업을 수행하는 데 정말로 필수적인 데이터 레코드에 있는 정보만 제공하고 그 이상은 제공하지 않습니다.  대부분의 추론 작업은 모든 데이터 레코드에 존재하는 모든 정보를 사용하지 않습니다.  AI가 이미지, 음성, 비디오 또는 구조화된 표 형식 데이터를 사용하는지 여부에 관계없이 Protopia는 추론 서비스에 필요한 것만 제공합니다.  특허받은 핵심 기술은 수학적으로 큐레이팅된 노이즈를 사용하여 데이터를 확률적으로 변환하고 주어진 ML 서비스에 필요하지 않은 정보를 왜곡합니다.  이 솔루션은 데이터를 가리지 않습니다. 오히려 큐레이팅된 무작위 노이즈를 사용하여 데이터 표현을 변경합니다.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Protopia 솔루션은 모델의 기능과 관련하여 입력 피처 공간에서 관련 정보를 유지하는 동시에 그래디언트 기반 섭동 극대화 방법으로 표현을 변경하는 문제를 공식화합니다.  이 발견 과정은 ML 모델 학습이 끝난 후 미세 조정 단계로 실행됩니다.  패스가 자동으로 일련의 확률 분포를 생성한 후, 로우 오버헤드 데이터 변환을 통해 이러한 분포의 노이즈 샘플을 데이터에 적용하여 추론을 위해 모델에 전달하기 전에 난독화합니다.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">DGX A100 시스템과 NetApp 클라우드 연결 스토리지 시스템으로 구동되는 NetApp ONTAP AI 참조 아키텍처는 NetApp 과 NVIDIA 에서 개발 및 검증했습니다.  IT 조직에 다음과 같은 이점을 제공하는 아키텍처를 제공합니다.</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">디자인의 복잡성을 제거합니다</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">컴퓨팅 및 스토리지의 독립적인 확장을 허용합니다.</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">고객이 소규모로 시작하여 원활하게 확장할 수 있도록 지원합니다.</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">다양한 성능 및 비용 지점에 맞는 다양한 스토리지 옵션을 제공합니다.</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI는 DGX A100 시스템과 NetApp AFF A800 스토리지 시스템을 최첨단 네트워킹과 긴밀하게 통합합니다.  ONTAP AI는 설계의 복잡성과 추측을 제거하여 AI 배포를 간소화합니다.  고객은 소규모로 시작하여 중단 없이 확장할 수 있으며, 엣지에서 코어, 클라우드로 데이터를 지능적으로 관리할 수 있습니다.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">다음 그림은 DGX A100 시스템을 기반으로 한 ONTAP AI 솔루션 제품군의 여러 변형을 보여줍니다.  AFF A800 시스템 성능은 최대 8개의 DGX A100 시스템으로 검증되었습니다.  ONTAP 클러스터에 스토리지 컨트롤러 쌍을 추가하면 아키텍처가 여러 랙으로 확장되어 선형적 성능으로 많은 DGX A100 시스템과 페타바이트 규모의 스토리지 용량을 지원할 수 있습니다.  이 접근 방식은 사용되는 DL 모델의 크기와 필요한 성능 지표에 따라 컴퓨팅 대 스토리지 비율을 독립적으로 변경할 수 있는 유연성을 제공합니다.</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치를 탑재한 NetApp ONTAP AI.</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">ONTAP AI에 대한 추가 정보는 다음을 참조하세요.<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">NetApp 의 최신 스토리지 관리 소프트웨어 ONTAP 9.11을 사용하면 기업이 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다.  ONTAP 업계 최고의 데이터 관리 역량을 활용하여 데이터가 어디에 있든 단일 도구 세트를 사용하여 데이터를 관리하고 보호할 수 있도록 지원합니다.  또한 필요한 곳, 즉 엣지, 코어, 클라우드로 데이터를 자유롭게 이동할 수 있습니다.  ONTAP 9.11에는 데이터 관리를 간소화하고, 중요 데이터를 가속화하고 보호하며, 하이브리드 클라우드 아키텍처 전반에서 차세대 인프라 기능을 구현하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit은 개발자, 데이터 과학자, DevOps 엔지니어, 데이터 엔지니어가 새로운 데이터 볼륨이나 JupyterLab 작업 공간의 거의 즉각적인 프로비저닝, 데이터 볼륨이나 JupyterLab 작업 공간의 거의 즉각적인 복제, 추적성이나 기준 설정을 위한 데이터 볼륨이나 JupyterLab 작업 공간의 거의 즉각적인 스냅샷 촬영 등 다양한 데이터 관리 작업을 간편하게 수행할 수 있도록 해주는 Python 라이브러리입니다.  이 Python 라이브러리는 명령줄 유틸리티로 작동할 수도 있고, 모든 Python 프로그램이나 Jupyter Notebook으로 가져올 수 있는 함수 라이브러리로 작동할 수도 있습니다.</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton Inference Server는 프로덕션에서 빠르고 확장 가능한 AI를 제공하기 위해 모델 배포 및 실행을 표준화하는 데 도움이 되는 오픈 소스 추론 제공 소프트웨어입니다.  Triton Inference Server는 팀이 GPU 또는 CPU 기반 인프라의 모든 프레임워크에서 학습된 AI 모델을 배포, 실행 및 확장할 수 있도록 하여 AI 추론을 간소화합니다.  Triton Inference Server는 TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO 등 모든 주요 프레임워크를 지원합니다.  Triton은 모든 주요 퍼블릭 클라우드 AI 및 Kubernetes 플랫폼에서 사용할 수 있는 오케스트레이션 및 확장을 위해 Kubernetes와 통합됩니다.  또한 다양한 MLOps 소프트웨어 솔루션과 통합되어 있습니다.</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>오픈소스 ML 프레임워크입니다.  GPU와 CPU를 사용하는 딥러닝을 위한 최적화된 텐서 라이브러리입니다.  PyTorch 패키지에는 다차원 텐서에 대한 데이터 구조가 포함되어 있으며, 텐서의 효율적인 직렬화를 위한 여러 유틸리티를 비롯한 다양한 유용한 유틸리티를 제공합니다.  또한 NVIDIA GPU에서 컴퓨팅 기능을 사용하여 텐서 계산을 실행할 수 있는 CUDA 대응 기능도 있습니다.  이 검증에서는 OpenCV-Python(cv2) 라이브러리를 사용하여 Python의 가장 직관적인 컴퓨터 비전 개념을 활용하면서 모델을 검증합니다.</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">성능과 낮은 지연 시간.  ONTAP 가능한 가장 낮은 지연 시간으로 가능한 가장 높은 처리량을 제공합니다.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">데이터 보호.  ONTAP 모든 플랫폼에서 공통적으로 관리할 수 있는 내장형 데이터 보호 기능을 제공합니다.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">다중 테넌시 및 다중 요소 인증.  ONTAP 최고 수준의 보안을 통해 인프라 리소스를 공유할 수 있도록 합니다.</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">원활한 확장과 중단 없는 운영.  ONTAP 기존 컨트롤러와 확장형 클러스터에 중단 없이 용량을 추가할 수 있도록 지원합니다.  고객은 비용이 많이 드는 데이터 마이그레이션이나 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra Control</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra 컨트롤 서비스</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">NetApp Astra 제품군은 NetApp 스토리지 및 데이터 관리 기술을 기반으로 온프레미스와 퍼블릭 클라우드에서 Kubernetes 애플리케이션을 위한 스토리지 및 애플리케이션 인식 데이터 관리 서비스를 제공합니다.  Kubernetes 애플리케이션을 쉽게 백업하고, 다른 클러스터로 데이터를 마이그레이션하고, 작동하는 애플리케이션 복제본을 즉시 생성할 수 있습니다.  퍼블릭 클라우드에서 실행되는 Kubernetes 애플리케이션을 관리해야 하는 경우 다음 문서를 참조하세요.<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block> .  Astra Control Service는 NetApp 에서 관리하는 서비스로, Google Kubernetes Engine(GKE)과 Azure Kubernetes Service(AKS)에서 Kubernetes 클러스터의 애플리케이션 인식 데이터 관리를 제공합니다.</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> NetApp 의 Docker와 Kubernetes를 위한 오픈소스 동적 스토리지 오케스트레이터로, 영구 스토리지의 생성, 관리 및 사용을 간소화합니다.  Kubernetes 기반 애플리케이션인 Trident 는 Kubernetes 클러스터 내에서 직접 실행됩니다.  Trident 사용하면 고객이 DL 컨테이너 이미지를 NetApp 스토리지에 원활하게 배포할 수 있으며 AI 컨테이너 배포를 위한 엔터프라이즈급 환경을 제공합니다.  Kubernetes 사용자(ML 개발자, 데이터 과학자 등)는 NetApp 기술이 제공하는 고급 데이터 관리 기능을 활용하여 오케스트레이션 및 복제를 생성, 관리 및 자동화할 수 있습니다.</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>빠르고 안전한 데이터 동기화를 위한 NetApp 서비스입니다.  온프레미스 NFS 또는 SMB 파일 공유, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, Amazon Simple Storage Service(Amazon S3), Amazon Elastic File System(Amazon EFS), Azure Blob, Google Cloud Storage 또는 IBM Cloud Object Storage 간에 파일을 전송해야 하는 경우 BlueXP Copy and Sync를 사용하면 파일을 필요한 곳으로 빠르고 안전하게 이동할 수 있습니다.  데이터가 전송되면 소스와 타겟 모두에서 자유롭게 사용할 수 있습니다.  BlueXP Copy and Syncc는 사전 정의된 일정에 따라 데이터를 지속적으로 동기화하여 델타만 이동하므로 데이터 복제에 소요되는 시간과 비용이 최소화됩니다.  BlueXP Copy and Sync는 설정과 사용이 매우 간단한 SaaS(소프트웨어 즉 서비스) 도구입니다.  BlueXP Copy and Sync에 의해 트리거되는 데이터 전송은 데이터 브로커를 통해 수행됩니다.  AWS, Azure, Google Cloud Platform 또는 온프레미스에 BlueXP 복사 및 동기화 데이터 브로커를 배포할 수 있습니다.</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">NetApp BlueXP 분류</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">강력한 AI 알고리즘으로 구동됩니다.<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block> 전체 데이터 자산에 걸쳐 자동화된 제어와 데이터 거버넌스를 제공합니다.  비용 절감 방안을 쉽게 찾고, 규정 준수 및 개인정보 보호 문제를 파악하고, 최적화 기회를 찾을 수 있습니다.  BlueXP 분류 대시보드를 사용하면 중복 데이터를 식별하여 중복을 제거하고, 개인 데이터, 비개인 데이터, 민감한 데이터를 매핑하고, 민감한 데이터와 이상 현상에 대한 알림을 켤 수 있는 통찰력을 얻을 수 있습니다.</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">디지털 이미지 처리에는 많은 장점이 있으며, 이를 통해 많은 조직이 시각적 표현과 관련된 데이터를 최대한 활용할 수 있습니다.  NetApp 과 Protopia 솔루션은 ML/DL 수명 주기 전반에 걸쳐 AI/ML 데이터를 보호하고 비공개화하는 고유한 AI 추론 설계를 제공합니다.  이를 통해 고객은 민감한 데이터의 소유권을 유지하고, 개인정보 보호와 관련된 우려를 완화하여 규모와 효율성을 위해 퍼블릭 또는 하이브리드 클라우드 배포 모델을 사용하고, 엣지에서 AI 추론을 배포할 수 있습니다.</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">환경 지능</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">산업계에서는 환경적 위험 측면에서 지리공간 분석을 활용할 수 있는 다양한 방법이 있습니다.  정부와 공공사업부는 전염병이나 산불과 같은 자연재해 발생 시 대중에게 더 나은 조언을 제공하기 위해 공중 보건과 기상 상황에 대한 실행 가능한 통찰력을 얻을 수 있습니다.  예를 들어, 공항이나 병원과 같은 공공 장소에서 영향을 받은 개인의 사생활을 침해하지 않고 COVID-19 양성 환자를 식별하고 해당 당국과 주변 대중에게 필요한 안전 조치를 알릴 수 있습니다.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">엣지 디바이스 웨어러블</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">군대와 전장에서 최첨단 AI 추론을 웨어러블 기기로 사용하여 군인의 건강을 추적하고, 운전자의 행동을 모니터링하고, 군용 차량에 접근하는 것과 관련된 안전 및 위험에 대해 당국에 경고하는 동시에 군인의 개인 정보를 보호하고 보존할 수 있습니다.  군대의 미래는 전장 사물 인터넷(IoBT)과 군사 사물 인터넷(IoMT)을 통해 첨단 기술로 전환되고 있으며, 이는 빠른 엣지 컴퓨팅을 사용하여 군인들이 적을 식별하고 전투에서 더 나은 성과를 낼 수 있도록 돕는 착용형 전투 장비를 의미합니다.  드론이나 웨어러블 장비와 같은 엣지 장치에서 수집된 시각적 데이터를 보호하고 보존하는 것은 해커와 적을 멀리하는 데 매우 중요합니다.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">비전투원 대피 작전</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">비전투원 대피 작전(NEO)은 국방부가 수행하며, 생명이 위험한 미국 시민과 국민, 국방부 민간인, 지정된 사람(주재국(HN)과 제3국 국민(TCN))을 적절한 안전한 피난처로 대피시키는 것을 돕기 위해 수행됩니다.  시행 중인 행정 통제는 대부분 수동 대피자 심사 절차를 사용합니다.  그러나 대피자 식별, 대피자 추적, 위협 스크리닝의 정확성, 보안, 속도는 AI/ML 비디오 난독화 기술과 결합된 고도로 자동화된 AI/ML 도구를 사용하면 잠재적으로 개선될 수 있습니다.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">의료 및 생물의학 연구</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">영상 처리란 컴퓨터 단층촬영(CT)이나 자기공명영상(MRI)으로부터 얻은 3D 영상을 바탕으로 수술 계획을 위한 병리학적 진단을 내리는 데 사용됩니다.  HIPAA 개인정보 보호 규칙은 조직이 모든 개인정보 및 사진과 같은 디지털 이미지에 대한 데이터를 수집, 처리 및 삭제하는 방법을 규정합니다.  HIPAA 안전 항구 규정에 따라 데이터가 공유 가능한 것으로 간주되려면 얼굴 전체가 나온 사진 이미지와 이와 비슷한 이미지를 삭제해야 합니다.  개인의 얼굴 특징을 구조적 CT/MR 이미지에서 가리는 데 사용되는 익명화나 두개골 제거 알고리즘과 같은 자동화된 기술은 생물의학 연구 기관의 데이터 공유 프로세스에 필수적인 부분이 되었습니다.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">AI/ML 분석의 클라우드 마이그레이션</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">데이터 보호</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">기업 고객은 전통적으로 온프레미스에서 AI/ML 모델을 훈련하고 배포해 왔습니다.  규모의 경제와 효율성을 이유로 이러한 고객은 AI/ML 기능을 퍼블릭, 하이브리드 또는 멀티 클라우드 배포로 옮기는 방향으로 확장하고 있습니다.  그러나 다른 인프라에 노출될 수 있는 데이터에 따라 제한을 받습니다.  NetApp 솔루션은 필요한 모든 사이버 보안 위협을 해결합니다.<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> 보안 평가를 수행하고 Protopia 데이터 변환과 결합하면 이미지 처리 AI/ML 워크로드를 클라우드로 마이그레이션하는 데 따른 위험을 최소화할 수 있습니다.</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 엣지에서의 AI 추론</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">지능 대 개인 정보 보호</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">다른 산업 분야에서 엣지 컴퓨팅 및 AI 추론에 대한 추가 사용 사례는 다음을 참조하세요.<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block> 그리고 NetApp AI 블로그,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block> .</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">Domino Data Lab 및 NetApp 활용한 하이브리드 멀티클라우드 MLOps - 추가 정보 확인 방법</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">추가 정보를 찾을 수 있는 곳</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">도미노 데이터 랩</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">도미노 넥서스</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetApp BlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">NetApp AI 솔루션</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Josh Mineroff, Domino Data Lab 기술 제휴 SA 디렉터</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">Nicholas Jablonski, Domino Data Lab 현장 CTO</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">Prabu Arjunan, 솔루션 설계자, NetApp</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">Brian Young, NetApp 기술 제휴 파트너 글로벌 제휴 이사</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">Domino Data Lab 및 NetApp 을 활용한 하이브리드 멀티클라우드 MLOps - 아키텍처</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">이 솔루션은 Domino Nexus의 하이브리드 멀티클라우드 워크로드 스케줄링 기능과 NetApp 데이터 서비스를 결합하여 통합된 하이브리드 클라우드 MLOps 플랫폼을 만듭니다.  자세한 내용은 다음 표를 참조하세요.</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">환경</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">MLOps 제어 평면</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Domino Nexus를 탑재한 Domino Enterprise AI 플랫폼</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">MLOps 플랫폼 컴퓨팅 환경</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Domino Nexus 데이터 플레인</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS, 온프레미스 데이터 센터</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">온프레미스 컴퓨팅 플랫폼</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>~와 함께<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">온프레미스 데이터 센터</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">클라우드 컴퓨팅 플랫폼</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">아마존 엘라스틱 쿠버네티스 서비스(EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>~와 함께<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">온프레미스 데이터 플랫폼</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">NetApp 스토리지 어플라이언스</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>에 의해 구동<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">클라우드 데이터 플랫폼</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">Domino Data Lab 및 NetApp 통한 하이브리드 멀티클라우드 MLOps - 다양한 환경에서 동일한 데이터에 액세스</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">다양한 환경에서 동일한 데이터에 액세스</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">이 섹션에서는 다양한 컴퓨팅 환경에서 동일한 데이터에 액세스하기 위해 수행해야 하는 작업을 설명합니다.  Domino MLOps 플랫폼에서는 컴퓨팅 환경을 "데이터 플레인"이라고 합니다.  데이터가 한 데이터 플레인의 NetApp 볼륨에 있지만 다른 데이터 플레인에서 해당 데이터에 액세스해야 하는 경우 이 섹션에 설명된 작업을 따르세요.  이런 유형의 시나리오는 종종 "버스팅"이라고 하며, 대상 환경이 클라우드인 경우 "클라우드 버스팅"이라고 합니다.  이러한 기능은 제한적이거나 과도하게 구독된 컴퓨팅 리소스를 처리할 때 종종 필요합니다.  예를 들어, 온프레미스 컴퓨팅 클러스터가 과도하게 구독된 경우 워크로드를 즉시 시작할 수 있는 클라우드에 예약할 수 있습니다.</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">다른 데이터 플레인에 있는 NetApp 볼륨에 액세스하는 데 권장되는 옵션은 두 가지입니다.  이러한 옵션은 아래 하위 섹션에 설명되어 있습니다.  귀하의 구체적인 요구 사항에 따라 다음 옵션 중 하나를 선택하세요.  두 가지 옵션의 장점과 단점은 다음 표에 설명되어 있습니다.</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">옵션</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">이익</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">단점</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">옵션 1 - 캐시</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- 더 간단한 워크플로 - 필요에 따라 데이터 하위 집합을 캐시하는 기능 - 소스에 데이터를 다시 쓰는 기능 - 관리할 원격 복사본 없음</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- 캐시가 수화되면 초기 데이터 액세스 시 지연 시간이 증가합니다.</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">옵션 2 - 미러</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- 소스 볼륨의 전체 복사 - 캐시 하이드레이션으로 인한 대기 시간 증가 없음(미러 작업 완료 후)</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- 데이터에 액세스하기 전에 미러 작업이 완료될 때까지 기다려야 함 - 원격 복사본을 관리해야 함 - 소스에 다시 쓸 수 없음</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">옵션 1 - 다른 데이터 플레인에 있는 볼륨의 캐시 생성</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">NetApp FlexCache 기술</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">와 함께<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block> 다른 데이터 평면에 있는 NetApp 볼륨의 캐시를 만들 수 있습니다.  예를 들어, 온프레미스 데이터 플레인에 NetApp 볼륨이 있고 AWS 데이터 플레인에서 해당 볼륨에 액세스해야 하는 경우 AWS에서 해당 볼륨의 캐시를 생성할 수 있습니다.  이 섹션에서는 다른 데이터 플레인에 있는 NetApp 볼륨의 캐시를 생성하기 위해 수행해야 하는 작업을 간략하게 설명합니다.</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">대상 환경에서 FlexCache 볼륨 생성</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">대상 환경이 온프레미스 데이터 센터인 경우 온프레미스 ONTAP 시스템에 FlexCache 볼륨을 생성합니다.  대상 환경이 AWS인 경우 Amazon FSx ONTAP 인스턴스에 FlexCache 볼륨을 생성합니다.</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">먼저 대상 환경에 FlexCache 볼륨을 만들어야 합니다.</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">BlueXP volume caching 문서</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">FlexCache 볼륨을 생성하려면 BlueXP 사용하는 것이 좋습니다.  BlueXP 사용하여 FlexCache 볼륨을 생성하려면 다음 지침을 따르세요.<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block> .</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">BlueXP 사용하지 않으려면 ONTAP System Manager나 ONTAP CLI를 사용하여 FlexCache 볼륨을 생성할 수 있습니다.  System Manager를 사용하여 FlexCache 볼륨을 생성하려면 다음 지침을 참조하십시오.<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block> .  ONTAP CLI를 사용하여 FlexCache 볼륨을 생성하려면 다음 지침을 참조하십시오.<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block> .</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">BlueXP API</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">ONTAP REST API</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">ONTAP Ansible 컬렉션</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">이 프로세스를 자동화하려면 다음을 사용할 수 있습니다.<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block> , 그<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block> , 또는<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block> .</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">Amazon FSx ONTAP 에서는 System Manager를 사용할 수 없습니다.</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">Domino에 FlexCache 볼륨 노출</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">'기존 NetApp 볼륨을 Domino에 노출' 섹션</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">다음으로, FlexCache 볼륨을 Domino MLOps 플랫폼에 노출해야 합니다.  Domino에 FlexCache 볼륨을 노출하려면 ' Trident 에서 프로비저닝되지 않은 기존 NFS 볼륨 노출' 하위 섹션에 설명된 지침을 따르세요.<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> 이 솔루션의.</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">이제 다음 스크린샷에 표시된 것처럼 대상 데이터 플레인에서 작업 및 작업 공간을 시작할 때 FlexCache 볼륨을 마운트할 수 있습니다.</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">FlexCache 볼륨을 생성하기 전에</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">Domino에 FlexCache 볼륨을 노출한 후</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">옵션 2 - 다른 데이터 플레인에 있는 볼륨 복제</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">NetApp SnapMirror 데이터 복제 기술</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">와 함께<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block> 다른 데이터 평면에 있는 NetApp 볼륨의 복사본을 만들 수 있습니다.  예를 들어, 온프레미스 데이터 플레인에 NetApp 볼륨이 있고 AWS 데이터 플레인에서 해당 볼륨에 액세스해야 하는 경우 AWS에서 볼륨 복사본을 만들 수 있습니다.  이 섹션에서는 다른 데이터 플레인에 있는 NetApp 볼륨의 복사본을 만들기 위해 수행해야 하는 작업을 간략하게 설명합니다.</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">SnapMirror 관계 생성</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">먼저, 대상 환경에서 소스 볼륨과 새 대상 볼륨 간에 SnapMirror 관계를 만들어야 합니다.  대상 볼륨은 SnapMirror 관계를 만드는 과정의 일부로 생성됩니다.</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">BlueXP replication 문서</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">SnapMirror 관계를 생성하려면 BlueXP 사용하는 것이 좋습니다.  BlueXP 와 SnapMirror 관계를 생성하려면 다음 지침을 따르세요.<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block> .</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">BlueXP 사용하지 않으려면 ONTAP System Manager나 ONTAP CLI를 사용하여 SnapMirror 관계를 생성할 수 있습니다.  System Manager와 SnapMirror 관계를 생성하려면 다음 지침을 참조하세요.<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block> .  ONTAP CLI를 사용하여 SnapMirror 관계를 생성하려면 다음 지침을 참조하세요.<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block> .</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">SnapMirror 관계 끊기</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">다음으로, 데이터 액세스를 위해 대상 볼륨을 활성화하려면 SnapMirror 관계를 해제해야 합니다.  이 단계를 수행하기 전에 초기 복제가 완료될 때까지 기다리세요.</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">BlueXP, ONTAP System Manager 또는 ONTAP CLI에서 미러 상태를 확인하여 복제가 완료되었는지 확인할 수 있습니다.  복제가 완료되면 미러 상태는 "snapmirrored"가 됩니다.</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">SnapMirror 관계를 끊으려면 BlueXP 사용하는 것이 좋습니다.  BlueXP 와 SnapMirror 관계를 끊으려면 다음 지침을 따르세요.<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block> .</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">BlueXP 사용하지 않으려면 ONTAP System Manager나 ONTAP CLI를 사용하여 SnapMirror 관계를 끊을 수 있습니다.  System Manager와 SnapMirror 관계를 끊으려면 다음 지침을 참조하세요.<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block> .  ONTAP CLI를 사용하여 SnapMirror 관계를 끊으려면 다음 지침을 참조하세요.<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block> .</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">Domino에 대상 볼륨 노출</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">다음으로, 대상 볼륨을 Domino MLOps 플랫폼에 노출해야 합니다.  Domino에 대상 볼륨을 노출하려면 ' Trident 에서 프로비저닝되지 않은 기존 NFS 볼륨 노출' 하위 섹션에 설명된 지침을 따르세요.<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block> 이 솔루션의.</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">이제 다음 스크린샷에 표시된 것처럼 대상 데이터 플레인에서 작업 및 작업 공간을 시작할 때 대상 볼륨을 마운트할 수 있습니다.</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">SnapMirror 관계를 생성하기 전에</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">Domino에 대상 볼륨을 노출한 후</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus는 모든 클라우드, 지역 또는 온프레미스의 모든 컴퓨팅 클러스터에서 데이터 과학 및 머신 러닝 워크로드를 실행할 수 있는 단일 창입니다.</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">Domino Data Lab 및 NetApp 활용한 하이브리드 멀티클라우드 MLOps</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">마이크 오글스비, NetApp</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">현재 전 세계의 기업들이 비즈니스와 프로세스를 혁신하기 위해 AI를 도입하고 있습니다.  이 때문에 AI에 적합한 컴퓨팅 인프라가 부족한 경우가 많습니다.  기업들은 다양한 지역, 데이터 센터, 클라우드에서 사용 가능한 컴퓨팅 환경을 활용하고 비용, 가용성, 성능의 균형을 맞추기 위해 하이브리드 멀티클라우드 MLOps 아키텍처를 채택하고 있습니다.</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Data Lab의 Domino Nexus는 모든 클라우드, 지역 또는 온프레미스의 모든 컴퓨팅 클러스터에서 데이터 과학 및 머신 러닝 워크로드를 실행할 수 있는 통합 MLOps 제어 평면입니다.  이를 통해 기업 전반의 데이터 과학 사일로를 통합하여 모델을 구축, 배포 및 모니터링할 수 있는 한곳을 확보할 수 있습니다.  마찬가지로 NetApp의 하이브리드 클라우드 데이터 관리 기능을 사용하면 데이터가 어디에 있든 작업 및 작업 공간으로 데이터를 가져올 수 있습니다.  Domino Nexus를 NetApp 과 함께 사용하면 데이터 가용성에 대한 걱정 없이 다양한 환경에서 작업 부하를 유연하게 예약할 수 있습니다.  다시 말해, 워크로드와 데이터를 적절한 컴퓨팅 환경으로 보낼 수 있으므로 데이터 개인 정보 보호 및 주권 관련 규정을 준수하면서 AI 배포를 가속화할 수 있습니다.</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">이 솔루션은 온프레미스 Kubernetes 클러스터와 Amazon Web Services(AWS)에서 실행되는 Elastic Kubernetes Service(EKS) 클러스터를 통합한 통합 MLOps 제어 평면의 배포를 보여줍니다.</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">Domino Data Lab 및 NetApp 사용한 하이브리드 멀티클라우드 MLOps - 초기 설정</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">초기 설정</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">이 섹션에서는 온프레미스 데이터 센터와 AWS를 통합한 하이브리드 환경에서 NetApp 데이터 서비스와 함께 Domino Nexus를 활용하기 위해 수행해야 하는 초기 설정 작업을 설명합니다.</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">이 섹션에 설명된 단계를 수행하기 전에 다음 작업을 이미 수행했다고 가정합니다.</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">온프레미스 NetApp ONTAP 스토리지 플랫폼을 이미 배포하고 구성했습니다. 자세한 내용은 다음을 참조하세요. <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> .</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Amazon FSx ONTAP 제품 페이지</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">AWS에서 Amazon FSx ONTAP 인스턴스를 이미 프로비저닝했습니다. 자세한 내용은 다음을 참조하세요. <block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> .</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Domino 관리자 가이드</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">온프레미스 데이터 센터에 Kubernetes 클러스터를 이미 프로비저닝했습니다. 자세한 내용은 다음을 참조하세요. <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">AWS에서 Amazon EKS 클러스터를 이미 프로비저닝했습니다. 자세한 내용은 다음을 참조하세요. <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> .</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">NetApp Trident 설명서</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">온프레미스 Kubernetes 클러스터에 NetApp Trident 설치했습니다.  또한, 스토리지 리소스를 프로비저닝하고 관리할 때 온프레미스 NetApp ONTAP 스토리지 플랫폼을 사용하도록 이 Trident 인스턴스를 구성했습니다. 자세한 내용은 다음을 참조하세요. <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">Amazon EKS 클러스터에 NetApp Trident 설치했습니다.  또한 스토리지 리소스를 프로비저닝하고 관리할 때 Amazon FSx ONTAP 인스턴스를 사용하도록 이 Trident 인스턴스를 구성했습니다. 자세한 내용은 다음을 참조하세요. <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> .</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Amazon 가상 사설망(VPN) 설명서</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">온프레미스 데이터 센터와 AWS의 Virtual Private Cloud(VPC) 간에 양방향 네트워크 연결이 있어야 합니다.  이를 구현하기 위한 다양한 옵션에 대한 자세한 내용은 다음을 참조하세요.<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block> .</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">AWS에 Domino Enterprise AI Platform 설치</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">AWS에 Domino Enterprise MLOps 플랫폼을 설치하려면 다음 지침을 따르세요.<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block> .  이전에 프로비저닝한 것과 동일한 Amazon EKS 클러스터에 Domino를 배포해야 합니다.  또한, NetApp Trident 이 EKS 클러스터에 이미 설치 및 구성되어 있어야 하며, domino.yml 설치 구성 파일에서 공유 스토리지 클래스로 Trident 관리 스토리지 클래스를 지정해야 합니다.</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Domino 설치 구성 참조 가이드</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">를 참조하세요<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block> domino.yml 설치 구성 파일에서 공유 저장소 클래스를 지정하는 방법에 대한 자세한 내용은 다음을 참조하세요.</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">기술 보고서 TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>Amazon FSx ONTAP 사용하여 AWS에 Domino를 배포하는 과정을 안내하며, 발생하는 문제를 해결하는 데 유용한 참고 자료가 될 수 있습니다.</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">Domino Nexus 활성화</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">다음으로 Domino Nexus를 활성화해야 합니다.  를 참조하세요<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block> 자세한 내용은.</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">온프레미스 데이터 센터에 Domino 데이터 플레인 배포</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">다음으로, 온프레미스 데이터 센터에 Domino 데이터 플레인을 배포해야 합니다.  이전에 프로비저닝한 온프레미스 Kubernetes 클러스터에 이 데이터 플레인을 배포해야 합니다.  또한 NetApp Trident 이 Kubernetes 클러스터에 이미 설치 및 구성되어 있어야 합니다.  를 참조하세요<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block> 자세한 내용은.</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">Domino Data Lab 및 NetApp 활용한 하이브리드 멀티클라우드 MLOps - 기술 개요</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">기술 개요</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">이 섹션에서는 Domino Data Lab과 NetApp 사용한 하이브리드 멀티클라우드 MLOps에 대한 기술 개요를 제공합니다.</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab은 Fortune 100 기업 중 20% 이상이 신뢰하는 선도적인 엔터프라이즈 AI 플랫폼을 통해 모델 기반 비즈니스를 지원합니다.  Domino는 협업과 거버넌스를 강화하는 동시에 데이터 과학 작업의 개발과 배포를 가속화합니다.  도미노를 사용하면 전 세계 기업이 더 나은 의약품을 개발하고, 생산성이 더 높은 작물을 재배하고, 더 나은 자동차를 만드는 등 다양한 작업을 수행할 수 있습니다.  2013년에 설립된 Domino는 Coatue Management, Great Hill Partners, Highland Capital, Sequoia Capital 등 주요 투자자들의 지원을 받고 있습니다.</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino를 사용하면 기업과 데이터 과학자가 통합된 엔드투엔드 플랫폼에서 빠르고 책임감 있게, 비용 효율적으로 AI를 구축, 배포 및 관리할 수 있습니다.  팀은 어떤 환경에서든 필요한 모든 데이터, 도구, 컴퓨팅, 모델 및 프로젝트에 액세스할 수 있으므로 협업하고, 과거 작업을 재사용하고, 정확도를 높이기 위해 프로덕션에서 모델을 추적하고, 모범 사례로 표준화하고, AI를 책임감 있고 관리 가능하게 만들 수 있습니다.</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*개방적이고 유연함:* 최고의 혁신을 이루고 공급업체에 종속되지 않는 가장 광범위한 오픈 소스 및 상용 도구와 인프라 생태계에 액세스하세요.</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*기록 시스템:* 기업 전체의 AI 운영 및 지식을 위한 중앙 허브로, 모범 사례, 기능 간 협업, 빠른 혁신 및 효율성을 지원합니다.</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*통합:* 기업 프로세스, 제어 및 거버넌스를 위해 구축된 통합 워크플로 및 자동화를 통해 규정 준수 및 규제 요구 사항을 충족합니다.</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*하이브리드 멀티클라우드:* 온프레미스, 하이브리드, 모든 클라우드 또는 멀티클라우드 등 어디에서나 데이터에 가까운 AI 워크로드를 실행하여 비용을 절감하고 성능과 규정 준수를 최적화합니다.</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus는 모든 클라우드, 지역 또는 온프레미스의 모든 컴퓨팅 클러스터에서 데이터 과학 및 머신 러닝 워크로드를 실행할 수 있는 단일 창입니다.  이를 통해 기업 전반의 데이터 과학 사일로를 통합하여 모델을 구축, 배포 및 모니터링할 수 있는 한곳을 확보할 수 있습니다.</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP NetApp의 모든 스토리지 및 데이터 서비스를 단일 도구로 통합하여 하이브리드 멀티클라우드 데이터 자산을 구축, 보호 및 관리할 수 있도록 지원합니다.  온프레미스와 클라우드 환경 전반에서 스토리지 및 데이터 서비스에 대한 통합된 경험을 제공하고, 오늘날의 클라우드 중심 세계에 필요한 유연한 소비 매개변수와 통합 보호 기능을 갖춘 AIOps의 힘을 통해 운영을 간소화합니다.</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">클라우드 연결.  ONTAP 은 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지와 클라우드 네이티브 인스턴스에 대한 옵션을 갖춘 가장 클라우드에 연결된 스토리지 관리 소프트웨어입니다.</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP NetApp의 인기 있는 ONTAP 파일 시스템을 기반으로 높은 안정성, 확장성, 고성능, 다양한 기능을 갖춘 파일 스토리지를 제공하는 완전 관리형 AWS 서비스입니다. FSx ONTAP NetApp 파일 시스템의 친숙한 기능, 성능, 기능 및 API 운영과 완벽하게 관리되는 AWS 서비스의 민첩성, 확장성 및 단순성을 결합합니다.</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Trident ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), Element 소프트웨어(NetApp HCI, SolidFire), Azure NetApp Files 서비스, Google Cloud의 Google Cloud NetApp Google Cloud NetApp Volumes 포함하여 퍼블릭 클라우드나 온프레미스에서 모든 인기 있는 NetApp 스토리지 플랫폼의 스토리지 리소스 사용 및 관리를 지원합니다.  Trident 는 Kubernetes와 기본적으로 통합되는 컨테이너 스토리지 인터페이스(CSI) 호환 동적 스토리지 오케스트레이터입니다.</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">쿠버네티스는 원래 Google에서 설계한 오픈 소스, 분산형 컨테이너 오케스트레이션 플랫폼으로, 현재는 Cloud Native Computing Foundation(CNCF)에서 관리하고 있습니다.  쿠버네티스는 컨테이너화된 애플리케이션의 배포, 관리 및 확장 기능을 자동화할 수 있게 해주며, 엔터프라이즈 환경에서 가장 널리 쓰이는 컨테이너 오케스트레이션 플랫폼입니다.</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service(Amazon EKS)는 AWS 클라우드의 관리형 Kubernetes 서비스입니다.  Amazon EKS는 컨테이너 일정 예약, 애플리케이션 가용성 관리, 클러스터 데이터 저장 및 기타 주요 작업을 담당하는 Kubernetes 제어 평면 노드의 가용성과 확장성을 자동으로 관리합니다.  Amazon EKS를 사용하면 AWS 인프라의 모든 성능, 확장성, 안정성 및 가용성을 활용할 수 있을 뿐만 아니라 AWS 네트워킹 및 보안 서비스와의 통합도 가능합니다.</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">Domino Data Lab 및 NetApp 활용한 하이브리드 멀티클라우드 MLOps - 기존 NetApp 볼륨을 Domino에 노출</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">기존 NetApp 볼륨을 Domino에 노출</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">이 섹션에서는 기존 NetApp ONTAP NFS 볼륨을 Domino MLOps 플랫폼에 노출하기 위해 수행해야 하는 작업에 대해 설명합니다.  동일한 단계는 온프레미스와 AWS 모두에 적용됩니다.</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">NetApp ONTAP 볼륨을 Domino에 노출하는 이유는 무엇입니까?</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">Domino와 함께 NetApp 볼륨을 사용하면 다음과 같은 이점이 있습니다.</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">NetApp ONTAP의 확장 기능을 활용하면 매우 큰 데이터 세트에 대한 워크로드를 실행할 수 있습니다.</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">데이터를 개별 노드에 복사하지 않고도 여러 컴퓨팅 노드에서 워크로드를 실행할 수 있습니다.</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">NetApp의 하이브리드 멀티클라우드 데이터 이동 및 동기화 기능을 활용하면 여러 데이터 센터 및/또는 클라우드에 있는 데이터에 액세스할 수 있습니다.</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">다른 데이터 센터나 클라우드에 데이터 캐시를 빠르고 쉽게 만들 수 있어야 합니다.</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">Trident 에서 프로비저닝되지 않은 기존 NFS 볼륨 노출</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">기존 NetApp ONTAP NFS 볼륨이 Trident 에서 프로비저닝되지 않은 경우 이 하위 섹션에 설명된 단계를 따르세요.</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">Kubernetes에서 PV 및 PVC 생성</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">온프레미스 볼륨의 경우 온프레미스 Kubernetes 클러스터에서 PV와 PVC를 만듭니다.  Amazon FSx ONTAP 볼륨의 경우 Amazon EKS에서 PV와 PVC를 생성합니다.</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">NFS PV/PVC 예시</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">먼저, Kubernetes 클러스터에서 영구 볼륨(PV)과 영구 볼륨 클레임(PVC)을 생성해야 합니다.  PV 및 PVC를 생성하려면 다음을 사용하세요.<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> Domino 관리자 가이드에서 값을 업데이트하여 사용자 환경에 맞게 반영합니다.  올바른 값을 지정해야 합니다.<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block> ,<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> , 그리고<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block> 전지.  또한, ONTAP NFS 볼륨에 저장된 데이터의 특성을 나타내는 고유한 이름을 PV 및 PVC에 지정하는 것이 좋습니다.  예를 들어, 볼륨에 제조 결함 이미지가 포함되어 있는 경우 PV 이름을 지정할 수 있습니다.<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block> , 그리고 PVC,<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> .</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">Domino에 외부 데이터 볼륨 등록</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">지침</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">다음으로, Domino에 외부 데이터 볼륨을 등록해야 합니다.  외부 데이터 볼륨을 등록하려면 다음을 참조하세요.<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> Domino 관리자 가이드에서.  볼륨을 등록할 때 '볼륨 유형' 드롭다운 메뉴에서 'NFS'를 선택하세요.  "NFS"를 선택하면 '사용 가능한 볼륨' 목록에 PVC가 표시됩니다.</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">Trident 에서 프로비저닝된 기존 볼륨 노출</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">기존 볼륨이 Trident 에서 프로비저닝된 경우 이 하위 섹션에 설명된 단계를 따르세요.</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">기존 PVC 편집</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">볼륨이 Trident 에서 프로비저닝된 경우 볼륨에 해당하는 영구 볼륨 클레임(PVC)이 이미 있습니다.  이 볼륨을 Domino에 노출하려면 PVC를 편집하고 다음 레이블을 레이블 목록에 추가해야 합니다.<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block> 필드:</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">다음으로, Domino에 외부 데이터 볼륨을 등록해야 합니다.  외부 데이터 볼륨을 등록하려면 다음을 참조하세요.<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> Domino 관리자 가이드에서.  볼륨을 등록할 때 '볼륨 유형' 드롭다운 메뉴에서 '일반'을 선택하세요.  "일반"을 선택하면 '사용 가능한 볼륨' 목록에 PVC가 표시됩니다.</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NetApp 및 VMware를 사용한 NVIDIA AI Enterprise - 추가 정보 확인 방법</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">VMware를 활용한 NVIDIA AI Enterprise</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, NetApp 선임 관리자</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, NetApp 시스템 관리자</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Roney Daniel, NetApp 기술 마케팅 엔지니어</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NetApp 및 VMware를 탑재한 NVIDIA AI Enterprise - 아키텍처</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">이 솔루션은 NetApp, VMware, NVIDIA 인증 시스템을 갖춘 검증되고 친숙한 아키텍처를 기반으로 구축되었습니다.  자세한 내용은 다음 표를 참조하세요.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">AI 및 데이터 분석 소프트웨어</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">VMware용 NVIDIA AI Enterprise</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">가상화 플랫폼</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">컴퓨팅 플랫폼</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA 인증 시스템</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">데이터 관리 플랫폼</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise는 모든 조직이 AI를 통해 성공할 수 있도록 최적화된 엔드 투 엔드 클라우드 기반 AI 및 데이터 분석 소프트웨어 제품군입니다.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NetApp 및 VMware를 활용한 NVIDIA AI Enterprise</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">IT 설계자와 관리자에게 AI 툴은 복잡하고 익숙하지 않을 수 있습니다.  게다가 많은 AI 플랫폼은 기업에 적합하지 않습니다.  NetApp 과 VMware 기반의 NVIDIA AI Enterprise는 간소화된 엔터프라이즈급 AI 아키텍처를 제공하기 위해 만들어졌습니다.</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NetApp 및 VMware를 사용한 NVIDIA AI Enterprise - NVIDIA NGC 소프트웨어 활용 - 설정</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">설정</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">이 섹션에서는 NVIDIA AI Enterprise 환경 내에서 NVIDIA NGC Enterprise 소프트웨어를 활용하기 위해 수행해야 하는 초기 설정 작업에 대해 설명합니다.</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">이 섹션에 설명된 단계를 수행하기 전에 이미 NVIDIA AI Entrprise 호스트 소프트웨어를 배포했다고 가정합니다.<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block> 페이지.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">vGPU를 사용하여 Ubuntu 게스트 VM 만들기</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI 엔터프라이즈 배포 가이드</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">먼저, vGPU가 있는 Ubuntu 20.04 게스트 VM을 만들어야 합니다.  vGPU를 사용하여 Ubuntu 20.04 게스트 VM을 생성하려면 다음 지침을 따르세요.<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block> .</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">NVIDIA 게스트 소프트웨어 다운로드 및 설치</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterprise 빠른 시작 가이드</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">다음으로, 이전 단계에서 만든 게스트 VM 내에 필요한 NVIDIA 게스트 소프트웨어를 설치해야 합니다.  게스트 VM 내에서 필요한 NVIDIA 게스트 소프트웨어를 다운로드하고 설치하려면 섹션 5.1-5.4에 설명된 지침을 따르세요.<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">섹션 5.4에 설명된 검증 작업을 수행할 때, 가이드 작성 이후 CUDA 컨테이너 이미지가 업데이트되었으므로 다른 CUDA 컨테이너 이미지 버전 태그를 사용해야 할 수 있습니다.  우리는 검증 과정에서 'nvidia/cuda:11.0.3-base-ubuntu20.04'를 사용했습니다.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">AI/분석 프레임워크 컨테이너 다운로드</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">다음으로, 게스트 VM에서 사용할 수 있도록 NVIDIA NGC에서 필요한 AI 또는 분석 프레임워크 컨테이너 이미지를 다운로드해야 합니다.  게스트 VM 내에서 프레임워크 컨테이너를 다운로드하려면 다음 지침을 따르세요.<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block> .</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">NetApp DataOps 툴킷 설치 및 구성</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">다음으로, 게스트 VM 내에 NetApp DataOps Toolkit for Traditional Environment를 설치해야 합니다.  NetApp DataOps Toolkit을 사용하면 게스트 VM 내의 터미널에서 직접 ONTAP 시스템의 확장형 데이터 볼륨을 관리할 수 있습니다.  게스트 VM 내에 NetApp DataOps Toolkit을 설치하려면 다음 작업을 수행하세요.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">pip를 설치합니다.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">게스트 VM 터미널에서 로그아웃한 다음 다시 로그인합니다.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">NetApp DataOps Toolkit을 구성합니다.  이 단계를 완료하려면 ONTAP 시스템에 대한 API 액세스 세부 정보가 필요합니다.  스토리지 관리자로부터 해당 정보를 얻어야 할 수도 있습니다.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">게스트 VM 템플릿 만들기</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">마지막으로 게스트 VM을 기반으로 VM 템플릿을 만들어야 합니다.  이 템플릿을 사용하면 NVIDIA NGC 소프트웨어를 활용하는 게스트 VM을 빠르게 만들 수 있습니다.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">게스트 VM을 기반으로 VM 템플릿을 생성하려면 VMware vSphere에 로그인하고 게스트 VM 이름을 마우스 오른쪽 버튼으로 클릭한 다음 '복제'를 선택하고 '템플릿에 복제...'를 선택한 다음 마법사를 따르세요.</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NetApp 및 VMware를 사용한 NVIDIA AI Enterprise - 초기 설정</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">이 섹션에서는 NetApp 및 VMware에서 NVIDIA AI Enterprise를 활용하기 위해 수행해야 하는 초기 설정 작업에 대해 설명합니다.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI Enterprise 제품 지원 매트릭스</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">NetApp 및 VMware 솔루션 설명서</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">이 섹션에 설명된 단계를 수행하기 전에 VMware vSphere와 NetApp ONTAP 이미 배포했다고 가정합니다.  를 참조하세요<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block> 지원되는 vSphere 버전에 대한 자세한 내용은 다음을 참조하세요.  를 참조하세요<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block> NetApp ONTAP 과 함께 VMware vSphere를 배포하는 방법에 대한 자세한 내용은 다음을 참조하세요.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">NVIDIA AI Enterprise 호스트 소프트웨어 설치</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">NVIDIA AI Entrprise 호스트 소프트웨어를 설치하려면 섹션 1-4에 설명된 지침을 따르십시오.<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> .</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NetApp 및 VMware를 활용한 NVIDIA AI Enterprise - 기술 개요</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">이 섹션에서는 NetApp 및 VMware를 기반으로 한 NVIDIA AI Enterprise에 대한 기술 개요를 제공합니다.</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise는 NVIDIA 인증 시스템을 통해 VMware vSphere에서 실행되도록 NVIDIA 에서 최적화, 인증 및 지원하는 엔드 투 엔드 클라우드 기반 AI 및 데이터 분석 소프트웨어 제품군입니다.  이 소프트웨어는 최신 하이브리드 클라우드 환경에서 AI 워크로드를 간단하고 빠르게 배포, 관리, 확장할 수 있도록 지원합니다.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC는 AI 실무자가 AI 솔루션을 개발할 수 있도록 GPU 최적화 소프트웨어 카탈로그를 호스팅합니다.  또한 모델 학습을 위한 NVIDIA Base Command, 모델 배포 및 모니터링을 위한 NVIDIA Fleet Command, 독점 AI 소프트웨어에 안전하게 액세스하고 관리하기 위한 NGC Private Registry 등 다양한 AI 서비스에 대한 액세스를 제공합니다.  또한 NVIDIA AI Enterprise 고객은 NGC 포털을 통해 지원을 요청할 수 있습니다.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere는 VMware의 가상화 플랫폼으로, 데이터 센터를 CPU, 스토리지 및 네트워킹 리소스를 포함하는 통합 컴퓨팅 인프라로 변환합니다. vSphere는 이러한 인프라를 통합 운영 환경으로 관리하고, 관리자에게 해당 환경에 참여하는 데이터 센터를 관리할 수 있는 도구를 제공합니다.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">vSphere의 두 가지 핵심 구성 요소는 ESXi와 vCenter Server입니다.  ESXi는 관리자가 가상 머신과 가상 어플라이언스를 생성하고 실행하는 가상화 플랫폼입니다. vCenter Server는 관리자가 네트워크에 연결된 여러 호스트를 관리하고 호스트 리소스를 풀링하는 서비스입니다.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps Toolkit은 고성능, 확장형 NetApp 스토리지에 의해 지원되는 개발/교육 작업 공간과 추론 서버의 관리를 간소화하는 Python 기반 도구입니다.  주요 기능은 다음과 같습니다.</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">실험이나 빠른 반복을 가능하게 하기 위해 대용량 JupyterLab 작업 공간을 거의 즉각적으로 복제합니다.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">대용량 JupyterLab 작업 공간의 스냅샷을 거의 즉각적으로 저장하여 백업 및/또는 추적/기준 설정을 할 수 있습니다.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">거의 즉각적으로 대용량, 고성능 데이터 볼륨을 프로비저닝, 복제 및 스냅샷합니다.</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NetApp 및 VMware를 활용한 NVIDIA AI Enterprise - NVIDIA NGC 소프트웨어 활용 - 예시 사용 사례 - TensorFlow 교육 작업</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">예시 사용 사례 - TensorFlow 학습 작업</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">이 섹션에서는 NVIDIA AI Enterprise 환경 내에서 TensorFlow 학습 작업을 실행하기 위해 수행해야 하는 작업에 대해 설명합니다.</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">이 섹션에 설명된 단계를 수행하기 전에 이미 다음 지침에 따라 게스트 VM 템플릿을 생성했다고 가정합니다.<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block> 페이지.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">템플릿에서 게스트 VM 만들기</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">먼저, 이전 섹션에서 만든 템플릿에서 새 게스트 VM을 만들어야 합니다.  템플릿에서 새 게스트 VM을 만들려면 VMware vSphere에 로그인하고 템플릿 이름을 마우스 오른쪽 버튼으로 클릭한 다음 '이 템플릿에서 새 VM...'을 선택하고 마법사를 따르세요.</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">데이터 볼륨 생성 및 마운트</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">다음으로, 훈련 데이터 세트를 저장할 새로운 데이터 볼륨을 만들어야 합니다.  NetApp DataOps Toolkit을 사용하면 새로운 데이터 볼륨을 빠르게 만들 수 있습니다.  다음 예제 명령은 2TB 용량의 'imagenet'이라는 볼륨을 생성하는 것을 보여줍니다.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">데이터 볼륨에 데이터를 채우려면 먼저 게스트 VM 내에서 해당 볼륨을 마운트해야 합니다.  NetApp DataOps Toolkit을 사용하면 데이터 볼륨을 빠르게 마운트할 수 있습니다.  다음 예제 명령은 이전 단계에서 생성된 볼륨의 마운트를 보여줍니다.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">데이터 볼륨 채우기</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">새 볼륨이 프로비저닝되고 마운트된 후에는 소스 위치에서 교육 데이터 세트를 검색하여 새 볼륨에 배치할 수 있습니다.  일반적으로 이 작업에는 S3 또는 Hadoop 데이터 레이크에서 데이터를 가져오는 작업이 포함되며, 때로는 데이터 엔지니어의 도움이 필요하기도 합니다.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">TensorFlow 학습 작업 실행</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">이제 TensorFlow 학습 작업을 실행할 준비가 되었습니다.  TensorFlow 학습 작업을 실행하려면 다음 작업을 수행하세요.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">NVIDIA NGC 엔터프라이즈 TensorFlow 컨테이너 이미지를 가져옵니다.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">NVIDIA NGC 엔터프라이즈 TensorFlow 컨테이너 인스턴스를 실행합니다.  컨테이너에 데이터 볼륨을 연결하려면 '-v' 옵션을 사용하세요.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">컨테이너 내에서 TensorFlow 학습 프로그램을 실행합니다.  다음 예제 명령은 컨테이너 이미지에 포함된 ResNet-50 학습 프로그램의 실행을 보여줍니다.</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">NetApp 활용한 오픈소스 MLOps - Apache Airflow 배포</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow 배포</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 Airflow를 배포하기 위해 완료해야 하는 작업을 설명합니다.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Kubernetes 외의 플랫폼에도 Airflow를 배포하는 것이 가능합니다.  Kubernetes 이외의 플랫폼에 Airflow를 배포하는 것은 이 솔루션의 범위를 벗어납니다.</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">이 섹션에 설명된 배포 연습을 수행하기 전에 다음 작업을 이미 수행했다고 가정합니다.</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">이미 작동하는 Kubernetes 클러스터가 있습니다.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Trident 문서</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">Kubernetes 클러스터에 NetApp Trident 이미 설치하고 구성했습니다.  Trident 에 대한 자세한 내용은 다음을 참조하세요.<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block> .</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Helm 설치</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">설치 지침</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow는 Kubernetes의 인기 있는 패키지 관리자인 Helm을 사용하여 배포됩니다.  Airflow를 배포하기 전에 배포 점프 호스트에 Helm을 설치해야 합니다.  배포 점프 호스트에 Helm을 설치하려면 다음을 따르세요.<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> 공식 Helm 문서에서.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">기본 Kubernetes StorageClass 설정</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow 배포</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">Airflow를 배포하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정해야 합니다.  Airflow 배포 프로세스는 기본 StorageClass를 사용하여 새로운 영구 볼륨을 프로비저닝하려고 시도합니다.  StorageClass가 기본 StorageClass로 지정되지 않으면 배포가 실패합니다.  클러스터 내에서 기본 StorageClass를 지정하려면 다음 지침을 따르세요.<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> 부분.  클러스터 내에서 이미 기본 StorageClass를 지정한 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Helm을 사용하여 공기 흐름 배포</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Helm을 사용하여 Kubernetes 클러스터에 Airflow를 배포하려면 배포 점프 호스트에서 다음 작업을 수행하세요.</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">배치 지침</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Helm을 사용하여 Airflow를 배포하려면 다음을 따르세요.<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Artifact Hub의 공식 Airflow 차트입니다.  다음 예제 명령은 Helm을 사용하여 Airflow를 배포하는 방법을 보여줍니다.  값을 수정, 추가 및/또는 제거합니다.<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block> 환경과 원하는 구성에 따라 필요에 따라 파일을 추가하세요.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">모든 Airflow 포드가 제대로 작동하는지 확인하세요.  모든 포드가 시작되려면 몇 분이 걸릴 수 있습니다.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">1단계에서 Helm을 사용하여 Airflow를 배포할 때 콘솔에 인쇄된 지침에 따라 Airflow 웹 서비스 URL을 얻습니다.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Airflow 웹 서비스에 액세스할 수 있는지 확인하세요.</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">NetApp 사용한 오픈 소스 MLOps - Airflow와 함께 NetApp DataOps 툴킷 사용</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">Airflow와 함께 NetApp DataOps Toolkit 사용</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">그만큼<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block> Airflow와 함께 사용할 수 있습니다.  Airflow와 함께 NetApp DataOps Toolkit을 사용하면 스냅샷 및 복제본 생성과 같은 NetApp 데이터 관리 작업을 Airflow에서 조정하는 자동화된 워크플로에 통합할 수 있습니다.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">공기 흐름 예</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">를 참조하세요<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block> Airflow와 함께 툴킷을 사용하는 방법에 대한 자세한 내용은 NetApp DataOps Toolkit GitHub 저장소 내 섹션을 참조하세요.</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">NetApp 사용한 오픈 소스 MLOps - 아키텍처</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">이 솔루션은 특정 하드웨어에 의존하지 않습니다.  이 솔루션은 NetApp Trident 가 지원하는 모든 NetApp 물리적 스토리지 어플라이언스, 소프트웨어 정의 인스턴스 또는 클라우드 서비스와 호환됩니다.  예로는 NetApp AFF 스토리지 시스템, Amazon FSx ONTAP, Azure NetApp Files, Google Cloud NetApp Volumes 또는 NetApp Cloud Volumes ONTAP 인스턴스가 있습니다.  또한, NetApp Trident 와 구현 중인 다른 솔루션 구성 요소에서 지원되는 Kubernetes 버전을 사용하는 한 모든 Kubernetes 클러스터에서 솔루션을 구현할 수 있습니다.  Trident 에서 지원하는 Kubernetes 버전 목록은 다음을 참조하세요.<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .  이 솔루션의 다양한 구성 요소를 검증하는 데 사용된 환경에 대한 자세한 내용은 다음 표를 참조하세요.</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Apache Airflow 검증 환경</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">소프트웨어 구성 요소</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">아파치 에어플로우</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Apache Airflow Helm 차트</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1, 다음을 통해 배포됨<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block> 8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1.18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21.01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">JupyterHub 검증 환경</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">주피터허브</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">JupyterHub Helm 차트</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5, 배포됨<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block> 3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1.29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24.02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">MLflow 검증 환경</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">ML플로우</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">MLflow Helm 차트</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1, 다음을 통해 배포됨<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block> 1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Kubeflow 검증 환경</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">쿠베플로우</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">배포KF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7, 배포를 통해<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block> 0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1.26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23.07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">지원하다</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">NetApp 에 문의하세요</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp Apache Airflow, JupyterHub, MLflow, Kubeflow 또는 Kubernetes에 대한 엔터프라이즈 지원을 제공하지 않습니다.  완벽하게 지원되는 MLOps 플랫폼에 관심이 있으시다면,<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block> NetApp 파트너와 함께 제공하는 완벽하게 지원되는 MLOps 솔루션에 대해 알아보세요.</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">NetApp 활용한 오픈소스 MLOps - 기술 개요</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">이 섹션에서는 NetApp 사용한 오픈소스 MLOps에 대한 기술 개요에 중점을 둡니다.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">인공지능</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">AI는 컴퓨터가 인간 정신의 인지 기능을 모방하도록 훈련되는 컴퓨터 과학 분야입니다.  AI 개발자는 컴퓨터가 인간과 비슷하거나 더 나은 방식으로 학습하고 문제를 해결하도록 훈련시킵니다.  딥러닝과 머신러닝은 AI의 하위 분야입니다.  점점 더 많은 기업이 중요한 비즈니스 요구 사항을 지원하기 위해 AI, ML, DL을 도입하고 있습니다.  몇 가지 예는 다음과 같습니다.</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">이전에 알려지지 않았던 비즈니스 통찰력을 발굴하기 위해 방대한 양의 데이터 분석</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">자연어 처리를 사용하여 고객과 직접 상호 작용</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">다양한 비즈니스 프로세스 및 기능 자동화</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">최신 AI 학습 및 추론 작업에는 대규모 병렬 컴퓨팅 기능이 필요합니다.  따라서 GPU는 AI 작업을 실행하는 데 점점 더 많이 사용되고 있는데, 그 이유는 GPU의 병렬 처리 능력이 범용 CPU보다 훨씬 뛰어나기 때문입니다.</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">컨테이너</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">컨테이너는 공유 호스트 운영 체제 커널 위에서 실행되는 격리된 사용자 공간 인스턴스입니다.  컨테이너의 도입이 급속히 증가하고 있습니다.  컨테이너는 가상 머신(VM)이 제공하는 것과 동일한 애플리케이션 샌드박싱 이점을 많이 제공합니다.  하지만 VM이 의존하는 하이퍼바이저와 게스트 운영 체제 계층이 제거되었기 때문에 컨테이너는 훨씬 더 가볍습니다.  다음 그림은 가상 머신과 컨테이너를 시각화하여 보여줍니다.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker 웹사이트</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">컨테이너를 사용하면 애플리케이션 종속성, 런타임 등을 애플리케이션과 직접 효율적으로 패키징할 수도 있습니다.  가장 일반적으로 사용되는 컨테이너 패키징 형식은 Docker 컨테이너입니다.  Docker 컨테이너 형식으로 컨테이너화된 애플리케이션은 Docker 컨테이너를 실행할 수 있는 모든 머신에서 실행될 수 있습니다.  이는 애플리케이션의 종속성이 머신에 존재하지 않더라도 사실입니다. 모든 종속성은 컨테이너 자체에 패키징되어 있기 때문입니다.  자세한 내용은 다음을 방문하세요.<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block> .</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">쿠버네티스 웹사이트</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">쿠버네티스는 원래 Google에서 설계한 오픈 소스, 분산형 컨테이너 오케스트레이션 플랫폼으로, 현재는 Cloud Native Computing Foundation(CNCF)에서 관리하고 있습니다.  쿠버네티스는 컨테이너화된 애플리케이션의 배포, 관리 및 확장 기능을 자동화할 수 있습니다.  최근 몇 년 동안 쿠버네티스는 지배적인 컨테이너 오케스트레이션 플랫폼으로 떠올랐습니다.  자세한 내용은 다음을 방문하세요.<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block> .</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>ONTAP (AFF, FAS, Select, Cloud, Amazon FSx ONTAP), Azure NetApp Files 서비스, Google Cloud NetApp Volumes 포함하여 퍼블릭 클라우드 또는 온프레미스에서 모든 인기 있는 NetApp 스토리지 플랫폼에서 스토리지 리소스를 사용하고 관리할 수 있도록 지원합니다.  Trident 는 Kubernetes와 기본적으로 통합되는 컨테이너 스토리지 인터페이스(CSI) 호환 동적 스토리지 오케스트레이터입니다.</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">그만큼<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block> 고성능, 확장형 NetApp 스토리지에 의해 지원되는 개발/교육 작업 공간과 추론 서버의 관리를 간소화하는 Python 기반 도구입니다.  주요 기능은 다음과 같습니다.</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">고성능, 확장형 NetApp 스토리지로 지원되는 대용량의 새로운 작업 공간을 빠르게 프로비저닝하세요.</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">실험이나 빠른 반복을 가능하게 하기 위해 대용량 작업 공간을 거의 즉각적으로 복제합니다.</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">대용량 작업 공간의 스냅샷을 거의 즉각적으로 저장하여 백업 및/또는 추적/기준 설정을 수행합니다.</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow는 복잡한 엔터프라이즈 워크플로에 대한 프로그래밍 방식 작성, 일정 예약 및 모니터링을 지원하는 오픈 소스 워크플로 관리 플랫폼입니다.  ETL 및 데이터 파이프라인 워크플로를 자동화하는 데 자주 사용되지만 이러한 유형의 워크플로에만 국한되지는 않습니다.  Airflow 프로젝트는 Airbnb에서 시작되었지만 그 이후로 업계에서 큰 인기를 얻었으며 현재는 Apache 소프트웨어 재단의 후원을 받고 있습니다.  Airflow는 Python으로 작성되었으며, Airflow 워크플로는 Python 스크립트를 통해 생성되고, Airflow는 "코드로 구성"이라는 원칙에 따라 설계되었습니다.  많은 기업 Airflow 사용자는 이제 Kubernetes를 기반으로 Airflow를 실행합니다.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">방향성 비순환 그래프(DAG)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">Airflow에서는 워크플로를 DAG(Directed Acycle Graphs)라고 합니다.  DAG는 DAG 정의에 따라 순차적으로, 병렬로 또는 두 가지를 조합하여 실행되는 작업으로 구성됩니다.  Airflow 스케줄러는 DAG 정의에 지정된 작업 수준 종속성을 준수하여 일련의 작업자에서 개별 작업을 실행합니다.  DAG는 Python 스크립트를 통해 정의되고 생성됩니다.</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">주피터 노트북</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">주피터 웹사이트</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Jupyter Notebook은 실시간 코드와 설명 텍스트를 포함하는 위키와 유사한 문서입니다.  Jupyter Notebooks는 AI 및 ML 커뮤니티에서 AI 및 ML 프로젝트를 문서화하고, 저장하고, 공유하는 수단으로 널리 사용됩니다.  Jupyter Notebooks에 대한 자세한 내용은 다음을 방문하세요.<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block> .</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Jupyter Notebook 서버</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Jupyter Notebook Server는 사용자가 Jupyter Notebook을 만들 수 있는 오픈 소스 웹 애플리케이션입니다.</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">JupyterHub 웹사이트</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub는 개별 사용자가 자신의 Jupyter Notebook 서버를 프로비저닝하고 액세스할 수 있도록 하는 다중 사용자 애플리케이션입니다.  JupyterHub에 대한 자세한 내용은 다음을 방문하세요.<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block> .</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">MLflow 웹사이트</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow는 인기 있는 오픈소스 AI 라이프사이클 관리 플랫폼입니다.  MLflow의 주요 기능으로는 AI/ML 실험 추적 및 AI/ML 모델 저장소가 있습니다.  MLflow에 대한 자세한 내용은 다음을 방문하세요.<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block> .</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow 웹사이트</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow는 원래 Google에서 개발한 Kubernetes용 오픈소스 AI 및 ML 툴킷입니다.  Kubeflow 프로젝트는 Kubernetes에서 AI 및 ML 워크플로를 간편하고, 이식 가능하며, 확장 가능하게 배포할 수 있도록 해줍니다.  Kubeflow는 Kubernetes의 복잡한 부분을 추상화하여 데이터 과학자가 자신이 가장 잘 아는 분야인 데이터 과학에 집중할 수 있도록 해줍니다.  다음 그림을 통해 시각화를 살펴보세요.  Kubeflow는 올인원 MLOps 플랫폼을 선호하는 조직에 적합한 오픈소스 옵션입니다.  자세한 내용은 다음을 방문하세요.<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block> .</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow 파이프라인</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">공식 Kubeflow 문서</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Kubeflow 파이프라인은 Kubeflow의 핵심 구성 요소입니다.  Kubeflow Pipelines는 이식 가능하고 확장 가능한 AI 및 ML 워크플로를 정의하고 배포하기 위한 플랫폼이자 표준입니다. 자세한 내용은 다음을 참조하세요.<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block> .</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Kubeflow 노트북</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow는 Kubernetes에서 Jupyter Notebook 서버의 프로비저닝과 배포를 간소화합니다.  Kubeflow 컨텍스트 내에서 Jupyter Notebooks에 대한 자세한 내용은 다음을 참조하세요.<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block> .</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">카티브</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib은 자동화된 머신 러닝(AutoML)을 위한 Kubernetes 기반 프로젝트입니다.  Katib은 하이퍼파라미터 튜닝, 조기 중단 및 NAS(신경망 구조 탐색)를 지원합니다.  Katib은 머신 러닝(ML) 프레임워크에 구애받지 않는 프로젝트입니다.  사용자가 선택한 언어로 작성된 애플리케이션의 하이퍼파라미터를 조정할 수 있으며 TensorFlow, MXNet, PyTorch, XGBoost 등 다양한 ML 프레임워크를 기본적으로 지원합니다.  Katib은 베이지안 최적화, 파젠 추정 트리, 무작위 탐색, 공분산 행렬 적응 진화 전략, 하이퍼밴드, 효율적 신경 구조 탐색, 미분 가능 구조 탐색 등 다양한 AutoML 알고리즘을 지원합니다.  Kubeflow 컨텍스트 내에서 Jupyter Notebooks에 대한 자세한 내용은 다음을 참조하세요.<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block> .</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">원활한 확장과 중단 없는 운영.  ONTAP 기존 컨트롤러와 확장형 클러스터에 중단 없이 용량을 추가할 수 있도록 지원합니다.  고객은 비용이 많이 드는 데이터 마이그레이션이나 중단 없이 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp 스냅샷 복사본</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp 스냅샷 복사본은 볼륨의 읽기 전용 특정 시점 이미지입니다.  다음 그림에서 볼 수 있듯이 이미지는 최소한의 저장 공간을 사용하고 마지막 스냅샷 복사본이 만들어진 이후에 생성된 파일의 변경 사항만 기록하므로 성능 오버헤드가 무시할 수 있을 정도입니다.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">스냅샷 복사본의 효율성은 핵심 ONTAP 스토리지 가상화 기술인 WAFL(Write Anywhere File Layout) 덕분에 가능합니다.  WAFL 데이터베이스와 마찬가지로 메타데이터를 사용하여 디스크의 실제 데이터 블록을 가리킵니다.  하지만 데이터베이스와 달리 WAFL 기존 블록을 덮어쓰지 않습니다.  업데이트된 데이터를 새로운 블록에 쓰고 메타데이터를 변경합니다.  ONTAP 스냅샷 복사본을 생성할 때 데이터 블록을 복사하는 대신 메타데이터를 참조하기 때문에 스냅샷 복사본이 매우 효율적입니다.  그렇게 하면 다른 시스템이 복사할 블록을 찾는 데 걸리는 탐색 시간과 복사 자체를 만드는 데 드는 비용을 없앨 수 있습니다.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">스냅샷 복사본을 사용하면 개별 파일이나 LUN을 복구하거나 볼륨의 전체 내용을 복원할 수 있습니다.  ONTAP 스냅샷 복사본의 포인터 정보를 디스크의 데이터와 비교하여 다운타임이나 상당한 성능 비용 없이 누락되거나 손상된 객체를 재구성합니다.</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone 기술</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone 기술은 스냅샷 메타데이터를 참조하여 볼륨의 쓰기 가능한 특정 시점 복사본을 생성합니다.  다음 그림에서 볼 수 있듯이 복사본은 부모와 데이터 블록을 공유하며, 복사본에 변경 사항이 기록될 때까지 메타데이터에 필요한 것을 제외하고는 저장 공간을 사용하지 않습니다.  기존 복사 작업에는 몇 분 또는 몇 시간이 걸릴 수 있지만, FlexClone 소프트웨어를 사용하면 가장 큰 데이터 세트도 거의 즉시 복사할 수 있습니다.  따라서 동일한 데이터 세트의 여러 사본이 필요한 상황(예: 개발 작업 공간)이나 데이터 세트의 임시 사본(예: 프로덕션 데이터 세트에 대한 애플리케이션 테스트)이 필요한 경우에 이상적입니다.</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror 데이터 복제 기술</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror 소프트웨어는 데이터 패브릭 전반에 걸친 비용 효율적이고 사용하기 쉬운 통합 복제 솔루션입니다.  LAN이나 WAN을 통해 고속으로 데이터를 복제합니다.  이 솔루션은 가상 및 기존 환경 모두에서 비즈니스에 중요한 애플리케이션을 포함하여 모든 유형의 애플리케이션에 대해 높은 데이터 가용성과 빠른 데이터 복제 기능을 제공합니다.  하나 이상의 NetApp 스토리지 시스템에 데이터를 복제하고 보조 데이터를 지속적으로 업데이트하면 데이터가 최신 상태로 유지되고 필요할 때마다 사용할 수 있습니다.  외부 복제 서버가 필요하지 않습니다.  SnapMirror 기술을 활용하는 아키텍처의 예는 다음 그림을 참조하세요.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror 소프트웨어는 변경된 블록만 네트워크를 통해 전송하여 NetApp ONTAP 스토리지 효율성을 활용합니다.  SnapMirror 소프트웨어는 내장된 네트워크 압축 기능을 사용하여 데이터 전송 속도를 높이고 네트워크 대역폭 사용량을 최대 70%까지 줄입니다.  SnapMirror 기술을 사용하면 단일 씬 복제 데이터 스트림을 활용하여 활성 미러와 이전 시점 복사본을 모두 유지하는 단일 저장소를 만들어 네트워크 트래픽을 최대 50%까지 줄일 수 있습니다.</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>빠르고 안전한 데이터 동기화를 위한 NetApp 서비스입니다.  온프레미스 NFS 또는 SMB 파일 공유, NetApp StorageGRID, NetApp ONTAP S3, Google Cloud NetApp Volumes, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google Cloud Storage 또는 IBM Cloud Object Storage 간에 파일을 전송해야 하는 경우 BlueXP Copy and Sync를 사용하면 파일을 필요한 곳으로 빠르고 안전하게 이동할 수 있습니다.</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">데이터가 전송되면 소스와 타겟 모두에서 자유롭게 사용할 수 있습니다.  BlueXP Copy and Sync는 업데이트가 발생할 때 필요에 따라 데이터를 동기화하거나 미리 정의된 일정에 따라 지속적으로 데이터를 동기화할 수 있습니다.  그럼에도 불구하고 BlueXP Copy and Sync는 델타만 이동하므로 데이터 복제에 소요되는 시간과 비용이 최소화됩니다.</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync는 설정과 사용이 매우 간단한 SaaS(Software as a Service) 도구입니다.  BlueXP Copy and Sync에 의해 트리거되는 데이터 전송은 데이터 브로커를 통해 수행됩니다.  BlueXP 복사 및 동기화 데이터 브로커는 AWS, Azure, Google Cloud Platform 또는 온프레미스에 배포할 수 있습니다.</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>모든 NetApp 및 NetApp NetApp 데이터 마이그레이션과 파일 시스템 통찰력을 위한 클라이언트 기반 소프트웨어입니다.  XCP는 사용 가능한 모든 시스템 리소스를 활용해 대용량 데이터 세트와 고성능 마이그레이션을 처리함으로써 확장성을 높이고 최대 성능을 달성하도록 설계되었습니다.  XCP는 보고서 생성 옵션을 통해 파일 시스템에 대한 완전한 가시성을 확보하는 데 도움이 됩니다.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup 볼륨</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">훈련 데이터 세트는 잠재적으로 수십억 개의 파일 모음이 될 수 있습니다.  파일에는 텍스트, 오디오, 비디오 및 기타 형태의 비정형 데이터가 포함될 수 있으며, 이러한 데이터는 병렬로 읽을 수 있도록 저장하고 처리해야 합니다.  저장 시스템은 많은 수의 작은 파일을 저장해야 하며, 순차적이고 무작위적인 I/O를 위해 해당 파일을 병렬로 읽어야 합니다.</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup 볼륨은 다음 그림에서 볼 수 있듯이 여러 구성 멤버 볼륨으로 구성된 단일 네임스페이스입니다.  스토리지 관리자 관점에서 FlexGroup 볼륨은 NetApp FlexVol volume 처럼 관리되고 작동합니다.  FlexGroup 볼륨의 파일은 개별 멤버 볼륨에 할당되며 볼륨이나 노드에 걸쳐 스트라이프되지 않습니다.  다음과 같은 기능을 제공합니다.</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup 볼륨은 대량의 메타데이터 워크로드에 대해 수 페타바이트의 용량과 예측 가능한 낮은 대기 시간을 제공합니다.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">동일한 네임스페이스에서 최대 4,000억 개의 파일을 지원합니다.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">이들은 CPU, 노드, 집계 및 구성 FlexVol 볼륨 전반의 NAS 워크로드에서 병렬화된 작업을 지원합니다.</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">이 솔루션은 MLOps 워크플로에 통합할 수 있는 여러 가지 오픈 소스 도구와 프레임워크를 보여주기 위한 것입니다.  이러한 다양한 도구와 프레임워크는 요구 사항과 사용 사례에 따라 함께 사용하거나 각각 따로 사용할 수 있습니다.</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">NetApp 사용한 오픈 소스 MLOps</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby, NetApp Sufian Ahmad, NetApp Rick Huang, NetApp Mohan Acharya, NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">다양한 산업 분야의 모든 규모의 회사와 조직은 실제 문제를 해결하고, 혁신적인 제품과 서비스를 제공하며, 점점 경쟁이 치열해지는 시장에서 우위를 점하기 위해 인공지능(AI)에 눈을 돌리고 있습니다.  많은 조직이 업계의 빠른 혁신 속도에 발맞추기 위해 오픈소스 MLOps 도구를 선택하고 있습니다.  이러한 오픈소스 도구는 고급 기능과 최첨단 기능을 제공하지만, 데이터 가용성과 데이터 보안을 고려하지 않는 경우가 많습니다.  안타깝게도 이는 고도로 숙련된 데이터 과학자들이 데이터에 액세스하거나 기본적인 데이터 관련 작업이 완료될 때까지 기다리는 데 상당한 시간을 소비해야 한다는 것을 의미합니다.  인기 있는 오픈소스 MLOps 도구를 NetApp 의 지능형 데이터 인프라와 결합하면 조직은 데이터 파이프라인을 가속화할 수 있으며, 이를 통해 AI 이니셔티브도 가속화됩니다.  데이터가 보호되고 보안되는 것을 보장하는 동시에 데이터에서 가치를 창출할 수 있습니다.  이 솔루션은 이러한 과제를 해결하기 위해 NetApp 데이터 관리 기능과 여러 가지 인기 있는 오픈 소스 도구 및 프레임워크를 결합하는 방법을 보여줍니다.</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">다음 목록은 이 솔루션을 통해 구현되는 몇 가지 주요 기능을 강조합니다.</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">사용자는 고성능, 확장형 NetApp 스토리지를 기반으로 새로운 대용량 데이터 볼륨과 개발 작업 공간을 빠르게 프로비저닝할 수 있습니다.</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">사용자는 대용량 데이터 볼륨과 개발 작업 공간을 거의 즉각적으로 복제하여 실험이나 빠른 반복을 수행할 수 있습니다.</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">사용자는 대용량 데이터 볼륨과 개발 작업 공간의 스냅샷을 거의 즉시 저장하여 백업 및/또는 추적/기준 설정을 수행할 수 있습니다.</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">주피터 노트북</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">일반적인 MLOps 워크플로는 일반적으로 다음과 같은 형태를 갖는 개발 작업 공간을 통합합니다.<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> ; 실험 추적; 자동화된 교육 파이프라인; 데이터 파이프라인; 추론/배포.  이 솔루션은 워크플로의 다양한 측면을 해결하기 위해 독립적으로 또는 함께 사용할 수 있는 여러 가지 도구와 프레임워크를 강조합니다.  또한 NetApp 데이터 관리 기능과 각 도구의 페어링을 보여드립니다.  이 솔루션은 조직이 자사의 사용 사례와 요구 사항에 맞춰 맞춤형 MLOps 워크플로를 구성할 수 있는 기본 요소를 제공하기 위해 고안되었습니다.</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">이 솔루션에는 다음과 같은 도구/프레임워크가 포함되어 있습니다.</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">다음 목록은 이러한 도구를 독립적으로 또는 결합하여 배포하는 일반적인 패턴을 설명합니다.</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">JupyterHub, MLflow 및 Apache Airflow를 함께 배포 - JupyterHub<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> 실험 추적을 위한 MLflow, 자동화된 학습 및 데이터 파이프라인을 위한 Apache Airflow.</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">Kubeflow와 Apache Airflow를 함께 배포 - Kubeflow for<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , 실험 추적, 자동화된 교육 파이프라인 및 추론, 데이터 파이프라인을 위한 Apache Airflow.</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">Kubeflow를 올인원 MLOps 플랫폼 솔루션으로 배포<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> , 실험 추적, 자동화된 학습 및 데이터 파이프라인, 추론.</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">NetApp 사용한 오픈소스 MLOps - JupyterHub 배포</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">JupyterHub 배포</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 JupyterHub를 배포하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">Kubernetes 외의 플랫폼에도 JupyterHub를 배포하는 것이 가능합니다.  Kubernetes 이외의 플랫폼에 JupyterHub를 배포하는 것은 이 솔루션의 범위를 벗어납니다.</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">Kubernetes 클러스터에 NetApp Trident 이미 설치하고 구성했습니다.  Trident 에 대한 자세한 내용은 다음을 참조하세요.<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub는 Kubernetes의 인기 있는 패키지 관리자인 Helm을 사용하여 배포됩니다.  JupyterHub를 배포하기 전에 Kubernetes 제어 노드에 Helm을 설치해야 합니다.  Helm을 설치하려면 다음을 따르세요.<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> 공식 Helm 문서에서.</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">JupyterHub를 배포하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정해야 합니다.  클러스터 내에서 기본 StorageClass를 지정하려면 다음 지침을 따르세요.<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> 부분.  클러스터 내에서 기본 StorageClass를 이미 지정한 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">JupyterHub 배포</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">위의 단계를 완료하면 이제 JupyterHub를 배포할 준비가 되었습니다.  JupyterHub를 배포하려면 다음 단계가 필요합니다.</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">JupyterHub 배포 구성</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">배포하기 전에 각자의 환경에 맞게 JupyterHub 배포를 최적화하는 것이 좋습니다.  *config.yaml* 파일을 만들고 Helm 차트를 사용하여 배포하는 동안 활용할 수 있습니다.</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">예제 *config.yaml* 파일은 다음에서 찾을 수 있습니다.<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">이 config.yaml 파일에서 NetApp Trident StorageClass에 대한 *(singleuser.storage.dynamic.storageClass)* 매개변수를 설정할 수 있습니다.  이는 개별 사용자 작업 공간에 대한 볼륨을 프로비저닝하는 데 사용되는 스토리지 클래스입니다.</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">공유 볼륨 추가</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">모든 JupyterHub 사용자를 위한 공유 볼륨을 사용하려면 *config.yaml*을 적절히 조정하면 됩니다.  예를 들어, jupyterhub-shared-volume이라는 공유 PersistentVolumeClaim이 있는 경우 다음과 같이 모든 사용자 Pod에서 /home/shared로 마운트할 수 있습니다.</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">이는 선택 사항이며, 귀하의 필요에 맞게 이러한 매개변수를 조정할 수 있습니다.</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">Helm Chart로 JupyterHub 배포</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">Helm에 JupyterHub Helm 차트 저장소를 알립니다.</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">다음과 같은 출력이 표시됩니다.</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">이제 config.yaml이 포함된 디렉토리에서 다음 명령을 실행하여 config.yaml에 의해 구성된 차트를 설치하세요.</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">이 예에서는:</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt;은 my-jupyterhub로 설정되며, 이는 JupyterHub 릴리스의 이름이 됩니다.  &lt;k8s-namespace&gt;는 JupyterHub를 설치하려는 네임스페이스인 my-namespace로 설정됩니다.  --create-namespace 플래그는 네임스페이스가 아직 존재하지 않을 경우 네임스페이스를 생성하는 데 사용됩니다.  --values 플래그는 원하는 구성 옵션이 포함된 config.yaml 파일을 지정합니다.</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">배포 확인</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">2단계가 실행되는 동안 다음 명령을 실행하면 포드가 생성되는 것을 볼 수 있습니다.</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">허브와 프록시 포드가 실행 상태로 전환될 때까지 기다리세요.</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">JupyterHub에 접속하세요</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">JupyterHub에 접속하는 데 사용할 수 있는 IP를 찾으세요.  예제 출력과 같이 proxy-public 서비스의 EXTERNAL-IP를 사용할 수 있을 때까지 다음 명령을 실행합니다.</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">config.yaml 파일에서 NodePort 서비스를 사용했는데, 설정(예: LoadBalancer)에 따라 환경에 맞게 조정할 수 있습니다.</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">JupyterHub를 사용하려면 프록시-공개 서비스의 외부 IP를 브라우저에 입력하세요.</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">NetApp 사용한 오픈 소스 MLOps - JupyterHub와 함께 NetApp DataOps 툴킷 사용</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">JupyterHub와 함께 NetApp DataOps Toolkit 사용</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">그만큼<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> JupyterHub와 함께 사용할 수 있습니다.  JupyterHub와 함께 NetApp DataOps Toolkit을 사용하면 최종 사용자는 Jupyter Notebook 내에서 직접 작업 공간 백업 및/또는 데이터 세트-모델 추적을 위한 볼륨 스냅샷을 만들 수 있습니다.</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">JupyterHub에서 DataOps Toolkit을 사용하려면 먼저 JupyterHub가 개별 사용자 Jupyter Notebook Server 포드에 할당한 Kubernetes 서비스 계정에 적절한 권한을 부여해야 합니다.  JupyterHub는 다음에 의해 지정된 서비스 계정을 사용합니다.<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> JupyterHub Helm 차트 구성 파일의 변수입니다.</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">DataOps Toolkit에 대한 클러스터 역할 생성</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">먼저, 볼륨 스냅샷을 만드는 데 필요한 Kubernetes API 권한이 있는 'netapp-dataops'라는 클러스터 역할을 만듭니다.</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">Notebook Server 서비스 계정에 클러스터 역할 할당</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">적절한 네임스페이스의 적절한 서비스 계정에 'netapp-dataops-snapshots' 클러스터 역할을 할당하는 역할 바인딩을 만듭니다.  예를 들어, 'jupyterhub' 네임스페이스에 JupyterHub를 설치하고 다음을 통해 '기본' 서비스 계정을 지정한 경우<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> 다음 예에서 보듯이 변수를 사용하면 'jupyterhub' 네임스페이스의 '기본' 서비스 계정에 'netapp-dataops-snapshots' 클러스터 역할을 할당할 수 있습니다.</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">Jupyter Notebook 내에서 볼륨 스냅샷 만들기</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">이제 JupyterHub 사용자는 다음 예에서 볼 수 있듯이 NetApp DataOps Toolkit을 사용하여 Jupyter Notebook 내에서 직접 볼륨 스냅샷을 만들 수 있습니다.</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">NetApp SnapMirror 사용하여 데이터 수집</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">NetApp SnapMirror 사용하여 JupyterHub에 데이터 수집</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirror 는 NetApp 스토리지 시스템 간에 데이터를 복제할 수 있는 복제 기술입니다.  SnapMirror 사용하면 원격 환경에서 JupyterHub로 데이터를 수집할 수 있습니다.</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">예제 워크플로 및 데모</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">이 Tech ONTAP 블로그 게시물</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">참조하다<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block> NetApp SnapMirror 사용하여 JupyterHub에 데이터를 수집하는 방법에 대한 자세한 예제 워크플로와 데모를 확인하세요.</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">NetApp 활용한 오픈소스 MLOps - Kubeflow 배포</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 Kubeflow를 배포하기 위해 완료해야 하는 작업을 설명합니다.</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">이미 작동하는 Kubernetes 클러스터가 있으며, 배포하려는 Kubeflow 버전에서 지원하는 Kubernetes 버전을 실행하고 있습니다.  지원되는 Kubernetes 버전 목록은 Kubeflow 버전에 대한 종속성을 참조하세요.<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block> .</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">Kubeflow를 배포하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정하는 것이 좋습니다.  Kubeflow 배포 프로세스는 기본 StorageClass를 사용하여 새로운 영구 볼륨을 프로비저닝하려고 시도할 수 있습니다.  StorageClass가 기본 StorageClass로 지정되지 않으면 배포가 실패할 수 있습니다.  클러스터 내에서 기본 StorageClass를 지정하려면 배포 점프 호스트에서 다음 작업을 수행하세요.  클러스터 내에서 기본 StorageClass를 이미 지정한 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">기존 StorageClass 중 하나를 기본 StorageClass로 지정합니다.  다음 예제 명령은 StorageClass라는 이름의 지정을 보여줍니다.<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block> 기본 StorageClass로.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">그만큼<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Trident 백엔드 유형은 최소 PVC 크기가 상당히 큽니다.  기본적으로 Kubeflow는 크기가 몇 GB에 불과한 PVC를 프로비저닝하려고 시도합니다.  따라서 StorageClass를 사용하는 StorageClass를 지정해서는 안 됩니다.<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Kubeflow 배포를 위해 기본 StorageClass로 백엔드 유형을 지정합니다.</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Kubeflow 배포 옵션</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">Kubeflow를 배포하는 데에는 다양한 옵션이 있습니다.  를 참조하세요<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block> 배포 옵션 목록을 확인하고, 귀하의 요구 사항에 가장 적합한 옵션을 선택하세요.</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">검증 목적으로 Kubeflow 1.7을 배포했습니다.<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1.</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">NetApp 사용한 오픈 소스 MLOps - Kubeflow와 함께 NetApp DataOps 툴킷 사용</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">Kubeflow와 함께 NetApp DataOps Toolkit 사용</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kubernetes를 위한 NetApp 데이터 과학 툴킷</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">그만큼<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block> Kubeflow와 함께 사용할 수 있습니다.  Kubeflow와 함께 NetApp 데이터 과학 툴킷을 사용하면 다음과 같은 이점이 있습니다.</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">데이터 과학자는 Jupyter Notebook 내에서 직접 스냅샷 및 복제본 생성과 같은 고급 NetApp 데이터 관리 작업을 수행할 수 있습니다.</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">Kubeflow Pipelines 프레임워크를 사용하면 스냅샷 및 복제본 생성과 같은 고급 NetApp 데이터 관리 작업을 자동화된 워크플로에 통합할 수 있습니다.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow 예제</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">를 참조하세요<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block> Kubeflow와 함께 툴킷을 사용하는 방법에 대한 자세한 내용은 NetApp Data Science Toolkit GitHub 저장소 내 섹션을 참조하세요.</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">NetApp 사용한 오픈 소스 MLOps - 데이터 과학자 또는 개발자를 위한 Jupyter Notebook 작업 공간 프로비저닝</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">데이터 과학자 또는 개발자를 위한 Jupyter Notebook 작업 공간 프로비저닝</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow는 데이터 과학자의 작업 공간 역할을 하는 새로운 Jupyter Notebook 서버를 빠르게 프로비저닝할 수 있습니다.  Kubeflow 컨텍스트 내 Jupyter Notebook에 대한 자세한 내용은 다음을 참조하세요.<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block> .</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">NetApp 사용한 오픈 소스 MLOps - 예시 워크플로 - Kubeflow와 NetApp DataOps 툴킷을 사용하여 이미지 인식 모델 학습</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">예제 워크플로 - Kubeflow와 NetApp DataOps 툴킷을 사용하여 이미지 인식 모델 학습</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">이 섹션에서는 Kubeflow와 NetApp DataOps Toolkit을 사용하여 이미지 인식을 위한 신경망을 훈련하고 배포하는 데 필요한 단계를 설명합니다.  이는 NetApp 스토리지를 통합한 교육 작업을 보여주는 예시로 사용됩니다.</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">Kubeflow 파이프라인 내의 학습 및 테스트 단계에 사용할 필수 구성을 포함하는 Dockerfile을 만듭니다.  다음은 Dockerfile의 예입니다.</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">요구 사항에 따라 프로그램을 실행하는 데 필요한 모든 라이브러리와 패키지를 설치하세요.  머신 러닝 모델을 학습하기 전에 이미 작동하는 Kubeflow 배포가 있다고 가정합니다.</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">PyTorch와 Kubeflow 파이프라인을 사용하여 MNIST 데이터에서 소규모 NN 학습</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">우리는 MNIST 데이터로 훈련된 작은 신경망의 예를 사용합니다.  MNIST 데이터 세트는 0~9까지의 숫자로 쓰인 손으로 쓴 이미지로 구성되어 있습니다.  이미지 크기는 28x28픽셀입니다.  데이터 세트는 60,000개의 훈련 이미지와 10,000개의 검증 이미지로 나뉩니다.  이 실험에 사용된 신경망은 2계층 피드포워드 네트워크입니다.  Kubeflow Pipelines를 사용하여 훈련이 실행됩니다. 문서를 참조하세요<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block> 자세한 내용은.  Kubeflow 파이프라인은 필수 구성 요소 섹션의 Docker 이미지를 통합합니다.</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Kubeflow 파이프라인 실행 시각화</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">Tensorboard를 사용하여 결과 시각화</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">텐서보드</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">모델이 훈련되면 Tensorboard를 사용하여 결과를 시각화할 수 있습니다.<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block> Kubeflow 대시보드의 기능으로 사용할 수 있습니다.  귀하의 작업에 맞는 사용자 정의 텐서보드를 만들 수 있습니다.  아래 예는 학습 정확도 대 에포크 수, 학습 손실 대 에포크 수의 플롯을 보여줍니다.</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">훈련 손실 및 정확도를 위한 텐서보드 그래프</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">Katib을 사용하여 하이퍼파라미터 실험</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>Kubeflow 내의 도구로, 모델 하이퍼파라미터를 실험하는 데 사용할 수 있습니다.  실험을 만들려면 먼저 원하는 지표/목표를 정의하세요.  이는 일반적으로 테스트 정확도입니다.  지표가 정의되면, 조정하고 싶은 하이퍼 매개변수(최적화 도구/학습 속도/계층 수)를 선택합니다.  Katib은 사용자 정의 값으로 하이퍼파라미터 스윕을 수행하여 원하는 지표를 만족하는 최적의 매개변수 조합을 찾습니다.  UI의 각 섹션에서 이러한 매개변수를 정의할 수 있습니다.  또는 필요한 사양을 담은 *YAML* 파일을 정의할 수 있습니다.  아래는 Katib 실험의 그림입니다.</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">하이퍼파라미터가 포함된 Katib 실험 대시보드</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">성공적인 시험 점검</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">NetApp 스냅샷을 사용하여 추적을 위한 데이터 저장</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">모델 학습 중에 추적을 위해 학습 데이터 세트의 스냅샷을 저장하고 싶을 수도 있습니다.  이를 위해 아래와 같이 파이프라인에 스냅샷 단계를 추가할 수 있습니다.  스냅샷을 생성하려면 다음을 사용할 수 있습니다.<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> .</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">Kubeflow에서 스냅샷 파이프라인을 빌드하는 코드</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">Kubeflow를 위한 NetApp DataOps Toolkit 예제</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">를 참조하세요 <block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block> 자세한 내용은.</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">NetApp 활용한 오픈소스 MLOps - MLflow 배포</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">MLflow 배포</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 MLflow를 배포하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">Kubernetes 외의 플랫폼에도 MLflow를 배포하는 것이 가능합니다.  Kubernetes 이외의 플랫폼에 MLflow를 배포하는 것은 이 솔루션의 범위를 벗어납니다.</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow는 Kubernetes의 인기 있는 패키지 관리자인 Helm을 사용하여 배포됩니다.  MLflow를 배포하기 전에 Kubernetes 제어 노드에 Helm을 설치해야 합니다.  Helm을 설치하려면 다음을 따르세요.<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> 공식 Helm 문서에서.</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">MLflow를 배포하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정해야 합니다.  클러스터 내에서 기본 StorageClass를 지정하려면 다음 지침을 따르세요.<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block> 부분.  클러스터 내에서 기본 StorageClass를 이미 지정한 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">MLflow 배포</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">필수 조건을 충족하면 Helm 차트를 사용하여 MLflow 배포를 시작할 수 있습니다.</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">MLflow Helm 차트 배포를 구성합니다.</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">Helm 차트를 사용하여 MLflow를 배포하기 전에 *config.yaml* 파일을 사용하여 NetApp Trident Storage Class를 사용하도록 배포를 구성하고 다른 매개변수를 요구 사항에 맞게 변경할 수 있습니다.  *config.yaml* 파일의 예는 다음에서 찾을 수 있습니다.<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">config.yaml 파일의 *global.defaultStorageClass* 매개변수에서 Trident storageClass를 설정할 수 있습니다(예: storageClass: "ontap-flexvol").</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">Helm 차트 설치</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">다음 명령을 사용하여 MLflow용 사용자 정의 *config.yaml* 파일로 Helm 차트를 설치할 수 있습니다.</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">이 명령은 제공된 *config.yaml* 파일을 통해 사용자 정의 구성으로 Kubernetes 클러스터에 MLflow를 배포합니다.  MLflow는 지정된 네임스페이스에 배포되고, 릴리스에 대한 무작위 릴리스 이름은 Kubernetes를 통해 제공됩니다.</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Helm 차트 배포가 완료되면 다음을 사용하여 서비스에 액세스할 수 있는지 확인할 수 있습니다.</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">*jupyterhub*를 배포 중에 사용한 네임스페이스로 바꾸세요.</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">다음 서비스가 표시되어야 합니다.</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">MLflow에 포트 30002로 접근하기 위해 NodePort 서비스를 사용하도록 config.yaml 파일을 편집했습니다.</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">MLflow에 접속하세요</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">MLflow와 관련된 모든 서비스가 실행되면 지정된 NodePort 또는 LoadBalancer IP 주소(예:<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block> )</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">NetApp 활용한 오픈소스 MLOps - NetApp 및 MLflow를 활용한 데이터셋-모델 추적성</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">NetApp 및 MLflow를 사용한 데이터 세트-모델 추적성</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">그만큼<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> MLflow의 실험 추적 기능과 함께 사용하여 데이터 세트-모델 또는 작업 공간-모델 추적을 구현할 수 있습니다.</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">데이터세트-모델 또는 작업 공간-모델 추적을 구현하려면 다음 예제 코드 조각과 같이 교육 실행의 일부로 DataOps Toolkit을 사용하여 데이터세트 또는 작업 공간 볼륨의 스냅샷을 만들기만 하면 됩니다.  이 코드는 MLflow 실험 추적 서버에 로깅하는 특정 교육 실행과 연관된 태그로 데이터 볼륨 이름과 스냅샷 이름을 저장합니다.</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">NetApp 사용한 오픈 소스 MLOps - 동기식 분산 AI 워크로드 실행</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">동기식 분산 AI 워크로드 실행</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Kubernetes 클러스터에서 동기식 멀티노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 다음 작업을 수행하세요.  이 프로세스를 사용하면 NetApp 볼륨에 저장된 데이터를 활용하고 단일 작업자 노드가 제공할 수 있는 것보다 많은 GPU를 사용할 수 있습니다.  동기식 분산 AI 작업을 묘사한 다음 그림을 참조하세요.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">동기 분산 작업은 비동기 분산 작업에 비해 성능과 교육 정확도를 높이는 데 도움이 될 수 있습니다.  동기 작업과 비동기 작업의 장단점에 대한 논의는 이 문서의 범위를 벗어납니다.</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">단일 노드 AI 워크로드 실행</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">다음 예제 명령은 섹션의 예제에서 단일 노드에서 실행된 동일한 TensorFlow 벤치마크 작업의 동기 분산 실행에 참여하는 하나의 작업자 생성을 보여줍니다.<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .  이 특정 예에서 작업은 두 개의 작업자 노드에서 실행되므로 단일 작업자만 배포됩니다.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">공식 Kubernetes 문서</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">이 예제 워커 배포에서는 8개의 GPU를 요청하므로 8개 이상의 GPU가 있는 단일 GPU 워커 노드에서 실행될 수 있습니다.  GPU 워커 노드에 8개 이상의 GPU가 있는 경우 성능을 극대화하려면 워커 노드가 제공하는 GPU 수와 같도록 이 숫자를 늘리는 것이 좋습니다.  Kubernetes 배포에 대한 자세한 내용은 다음을 참조하세요.<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block> .</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">이 예에서는 특정 컨테이너화된 작업자가 스스로 완료될 수 없기 때문에 Kubernetes 배포가 생성됩니다.  따라서 Kubernetes 작업 구조를 사용하여 배포하는 것은 의미가 없습니다.  작업자가 자체적으로 완료되도록 설계되거나 작성된 경우, 작업 구성을 사용하여 작업자를 배치하는 것이 합리적일 수 있습니다.</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">이 예제 배포 사양에 지정된 포드는 다음과 같습니다.<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> 의 가치<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  이 값은 Kubernetes가 일반적으로 각 Pod에 대해 생성하는 가상 네트워킹 스택 대신, Pod가 호스트 워커 노드의 네트워킹 스택을 사용한다는 것을 의미합니다.  이 주석이 사용되는 이유는 특정 워크로드가 동기식 분산 방식으로 워크로드를 실행하기 위해 Open MPI, NCCL 및 Horovod에 의존하기 때문입니다.  따라서 호스트 네트워킹 스택에 액세스해야 합니다.  Open MPI, NCCL, Horovod에 대한 논의는 이 문서의 범위를 벗어납니다.  이것이든 아니든<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block> 주석이 필요한지는 실행 중인 특정 작업 부하의 요구 사항에 따라 달라집니다.  자세한 내용은<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> 필드에서 확인하세요<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block> .</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">1단계에서 생성한 작업자 배포가 성공적으로 시작되었는지 확인하세요.  다음 예제 명령은 배포 정의에 표시된 대로 배포에 대해 단일 워커 포드가 생성되었으며, 이 포드가 현재 GPU 워커 노드 중 하나에서 실행 중인지 확인합니다.</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">동기식 멀티노드 작업을 시작하고, 참여하고, 실행을 추적하는 마스터에 대한 Kubernetes 작업을 만듭니다.  다음 예제 명령은 예제 섹션의 단일 노드에서 실행된 동일한 TensorFlow 벤치마크 작업의 동기 분산 실행을 시작하고 참여하고 추적하는 하나의 마스터를 생성합니다.<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> .</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">이 예제 마스터 작업은 8개의 GPU를 요청하므로 8개 이상의 GPU가 있는 단일 GPU 워커 노드에서 실행될 수 있습니다.  GPU 워커 노드에 8개 이상의 GPU가 있는 경우 성능을 극대화하려면 워커 노드가 제공하는 GPU 수와 같도록 이 숫자를 늘리는 것이 좋습니다.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">이 예제 작업 정의에 지정된 마스터 포드에는 다음이 제공됩니다.<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> 의 가치<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> , 작업자 포드에 다음과 같은 것이 주어진 것처럼<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block> 의 가치<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> 1단계에서.  이 값이 필요한 이유에 대한 자세한 내용은 1단계를 참조하세요.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">3단계에서 생성한 마스터 작업이 올바르게 실행되는지 확인하세요.  다음 예제 명령은 작업 정의에 표시된 대로 작업에 대한 단일 마스터 포드가 생성되었으며, 이 포드가 현재 GPU 워커 노드 중 하나에서 실행 중인지 확인합니다.  1단계에서 처음 본 워커 포드가 여전히 실행 중인지, 마스터 포드와 워커 포드가 다른 노드에서 실행 중인지도 확인해야 합니다.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">3단계에서 생성한 마스터 작업이 성공적으로 완료되는지 확인하세요.  다음 예제 명령은 작업이 성공적으로 완료되었음을 확인합니다.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">더 이상 필요하지 않으면 작업자 배포를 삭제하세요.  다음 예제 명령은 1단계에서 생성된 작업자 배포 개체를 삭제하는 방법을 보여줍니다.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">워커 배포 객체를 삭제하면 쿠버네티스는 연관된 모든 워커 포드를 자동으로 삭제합니다.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*선택 사항:* 마스터 작업 아티팩트를 정리합니다.  다음 예제 명령은 3단계에서 생성된 마스터 작업 개체를 삭제하는 방법을 보여줍니다.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">마스터 작업 객체를 삭제하면 Kubernetes는 연관된 모든 마스터 포드를 자동으로 삭제합니다.</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">NetApp 사용한 오픈 소스 MLOps - 단일 노드 AI 워크로드 실행</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">Kubernetes 클러스터에서 단일 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 다음 작업을 수행하세요.  Trident 사용하면 페타바이트 규모의 데이터를 포함하는 데이터 볼륨을 Kubernetes 워크로드에서 쉽고 빠르게 액세스할 수 있습니다.  Kubernetes 포드 내에서 이러한 데이터 볼륨에 액세스할 수 있게 하려면 포드 정의에서 PVC를 지정하기만 하면 됩니다.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">이 섹션에서는 Kubernetes 클러스터에서 실행하려는 특정 AI 및 ML 워크로드를 이미 컨테이너화(Docker 컨테이너 형식)했다고 가정합니다.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet 웹사이트</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">다음 예제 명령은 ImageNet 데이터 세트를 사용하는 TensorFlow 벤치마크 워크로드에 대한 Kubernetes 작업을 생성하는 방법을 보여줍니다.  ImageNet 데이터 세트에 대한 자세한 내용은 다음을 참조하세요.<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block> .</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">이 예제 작업은 8개의 GPU를 요청하므로 8개 이상의 GPU를 갖춘 단일 GPU 워커 노드에서 실행될 수 있습니다.  이 예제 작업은 8개 이상의 GPU를 갖춘 작업자 노드가 없거나 현재 다른 작업 부하로 인해 사용 중인 클러스터에 제출될 수 있습니다.  그렇다면 해당 작업은 해당 작업자 노드가 사용 가능해질 때까지 보류 상태로 유지됩니다.</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">또한, 저장 대역폭을 최대화하기 위해 이 작업이 생성하는 포드 내에 필요한 학습 데이터가 포함된 볼륨이 두 번 마운트됩니다.  또 다른 볼륨도 포드에 마운트됩니다.  두 번째 볼륨은 결과와 측정 항목을 저장하는 데 사용됩니다.  이러한 볼륨은 PVC의 이름을 사용하여 작업 정의에 참조됩니다.  Kubernetes 작업에 대한 자세한 내용은 다음을 참조하세요.<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block> .</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">안<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> 볼륨이 있는<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block> 의 가치<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block> 에 마운트됩니다<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> 이 예제 작업이 생성하는 포드에서.  기본 크기<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> Docker 컨테이너 런타임에서 자동으로 생성되는 가상 볼륨은 때때로 TensorFlow의 요구 사항을 충족하지 못할 수 있습니다.  장착<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> 다음 예와 같이 볼륨은 충분히 큰 크기를 제공합니다.<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block> 가상 볼륨.  더 많은 정보를 원하시면<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block> 볼륨을 참조하십시오<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block> .</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">이 예제 작업 정의에 지정된 단일 컨테이너에는 다음이 제공됩니다.<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block> 의 가치<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block> .  이 값은 컨테이너가 호스트에 대한 루트 액세스 권한을 효과적으로 가지고 있음을 의미합니다.  이 주석은 실행되는 특정 작업 부하에 루트 액세스가 필요하기 때문에 이 경우에 사용됩니다.  구체적으로, 워크로드가 수행하는 캐시 지우기 작업에는 루트 액세스가 필요합니다.  이것이든 아니든<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block> 주석이 필요한지는 실행 중인 특정 작업 부하의 요구 사항에 따라 달라집니다.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">1단계에서 생성한 작업이 올바르게 실행되는지 확인하세요.  다음 예제 명령은 작업 정의에 지정된 대로 작업에 대한 단일 포드가 생성되었으며, 이 포드가 현재 GPU 워커 노드 중 하나에서 실행 중인지 확인합니다.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">1단계에서 생성한 작업이 성공적으로 완료되는지 확인하세요.  다음 예제 명령은 작업이 성공적으로 완료되었음을 확인합니다.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*선택 사항:* 작업 아티팩트를 정리합니다.  다음 예제 명령은 1단계에서 생성된 작업 객체를 삭제하는 방법을 보여줍니다.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">작업 객체를 삭제하면 Kubernetes는 연관된 모든 Pod를 자동으로 삭제합니다.</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">NetApp 활용한 오픈소스 MLOps - NetApp AIPod 배포를 위한 Trident 백엔드 예시</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">NetApp AIPod 배포를 위한 Trident 백엔드 예시</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">Kubernetes 클러스터 내에서 Trident 사용하여 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Trident 백엔드를 만들어야 합니다.  다음 예는 이 솔루션의 구성 요소를 배포하는 경우 생성하려는 다양한 유형의 백엔드를 나타냅니다.<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  백엔드에 대한 자세한 내용과 예를 들어 다른 플랫폼/환경의 백엔드에 대한 내용은 다음을 참조하세요.<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp AIPod 에 대해 FlexGroup 지원 Trident 백엔드를 만드는 것을 권장합니다.</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">다음 예제 명령은 AIPod 스토리지 가상 머신(SVM)에 대한 FlexGroup 지원 Trident 백엔드를 만드는 방법을 보여줍니다.  이 백엔드는 다음을 사용합니다.<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> 저장 드라이버.  ONTAP FlexVol 과 FlexGroup 이라는 두 가지 주요 데이터 볼륨 유형을 지원합니다.  FlexVol 볼륨은 크기가 제한되어 있습니다(이 글을 쓰는 시점에서 최대 크기는 특정 배포에 따라 달라집니다).  반면 FlexGroup 볼륨은 최대 20PB와 4,000억 개의 파일까지 선형적으로 확장할 수 있어 데이터 관리를 크게 간소화하는 단일 네임스페이스를 제공합니다.  따라서 FlexGroup 볼륨은 대량의 데이터에 의존하는 AI 및 ML 워크로드에 최적화되어 있습니다.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">소량의 데이터로 작업하고 FlexGroup 볼륨 대신 FlexVol 볼륨을 사용하려는 경우 다음을 사용하는 Trident 백엔드를 생성할 수 있습니다.<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> 대신 저장 드라이버<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> 저장 드라이버.</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp FlexVol 이 지원되는 Trident 백엔드를 만드는 것도 권장합니다.  영구적인 애플리케이션을 호스팅하고, 결과, 출력, 디버그 정보 등을 저장하는 데 FlexVol 볼륨을 사용할 수 있습니다.  FlexVol 볼륨을 사용하려면 FlexVol 이 활성화된 Trident 백엔드를 하나 이상 만들어야 합니다.  다음 명령 예시는 FlexVol 이 활성화된 단일 Trident 백엔드를 만드는 방법을 보여줍니다.</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">NetApp 사용한 오픈 소스 MLOps - Trident Operations 예시</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Trident 작업 예시</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">이 섹션에는 Trident 사용하여 수행할 수 있는 다양한 작업의 예가 포함되어 있습니다.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">기존 볼륨 가져오기</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Kubernetes 클러스터 내의 컨테이너에 마운트하려는 NetApp 스토리지 시스템/플랫폼에 기존 볼륨이 있지만 해당 볼륨이 클러스터의 PVC에 연결되지 않은 경우 해당 볼륨을 가져와야 합니다.  Trident 볼륨 가져오기 기능을 사용하면 이러한 볼륨을 가져올 수 있습니다.</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">다음 예제 명령은 이름이 지정된 볼륨을 가져오는 방법을 보여줍니다.<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block> .  PVC에 대한 자세한 내용은 다음을 참조하세요.<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .  볼륨 가져오기 기능에 대한 자세한 내용은 다음을 참조하세요.<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> .</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">안<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> 의 가치<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block> 예제 PVC 사양 파일에 지정되어 있습니다.  자세한 내용은<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> 필드에서 확인하세요<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">새 볼륨 제공</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">Trident 사용하면 NetApp 스토리지 시스템이나 플랫폼에 새 볼륨을 프로비저닝할 수 있습니다.</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">kubectl을 사용하여 새 볼륨 프로비저닝</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">다음 예제 명령은 kubectl을 사용하여 새로운 FlexVol volume 프로비저닝하는 방법을 보여줍니다.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">안<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block> 의 가치<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block> 다음 예제 PVC 정의 파일에 지정되어 있습니다.  자세한 내용은<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block> 필드에서 확인하세요<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> .</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">NetApp DataOps 툴킷을 사용하여 새 볼륨 프로비저닝</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">선적 서류 비치</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">Kubernetes용 NetApp DataOps Toolkit을 사용하여 NetApp 스토리지 시스템이나 플랫폼에 새 볼륨을 프로비저닝할 수도 있습니다.  Kubernetes용 NetApp DataOps Toolkit은 Trident 사용하여 볼륨을 프로비저닝하지만 사용자를 위해 프로세스를 간소화합니다.  를 참조하세요<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block> 자세한 내용은.</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">NetApp 사용한 오픈소스 MLOps - NetApp AIPod 배포를 위한 Kubernetes StorageClass 예시</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">NetApp AIPod 배포를 위한 Kubernetes StorageClass 예시</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">Kubernetes 클러스터 내에서 Trident 사용하여 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Kubernetes StorageClass를 만들어야 합니다.  다음 예는 이 솔루션의 구성 요소를 배포하는 경우 생성하려는 다양한 유형의 StorageClass를 나타냅니다.<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> .  StorageClass에 대한 자세한 내용과 다른 플랫폼/환경에 대한 StorageClass에 대한 내용은 다음을 참조하세요.<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> .</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">RDMA를 통한 NFS</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetApp 섹션에서 생성한 FlexGroup 지원 Trident 백엔드에 대한 StorageClass를 생성하는 것을 권장합니다.<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , 1단계.  다음 예제 명령은 섹션에서 생성된 예제 백엔드에 해당하는 여러 StorageClass를 생성하는 방법을 보여줍니다.<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> , 1단계 - 활용하는 단계<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block> 그리고 그렇지 않은 것도 하나 있습니다.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">쿠버네티스 문서</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">해당 PersistentVolumeClaim(PVC)이 삭제될 때 영구 볼륨이 삭제되지 않도록 다음 예제에서는 다음을 사용합니다.<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> 의 가치<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block> .  자세한 내용은<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block> 필드, 공식을 참조하세요<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block> .</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">참고: 다음 예제 StorageClass는 최대 전송 크기인 262144를 사용합니다.  이 최대 전송 크기를 사용하려면 ONTAP 시스템에서 최대 전송 크기를 적절히 구성해야 합니다.  를 참조하세요<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block> 자세한 내용은.</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">참고: RDMA를 통한 NFS를 사용하려면 ONTAP 시스템에서 RDMA를 통한 NFS를 구성해야 합니다.  를 참조하세요<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block> 자세한 내용은.</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">참고: 다음 예에서는 StorageClass 정의 파일의 storagePool 필드에 특정 백엔드가 지정됩니다.</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">AIPod 배포를 위한 Trident 백엔드 예시</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp 또한 섹션에서 생성한 FlexVol 지원 Trident 백엔드에 해당하는 StorageClass를 생성할 것을 권장합니다.<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block> , 2단계.  다음 예제 명령은 FlexVol 볼륨에 대한 단일 StorageClass를 생성하는 방법을 보여줍니다.</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">참고: 다음 예에서는 StorageClass 정의 파일의 storagePool 필드에 특정 백엔드가 지정되지 않았습니다.  이 StorageClass를 사용하여 Kubernetes를 사용하여 볼륨을 관리하는 경우 Trident 해당 StorageClass를 사용하는 사용 가능한 백엔드를 사용하려고 시도합니다.<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block> 운전사.</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">실험이나 빠른 반복을 가능하게 하기 위해 대용량 JupyterLab 작업 공간을 거의 즉각적으로 복제합니다.</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">대용량 JupyterLab 작업 공간의 스냅샷을 거의 즉시 저장하여 백업 및/또는 추적/기준 설정을 수행합니다.</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">대용량, 고성능 데이터 볼륨을 거의 즉각적으로 프로비저닝, 복제 및 스냅샷합니다.</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">결론 - NetApp을 위한 벡터 데이터베이스 솔루션</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">이 섹션에서는 NetApp 의 벡터 데이터베이스 솔루션을 마무리합니다.</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">결론적으로, 이 문서는 NetApp 스토리지 솔루션에서 Milvus 및 pgvector와 같은 벡터 데이터베이스를 배포하고 관리하는 방법에 대한 포괄적인 개요를 제공합니다.  NetApp ONTAP 및 StorageGRID 객체 스토리지를 활용하기 위한 인프라 가이드라인을 논의하고 파일 및 객체 저장소를 통해 AWS FSx ONTAP 에서 Milvus 데이터베이스를 검증했습니다.</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">우리는 NetApp의 파일-객체 이중성을 살펴보고 벡터 데이터베이스의 데이터뿐만 아니라 다른 애플리케이션에도 유용하다는 것을 보여주었습니다.  또한 NetApp의 엔터프라이즈 관리 제품인 SnapCenter 벡터 데이터베이스 데이터에 대한 백업, 복원 및 복제 기능을 제공하여 데이터 무결성과 가용성을 보장하는 방식도 강조했습니다.</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">또한 이 문서에서는 NetApp의 하이브리드 클라우드 솔루션이 온프레미스 및 클라우드 환경에서 데이터 복제 및 보호를 제공하여 원활하고 안전한 데이터 관리 환경을 제공하는 방법을 자세히 설명합니다.  우리는 NetApp ONTAP 에서 Milvus와 pgvecto와 같은 벡터 데이터베이스의 성능 검증에 대한 통찰력을 제공하고, 이러한 데이터베이스의 효율성과 확장성에 대한 귀중한 정보를 제공했습니다.</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">마지막으로 LLM을 활용한 RAG와 NetApp의 내부 ChatAI라는 두 가지 생성 AI 사용 사례에 대해 논의했습니다.  이러한 실제 사례는 이 문서에 설명된 개념과 관행의 실제 적용과 이점을 강조합니다.  전반적으로 이 문서는 벡터 데이터베이스를 관리하기 위해 NetApp의 강력한 스토리지 솔루션을 활용하고자 하는 모든 사람을 위한 포괄적인 가이드 역할을 합니다.</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">저자는 아래의 기여자들과 NetApp 고객과 NetApp 분야에 귀중한 이 논문을 만들기 위해 피드백과 의견을 제공해주신 분들께 진심으로 감사드리고 싶습니다.</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan, NetApp ONTAP AI 및 분석 기술 마케팅 엔지니어</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">Mike Oglesby, NetApp 기술 마케팅 엔지니어</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">AJ Mahajan, NetApp 수석 이사</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">Joe Scott, NetApp 워크로드 성능 엔지니어링 관리자</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">Puneet Dhawan, NetApp Fsx 제품 관리 부문 수석 이사</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">Yuval Kalderon, NetApp FSx 제품 팀 수석 제품 관리자</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Milvus 문서 -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Milvus 독립형 문서 -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">NetApp 제품 문서<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">설치 클러스터 문서</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">인스타클러스트 -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">2024년 4월</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">NetApp용 벡터 데이터베이스 솔루션에 대한 데이터 준비</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">부록 B: prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">이 섹션에서는 벡터 데이터베이스의 데이터를 준비하는 데 사용되는 샘플 Python 스크립트를 제공합니다.</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">벡터 데이터베이스 배포 절차 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">이 섹션에서는 NetApp 용 벡터 데이터베이스 솔루션의 배포 절차에 대해 설명합니다.</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">배포 절차</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">이 배포 섹션에서는 아래와 같이 랩 설정을 위해 Kubernetes와 함께 milvus 벡터 데이터베이스를 사용했습니다.</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">NetApp 스토리지는 클러스터가 고객 데이터와 Milvus 클러스터 데이터를 보관할 수 있는 스토리지를 제공합니다.</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">NetApp 스토리지 설정 – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">NFS(네트워크 파일 시스템)의 경우 아래 단계를 따르세요.</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">NFSv4에 대한 FlexGroup 볼륨을 생성합니다.  이 검증을 위한 설정에서 48개의 SSD를 사용했습니다. 1개의 SSD는 컨트롤러의 루트 볼륨에 전용으로 사용하고 47개의 SSD는 NFSv4에 분산했습니다. FlexGroup 볼륨에 대한 NFS 내보내기 정책에 Kubernetes(K8s) 노드 네트워크에 대한 읽기/쓰기 권한이 있는지 확인하세요.  이러한 권한이 없는 경우 K8s 노드 네트워크에 대한 읽기/쓰기(rw) 권한을 부여하세요.</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">모든 K8s 노드에서 폴더를 만들고 각 K8s 노드의 논리 인터페이스(LIF)를 통해 FlexGroup 볼륨을 이 폴더에 마운트합니다.</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">NAS S3(Network Attached Storage Simple Storage Service)의 경우 아래 단계를 따르세요.</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">NFS용 FlexGroup 볼륨을 생성합니다.</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">유형을 "nas"로 설정하고 NFSv3 볼륨의 경로를 제공하여 NAS 버킷을 만듭니다.  이 목적으로 S3 버킷을 활용하는 것도 가능합니다.</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">NetApp 스토리지 설정 – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">storageGRID 소프트웨어를 설치하세요.</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">테넌트와 버킷을 생성합니다.</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">필요한 권한이 있는 사용자를 생성합니다.</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">자세한 내용은 에서 확인하세요.<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml - netapp을 위한 벡터 데이터베이스 솔루션</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">부록 D: docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">이 섹션에는 NetApp 의 벡터 데이터베이스 솔루션에 대한 샘플 YAML 코드가 포함되어 있습니다.</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">SnapCenter를 사용한 벡터 데이터베이스 보호 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">SnapCenter 사용한 벡터 데이터베이스 보호</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">이 섹션에서는 NetApp SnapCenter 사용하여 벡터 데이터베이스에 대한 데이터 보호를 제공하는 방법을 설명합니다.</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">NetApp SnapCenter 사용한 벡터 데이터베이스 보호.</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">예를 들어, 영화 제작 산업에서 고객은 종종 비디오 및 오디오 파일과 같은 중요한 내장 데이터를 보유하고 있습니다.  하드 드라이브 오류 등의 문제로 인해 이러한 데이터가 손실되면 운영에 상당한 영향을 미칠 수 있으며, 수백만 달러 규모의 사업이 위험에 처할 수도 있습니다.  우리는 귀중한 콘텐츠가 손실되어 상당한 중단과 재정적 손실을 초래하는 사례들을 경험했습니다.  따라서 이 필수 데이터의 보안과 무결성을 보장하는 것이 이 업계에서 가장 중요합니다.  이 섹션에서는 SnapCenter ONTAP 에 있는 벡터 데이터베이스 데이터와 Milvus 데이터를 어떻게 보호하는지 자세히 살펴보겠습니다.  이 예에서는 고객 데이터에 대해 NFS ONTAP 볼륨(vol1)에서 파생된 NAS 버킷(milvusdbvol1)을 활용했으며 Milvus 클러스터 구성 데이터에 대해 별도의 NFS 볼륨(vectordbpv)을 활용했습니다. 다음을 확인하십시오.<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block> SnapCenter 백업 워크플로우용</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">SnapCenter 명령을 실행하는 데 사용될 호스트를 설정합니다.</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">NetApp 자동화 스토어</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">스토리지 플러그인을 설치하고 구성합니다.  추가된 호스트에서 "추가 옵션"을 선택하세요.  다운로드한 저장소 플러그인을 탐색하여 선택하세요.<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block> .  플러그인을 설치하고 구성을 저장합니다.</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">스토리지 시스템 및 볼륨 설정: "스토리지 시스템"에서 스토리지 시스템을 추가하고 SVM(스토리지 가상 머신)을 선택합니다.  이 예에서는 "vs_nvidia"를 선택했습니다.</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">백업 정책과 사용자 정의 스냅샷 이름을 통합하여 벡터 데이터베이스에 대한 리소스를 설정합니다.</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">기본값으로 일관성 그룹 백업을 활성화하고 파일 시스템 일관성 없이 SnapCenter 활성화합니다.</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">저장소 공간 섹션에서 벡터 데이터베이스 고객 데이터와 Milvus 클러스터 데이터와 연결된 볼륨을 선택합니다.  우리의 예에서는 "vol1"과 "vectordbpv"가 있습니다.</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">벡터 데이터베이스 보호에 대한 정책을 만들고 해당 정책을 사용하여 벡터 데이터베이스 리소스를 보호합니다.</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">Python 스크립트를 사용하여 S3 NAS 버킷에 데이터를 삽입합니다.  우리의 경우 Milvus가 제공한 백업 스크립트인 'prepare_data_netapp.py'를 수정하고 'sync' 명령을 실행하여 운영 체제에서 데이터를 플러시했습니다.</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">S3 NAS 버킷의 데이터를 확인합니다.  예를 들어, 타임스탬프가 '2024-04-08 21:22'인 파일은 'prepare_data_netapp.py' 스크립트에 의해 생성되었습니다.</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">'milvusdb' 리소스의 일관성 그룹(CG) 스냅샷을 사용하여 백업을 시작합니다.</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">백업 기능을 테스트하기 위해 백업 프로세스 후에 새 테이블을 추가하거나 NFS(S3 NAS 버킷)에서 일부 데이터를 제거했습니다.</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">이 테스트에서는 백업 후 누군가가 새롭고 불필요하거나 부적절한 컬렉션을 만든 상황을 상상해 보세요.  이런 경우에는 새로운 컬렉션이 추가되기 전 상태로 벡터 데이터베이스를 되돌려야 합니다.  예를 들어, 'hello_milvus_netapp_sc_testnew' 및 'hello_milvus_netapp_sc_testnew2'와 같은 새로운 컬렉션이 삽입되었습니다.</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">이전 스냅샷에서 S3 NAS 버킷의 전체 복원을 실행합니다.</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">Python 스크립트를 사용하여 'hello_milvus_netapp_sc_test' 및 'hello_milvus_netapp_sc_test2' 컬렉션의 데이터를 확인합니다.</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">불필요하거나 부적절한 컬렉션이 더 이상 데이터베이스에 존재하지 않는지 확인하세요.</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">결론적으로, ONTAP 에 있는 벡터 데이터베이스 데이터와 Milvus 데이터를 보호하기 위해 NetApp의 SnapCenter 사용하면 고객에게 상당한 이점을 제공하며, 특히 영화 제작과 같이 데이터 무결성이 가장 중요한 산업의 고객에게 큰 이점을 제공합니다.  SnapCenter는 일관된 백업을 생성하고 전체 데이터 복원을 수행할 수 있는 기능을 통해 내장된 비디오 및 오디오 파일과 같은 중요한 데이터가 하드 드라이브 오류나 기타 문제로 인한 손실로부터 보호됩니다.  이는 운영 중단을 방지할 뿐만 아니라 상당한 재정적 손실로부터도 보호해줍니다.</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">이 섹션에서는 호스트 설정, 스토리지 플러그인 설치 및 구성, 사용자 정의 스냅샷 이름을 사용하여 벡터 데이터베이스에 대한 리소스 생성을 포함하여 ONTAP 에 있는 데이터를 보호하기 위해 SnapCenter 구성하는 방법을 보여주었습니다.  또한 일관성 그룹 스냅샷을 사용하여 백업을 수행하고 S3 NAS 버킷의 데이터를 검증하는 방법도 보여드렸습니다.</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">더 나아가, 백업 후 불필요하거나 부적절한 컬렉션이 생성되는 시나리오를 시뮬레이션했습니다.  이런 경우 SnapCenter는 이전 스냅샷에서 전체 복원을 수행할 수 있는 기능을 통해 벡터 데이터베이스를 새 컬렉션을 추가하기 전 상태로 되돌릴 수 있으므로 데이터베이스의 무결성을 유지할 수 있습니다.  특정 시점으로 데이터를 복원하는 기능은 고객에게 매우 귀중하며, 데이터가 안전할 뿐만 아니라 올바르게 유지 관리되고 있다는 확신을 제공합니다.  따라서 NetApp의 SnapCenter 제품은 고객에게 데이터 보호 및 관리를 위한 견고하고 안정적인 솔루션을 제공합니다.</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">NetApp SnapMirror 사용한 재해 복구 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">NetApp SnapMirror 사용한 재해 복구</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">이 섹션에서는 NetApp 의 벡터 데이터베이스 솔루션을 위한 SnapMirror 사용한 DR(재해 복구)에 대해 설명합니다.</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">재해 복구는 벡터 데이터베이스의 무결성과 가용성을 유지하는 데 필수적이며, 특히 고차원 데이터를 관리하고 복잡한 유사성 검색을 실행하는 역할을 감안할 때 더욱 그렇습니다.  잘 계획하고 구현된 재해 복구 전략은 하드웨어 장애, 자연재해, 사이버 공격 등 예상치 못한 사고가 발생하더라도 데이터가 손실되거나 손상되지 않도록 보장합니다.  이는 벡터 데이터베이스에 의존하는 애플리케이션에 특히 중요한데, 데이터가 손실되거나 손상되면 상당한 운영 중단과 재정적 손실로 이어질 수 있기 때문입니다.  더욱이, 강력한 재해 복구 계획은 가동 중지 시간을 최소화하고 서비스를 신속하게 복구할 수 있게 하여 비즈니스 연속성을 보장합니다.  이는 다양한 지리적 위치에 걸친 NetApp 데이터 복제 제품 SnapMirrror, 정기적 백업 및 장애 조치 메커니즘을 통해 달성됩니다.  따라서 재해 복구는 단순한 보호 조치가 아니라 책임감 있고 효율적인 벡터 데이터베이스 관리의 중요한 구성 요소입니다.</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">NetApp의 SnapMirror 하나의 NetApp ONTAP 스토리지 컨트롤러에서 다른 컨트롤러로 데이터를 복제하는 기능을 제공하며, 주로 재해 복구(DR) 및 하이브리드 솔루션에 사용됩니다.  벡터 데이터베이스의 맥락에서 이 도구는 온프레미스와 클라우드 환경 간의 원활한 데이터 전환을 용이하게 합니다.  이러한 전환은 데이터 변환이나 애플리케이션 리팩토링이 필요 없이 이루어지므로 여러 플랫폼에서 데이터 관리의 효율성과 유연성이 향상됩니다.</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">벡터 데이터베이스 시나리오에서 NetApp 하이브리드 솔루션은 더 많은 이점을 가져올 수 있습니다.</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">확장성: NetApp의 하이브리드 클라우드 솔루션은 요구 사항에 따라 리소스를 확장할 수 있는 기능을 제공합니다.  정기적이고 예측 가능한 작업 부하에는 온프레미스 리소스를 활용하고, 피크 시간이나 예상치 못한 부하에는 Amazon FSx ONTAP for NetApp ONTAP 및 Google Cloud NetApp Volume(NetApp Volumes)과 같은 클라우드 리소스를 활용할 수 있습니다.</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">비용 효율성: NetApp의 하이브리드 클라우드 모델을 사용하면 정기적인 작업에는 온프레미스 리소스를 사용하고 필요할 때만 클라우드 리소스에 대한 비용을 지불하여 비용을 최적화할 수 있습니다.  NetApp instaclustr 서비스를 이용하면 이러한 사용량 기반 결제 모델을 상당히 비용 효율적으로 활용할 수 있습니다.  온프레미스 및 주요 클라우드 서비스 공급업체를 위해 instaclustr는 지원과 컨설팅을 제공합니다.</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">유연성: NetApp의 하이브리드 클라우드는 데이터를 처리할 위치를 선택할 수 있는 유연성을 제공합니다.  예를 들어, 더 강력한 하드웨어를 갖춘 온프레미스에서 복잡한 벡터 작업을 수행하고, 덜 집약적인 작업은 클라우드에서 수행하기로 선택할 수 있습니다.</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">비즈니스 연속성: 재해 발생 시 NetApp 하이브리드 클라우드에 데이터를 보관하면 비즈니스 연속성을 보장할 수 있습니다.  온프레미스 리소스에 영향을 미치는 경우 신속하게 클라우드로 전환할 수 있습니다.  NetApp SnapMirror 활용하면 온프레미스에서 클라우드로 데이터를 이동할 수 있으며, 그 반대의 경우도 가능합니다.</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">혁신: NetApp의 하이브리드 클라우드 솔루션은 최첨단 클라우드 서비스와 기술에 대한 액세스를 제공함으로써 보다 빠른 혁신을 가능하게 합니다.  Amazon FSx ONTAP for NetApp ONTAP, Azure NetApp Files , Google Cloud NetApp Volumes 와 같은 클라우드의 NetApp 혁신은 클라우드 서비스 제공업체의 혁신적인 제품이자 선호되는 NAS입니다.</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">pgvector를 활용한 instaclustr - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">PostgreSQL을 사용하는 Instaclustr의 벡터 데이터베이스: pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">이 섹션에서는 instaclustr 제품이 NetApp 의 벡터 데이터베이스 솔루션에서 pgvector 기능과 postgreSQL을 통합하는 방법에 대한 세부 사항을 설명합니다.</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">블로그</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">이 섹션에서는 instaclustr 제품이 pgvector 기능을 통해 postgreSQL과 어떻게 통합되는지 자세히 살펴보겠습니다.  "PGVector와 PostgreSQL을 사용하여 LLM 정확도와 성능을 개선하는 방법: 임베딩 소개 및 PGVector의 역할"에 대한 예가 있습니다.  확인해 주세요<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block> 더 많은 정보를 얻으려면.</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">NetApp용 벡터 데이터베이스 솔루션 소개</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">이 섹션에서는 NetApp 용 벡터 데이터베이스 솔루션을 소개합니다.</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">벡터 데이터베이스는 대규모 언어 모델(LLM)과 생성형 인공 지능(AI)에서 의미 검색의 복잡성을 처리하도록 설계된 과제를 효과적으로 해결합니다.  기존 데이터 관리 시스템과 달리 벡터 데이터베이스는 레이블이나 태그가 아닌 데이터 자체의 내용을 사용하여 이미지, 비디오, 텍스트, 오디오 및 기타 형태의 비정형 데이터를 포함한 다양한 유형의 데이터를 처리하고 검색할 수 있습니다.</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">관계형 데이터베이스 관리 시스템(RDBMS)의 한계는 잘 알려져 있으며, 특히 AI 애플리케이션에서 흔히 볼 수 있는 고차원 데이터 표현과 비정형 데이터 처리의 어려움에 대한 내용이 많습니다.  RDBMS는 데이터를 관리하기 쉬운 구조로 평면화하는 데 시간이 많이 걸리고 오류가 발생하기 쉬운 프로세스를 필요로 하며, 이로 인해 검색이 지연되고 비효율적이 됩니다.  그러나 벡터 데이터베이스는 이러한 문제를 해결하도록 설계되어 복잡하고 고차원 데이터를 관리하고 검색하기 위한 보다 효율적이고 정확한 솔루션을 제공함으로써 AI 애플리케이션의 발전을 촉진합니다.</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">이 문서는 현재 벡터 데이터베이스를 사용 중이거나 사용할 계획인 고객을 위한 포괄적인 가이드로, NetApp ONTAP, NetApp StorageGRID, Amazon FSx ONTAP for NetApp ONTAP, SnapCenter 등의 플랫폼에서 벡터 데이터베이스를 활용하는 모범 사례를 자세히 설명합니다.  여기에 제공된 내용은 다음과 같은 다양한 주제를 다룹니다.</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">NetApp ONTAP 및 StorageGRID 개체 스토리지를 통해 NetApp 스토리지에서 제공하는 Milvus와 같은 벡터 데이터베이스에 대한 인프라 가이드라인입니다.</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">파일 및 객체 저장소를 통해 AWS FSx ONTAP 에서 Milvus 데이터베이스를 검증합니다.</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">NetApp의 파일-객체 이중성을 탐구하여 벡터 데이터베이스와 기타 애플리케이션의 데이터에 대한 유용성을 보여줍니다.</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">NetApp의 데이터 보호 관리 제품인 SnapCenter 는 벡터 데이터베이스 데이터에 대한 백업 및 복원 기능을 제공합니다.</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">NetApp의 하이브리드 클라우드가 온프레미스 및 클라우드 환경 전반에서 데이터 복제 및 보호를 제공하는 방식입니다.</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">NetApp ONTAP 에서 Milvus 및 pgvector와 같은 벡터 데이터베이스의 성능 검증에 대한 통찰력을 제공합니다.</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">두 가지 구체적인 사용 사례: 대규모 언어 모델(LLM)을 사용한 검색 증강 생성(RAG)과 NetApp IT 팀의 ChatAI를 통해 설명된 개념과 관행에 대한 실제적 예를 제공합니다.</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">벡터 데이터베이스 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">벡터 데이터베이스</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">이 섹션에서는 NetApp AI 솔루션에서 벡터 데이터베이스의 정의와 사용에 대해 다룹니다.</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">벡터 데이터베이스는 머신 러닝 모델의 임베딩을 사용하여 비정형 데이터를 처리, 인덱싱, 검색하도록 설계된 특수한 유형의 데이터베이스입니다.  데이터를 기존의 표 형식으로 구성하는 대신, 벡터 임베딩이라고도 하는 고차원 벡터로 데이터를 정리합니다.  이 독특한 구조 덕분에 데이터베이스는 복잡하고 다차원적인 데이터를 보다 효율적이고 정확하게 처리할 수 있습니다.</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">벡터 데이터베이스의 주요 기능 중 하나는 생성적 AI를 사용하여 분석을 수행하는 것입니다.  여기에는 데이터베이스가 주어진 입력과 유사한 데이터 포인트를 식별하는 유사성 검색과, 표준에서 크게 벗어나는 데이터 포인트를 발견할 수 있는 이상 감지가 포함됩니다.</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">더욱이 벡터 데이터베이스는 시간 데이터나 타임스탬프가 있는 데이터를 처리하는 데 적합합니다.  이러한 유형의 데이터는 IT 시스템 내에서 발생한 '무엇'이 언제 발생했는지에 대한 정보를 순서대로, 그리고 다른 모든 이벤트와 비교하여 제공합니다.  시간적 데이터를 처리하고 분석하는 이러한 기능 덕분에 벡터 데이터베이스는 시간 경과에 따른 이벤트를 이해해야 하는 애플리케이션에 특히 유용합니다.</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">ML 및 AI를 위한 벡터 데이터베이스의 장점:</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">고차원 검색: 벡터 데이터베이스는 AI 및 ML 애플리케이션에서 자주 생성되는 고차원 데이터를 관리하고 검색하는 데 탁월합니다.</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">확장성: 대량의 데이터를 처리하도록 효율적으로 확장할 수 있어 AI 및 ML 프로젝트의 성장과 확장을 지원합니다.</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">유연성: 벡터 데이터베이스는 높은 수준의 유연성을 제공하여 다양한 데이터 유형과 구조를 수용할 수 있습니다.</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">성능: AI와 ML 작업의 속도와 효율성에 중요한 고성능 데이터 관리 및 검색 기능을 제공합니다.</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">사용자 정의 가능한 인덱싱: 벡터 데이터베이스는 사용자 정의 가능한 인덱싱 옵션을 제공하여 특정 요구 사항에 따라 최적화된 데이터 구성 및 검색이 가능합니다.</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">벡터 데이터베이스와 사용 사례.</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">이 섹션에서는 다양한 벡터 데이터베이스와 해당 사용 사례에 대한 세부 정보를 제공합니다.</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">파이스와 스카NN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">이들은 벡터 검색 영역에서 중요한 도구 역할을 하는 라이브러리입니다.  이러한 라이브러리는 벡터 데이터를 관리하고 검색하는 데 도움이 되는 기능을 제공하므로 데이터 관리의 특수 분야에서 매우 귀중한 리소스입니다.</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">엘라스틱서치</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">널리 사용되는 검색 및 분석 엔진이며, 최근 벡터 검색 기능을 통합했습니다.  이 새로운 기능은 기능성을 향상시켜 벡터 데이터를 보다 효과적으로 처리하고 검색할 수 있게 해줍니다.</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">솔방울</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">이는 고유한 기능을 갖춘 강력한 벡터 데이터베이스입니다.  인덱싱 기능에서 밀집 벡터와 희소 벡터를 모두 지원하므로 유연성과 적응성이 향상됩니다.  이 솔루션의 주요 장점 중 하나는 기존 검색 방법과 AI 기반 고밀도 벡터 검색을 결합하여 두 가지의 장점을 모두 활용하는 하이브리드 검색 방식을 만드는 능력입니다.</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Pinecone은 주로 클라우드 기반으로, 머신 러닝 애플리케이션용으로 설계되었으며 GCP, AWS, Open AI, GPT-3, GPT-3.5, GPT-4, Catgut Plus, Elasticsearch, Haystack 등 다양한 플랫폼과 잘 통합됩니다.  Pinecone은 폐쇄형 소스 플랫폼이며 SaaS(Software as a Service) 형태로 제공된다는 점에 유의하는 것이 중요합니다.</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">고급 기능을 갖춘 Pinecone은 사이버 보안 산업에 특히 적합합니다. 고차원 검색 및 하이브리드 검색 기능을 효과적으로 활용하여 위협을 탐지하고 대응할 수 있습니다.</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">크로마</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">4가지 주요 기능을 갖춘 Core-API를 갖춘 벡터 데이터베이스로, 그 중 하나에는 메모리 내 문서 벡터 저장소가 포함됩니다.  또한, Face Transformers 라이브러리를 활용하여 문서를 벡터화하여 기능성과 다양성을 향상시켰습니다.  Chroma는 클라우드와 온프레미스 모두에서 작동하도록 설계되었으며, 사용자 요구 사항에 따라 유연성을 제공합니다.  특히 오디오 관련 애플리케이션에 탁월하여 오디오 기반 검색 엔진, 음악 추천 시스템 및 기타 오디오 관련 사용 사례에 매우 적합한 선택입니다.</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">위비에이트</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">사용자가 내장 모듈이나 사용자 정의 모듈을 사용하여 콘텐츠를 벡터화할 수 있는 다용도 벡터 데이터베이스로, 특정 요구 사항에 따라 유연성을 제공합니다.  다양한 배포 환경 설정에 맞춰 완전 관리형 솔루션과 자체 호스팅 솔루션을 모두 제공합니다.</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Weaviate의 주요 특징 중 하나는 벡터와 객체를 모두 저장할 수 있는 기능으로, 이를 통해 데이터 처리 기능이 향상됩니다.  이는 ERP 시스템의 의미 검색 및 데이터 분류를 포함한 다양한 응용 분야에 널리 사용됩니다.  전자상거래 부문에서는 검색 및 추천 엔진을 구동합니다.  Weaviate는 이미지 검색, 이상 감지, 자동 데이터 조화, 사이버 보안 위협 분석에도 사용되어 여러 도메인에 걸친 다재다능함을 보여줍니다.</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">레디스</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis는 빠른 인메모리 스토리지로 유명한 고성능 벡터 데이터베이스로, 읽기-쓰기 작업에 대한 낮은 지연 시간을 제공합니다.  따라서 빠른 데이터 액세스가 필요한 추천 시스템, 검색 엔진, 데이터 분석 애플리케이션에 매우 적합합니다.</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis는 목록, 집합, 정렬된 집합을 포함하여 벡터에 대한 다양한 데이터 구조를 지원합니다.  또한 벡터 간의 거리를 계산하거나 교집합과 합집합을 찾는 등의 벡터 연산도 제공합니다.  이러한 기능은 특히 유사성 검색, 클러스터링, 콘텐츠 기반 추천 시스템에 유용합니다.</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">확장성과 가용성 측면에서 Redis는 높은 처리량 작업 부하를 처리하는 데 탁월하며 데이터 복제 기능을 제공합니다.  또한 기존의 관계형 데이터베이스(RDBMS)를 포함한 다른 데이터 유형과도 잘 통합됩니다.  Redis에는 실시간 업데이트를 위한 게시/구독(Pub/Sub) 기능이 포함되어 있어 실시간 벡터를 관리하는 데 유용합니다.  게다가 Redis는 가볍고 사용하기 간편하여 벡터 데이터를 관리하는 데 사용하기 편리한 솔루션입니다.</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">밀버스</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">MongoDB와 매우 비슷하게 문서 저장소와 같은 API를 제공하는 다용도 벡터 데이터베이스입니다.  다양한 데이터 유형을 지원한다는 점에서 두드러지며, 이로 인해 데이터 과학 및 머신 러닝 분야에서 인기 있는 선택이 되었습니다.</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Milvus의 독특한 기능 중 하나는 다중 벡터화 기능으로, 사용자는 런타임에 검색에 사용할 벡터 유형을 지정할 수 있습니다.  더욱이 Faiss와 같은 다른 라이브러리 위에 있는 라이브러리인 Knowwhere를 활용하여 쿼리와 벡터 검색 알고리즘 간의 통신을 관리합니다.</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">Milvus는 PyTorch 및 TensorFlow와의 호환성 덕분에 머신 러닝 워크플로우와의 원활한 통합을 제공합니다.  이로 인해 이 도구는 전자상거래, 이미지 및 비디오 분석, 객체 인식, 이미지 유사성 검색, 콘텐츠 기반 이미지 검색을 포함한 다양한 응용 분야에 매우 적합합니다.  자연어 처리 분야에서 Milvus는 문서 클러스터링, 의미 검색, 질의응답 시스템에 사용됩니다.</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">이 솔루션의 경우, 솔루션 검증을 위해 milvus를 선택했습니다.  성능을 위해 milvus와 postgres(pgvecto.rs)를 모두 사용했습니다.</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">이 솔루션을 위해 왜 Milvus를 선택했을까요?</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">오픈 소스: Milvus는 커뮤니티 중심의 개발과 개선을 장려하는 오픈 소스 벡터 데이터베이스입니다.</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">AI 통합: 유사성 검색과 AI 애플리케이션을 내장하여 벡터 데이터베이스 기능을 강화합니다.</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">대용량 처리: Milvus는 딥 신경망(DNN) 및 머신 러닝(ML) 모델에서 생성된 10억 개 이상의 임베딩 벡터를 저장, 색인화하고 관리할 수 있는 역량을 갖추고 있습니다.</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">사용자 친화적: 사용하기 쉽고, 설정하는 데 1분도 걸리지 않습니다.  Milvus는 또한 다양한 프로그래밍 언어에 대한 SDK를 제공합니다.</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">속도: 일부 대안보다 최대 10배 빠른 매우 빠른 검색 속도를 제공합니다.</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">확장성 및 가용성: Milvus는 필요에 따라 확장 및 축소할 수 있는 옵션을 갖추고 있어 확장성이 매우 뛰어납니다.</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">풍부한 기능: 다양한 데이터 유형, 속성 필터링, 사용자 정의 함수(UDF) 지원, 구성 가능한 일관성 수준 및 이동 시간을 지원하므로 다양한 애플리케이션에 적합한 다재다능한 도구입니다.</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Milvus 아키텍처 개요</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">이 섹션에서는 Milvus 아키텍처에서 사용되는 상위 레벨 구성 요소와 서비스를 제공합니다.  * 액세스 계층 – 상태 비저장 프록시 그룹으로 구성되며 시스템의 프런트 계층이자 사용자의 엔드포인트 역할을 합니다.  * 코디네이터 서비스 – 작업자 노드에 작업을 할당하고 시스템의 두뇌 역할을 합니다.  세 가지 코디네이터 유형이 있습니다: 루트 좌표, 데이터 좌표, 쿼리 좌표.  * 워커 노드: 코디네이터 서비스의 지시를 따르고 사용자가 트리거한 DML/DDL 명령을 실행합니다. 쿼리 노드, 데이터 노드, 인덱스 노드와 같이 세 가지 유형의 워커 노드가 있습니다.  * 저장소: 데이터 지속성을 담당합니다.  여기에는 메타 스토리지, 로그 브로커, 객체 스토리지가 포함됩니다.  ONTAP 및 StorageGRID 와 같은 NetApp 스토리지는 Milvus에 고객 데이터와 벡터 데이터베이스 데이터 모두를 위한 객체 스토리지와 파일 기반 스토리지를 제공합니다.</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">Amazon FSx ONTAP for NetApp ONTAP 을 사용한 milvus - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">NetApp ONTAP 용 Amazon FSx ONTAP 탑재한 Milvus - 파일 및 객체 이중성</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">이 섹션에서는 NetApp 의 벡터 데이터베이스 솔루션을 위한 Amazon FSx ONTAP 사용한 milvus 클러스터 설정에 대해 설명합니다.</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">NetApp ONTAP 용 Amazon FSx ONTAP 탑재한 Milvus – 파일 및 객체 이중성</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">이 섹션에서는 왜 클라우드에 벡터 데이터베이스를 배포해야 하는지, 그리고 Docker 컨테이너 내 NetApp ONTAP 용 Amazon FSx ONTAP 에 벡터 데이터베이스(milvus standalone)를 배포하는 단계를 알아봅니다.</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">클라우드에 벡터 데이터베이스를 구축하면 여러 가지 중요한 이점이 있는데, 특히 고차원 데이터를 처리하고 유사성 검색을 실행해야 하는 애플리케이션의 경우 이점이 큽니다.  첫째, 클라우드 기반 배포는 확장성을 제공하므로 증가하는 데이터 볼륨과 쿼리 부하에 맞춰 리소스를 쉽게 조정할 수 있습니다.  이를 통해 데이터베이스는 높은 성능을 유지하는 동시에 증가된 수요를 효율적으로 처리할 수 있습니다.  두 번째로, 클라우드 구축은 여러 지리적 위치에 걸쳐 데이터를 복제할 수 있으므로 높은 가용성과 재해 복구를 제공하고, 데이터 손실 위험을 최소화하며, 예상치 못한 이벤트 발생 시에도 지속적인 서비스를 보장합니다.  셋째, 사용한 리소스에 대해서만 비용을 지불하고 수요에 따라 확장하거나 축소할 수 있으므로 하드웨어에 대한 상당한 사전 투자가 필요 없어 비용 효율성이 높습니다.  마지막으로, 클라우드에 벡터 데이터베이스를 구축하면 어디서나 데이터에 접근하고 공유할 수 있으므로 협업이 향상되고, 팀 기반 작업과 데이터 기반 의사 결정이 용이해집니다.  이 검증에 사용된 NetApp ONTAP 용 Amazon FSx ONTAP 과 함께 사용되는 milvus 독립형의 아키텍처를 확인하세요.</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">NetApp ONTAP 인스턴스를 위한 Amazon FSx ONTAP 생성하고 VPC, VPC 보안 그룹 및 서브넷의 세부 정보를 기록해 둡니다.  이 정보는 EC2 인스턴스를 생성할 때 필요합니다.  자세한 내용은 여기에서 확인할 수 있습니다.<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">VPC, 보안 그룹 및 서브넷이 NetApp ONTAP 인스턴스의 Amazon FSx ONTAP 과 일치하는지 확인하여 EC2 인스턴스를 생성합니다.</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">'apt-get install nfs-common' 명령어를 사용하여 nfs-common을 설치하고 'sudo apt-get update'를 사용하여 패키지 정보를 업데이트합니다.</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">마운트 폴더를 만들고 해당 폴더에 NetApp ONTAP 용 Amazon FSx ONTAP 마운트합니다.</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">'apt-get install'을 사용하여 Docker와 Docker Compose를 설치합니다.</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">Milvus 웹사이트에서 다운로드할 수 있는 docker-compose.yaml 파일을 기반으로 Milvus 클러스터를 설정합니다.</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">docker-compose.yml 파일의 'volumes' 섹션에서 NetApp NFS 마운트 지점을 해당 Milvus 컨테이너 경로(특히 etcd, minio 및 standalone)에 매핑합니다.<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block> yml 변경 사항에 대한 자세한 내용은</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">마운트된 폴더와 파일을 확인하세요.</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">docker-compose.yml 파일이 있는 디렉토리에서 'docker-compose up -d'를 실행합니다.</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">Milvus 컨테이너의 상태를 확인하세요.</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">NetApp ONTAP 용 Amazon FSx ONTAP 에서 벡터 데이터베이스와 데이터의 읽기 및 쓰기 기능을 검증하기 위해 Python Milvus SDK와 PyMilvus의 샘플 프로그램을 사용했습니다.  'apt-get install python3-numpy python3-pip'를 사용하여 필요한 패키지를 설치하고 'pip3 install pymilvus'를 사용하여 PyMilvus를 설치합니다.</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">벡터 데이터베이스에서 NetApp ONTAP 용 Amazon FSx ONTAP 의 데이터 쓰기 및 읽기 작업을 검증합니다.</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">verify_data_netapp.py 스크립트를 사용하여 읽기 작업을 확인합니다.</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">고객이 AI 워크로드를 위해 S3 프로토콜을 통해 벡터 데이터베이스에서 테스트된 NFS 데이터에 액세스(읽기)하려는 경우 간단한 Python 프로그램을 사용하여 이를 검증할 수 있습니다.  이에 대한 예로는 이 섹션의 시작 부분에 있는 그림에서 언급한 것처럼 다른 애플리케이션의 이미지에 대한 유사성 검색을 들 수 있습니다.</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">이 섹션에서는 고객이 Amazon의 NetApp FSx ONTAP NetApp ONTAP 데이터 스토리지에 활용하여 Docker 컨테이너 내에서 독립형 Milvus 설정을 배포하고 운영하는 방법을 효과적으로 보여줍니다.  이러한 설정을 통해 고객은 Docker 컨테이너의 확장 가능하고 효율적인 환경 내에서 벡터 데이터베이스의 힘을 활용하여 고차원 데이터를 처리하고 복잡한 쿼리를 실행할 수 있습니다.  NetApp ONTAP 인스턴스와 일치하는 EC2 인스턴스를 위한 Amazon FSx ONTAP 생성하면 고객은 최적의 리소스 활용과 데이터 관리를 보장할 수 있습니다.  FSx ONTAP 에서 벡터 데이터베이스의 데이터 쓰기 및 읽기 작업을 성공적으로 검증함으로써 고객은 안정적이고 일관된 데이터 작업을 보장받을 수 있습니다.  또한 S3 프로토콜을 통해 AI 워크로드의 데이터를 나열(읽기)하는 기능을 통해 데이터 접근성이 향상됩니다.  따라서 이 포괄적인 프로세스는 고객에게 Amazon FSx ONTAP for NetApp ONTAP 의 기능을 활용하여 대규모 데이터 작업을 관리할 수 있는 강력하고 효율적인 솔루션을 제공합니다.</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">milvus 클러스터 설정 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">온프레미스에서 Kubernetes를 사용한 Milvus 클러스터 설정</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">이 섹션에서는 NetApp 의 벡터 데이터베이스 솔루션을 위한 milvus 클러스터 설정에 대해 설명합니다.</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">온프레미스에서 Kubernetes를 사용한 Milvus 클러스터 설정</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">고객이 스토리지와 컴퓨팅을 독립적으로 확장하고, 효과적인 인프라 관리와 데이터 관리를 수행해야 하는 과제에 직면해 있습니다. Kubernetes와 벡터 데이터베이스는 함께 대규모 데이터 작업을 관리하기 위한 강력하고 확장 가능한 솔루션을 형성합니다.  쿠버네티스는 리소스를 최적화하고 컨테이너를 관리하는 반면, 벡터 데이터베이스는 고차원 데이터와 유사성 검색을 효율적으로 처리합니다.  이러한 조합을 통해 대규모 데이터 세트에 대한 복잡한 쿼리를 신속하게 처리할 수 있으며 증가하는 데이터 볼륨에 따라 원활하게 확장되므로 빅데이터 애플리케이션과 AI 워크로드에 이상적입니다.</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">이 섹션에서는 클러스터 데이터와 고객 데이터 모두에 NetApp 스토리지 컨트롤러를 활용하여 Kubernetes에 Milvus 클러스터를 설치하는 과정을 자세히 설명합니다.</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">Milvus 클러스터를 설치하려면 다양한 Milvus 클러스터 구성 요소의 데이터를 저장하기 위한 영구 볼륨(PV)이 필요합니다.  이러한 구성 요소에는 etcd(인스턴스 3개), pulsar-bookie-journal(인스턴스 3개), pulsar-bookie-ledgers(인스턴스 3개), pulsar-zookeeper-data(인스턴스 3개)가 포함됩니다.</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">이 링크</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">Milvus 클러스터에서는 Milvus 클러스터의 안정적인 저장과 메시지 스트림의 게시/구독을 지원하는 기본 엔진으로 Pulsar나 Kafka를 사용할 수 있습니다.  NFS를 사용하는 Kafka의 경우, NetApp ONTAP 9.12.1 이상에서 개선 사항을 적용했으며, 이러한 개선 사항과 RHEL 8.7 또는 9.1 이상에 포함된 NFSv4.1 및 Linux 변경 사항은 NFS에서 Kafka를 실행할 때 발생할 수 있는 "쓸데없는 이름 바꾸기" 문제를 해결합니다. NetApp NFS 솔루션에서 Kafka 실행에 대한 자세한 내용은 다음을 참조하세요.<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> .</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">NetApp ONTAP 에서 단일 NFS 볼륨을 생성하고 각각 250GB의 저장 용량을 갖춘 12개의 영구 볼륨을 설정했습니다.  저장 용량은 클러스터 크기에 따라 달라질 수 있습니다. 예를 들어, 각 PV가 50GB인 다른 클러스터가 있습니다.  자세한 내용은 아래 PV YAML 파일 중 하나를 참조하세요. 총 12개의 파일이 있습니다.  각 파일에서 storageClassName은 'default'로 설정되고, 저장소와 경로는 각 PV마다 고유합니다.</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">각 PV YAML 파일에 대해 'kubectl apply' 명령을 실행하여 영구 볼륨을 생성한 다음 'kubectl get pv'를 사용하여 생성을 확인합니다.</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">Milvus는 고객 데이터를 저장하기 위해 MinIO, Azure Blob, S3와 같은 개체 스토리지 솔루션을 지원합니다.  이 가이드에서는 S3를 활용합니다.  다음 단계는 ONTAP S3와 StorageGRID 개체 저장소 모두에 적용됩니다.  Milvus 클러스터를 배포하기 위해 Helm을 사용합니다.  Milvus 다운로드 위치에서 구성 파일 values.yaml을 다운로드합니다.  이 문서에서 사용한 values.yaml 파일은 부록을 참조하세요.</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">로그, etcd, zookeeper, bookkeeper를 포함하여 각 섹션에서 'storageClass'가 'default'로 설정되어 있는지 확인하세요.</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">MinIO 섹션에서 MinIO를 비활성화합니다.</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">ONTAP 또는 StorageGRID 개체 스토리지에서 NAS 버킷을 만들고 개체 스토리지 자격 증명을 사용하여 외부 S3에 포함합니다.</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">Milvus 클러스터를 생성하기 전에 PersistentVolumeClaim(PVC)에 기존 리소스가 없는지 확인하세요.</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">Helm과 values.yaml 구성 파일을 활용하여 Milvus 클러스터를 설치하고 시작합니다.</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">PersistentVolumeClaims(PVC)의 상태를 확인합니다.</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">포드의 상태를 확인하세요.</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">포드 상태가 '실행 중'이고 예상대로 작동하는지 확인하세요.</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">Milvus와 NetApp 개체 스토리지에서 데이터 쓰기와 읽기를 테스트합니다.</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">"prepare_data_netapp_new.py" Python 프로그램을 사용하여 데이터를 작성합니다.</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">"verify_data_netapp.py" Python 파일을 사용하여 데이터를 읽습니다.</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">위의 검증을 바탕으로 NetApp 스토리지 컨트롤러를 사용하여 Kubernetes에 Milvus 클러스터를 배포하는 방식으로 Kubernetes와 벡터 데이터베이스를 통합하면 고객에게 대규모 데이터 작업을 관리할 수 있는 견고하고 확장 가능하며 효율적인 솔루션을 제공합니다.  이러한 설정은 고객에게 고차원 데이터를 처리하고 복잡한 쿼리를 빠르고 효율적으로 실행할 수 있는 기능을 제공하므로 빅데이터 애플리케이션과 AI 워크로드에 이상적인 솔루션입니다.  다양한 클러스터 구성 요소에 대해 영구 볼륨(PV)을 사용하고 NetApp ONTAP 에서 단일 NFS 볼륨을 생성하면 최적의 리소스 활용과 데이터 관리가 보장됩니다.  PersistentVolumeClaims(PVC) 및 Pod 상태를 검증하고, 데이터 쓰기 및 읽기를 테스트하는 프로세스를 통해 고객은 안정적이고 일관된 데이터 작업을 보장받을 수 있습니다.  고객 데이터에 ONTAP 또는 StorageGRID 개체 스토리지를 사용하면 데이터 접근성과 보안이 더욱 향상됩니다.  전반적으로 이러한 설정은 고객에게 증가하는 데이터 요구에 맞춰 원활하게 확장할 수 있는 탄력적이고 고성능 데이터 관리 솔루션을 제공합니다.</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">NetApp용 벡터 데이터베이스 솔루션 개요</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">이 섹션에서는 NetApp 벡터 데이터베이스 솔루션에 대한 개요를 제공합니다.</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">이 솔루션은 NetApp 이 벡터 데이터베이스 고객이 겪는 과제를 해결하기 위해 제공하는 독특한 이점과 기능을 보여줍니다.  NetApp ONTAP, StorageGRID, NetApp의 클라우드 솔루션 및 SnapCenter 활용함으로써 고객은 비즈니스 운영에 상당한 가치를 더할 수 있습니다.  이러한 도구는 기존 문제를 해결할 뿐만 아니라 효율성과 생산성을 높여 전반적인 비즈니스 성장에 기여합니다.</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">왜 NetApp 인가?</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">ONTAP 및 StorageGRID 와 같은 NetApp의 제품을 사용하면 스토리지와 컴퓨팅을 분리하여 특정 요구 사항에 따라 최적의 리소스 활용이 가능합니다.  이러한 유연성 덕분에 고객은 NetApp 스토리지 솔루션을 사용하여 스토리지를 독립적으로 확장할 수 있습니다.</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP AWS, Azure, Google Cloud 등 주요 클라우드 서비스 공급업체에서 NAS 및 개체 스토리지에 대한 기본 지원을 제공합니다.  이러한 광범위한 호환성은 원활한 통합을 보장하여 고객 데이터 이동성, 글로벌 접근성, 재해 복구, 동적 확장성 및 고성능을 구현합니다.</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">NetApp의 강력한 데이터 관리 기능을 통해 고객은 자신의 데이터가 잠재적 위험과 위협으로부터 잘 보호된다는 확신을 가질 수 있습니다.  NetApp 데이터 보안을 우선시하여 고객에게 귀중한 정보의 안전성과 무결성에 대한 안심을 제공합니다.</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">벡터 데이터베이스 성능 검증 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">벡터 데이터베이스 성능 검증</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">이 섹션에서는 벡터 데이터베이스에서 수행된 성능 검증을 강조합니다.</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">성능 검증</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">성능 검증은 벡터 데이터베이스와 저장 시스템 모두에서 중요한 역할을 하며, 최적의 운영과 효율적인 리소스 활용을 보장하는 핵심 요소로 작용합니다.  고차원 데이터를 처리하고 유사성 검색을 실행하는 것으로 알려진 벡터 데이터베이스는 복잡한 쿼리를 빠르고 정확하게 처리하기 위해 높은 성능 수준을 유지해야 합니다.  성능 검증은 병목 현상을 파악하고, 구성을 미세하게 조정하고, 시스템이 서비스 저하 없이 예상되는 부하를 처리할 수 있는지 확인하는 데 도움이 됩니다.  마찬가지로 저장 시스템에서도 성능 검증은 데이터가 효율적으로 저장되고 검색되며, 전반적인 시스템 성능에 영향을 줄 수 있는 지연 문제나 병목 현상이 발생하지 않도록 하는 데 필수적입니다.  또한, 스토리지 인프라의 필요한 업그레이드나 변경에 대한 정보에 입각한 결정을 내리는 데 도움이 됩니다.  따라서 성능 검증은 시스템 관리의 중요한 측면이며, 높은 서비스 품질, 운영 효율성, 전반적인 시스템 안정성을 유지하는 데 크게 기여합니다.</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">이 섹션에서는 Milvus 및 pgvecto.rs와 같은 벡터 데이터베이스의 성능 검증을 자세히 살펴보고, LLM 수명 주기 내에서 RAG 및 추론 워크로드를 지원하는 I/O 프로필 및 netapp 스토리지 컨트롤러 동작과 같은 스토리지 성능 특성에 중점을 둡니다.  이러한 데이터베이스를 ONTAP 스토리지 솔루션과 결합하면 성능상의 차이점을 평가하고 파악할 것입니다.  당사의 분석은 초당 처리되는 쿼리 수(QPS)와 같은 핵심 성과 지표를 기반으로 진행됩니다.</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">아래에서 밀부스와 진행 상황에 사용된 방법론을 확인하세요.</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus(독립형 및 클러스터)</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres(pgvecto.rs) #</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">버전</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">파일 시스템</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">iSCSI LUN의 XFS</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">워크로드 생성기</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">VectorDB-벤치</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– v0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">데이터 세트</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">LAION 데이터 세트 * 1,000만 개의 임베딩 * 768개의 차원 * ~300GB 데이터 세트 크기</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * 버전 – 9.14.1 * 4 x 100GbE – milvus용 및 2 x 100GbE – postgres용 * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">Milvus 독립형 클러스터가 포함된 VectorDB-Bench</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">우리는 vectorDB-Bench를 사용하여 milvus 독립형 클러스터에서 다음과 같은 성능 검증을 수행했습니다.  milvus 독립형 클러스터의 네트워크 및 서버 연결성은 아래와 같습니다.</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">이 섹션에서는 Milvus 독립형 데이터베이스를 테스트하여 얻은 관찰 결과와 결과를 공유합니다. .  우리는 이러한 테스트의 인덱스 유형으로 DiskANN을 선택했습니다. .  약 100GB 규모의 데이터 세트를 수집, 최적화하고 인덱스를 생성하는 데 약 5시간이 걸렸습니다.  이 기간의 대부분 동안, 하이퍼스레딩이 활성화된 경우 40개의 vcpu에 해당하는 20개의 코어를 갖춘 Milvus 서버는 최대 CPU 용량인 100%로 작동했습니다. DiskANN은 시스템 메모리 크기를 초과하는 대규모 데이터 세트에 특히 중요하다는 것을 발견했습니다. .  쿼리 단계에서 우리는 0.9987의 회수율로 초당 쿼리 수(QPS) 10.93을 관찰했습니다.  쿼리에 대한 99번째 백분위수 지연 시간은 708.2밀리초로 측정되었습니다.</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">저장 관점에서 볼 때, 데이터베이스는 수집, 삽입 후 최적화, 인덱스 생성 단계에서 초당 약 1,000개의 작업을 실행했습니다.  쿼리 단계에서는 초당 32,000개의 작업이 요구되었습니다.</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">다음 섹션에서는 스토리지 성능 측정 항목을 소개합니다.</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">작업 부하 단계</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">미터법</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">데이터 수집 및 삽입 후 최적화</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">아이옵스</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">&lt; 1,000</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">숨어 있음</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">&lt; 400유초</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">작업량</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">읽기/쓰기 혼합, 주로 쓰기</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">IO 크기</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">질문</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">최고 32,000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">100% 캐시된 읽기</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">대부분 8KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">vectorDB-bench 결과는 아래와 같습니다.</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">독립형 Milvus 인스턴스의 성능 검증을 통해, 현재 설정은 1536차원의 500만 개 벡터 데이터 세트를 지원하기에 부족하다는 것이 분명해졌습니다. 저장소에 충분한 리소스가 있으며 시스템에 병목 현상을 일으키지 않는다는 것을 확인했습니다.</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">Milvus 클러스터가 포함된 VectorDB-Bench</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">이 섹션에서는 Kubernetes 환경 내에서 Milvus 클러스터를 배포하는 방법에 대해 설명합니다.  이 Kubernetes 설정은 Kubernetes 마스터 및 워커 노드를 호스팅하는 VMware vSphere 배포를 기반으로 구성되었습니다.</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">다음 섹션에서는 VMware vSphere 및 Kubernetes 배포에 대한 세부 정보를 제공합니다.</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">이 섹션에서는 Milvus 데이터베이스 테스트에서 얻은 관찰 결과와 결과를 제시합니다.  * 사용된 인덱스 유형은 DiskANN입니다.  * 아래 표는 1536차원에서 500만 개의 벡터로 작업할 때 독립 실행형 배포와 클러스터 배포를 비교한 것입니다.  클러스터 배포에서는 데이터 수집과 삽입 후 최적화에 걸리는 시간이 더 짧은 것을 확인했습니다.  클러스터 배포에서는 독립 실행형 설정에 비해 쿼리의 99번째 백분위수 지연 시간이 6배나 단축되었습니다.  * 클러스터 배포 시 초당 쿼리 수(QPS)는 더 높았지만 원하는 수준은 아니었습니다.</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">아래 이미지는 스토리지 클러스터 지연 시간과 총 IOPS(초당 입출력 작업)를 포함한 다양한 스토리지 측정 항목을 보여줍니다.</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">다음 섹션에서는 주요 스토리지 성능 지표를 소개합니다.</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">최고치 147,000</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">독립형 Milvus와 Milvus 클러스터의 성능 검증을 바탕으로 스토리지 I/O 프로필에 대한 세부 정보를 제시합니다.  * 독립 실행형과 클러스터 배포 모두에서 I/O 프로필이 일관되게 유지되는 것을 확인했습니다.  * 관찰된 최대 IOPS의 차이는 클러스터 배포에 포함된 클라이언트 수가 더 많은 데 기인할 수 있습니다.</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">Postgres를 사용한 vectorDB-Bench(pgvecto.rs)</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">VectorDB-Bench를 사용하여 PostgreSQL(pgvecto.rs)에서 다음 작업을 수행했습니다. PostgreSQL(특히 pgvecto.rs)의 네트워크 및 서버 연결에 대한 세부 정보는 다음과 같습니다.</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">이 섹션에서는 pgvecto.rs를 사용하여 PostgreSQL 데이터베이스를 테스트한 결과와 관찰 내용을 공유합니다.  * 테스트 당시 pgvecto.rs에서 DiskANN을 사용할 수 없었기 때문에 이러한 테스트의 인덱스 유형으로 HNSW를 선택했습니다.  * 데이터 수집 단계에서는 768차원의 1,000만 개의 벡터로 구성된 Cohere 데이터 세트를 로드했습니다.  이 과정은 약 4.5시간이 걸렸습니다.  * 쿼리 단계에서 우리는 0.6344의 회수율로 초당 쿼리 수(QPS) 1,068을 관찰했습니다.  쿼리에 대한 99번째 백분위수 지연 시간은 20밀리초로 측정되었습니다.  대부분의 런타임 동안 클라이언트 CPU는 100% 용량으로 작동했습니다.</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">아래 이미지는 스토리지 클러스터 지연 총 IOPS(초당 입출력 작업)를 포함한 다양한 스토리지 측정 항목을 보여줍니다.</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">벡터 DB 벤치에서 milvus와 postgres의 성능 비교</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">VectorDBBench를 사용하여 Milvus와 PostgreSQL의 성능을 검증한 결과, 다음과 같은 결과가 관찰되었습니다.</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">인덱스 유형: HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">데이터 세트: 768차원의 1,000만 개 벡터로 구성된 Cohere</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">pgvecto.rs는 0.6344의 재현율로 초당 쿼리 수(QPS) 1,068을 달성한 반면, Milvus는 0.9842의 재현율로 초당 쿼리 수 106을 달성한 것으로 나타났습니다.</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">질의의 정확도를 높이는 것이 우선순위라면 Milvus는 pgvecto.rs보다 우수한 성능을 보이는데, 이는 질의당 관련 항목의 비율이 더 높기 때문입니다.  하지만 초당 쿼리 수가 더 중요한 요소라면 pgvecto.rs가 Milvus를 능가합니다.  하지만 pgvecto.rs를 통해 검색된 데이터의 품질이 낮다는 점을 알아두는 것이 중요합니다. 검색 결과의 약 37%가 관련성이 없는 항목입니다.</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">성과 검증을 기반으로 한 관찰 결과:</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">성과 검증을 바탕으로 다음과 같은 관찰 결과를 얻었습니다.</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">Milvus에서 I/O 프로필은 Oracle SLOB에서 볼 수 있는 것과 같은 OLTP 작업 부하와 매우 유사합니다.  벤치마크는 데이터 수집, 사후 최적화, 쿼리의 세 단계로 구성됩니다.  초기 단계는 주로 64KB 쓰기 작업을 특징으로 하는 반면, 쿼리 단계는 주로 8KB 읽기 작업을 포함합니다.  ONTAP 이 Milvus I/O 부하를 효율적으로 처리할 것으로 기대합니다.</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">PostgreSQL I/O 프로필은 까다로운 스토리지 작업 부하를 나타내지 않습니다.  현재 진행 중인 메모리 내 구현을 고려하면 쿼리 단계에서 디스크 I/O가 관찰되지 않았습니다.</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN은 스토리지 차별화를 위한 핵심 기술로 부상하고 있습니다.  시스템 메모리 경계를 넘어 벡터 DB 검색을 효율적으로 확장할 수 있습니다.  그러나 HNSW와 같은 메모리 내 벡터 DB 인덱스를 사용하여 스토리지 성능 차별화를 확립하기는 어려울 것입니다.</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">또한 인덱스 유형이 HSNW인 경우 쿼리 단계에서 저장소가 중요한 역할을 하지 않는다는 점도 주목할 만합니다. HSNW는 RAG 애플리케이션을 지원하는 벡터 데이터베이스의 가장 중요한 운영 단계입니다.  여기서 의미하는 바는 저장 성능이 이러한 애플리케이션의 전반적인 성능에 큰 영향을 미치지 않는다는 것입니다.</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">이는 Netapp을 사용한 벡터 데이터베이스 솔루션에 대한 추상 페이지입니다.</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">NetApp 사용한 벡터 데이터베이스 솔루션</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">Karthikeyan Nagalingam 및 Rodrigo Nascimento, NetApp</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">이 문서에서는 NetApp의 스토리지 솔루션을 사용하여 Milvus와 오픈소스 PostgreSQL 확장 프로그램인 pgvecto와 같은 벡터 데이터베이스를 구축하고 관리하는 방법에 대해 자세히 살펴봅니다.  NetApp ONTAP 및 StorageGRID 객체 스토리지를 사용하기 위한 인프라 가이드라인을 자세히 설명하고 AWS FSx ONTAP 에서 Milvus 데이터베이스의 적용을 검증합니다.  이 문서에서는 NetApp의 파일-객체 이중성과 벡터 임베딩을 지원하는 벡터 데이터베이스 및 애플리케이션에 대한 유용성을 설명합니다.  이는 NetApp의 엔터프라이즈 관리 제품인 SnapCenter 의 역량을 강조하여 벡터 데이터베이스에 대한 백업 및 복원 기능을 제공하고 데이터 무결성과 가용성을 보장합니다.  이 문서에서는 NetApp의 하이브리드 클라우드 솔루션을 자세히 살펴보고, 온프레미스와 클라우드 환경에서의 데이터 복제 및 보호에 있어서 이 솔루션의 역할을 설명합니다.  여기에는 NetApp ONTAP 에서 벡터 데이터베이스의 성능 검증에 대한 통찰력이 포함되며, 생성 AI에 대한 두 가지 실제 사용 사례인 LLM을 갖춘 RAG와 NetApp의 내부 ChatAI에 대한 내용으로 마무리됩니다.  이 문서는 벡터 데이터베이스를 관리하기 위해 NetApp의 스토리지 솔루션을 활용하는 방법에 대한 포괄적인 가이드입니다.</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">참조 아키텍처는 다음 사항에 초점을 맞춥니다.</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">기술 요구 사항</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">솔루션 검증 개요</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">링크:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP .html[ NetApp ONTAP 용 Amazon FSx ONTAP 과 함께하는 Milvus - 파일 및 객체 이중성]</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">벡터 데이터베이스 사용 사례</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">부록 A: values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">부록 C: verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">기술 요구 사항 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">이 섹션에서는 NetApp 벡터 데이터베이스 솔루션에 대한 요구 사항에 대한 개요를 제공합니다.</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">아래에 설명된 하드웨어 및 소프트웨어 구성은 성능을 제외하고 이 문서에서 수행된 대부분의 검증에 활용되었습니다.  이러한 구성은 환경을 설정하는 데 도움이 되는 지침으로 사용됩니다.  그러나 구체적인 구성 요소는 개별 고객 요구 사항에 따라 달라질 수 있습니다.</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3.49TB SSD-NVM * 두 개의 유연한 그룹 볼륨: 메타데이터 및 데이터.  * 메타데이터 NFS 볼륨에는 250GB의 영구 볼륨이 12개 있습니다.  * 데이터는 ONTAP NAS S3 볼륨입니다.</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">후지쯔 프라이머지 RX2540 M4 6개</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64개 CPU * Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz * 256 GM 물리적 메모리 * 1 x 100GbE 네트워크 포트</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100, 3xSGF6024 * 3 x 24 x 7.68TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">밀부스 클러스터</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* 차트 - milvus-4.1.11.  * APP 버전 – 2.3.4 * Bookkeeper, Zookeeper, Pulsar, Etcd, Proxy, QueryNode, Worker와 같은 종속 번들</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* 5개 노드 K8s 클러스터 * 1개 마스터 노드 및 4개 워커 노드 * 버전 – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">사용 사례 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">이 섹션에서는 NetApp 벡터 데이터베이스 솔루션의 사용 사례에 대한 개요를 제공합니다.</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">이 섹션에서는 대규모 언어 모델을 사용한 검색 증강 생성 및 NetApp IT 챗봇과 같은 두 가지 사용 사례에 대해 설명합니다.</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">대규모 언어 모델(LLM)을 사용한 검색 증강 생성(RAG)</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">NVIDIA Enterprise RAG LLM Operator는 기업에서 RAG를 구현하는 데 유용한 도구입니다.  이 연산자는 전체 RAG 파이프라인을 배포하는 데 사용할 수 있습니다.  RAG 파이프라인은 지식 기반 임베딩을 저장하기 위한 벡터 데이터베이스로 Milvus나 pgvecto를 활용하도록 사용자 정의할 수 있습니다.  자세한 내용은 설명서를 참조하세요.</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">그림 1) NVIDIA NeMo 마이크로서비스와 NetApp 기반 엔터프라이즈 RAG</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">NetApp IT 챗봇 사용 사례</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">NetApp의 챗봇은 벡터 데이터베이스의 또 다른 실시간 사용 사례로 활용됩니다.  이 경우 NetApp Private OpenAI Sandbox는 NetApp 내부 사용자의 쿼리를 관리하기 위한 효과적이고 안전하며 효율적인 플랫폼을 제공합니다.  엄격한 보안 프로토콜, 효율적인 데이터 관리 시스템, 정교한 AI 처리 기능을 통합하여 SSO 인증을 통해 조직 내 사용자의 역할과 책임에 따라 고품질의 정확한 응답을 보장합니다.  이 아키텍처는 고급 기술을 통합하여 사용자 중심의 지능형 시스템을 만드는 잠재력을 강조합니다.</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">사용 사례는 네 가지 주요 섹션으로 나눌 수 있습니다.</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">사용자 인증 및 검증:</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">사용자 쿼리는 먼저 NetApp Single Sign-On(SSO) 프로세스를 거쳐 사용자의 신원을 확인합니다.</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">인증이 성공하면 시스템은 VPN 연결을 확인하여 안전한 데이터 전송이 이루어지는지 확인합니다.</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">데이터 전송 및 처리:</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">VPN이 검증되면 데이터는 NetAIChat 또는 NetAICreate 웹 애플리케이션을 통해 MariaDB로 전송됩니다.  MariaDB는 사용자 데이터를 관리하고 저장하는 데 사용되는 빠르고 효율적인 데이터베이스 시스템입니다.</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">그런 다음 MariaDB는 해당 정보를 NetApp Azure 인스턴스로 전송하고, 이를 통해 사용자 데이터가 AI 처리 장치에 연결됩니다.</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">OpenAI 및 콘텐츠 필터링과의 상호 작용:</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">Azure 인스턴스는 사용자의 질문을 콘텐츠 필터링 시스템으로 전송합니다.  이 시스템은 쿼리를 정리하고 처리를 위해 준비합니다.</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">정리된 입력은 Azure OpenAI 기본 모델로 전송되고, 이 모델에서는 입력을 기반으로 응답을 생성합니다.</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">응답 생성 및 조정:</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">기본 모델의 응답은 먼저 정확하고 콘텐츠 표준을 충족하는지 확인하기 위해 검사됩니다.</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">검사를 통과하면 응답이 사용자에게 다시 전송됩니다.  이 과정을 통해 사용자는 자신의 질문에 대해 명확하고 정확하며 적절한 답변을 받을 수 있습니다.</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - netapp용 벡터 데이터베이스 솔루션</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">부록 A: Values.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">이 섹션에서는 NetApp 벡터 데이터베이스 솔루션에서 사용되는 값에 대한 샘플 YAML 코드를 제공합니다.</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">솔루션 검증 개요 - NetApp용 벡터 데이터베이스 솔루션</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">우리는 5가지 핵심 영역에 초점을 맞춘 포괄적인 솔루션 검증을 수행했으며, 자세한 내용은 아래에 설명되어 있습니다.  각 섹션에서는 고객이 직면한 과제, NetApp 이 제공하는 솔루션, 그리고 이를 통해 고객에게 제공되는 이점을 자세히 살펴봅니다.</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>고객이 스토리지와 컴퓨팅을 독립적으로 확장하고, 인프라를 효과적으로 관리하고, 데이터를 관리해야 하는 과제가 있습니다.  이 섹션에서는 클러스터 데이터와 고객 데이터 모두에 NetApp 스토리지 컨트롤러를 활용하여 Kubernetes에 Milvus 클러스터를 설치하는 과정을 자세히 설명합니다.</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP .html[ NetApp ONTAP 용 Amazon FSx ONTAP 과 함께 사용하는 Milvus - 파일과 객체의 이중성] 이 섹션에서는 왜 클라우드에 벡터 데이터베이스를 배포해야 하는지, 그리고 Docker 컨테이너 내에서 NetApp ONTAP 용 Amazon FSx ONTAP 에 벡터 데이터베이스(milvus 독립형)를 배포하는 단계에 대해 설명합니다.</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>이 섹션에서는 SnapCenter ONTAP 에 있는 벡터 데이터베이스 데이터와 Milvus 데이터를 어떻게 보호하는지 자세히 살펴보겠습니다.  이 예에서는 고객 데이터에 대한 NFS ONTAP 볼륨(vol1)에서 파생된 NAS 버킷(milvusdbvol1)과 Milvus 클러스터 구성 데이터에 대한 별도의 NFS 볼륨(vectordbpv)을 활용했습니다.</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>이 섹션에서는 벡터 데이터베이스에 대한 재해 복구(DR)의 중요성과 NetApp 재해 복구 제품인 Snapmirror가 벡터 데이터베이스에 DR 솔루션을 제공하는 방식에 대해 설명합니다.</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>이 섹션에서는 Milvus 및 pgvecto.rs와 같은 벡터 데이터베이스의 성능 검증을 자세히 살펴보고, LLM 수명 주기 내에서 RAG 및 추론 워크로드를 지원하는 I/O 프로필 및 netapp 스토리지 컨트롤러 동작과 같은 스토리지 성능 특성에 중점을 둡니다.  이러한 데이터베이스를 ONTAP 스토리지 솔루션과 결합하면 성능상의 차이점을 평가하고 파악할 것입니다.  당사의 분석은 초당 처리되는 쿼리 수(QPS)와 같은 핵심 성과 지표를 기반으로 진행됩니다.</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py - netapp용 벡터 데이터베이스 솔루션</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">이 섹션에는 NetApp 벡터 데이터베이스 솔루션의 벡터 데이터베이스를 검증하는 데 사용할 수 있는 샘플 Python 스크립트가 포함되어 있습니다.</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">NetApp 의 AI 솔루션에 대한 비디오 시청</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">NetApp AI 및 머신 러닝 이니셔티브를 어떻게 강화하는지 알아보세요.  큐레이팅된 이 비디오 재생 목록은 NetApp AI 솔루션과 MLOps 워크플로를 소개하며, 고급 분석을 위한 배포 전략, 자동화 및 데이터 관리를 강조합니다.</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">NetApp AI 솔루션</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">NetApp AI 솔루션 플레이리스트를 시청하세요</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">AI 인프라, 컨버지드 시스템, 엔터프라이즈 AI 배포를 다루는 포괄적인 비디오 재생 목록입니다.<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">머신 러닝 운영(MLOps)</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">MLOps 플레이리스트를 시청하세요</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">MLOps 워크플로, 데이터 파이프라인 및 운영 모범 사례에 대한 비디오 시리즈입니다.<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">NetApp 솔루션의 다양한 기능을 논의하는 일련의 비디오 및 데모</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetApp 솔루션: 비디오 및 데모</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">NetApp 솔루션의 다양한 특정 기능을 강조하는 비디오와 데모에 대한 개요입니다.</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">NetApp 인공지능 솔루션 담보에 대한 최근 변경 사항 로그입니다.</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">NetApp 인공지능 솔루션의 새로운 기능</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">인공지능 솔루션의 새로운 소식을 알아보세요.</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">2025년 8월 18일</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">NetApp 솔루션 제품군</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">NetApp Solutions 사이트는 이제<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block> 다음 사이트를 포함합니다.</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">NetApp 인공지능 솔루션</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">NetApp 컨테이너 솔루션</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">NetApp 데이터 관리 솔루션</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">NetApp 데이터베이스 솔루션</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">NetApp 퍼블릭 및 하이브리드 클라우드 솔루션</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">SAP용 NetApp 솔루션</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">NetApp 가상화 솔루션</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp 엔터프라이즈급 데이터 관리, 검증된 참조 아키텍처, 전략적 파트너십을 결합한 포괄적인 AI 솔루션을 제공하여 AI 이니셔티브를 가속화하고 중요한 비즈니스 성과를 지원합니다.  인프라 구축부터 MLOps 자동화까지, 당사의 솔루션은 엣지, 데이터 센터, 하이브리드 클라우드 환경 전반에서 원활하게 확장됩니다.</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">시작하기</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">새로운 소식</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">블로그</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">비디오 및 데모</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">AI 인프라 및 융합 시스템</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">NVIDIA DGX 시스템을 탑재한 NetApp AIPod</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">EF 시리즈가 탑재된 NVIDIA DGX SuperPOD</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NVIDIA OVX를 위한 Lenovo와 NetApp AIPod</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">E-Series를 탑재한 BeeGFS 병렬 파일 시스템</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">AI 사용 사례 및 응용 프로그램</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">RAG 추론을 위한 AIPod Mini</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">엣지에서의 AI 추론</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">벡터 데이터베이스 솔루션</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">자율 주행 작업 부하</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">E-시리즈를 탑재한 Quantum StorNext</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOps 및 데이터 관리</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">NetApp 사용한 오픈 소스 MLOps</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">Domino Data Lab을 활용한 하이브리드 멀티클라우드 MLOps</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">MLOps를 위한 FSx ONTAP</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">빅데이터 및 하이브리드 클라우드 AI 솔루션</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">하이브리드 클라우드 데이터 솔루션</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Apache Spark 솔루션</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">NetApp ONTAP 스토리지를 갖춘 Confluent Kafka</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">Splunk SmartStore가 포함된 NetApp StorageGRID</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">NetApp 스토리지를 갖춘 Dremio 레이크하우스</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">솔루션 요청 및 피드백</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">요청 자동화</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">새로운 솔루션을 제안하다</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">솔루션 피드백 제공</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">NetApp의 포괄적인 MLOps 및 데이터 관리 솔루션으로 AI/ML 워크플로를 간소화하세요.  오픈소스 플랫폼부터 엔터프라이즈급 도구까지, 당사의 솔루션은 데이터 일관성과 성능을 보장하는 동시에 하이브리드 클라우드 환경에서 효율적인 모델 개발, 배포 및 확장을 가능하게 합니다.</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">NetApp MLOps 및 데이터 관리 솔루션</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">오픈소스 MLOps 플랫폼</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">AIPod 용 NetApp Trident 구성</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Apache Airflow 배포 및 통합</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">JupyterHub 배포 및 데이터 작업</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">MLflow 배포 및 추적성</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">고급 MLOps 워크플로</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Kubeflow 배포 및 노트북</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">Kubeflow를 사용하여 이미지 인식 모델 학습</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">단일 노드 AI 워크로드 실행</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">분산형 AI 워크로드 실행</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">SnapMirror 사용한 데이터 수집</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">엔터프라이즈 MLOps 솔루션</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">Domino Data Lab을 활용한 하이브리드 MLOps</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">Domino를 사용한 교차 환경 데이터 액세스</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">NVIDIA NGC 소프트웨어 통합</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">클라우드 MLOps와 AWS 통합</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">ONTAP MLOps용 Amazon FSx</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">SageMaker에서 FSx ONTAP 개인 S3로 통합</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">SageMaker 모델 학습을 위한 FSx ONTAP</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">FSx를 사용하여 간소화된 MLOps 파이프라인 구축</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">벡터 데이터베이스 및 AI 애플리케이션</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">NetApp 사용한 벡터 데이터베이스 솔루션</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">Kubernetes를 사용한 Milvus 클러스터 설정</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">SnapCenter 사용한 벡터 데이터베이스 보호</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">벡터 데이터베이스 성능 검증</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">벡터 데이터베이스 사용 사례</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">데이터 관리 도구 및 스토리지</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">자율 주행을 위한 StorageGRID 데이터 레이크</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">SnapMirror 사용한 재해 복구</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">NetApp의 검증된 참조 아키텍처와 컨버지드 시스템을 사용하여 기업에 적합한 AI 인프라를 구축하세요.  NetApp AIPod 솔루션부터 고성능 스토리지 플랫폼까지, 당사의 설계는 까다로운 AI/ML 워크로드에 필요한 성능, 확장성, 안정성을 제공합니다.</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">NetApp AI 인프라 및 컨버지드 시스템</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">NetApp AIPod 참조 아키텍처</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">AIPod 아키텍처</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">AIPod 배포 세부 정보</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">AIPod 검증 및 크기 조정 지침</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">AI 워크로드를 위한 고성능 스토리지</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">EF 시리즈 스토리지를 탑재한 NVIDIA DGX SuperPOD</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">E-Series 스토리지를 탑재한 IBM Spectrum Scale</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">Lenovo ThinkSystem을 탑재한 NetApp ONTAP</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">NetApp 솔루션을 통해 엔터프라이즈 RAG 시스템 및 엣지 추론부터 책임 있는 AI 관행 및 데이터 마이그레이션 전략까지 실제 AI 구현 사례를 살펴보세요.  이러한 사용 사례는 NetApp 이 조직이 보안, 성능 및 확장성을 유지하면서 다양한 환경에 AI 애플리케이션을 배포할 수 있도록 지원하는 방식을 보여줍니다.</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">NetApp AI 사용 사례 및 애플리케이션</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">NetApp 솔루션을 통해 엔터프라이즈 RAG 시스템 및 엣지 추론부터 책임 있는 AI 관행 및 데이터 마이그레이션 전략까지 실제 AI 구현 사례를 살펴보세요.  이러한 사용 사례는 NetApp 보안, 성능 및 확장성을 유지하면서 다양한 환경에서 AI 애플리케이션을 지원하는 방법을 보여줍니다.</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">엔터프라이즈 AI 애플리케이션 및 사용 사례</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">기업 RAG를 위한 NetApp AIPod Mini</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">생성적 AI와 NetApp 가치</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">NetApp 및 Lenovo를 통한 Edge AI 추론</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">빅데이터 분석에서 AI로의 마이그레이션</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">책임 있는 AI</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">Protopia 이미지 변환을 통한 책임 있는 AI</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">AI 스토리지 및 인프라 솔루션</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">E-Series 시스템을 사용한 Quantum StorNext 설계</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">E-Series 시스템에 Quantum StorNext 배포</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">Apache Spark, Hadoop, Kafka 및 엣지에서 클라우드까지 확장 가능한 최신 데이터 레이크 아키텍처를 포함하여 빅데이터 워크로드를 위한 NetApp의 검증된 솔루션으로 데이터 분석 인프라를 혁신하세요.</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">NetApp 최신 데이터 분석 솔루션</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">NetApp 최신 데이터 분석 솔루션은 AI 분야 전반에 걸쳐 NetApp 스토리지의 역량을 입증하는 전략적 및 기술적 역량의 집합입니다.</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Apache Kafka 솔루션</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">NetApp NFS 스토리지를 사용한 Apache Kafka 워크로드</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">NetApp ONTAP 스토리지 컨트롤러가 포함된 Confluent Kafka</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Confluent Kafka 모범 사례</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">AWS를 통한 Kafka 성능 검증</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Apache Spark 및 Hadoop 솔루션</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">Apache Spark를 위한 NetApp 스토리지 솔루션</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">NetApp 스토리지를 사용하여 Apache Spark 워크로드 배포</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">Spark 및 Hadoop을 위한 NetApp 하이브리드 클라우드 데이터 솔루션</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">사용 사례 및 아키텍처</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Apache Spark 테스트 결과</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">클라우드 데이터 관리 및 AI</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">NetApp 파일-객체 이중성과 AWS SageMaker를 활용한 클라우드 데이터 관리</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">빅데이터 분석 데이터를 인공지능으로</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">MLOps Amazon FSx for NetApp ONTAP</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Apache Spark 하이브리드 클라우드 솔루션</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">최신 데이터 레이크 및 분석 플랫폼</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">NetApp 과 Dremio의 차세대 하이브리드 아이스버그 레이크하우스 솔루션</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 및 Splunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">추가 자료</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">다양한 분석 전략에 따른 다양한 솔루션</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">블로그: NetApp 데이터 분석 분야에서 Apache Spark의 활약</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">블로그: XCP를 사용하여 데이터 레이크 및 HPC에서 ONTAP NFS로 데이터 마이그레이션</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: 빅데이터 분석 플레이리스트</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">인공지능 솔루션</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">비디오</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">NetApp Trident 구성</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">AIPod 배포를 위한 Trident 백엔드</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">AIPod 배포를 위한 Kubernetes StorageClass</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Apache Airflow 배포</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">JupyterHub 배포</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">NetApp SnapMirror 로 데이터 수집</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">MLflow 배포</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">NetApp 및 MLflow를 사용한 데이터 세트-모델 추적성</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Kubeflow 배포</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">Jupyter Notebook 작업 공간 제공</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">이미지 인식 모델 학습 - 예시 워크플로</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Trident 작업 예시</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">AIPod 배포를 위한 고성능 작업 예시</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">단일 노드 AI 워크로드 실행</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">동기식 분산 AI 워크로드 실행</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">Domino Data Lab 및 NetApp 사용한 하이브리드 MLOps</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">초기 설정</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">기존 NetApp 볼륨을 Domino에 노출</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">다양한 환경에서 동일한 데이터에 액세스</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">추가 정보</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">NVIDIA NGC 소프트웨어를 사용하세요</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">사용 사례 예시 - TensorFlow 학습 작업</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">1부 - Amazon FSx for NetApp ONTAP 프라이빗 S3 버킷으로 AWS SageMaker에 통합</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">2부 - SageMaker에서 모델 학습을 위한 데이터 소스로 Amazon FSx for NetApp ONTAP 활용</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">3부 - 단순화된 MLOps 파이프라인 구축</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">자율 주행 워크로드를 위한 NetApp StorageGRID 데이터 레이크</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">NetApp 사용한 벡터 데이터베이스 솔루션</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">벡터 데이터베이스</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">기술 요구 사항</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">SnapCenter 사용한 벡터 데이터베이스 보호</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">SnapMirror 사용한 재해 복구</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">PostGreSQL을 사용하는 Instaclustr의 벡터 데이터베이스: pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">부록 B: prepare_data_netapp_new_py</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">부록 D: docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">AI 융합 인프라</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">하드웨어 구성 요소</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">소프트웨어 구성 요소</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">배포 세부 정보 예시</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">검증 및 크기 조정 지침</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">결론 및 추가 정보</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">NetApp EF 시리즈를 탑재한 NVIDIA DGX SuperPOD</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">E-Series 스토리지를 갖춘 NetApp 의 BeeGFS</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">E-Series 스토리지를 사용하여 IBM Spectrum Scale 배포</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">AI를 위한 ONTAP 및 Lenovo ThinkSystem</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">AI를 위한 NetApp ONTAP 및 Lenovo ThinkSystem SR670</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">AI 사용 사례</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">RAG 추론을 위한 NetApp AIPod Mini</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">책임 있는 AI와 기밀 추론 - Protopia 이미지 변환을 갖춘 NetApp AI</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">빅데이터 환경에서 AI 환경으로 데이터 이동</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">엣지에서의 AI 추론 - NetApp 과 Lenovo ThinkSystem - 솔루션 설계</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">NetApp E-Series 시스템을 사용한 Quantum StorNext 설계 가이드</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">NetApp E-Series 시스템을 사용한 Quantum StorNext 배포 가이드</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">최신 데이터 분석</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">NFS에서 Kafka 워크로드로의 어리석은 이름 변경 문제에 대한 NetApp 솔루션</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">AWS에서의 성능 개요 및 검증 - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">AWS에서의 성능 개요 및 검증 - FSx for NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">AFF 온프레미스를 통한 성능 개요 및 검증</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">Confluent 성능 검증</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">사용 사례 요약</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS에서 NFS로 - 자세한 단계</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">합류형 자체 재조정 클러스터</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp 하이브리드 클라우드 데이터 솔루션 - 고객 사용 사례 기반 Spark 및 Hadoop</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">사례 1 - Hadoop 데이터 백업</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">사용 사례 2 - 클라우드에서 온프레미스로의 백업 및 재해 복구</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">사용 사례 3 - 기존 Hadoop 데이터에 DevTest 활성화</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">사용 사례 4 - 데이터 보호 및 멀티클라우드 연결</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">사용 사례 5 - 분석 워크로드 가속화</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">NetApp 과 Dremio의 차세대 하이브리드 Iceberg Lakehouse 솔루션</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">고객 사용 사례</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">다양한 분석 전략에 대한 다양한 솔루션 솔루션 개요</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Splunk SmartStore의 StorageGRID 기능</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">계층화 및 비용 절감</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">단일 사이트 SmartStore 성능</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">NetApp 스토리지 솔루션을 사용한 Apache Spark 워크로드(배포 가이드)</block>
  <block id="74916818f2584b32e727fdc509b2f992" category="cell">P4X-GNR6980P-SRPL2-UCC</block>
  <block id="abaa679b5e80256d8e1d4fd65296a270" category="cell">인텔 제온 6980P 2P 128C 2G 504M 500W SGX512</block>
  <block id="22f22b60e3e496fa07e67cfbf53cb70e" category="cell">RPL-E 6369P IP 8C/16T 3.3G 24MB 95W 1700 BO</block>
</blocks>