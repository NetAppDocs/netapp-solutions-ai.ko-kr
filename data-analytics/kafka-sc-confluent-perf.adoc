---
sidebar: sidebar 
permalink: data-analytics/kafka-sc-confluent-perf.html 
keywords: setup, verification results, Object store, correctness test, Tiering functionality, Tier fetch benchmark, Produce-consume, workload generator, Retention 
summary: 이 페이지에서는 이 솔루션의 매개변수 내에서 Confluent의 성능 검증을 설명합니다. 
---
= Confluent 성능 검증
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
NetApp ONTAP 의 계층형 스토리지에 대해 Confluent Platform을 사용하여 검증을 수행했습니다.  NetApp 과 Confluent 팀은 이 검증 작업을 함께 수행했으며 이에 필요한 테스트 사례를 실행했습니다.



== Confluent 설정

설정을 위해 256GB RAM과 16개 CPU를 갖춘 3개의 동물원 관리자, 5개의 브로커, 5개의 테스트 서버를 사용했습니다.  NetApp 스토리지의 경우 AFF A900 HA 쌍이 있는 ONTAP 사용했습니다.  저장소와 브로커는 100GbE 연결을 통해 연결되었습니다.

다음 그림은 계층형 스토리지 검증에 사용되는 구성의 네트워크 토폴로지를 보여줍니다.

image:kafka-sc-007.png["이 그래픽은 계층형 스토리지 검증에 사용되는 구성의 네트워크 토폴로지를 보여줍니다."]

도구 서버는 Confluent 노드와 이벤트를 주고받는 애플리케이션 클라이언트 역할을 합니다.



== Confluent 계층형 스토리지 구성

우리는 다음과 같은 테스트 매개변수를 사용했습니다.

....
confluent.tier.fetcher.num.threads=80
confluent.tier.archiver.num.threads=80
confluent.tier.enable=true
confluent.tier.feature=true
confluent.tier.backend=S3
confluent.tier.s3.bucket=kafkabucket1-1
confluent.tier.s3.region=us-east-1
confluent.tier.s3.cred.file.path=/data/kafka/.ssh/credentials
confluent.tier.s3.aws.endpoint.override=http://wle-mendocino-07-08/
confluent.tier.s3.force.path.style.access=true
bootstrap.server=192.168.150.172:9092,192.168.150.120:9092,192.168.150.164:9092,192.168.150.198:9092,192.168.150.109:9092,192.168.150.165:9092,192.168.150.119:9092,192.168.150.133:9092
debug=true
jmx.port=7203
num.partitions=80
num.records=200000000
#object PUT size - 512MB and fetch 100MB – netapp
segment.bytes=536870912
max.partition.fetch.bytes=1048576000
#GET size is max.partition.fetch.bytes/num.partitions
length.key.value=2048
trogdor.agent.nodes=node0,node1,node2,node3,node4
trogdor.coordinator.hostname.port=192.168.150.155:8889
num.producers=20
num.head.consumers=20
num.tail.consumers=1
test.binary.task.max.heap.size=32G
test.binary.task.timeout.sec=3600
producer.timeout.sec=3600
consumer.timeout.sec=3600
....
검증을 위해 HTTP 프로토콜을 사용하는 ONTAP 사용했지만 HTTPS도 작동했습니다.  액세스 키와 비밀 키는 제공된 파일 이름에 저장됩니다. `confluent.tier.s3.cred.file.path` 매개변수.



== NetApp 스토리지 컨트롤러 – ONTAP

검증을 위해 ONTAP 에서 단일 HA 쌍 구성을 구성했습니다.

image:kafka-sc-008.png["이 그래픽은 검증을 위해 환경이 단일 HA 쌍으로 구성된 방식을 보여줍니다."]



== 검증 결과

우리는 검증을 위해 다음의 5가지 테스트 사례를 완료했습니다.  처음 두 가지는 기능 테스트였고 나머지 세 가지는 성능 테스트였습니다.



=== 객체 저장소 정확성 테스트

이 테스트는 API 호출을 사용하여 계층형 스토리지에 사용되는 객체 저장소에서 get, put, delete와 같은 기본 작업을 수행합니다.



=== 계층화 기능 정확성 테스트

이 테스트는 개체 스토리지의 종단 간 기능을 확인합니다.  주제를 생성하고, 새로 생성된 주제에 대한 이벤트 스트림을 생성하고, 브로커가 세그먼트를 개체 스토리지에 보관할 때까지 기다리고, 이벤트 스트림을 사용하고, 사용된 스트림이 생성된 스트림과 일치하는지 검증합니다.  우리는 객체 저장소 오류 주입을 적용한 경우와 적용하지 않은 경우로 이 테스트를 수행했습니다.  ONTAP 의 노드 중 하나에서 서비스 관리자 서비스를 중지하고 엔드투엔드 기능이 개체 스토리지에서 작동하는지 검증하여 노드 장애를 시뮬레이션했습니다.



=== 티어 페치 벤치마크

이 테스트는 계층형 개체 스토리지의 읽기 성능을 검증하고 벤치마크에서 생성된 세그먼트에서 높은 부하가 걸리는 범위 페치 읽기 요청을 확인했습니다.  이 벤치마크에서 Confluent는 계층별 페치 요청을 처리하기 위해 사용자 정의 클라이언트를 개발했습니다.



=== 생산-소비 작업 생성기

이 테스트는 세그먼트 보관을 통해 개체 저장소에 대한 쓰기 작업 부하를 간접적으로 생성합니다.  소비자 그룹이 세그먼트를 가져올 때 개체 스토리지에서 읽기 작업 부하(세그먼트 읽기)가 생성되었습니다.  이 작업 부하는 TOCC 스크립트에 의해 생성되었습니다.  이 테스트는 병렬 스레드에서 개체 스토리지의 읽기 및 쓰기 성능을 확인했습니다.  우리는 계층화 기능 정확성 테스트에서 했던 것처럼 객체 저장소 오류 주입을 적용한 경우와 적용하지 않은 경우를 테스트했습니다.



=== 보존 작업량 생성기

이 테스트는 주제 보존 작업 부하가 큰 상황에서 개체 스토리지의 삭제 성능을 점검했습니다.  보존 작업 부하는 테스트 주제와 병렬로 많은 메시지를 생성하는 TOCC 스크립트를 사용하여 생성되었습니다.  테스트 주제는 이벤트 스트림이 개체 저장소에서 지속적으로 제거되도록 하는 공격적인 크기 기반 및 시간 기반 보존 설정으로 구성되었습니다.  그런 다음 세그먼트는 보관되었습니다.  이로 인해 브로커가 개체 저장소에서 많은 삭제를 수행하게 되었고 개체 저장소 삭제 작업의 성능이 저하되었습니다.

확인 세부 사항은 다음을 참조하세요. https://docs.confluent.io/platform/current/kafka/tiered-storage.html["지류"^] 웹사이트.
