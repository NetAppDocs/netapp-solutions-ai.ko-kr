---
sidebar: sidebar 
permalink: infra/ai-aipod-nv-validation.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 솔루션 검증 및 크기 조정 지침 
---
= NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 솔루션 검증 및 크기 조정 지침
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
이 섹션에서는 NVIDIA DGX 시스템을 사용하는 NetApp AIPod 에 대한 솔루션 검증 및 크기 조정 지침에 중점을 둡니다.



== 솔루션 검증

이 솔루션의 스토리지 구성은 오픈 소스 도구인 FIO를 사용하여 일련의 합성 워크로드를 통해 검증되었습니다.  이러한 테스트에는 DGX 시스템이 딥 러닝 학습 작업을 수행하면서 생성되는 스토리지 작업 부하를 시뮬레이션하기 위한 읽기 및 쓰기 I/O 패턴이 포함됩니다.  DGX 시스템 클러스터를 시뮬레이션하기 위해 FIO 워크로드를 동시에 실행하는 2소켓 CPU 서버 클러스터를 사용하여 스토리지 구성을 검증했습니다.  각 클라이언트는 이전에 설명한 것과 동일한 네트워크 구성으로 구성되었으며, 다음 세부 정보가 추가되었습니다.

이 검증에는 다음 마운트 옵션이 사용되었습니다.

[cols="30%, 70%"]
|===


| 버전=4.1 | 여러 스토리지 노드에 대한 병렬 액세스를 위해 pNFS를 활성화합니다. 


| 프로토=rdma | 기본 TCP 대신 RDMA로 전송 프로토콜을 설정합니다. 


| 포트=20049 | RDMA NFS 서비스에 대한 올바른 포트를 지정하세요 


| 최대 연결=16 | NFS 세션 트렁킹을 통해 스토리지 포트 대역폭을 집계할 수 있습니다. 


| 쓰기=열망 | 버퍼링된 쓰기의 쓰기 성능을 향상시킵니다. 


| rsize=262144, wsize=262144 | I/O 전송 크기를 256k로 설정합니다. 
|===
또한 클라이언트는 NFS max_session_slots 값이 1024로 구성되었습니다.  NFS over RDMA를 사용하여 솔루션을 테스트했으므로 스토리지 네트워크 포트는 액티브/패시브 본드로 구성되었습니다.  이 검증에는 다음과 같은 결합 매개변수가 사용되었습니다.

[cols="30%, 70%"]
|===


| 모드=활성 백업 | 결합을 활성/수동 모드로 설정합니다 


| primary=<인터페이스 이름> | 모든 클라이언트의 기본 인터페이스는 스위치에 분산되었습니다. 


| mii-모니터-간격=100 | 100ms의 모니터링 간격을 지정합니다. 


| fail-over-mac-policy=active | 활성 링크의 MAC 주소가 본드의 MAC임을 지정합니다.  이는 본딩된 인터페이스를 통한 RDMA의 적절한 작동에 필요합니다. 
|===
스토리지 시스템은 각 HA 쌍에 24개의 1.9TB NVMe 디스크 드라이브가 연결된 2개의 NS224 디스크 셸프와 함께 2개의 A900 HA 쌍(컨트롤러 4개)으로 구성된 것과 같이 구성되었습니다.  아키텍처 섹션에서 설명한 대로 모든 컨트롤러의 저장 용량은 FlexGroup 볼륨을 사용하여 결합되었으며 모든 클라이언트의 데이터는 클러스터의 모든 컨트롤러에 분산되었습니다.



== 스토리지 시스템 크기 지침

NetApp DGX BasePOD 인증을 성공적으로 완료했으며, 테스트된 두 개의 A90 HA 쌍은 16개의 DGX H100 시스템 클러스터를 쉽게 지원할 수 있습니다.  더 높은 스토리지 성능 요구 사항이 있는 대규모 배포의 경우 NetApp ONTAP 클러스터에 최대 12개의 HA 쌍(24개 노드)까지 추가 AFF 시스템을 추가할 수 있습니다.  이 솔루션에 설명된 FlexGroup 기술을 사용하면 24노드 클러스터가 단일 네임스페이스에서 79PB 이상과 최대 552GBps의 처리량을 제공할 수 있습니다.  AFF A400 , A250 및 C800과 같은 다른 NetApp 스토리지 시스템은 더 낮은 비용으로 더 작은 규모의 배포에 대해 더 낮은 성능 및/또는 더 큰 용량 옵션을 제공합니다.  ONTAP 9는 혼합 모델 클러스터를 지원하므로 고객은 처음에는 작은 공간으로 시작한 후 용량과 성능 요구 사항이 증가함에 따라 클러스터에 더 많거나 더 큰 스토리지 시스템을 추가할 수 있습니다.  아래 표는 각 AFF 모델에서 지원되는 A100 및 H100 GPU의 수를 대략적으로 추정한 것입니다.

_NetApp 스토리지 시스템 크기 조정 지침_

image:aipod-nv-a90-sizing.png["입력/출력 대화 상자 또는 서면 내용을 나타내는 그림"]
