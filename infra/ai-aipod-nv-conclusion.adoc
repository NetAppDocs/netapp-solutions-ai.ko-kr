---
sidebar: sidebar 
permalink: infra/ai-aipod-nv-conclusion.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NVIDIA DGX 시스템을 탑재한 NetApp AIPod - 추가 정보를 찾을 수 있는 곳 
---
= NVIDIA DGX 시스템을 탑재한 NVA-1173 NetApp AIPod - 결론 및 추가 정보
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
이 섹션에는 NVIDIA DGX 시스템을 탑재한 NetApp AIPod 에 대한 추가 정보에 대한 참조가 포함되어 있습니다.



== 결론

DGX BasePOD 아키텍처는 동등하게 고급 스토리지 및 데이터 관리 기능을 요구하는 차세대 딥 러닝 플랫폼입니다.  DGX BasePOD를 NetApp AFF 시스템과 결합하면 NetApp AIPod 와 DGX 시스템 아키텍처를 거의 모든 규모로 구현할 수 있습니다.  NetApp ONTAP 의 탁월한 클라우드 통합 및 소프트웨어 정의 기능과 결합된 AFF 성공적인 DL 프로젝트를 위해 에지, 코어 및 클라우드를 아우르는 광범위한 데이터 파이프라인을 지원합니다.



== 추가 정보

이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹사이트를 참조하세요.

* NetApp ONTAP 데이터 관리 소프트웨어 - ONTAP 정보 라이브러리
+
https://docs.netapp.com/us-en/ontap-family/["https://docs.netapp.com/us-en/ontap-family/"^]

* NetApp AFF A90 스토리지 시스템-
+
https://www.netapp.com/pdf.html?item=/media/7828-ds-3582-aff-a-series-ai-era.pdf["https://www.netapp.com/pdf.html?item=/media/7828-ds-3582-aff-a-series-ai-era.pdf"]

* NetApp ONTAP RDMA 정보-
+
link:https://docs.netapp.com/us-en/ontap/nfs-rdma/index.html["https://docs.netapp.com/us-en/ontap/nfs-rdma/index.html"]

* NetApp DataOps 툴킷
+
https://github.com/NetApp/netapp-dataops-toolkit["https://github.com/NetApp/netapp-dataops-toolkit"^]

* NetApp Trident
+
link:https://docs.netapp.com/us-en/netapp-solutions-containers/openshift/os-trident-overview.html["개요"^]

* NetApp GPUDirect 스토리지 블로그-
+
https://www.netapp.com/blog/ontap-reaches-171-gpudirect-storage/["https://www.netapp.com/blog/ontap-reaches-171-gpudirect-storage/"]

* NVIDIA DGX BasePOD
+
https://www.nvidia.com/en-us/data-center/dgx-basepod/["https://www.nvidia.com/en-us/data-center/dgx-basepod/"^]

* NVIDIA DGX H100 시스템
+
https://www.nvidia.com/en-us/data-center/dgx-h100/["https://www.nvidia.com/en-us/data-center/dgx-h100/"^]

* NVIDIA 네트워킹
+
https://www.nvidia.com/en-us/networking/["https://www.nvidia.com/en-us/networking/"^]

* NVIDIA Magnum IO&#8482; GPUDirect&#174; 스토리지
+
https://docs.nvidia.com/gpudirect-storage["https://docs.nvidia.com/gpudirect-storage"]

* NVIDIA 베이스 명령
+
https://www.nvidia.com/en-us/data-center/base-command/["https://www.nvidia.com/en-us/data-center/base-command/"]

* NVIDIA Base Command Manager
+
https://www.nvidia.com/en-us/data-center/base-command/manager["https://www.nvidia.com/en-us/data-center/base-command/manager"]

* NVIDIA AI 엔터프라이즈
+
https://www.nvidia.com/en-us/data-center/products/ai-enterprise/["https://www.nvidia.com/en-us/data-center/products/ai-enterprise/"^]





== 감사의 말

이 문서는 NetApp Solutions 및 ONTAP Engineering 팀(David Arnette, Olga Kornievskaia, Dustin Fischer, Srikanth Kaligotla, Mohit Kumar, Raghuram Sudhaakar)의 작품입니다.  저자는 또한 지속적인 지원을 해주신 NVIDIA 와 NVIDIA DGX BasePOD 엔지니어링 팀에 감사드리고 싶습니다.
